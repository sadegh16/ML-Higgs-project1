{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-epfl.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te5wEkHZP316"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "np.random.seed(0) \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGJ6HnyDANPk",
        "outputId": "cc18885a-aa59-4c61-bbc0-b8ca71506901"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXc4HUw05Ew1",
        "outputId": "48db4363-6ed8-41e6-a1c3-1d7b5cd45230"
      },
      "source": [
        "%cd /content/drive/MyDrive/ML-epfl/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML-epfl/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hg5eBKiYUMv"
      },
      "source": [
        "\"\"\"some helper functions for project 1.\"\"\"\n",
        "\n",
        "\n",
        "def load_csv_data(data_path, sub_sample=False):\n",
        "    \"\"\"Loads data and returns y (class labels), tX (features) and ids (event ids)\"\"\"\n",
        "    y = np.genfromtxt(data_path, delimiter=\",\", skip_header=1, dtype=str, usecols=1)\n",
        "    x = np.genfromtxt(data_path, delimiter=\",\", skip_header=1)\n",
        "    ids = x[:, 0].astype(np.int)\n",
        "    input_data = x[:, 2:]\n",
        "\n",
        "    # convert class labels from strings to binary (-1,1)\n",
        "    yb = np.ones(len(y))\n",
        "    yb[np.where(y=='b')] = -1\n",
        "    \n",
        "    # sub-sample\n",
        "    if sub_sample:\n",
        "        yb = yb[::50]\n",
        "        input_data = input_data[::50]\n",
        "        ids = ids[::50]\n",
        "\n",
        "    return yb, input_data, ids\n",
        "\n",
        "def predict_labels(weights, data):\n",
        "    \"\"\"Generates class predictions given weights, and a test data matrix\"\"\"\n",
        "    y_pred = np.dot(data, weights)\n",
        "    y_pred[np.where(y_pred <= 0.5)] = -1\n",
        "    y_pred[np.where(y_pred > 0.5)] = 1\n",
        "    \n",
        "    return y_pred\n",
        "\n",
        "def create_csv_submission(ids, y_pred, name):\n",
        "    \"\"\"\n",
        "    Creates an output file in .csv format for submission to Kaggle or AIcrowd\n",
        "    Arguments: ids (event ids associated with each prediction)\n",
        "               y_pred (predicted class labels)\n",
        "               name (string name of .csv output file to be created)\n",
        "    \"\"\"\n",
        "    with open(name, 'w') as csvfile:\n",
        "        fieldnames = ['Id', 'Prediction']\n",
        "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for r1, r2 in zip(ids, y_pred):\n",
        "            writer.writerow({'Id':int(r1),'Prediction':int(r2)})\n",
        "\n",
        "\n",
        "def find_acc(y,y_hat):\n",
        "  \"\"\"\n",
        "  give y and y_hat based on the threshold of 0.5, we compute\n",
        "  the accuracy\n",
        "\n",
        "  \"\"\"\n",
        "  y,y_hat=np.copy(y), np.copy(y_hat)\n",
        "  y[np.where(y <= 0.5)] = -1\n",
        "  y[np.where(y > 0.5)] = 1\n",
        "  y_hat[np.where(y_hat <= 0.5)] = -1\n",
        "  y_hat[np.where(y_hat > 0.5)] = 1\n",
        "  return np.sum(y==y_hat)/len(y)\n",
        "\n",
        "\n",
        "\n",
        "def poly_M(X,m):\n",
        "\n",
        "  \"\"\"\n",
        "  This function creates new X ( feature matrix ) by concatinating\n",
        "  X^i from the primitive X matrix for i from 2 to m \n",
        "\n",
        "  \"\"\"\n",
        "  nan_ids=X==-999\n",
        "  nan_ids_tmp=np.copy(nan_ids)\n",
        "  X_tmp=np.copy(X)\n",
        "  for i in range(2,m+1): \n",
        "    X = np.c_[X_tmp**i, X]\n",
        "    nan_ids= np.c_[nan_ids_tmp, nan_ids]\n",
        "  X[nan_ids]=-999\n",
        "  return X\n",
        "\n",
        "def featureNormalize(X):\n",
        "\n",
        "  \"\"\"\n",
        "  Normalize X by minimizing its mean and deviding by standard deviation\n",
        "  Note:  we replace -999 elements with 0 after normalaizing by other element of each column\n",
        "  \"\"\"\n",
        "  X_norm = np.copy(X)\n",
        "  mu = np.zeros(X.shape[1])\n",
        "  sigma = np.zeros(X.shape[1])\n",
        "\n",
        "  for j in range(X.shape[1]): \n",
        "    nonnan_ids = np.where(X[:,j]!=-999)[0]\n",
        "    mu[j]=X[nonnan_ids,j].mean()\n",
        "    sigma[j] = X[nonnan_ids,j].std()\n",
        "  \n",
        "  \n",
        "  for j in range(X.shape[1]): \n",
        "    nan_ids = np.where(X[:,j]==-999)[0]\n",
        "    X_norm[:,j] = (X[:,j]-mu[j])/sigma[j]\n",
        "    X_norm[nan_ids,j] = 0\n",
        "\n",
        "  return X_norm, mu, sigma\n",
        "\n",
        "\n",
        "def prepare_input_data(data,degree=1):\n",
        "  \"\"\"\n",
        "  prepareing the input data\n",
        "  \"\"\"\n",
        "  # valid_rows=np.any(input_data==-999,axis=1)\n",
        "  # yb, input_data, ids=yb[valid_rows], input_data[valid_rows], ids[valid_rows]\n",
        "\n",
        "  valid_columns=None\n",
        "  # valid_columns=np.sum(data==-999,axis=0)<0.3*len(data)\n",
        "  # data=data[:,valid_columns]\n",
        "  data= poly_M(data,degree)\n",
        "  data, mu, sigma = featureNormalize(data)\n",
        "  m,n= data.shape\n",
        "\n",
        "  # add a column with number 1 as the bias\n",
        "  data = np.c_[np.ones((m,1)), data]\n",
        "  return data, valid_columns,mu, sigma \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def prepare_test_data(data,mu, sigma,degree=1):\n",
        "\n",
        "  data= poly_M(data,degree)\n",
        "    \n",
        "  for j in range(data.shape[1]): \n",
        "    nan_ids = np.where(data[:,j]==-999)[0]\n",
        "    data[:,j] = (data[:,j]-mu[j])/sigma[j]\n",
        "    data[nan_ids,j] = 0\n",
        "\n",
        "  m,n= data.shape\n",
        "  data = np.c_[np.ones((m,1)), data]\n",
        "  return data\n",
        "\n",
        "# NOT USED\n",
        "def upsample_minority(y, X):\n",
        "\n",
        "  \"\"\"\n",
        "  this function is used to upsample minority class \n",
        "  \"\"\"\n",
        "\n",
        "  minority_class_ids = np.where(y==1)[0]\n",
        "  majority_class_ids = np.where(y==0)[0]\n",
        "  extra_minority_ids= np.random.choice(minority_class_ids,\n",
        "                                       len(majority_class_ids)-len(minority_class_ids),\n",
        "                                       replace=True)\n",
        "  new_minority_class_ids= np.concatenate([minority_class_ids , extra_minority_ids])\n",
        "\n",
        "\n",
        "  return  np.concatenate([y , y[extra_minority_ids]]), np.concatenate([X , X[extra_minority_ids]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flqgp09-m580",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1603e30a-932e-42e2-fcc9-dc018eec9f34"
      },
      "source": [
        "(yb, input_data, ids)=load_csv_data(\"train.csv\")\n",
        "# we change the lables from 1 and -1 to 1 and 0\n",
        "yb=(yb+1)/2\n",
        "input_data, valid_columns, mu, sigma = prepare_input_data(input_data,degree=9)\n",
        "\n",
        "input_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250000, 271)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqVjvrI_BtMX"
      },
      "source": [
        "def train_val_split(y, X):\n",
        "\n",
        "  \"\"\"\n",
        "  devide input data to train and validation (80% and 20%)\n",
        "\n",
        "  \"\"\"\n",
        "  train_size= int(X.shape[0]*0.8)\n",
        "  val_size= X.shape[0]- train_size\n",
        "  indices = np.random.RandomState(seed=42).permutation(X.shape[0])\n",
        "  training_idx, val_idx = indices[:train_size], indices[val_size:]\n",
        "  return X[training_idx,:], X[val_idx,:], y[training_idx], y[val_idx]\n",
        "\n",
        "train_X, val_X, train_y, val_y = train_val_split(yb, input_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adg6g7Ox8P48"
      },
      "source": [
        "def computeCost(X, y, theta):\n",
        "  m = len(y);\n",
        "  h = np.matmul(X,theta);\n",
        "  return 1/(2*m)*np.linalg.norm(h-y,ord=2)**2;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb9cigMdcW87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a75cb19-85af-478a-e4ec-3219186cbe4c"
      },
      "source": [
        "def least_squares(y, X):\n",
        "  X_T=np.transpose(X)\n",
        "  theta = np.matmul(np.matmul(np.linalg.inv(np.matmul(X_T,X)),X_T),y)\n",
        "  train_loss=computeCost(X, y, theta)\n",
        "  val_loss=computeCost(val_X, val_y, theta)\n",
        "  train_acc = find_acc(y, np.matmul(X,theta))\n",
        "  val_acc = find_acc(val_y, np.matmul(val_X,theta))\n",
        "  print('Training loss= {:.6f} Val loss= {:.6f} Training acc= {:.6f} Val acc= {:.6f}'.format(train_loss, \n",
        "                                                                                               val_loss,\n",
        "                                                                                               train_acc, val_acc))\n",
        "  return theta\n",
        "weight=least_squares(train_y, train_X);\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss= 0.069448 Val loss= 2.862265 Training acc= 0.818190 Val acc= 0.817195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MkCIZGNepzc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed9d6029-e2b3-40c6-80dc-9b76e166ef4e"
      },
      "source": [
        "\n",
        "def least_squares_GD(y, X, theta, num_iters, gamma, show=False):\n",
        "  m = len(y);\n",
        "  train_loss= np.zeros(num_iters);\n",
        "  val_loss = np.zeros(num_iters);\n",
        "  train_acc= np.zeros(num_iters);\n",
        "  val_acc = np.zeros(num_iters);\n",
        "  models=[]\n",
        "  for iter in range (num_iters):\n",
        "    \n",
        "    # update weights\n",
        "    theta = theta - gamma/m * np.matmul(np.transpose(X),(np.matmul(X,theta)-y))\n",
        "    # compute losses\n",
        "    train_loss[iter] = computeCost(X, y, theta)\n",
        "    val_loss[iter] = computeCost(val_X, val_y, theta)\n",
        "    train_acc[iter] = find_acc(y, np.matmul(X,theta))\n",
        "    val_acc[iter] = find_acc(val_y, np.matmul(val_X,theta))\n",
        "    models.append(np.copy(theta))\n",
        "    print('Epoch {:d}: Training loss= {:.6f} Val loss= {:.6f} Training acc= {:.6f} Val acc= {:.6f}'.format(iter, train_loss[iter], val_loss[iter], train_acc[iter], val_acc[iter]))\n",
        "  best_model_idx=np.argmin(val_loss)\n",
        "  print(\"Best model info *** :\")\n",
        "  print('Epoch {:d}: Training loss= {:.6f} Val loss= {:.6f} Training acc= {:.6f} Val acc= {:.6f}'.format(iter, train_loss[best_model_idx],val_loss[best_model_idx],\n",
        "                                                                                                         train_acc[best_model_idx],val_acc[best_model_idx],))\n",
        "  \n",
        "  if show:\n",
        "    plt.plot(range(1,num_iters+1), train_acc)\n",
        "    plt.plot(range(1,num_iters+1), train_acc)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.legend(['training', 'validation'], loc='upper right')\n",
        "    plt.show()\n",
        "  return models[best_model_idx], train_loss[best_model_idx]\n",
        "\n",
        "\n",
        "least_squares_GD(train_y,train_X,np.random.rand(train_X.shape[1]),5000,0.01,show=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 2: Training loss= 124.377213 Val loss= 151.678181 Training acc= 0.566560 Val acc= 0.565830\n",
            "Epoch 3: Training loss= 93.969200 Val loss= 120.875936 Training acc= 0.564705 Val acc= 0.564260\n",
            "Epoch 4: Training loss= 73.830217 Val loss= 98.773152 Training acc= 0.562685 Val acc= 0.562140\n",
            "Epoch 5: Training loss= 59.916455 Val loss= 82.500775 Training acc= 0.561180 Val acc= 0.560700\n",
            "Epoch 6: Training loss= 49.907490 Val loss= 70.216220 Training acc= 0.559750 Val acc= 0.559210\n",
            "Epoch 7: Training loss= 42.437688 Val loss= 60.718908 Training acc= 0.558790 Val acc= 0.558410\n",
            "Epoch 8: Training loss= 36.680553 Val loss= 53.213929 Training acc= 0.558235 Val acc= 0.558015\n",
            "Epoch 9: Training loss= 32.120576 Val loss= 47.165633 Training acc= 0.557485 Val acc= 0.557360\n",
            "Epoch 10: Training loss= 28.425910 Val loss= 42.206193 Training acc= 0.556815 Val acc= 0.556760\n",
            "Epoch 11: Training loss= 25.375959 Val loss= 38.077952 Training acc= 0.556190 Val acc= 0.556340\n",
            "Epoch 12: Training loss= 22.819373 Val loss= 34.596711 Training acc= 0.556020 Val acc= 0.556260\n",
            "Epoch 13: Training loss= 20.649127 Val loss= 31.628078 Training acc= 0.555970 Val acc= 0.556160\n",
            "Epoch 14: Training loss= 18.787390 Val loss= 29.072037 Training acc= 0.555780 Val acc= 0.556090\n",
            "Epoch 15: Training loss= 17.176108 Val loss= 26.852744 Training acc= 0.555730 Val acc= 0.556020\n",
            "Epoch 16: Training loss= 15.770999 Val loss= 24.911666 Training acc= 0.555905 Val acc= 0.556095\n",
            "Epoch 17: Training loss= 14.537619 Val loss= 23.202910 Training acc= 0.556110 Val acc= 0.556240\n",
            "Epoch 18: Training loss= 13.448718 Val loss= 21.689971 Training acc= 0.556230 Val acc= 0.556495\n",
            "Epoch 19: Training loss= 12.482422 Val loss= 20.343439 Training acc= 0.556255 Val acc= 0.556695\n",
            "Epoch 20: Training loss= 11.620954 Val loss= 19.139351 Training acc= 0.556215 Val acc= 0.556750\n",
            "Epoch 21: Training loss= 10.849709 Val loss= 18.057986 Training acc= 0.556280 Val acc= 0.556960\n",
            "Epoch 22: Training loss= 10.156574 Val loss= 17.082971 Training acc= 0.556390 Val acc= 0.556915\n",
            "Epoch 23: Training loss= 9.531422 Val loss= 16.200601 Training acc= 0.556280 Val acc= 0.556750\n",
            "Epoch 24: Training loss= 8.965723 Val loss= 15.399329 Training acc= 0.556240 Val acc= 0.556695\n",
            "Epoch 25: Training loss= 8.452244 Val loss= 14.669359 Training acc= 0.556120 Val acc= 0.556420\n",
            "Epoch 26: Training loss= 7.984819 Val loss= 14.002337 Training acc= 0.555850 Val acc= 0.555895\n",
            "Epoch 27: Training loss= 7.558160 Val loss= 13.391095 Training acc= 0.555090 Val acc= 0.555110\n",
            "Epoch 28: Training loss= 7.167712 Val loss= 12.829460 Training acc= 0.554505 Val acc= 0.554575\n",
            "Epoch 29: Training loss= 6.809532 Val loss= 12.312085 Training acc= 0.554000 Val acc= 0.553960\n",
            "Epoch 30: Training loss= 6.480192 Val loss= 11.834325 Training acc= 0.553280 Val acc= 0.553475\n",
            "Epoch 31: Training loss= 6.176703 Val loss= 11.392126 Training acc= 0.552570 Val acc= 0.552730\n",
            "Epoch 32: Training loss= 5.896445 Val loss= 10.981937 Training acc= 0.551830 Val acc= 0.552305\n",
            "Epoch 33: Training loss= 5.637118 Val loss= 10.600638 Training acc= 0.551385 Val acc= 0.551810\n",
            "Epoch 34: Training loss= 5.396692 Val loss= 10.245478 Training acc= 0.550670 Val acc= 0.551185\n",
            "Epoch 35: Training loss= 5.173374 Val loss= 9.914025 Training acc= 0.550085 Val acc= 0.550475\n",
            "Epoch 36: Training loss= 4.965574 Val loss= 9.604124 Training acc= 0.549320 Val acc= 0.549680\n",
            "Epoch 37: Training loss= 4.771877 Val loss= 9.313855 Training acc= 0.548770 Val acc= 0.549165\n",
            "Epoch 38: Training loss= 4.591024 Val loss= 9.041510 Training acc= 0.548370 Val acc= 0.548605\n",
            "Epoch 39: Training loss= 4.421889 Val loss= 8.785562 Training acc= 0.547885 Val acc= 0.548035\n",
            "Epoch 40: Training loss= 4.263465 Val loss= 8.544642 Training acc= 0.547055 Val acc= 0.547190\n",
            "Epoch 41: Training loss= 4.114847 Val loss= 8.317523 Training acc= 0.546045 Val acc= 0.546285\n",
            "Epoch 42: Training loss= 3.975223 Val loss= 8.103099 Training acc= 0.545410 Val acc= 0.545555\n",
            "Epoch 43: Training loss= 3.843862 Val loss= 7.900376 Training acc= 0.544780 Val acc= 0.545035\n",
            "Epoch 44: Training loss= 3.720103 Val loss= 7.708455 Training acc= 0.544050 Val acc= 0.544365\n",
            "Epoch 45: Training loss= 3.603349 Val loss= 7.526522 Training acc= 0.543525 Val acc= 0.543790\n",
            "Epoch 46: Training loss= 3.493060 Val loss= 7.353840 Training acc= 0.543015 Val acc= 0.543260\n",
            "Epoch 47: Training loss= 3.388747 Val loss= 7.189740 Training acc= 0.542275 Val acc= 0.542525\n",
            "Epoch 48: Training loss= 3.289966 Val loss= 7.033613 Training acc= 0.541620 Val acc= 0.542005\n",
            "Epoch 49: Training loss= 3.196310 Val loss= 6.884905 Training acc= 0.541330 Val acc= 0.541635\n",
            "Epoch 50: Training loss= 3.107414 Val loss= 6.743109 Training acc= 0.540900 Val acc= 0.541240\n",
            "Epoch 51: Training loss= 3.022939 Val loss= 6.607763 Training acc= 0.540395 Val acc= 0.540755\n",
            "Epoch 52: Training loss= 2.942581 Val loss= 6.478444 Training acc= 0.539875 Val acc= 0.540295\n",
            "Epoch 53: Training loss= 2.866058 Val loss= 6.354764 Training acc= 0.539425 Val acc= 0.539785\n",
            "Epoch 54: Training loss= 2.793114 Val loss= 6.236367 Training acc= 0.539070 Val acc= 0.539515\n",
            "Epoch 55: Training loss= 2.723512 Val loss= 6.122926 Training acc= 0.538475 Val acc= 0.538815\n",
            "Epoch 56: Training loss= 2.657038 Val loss= 6.014138 Training acc= 0.538445 Val acc= 0.538665\n",
            "Epoch 57: Training loss= 2.593492 Val loss= 5.909727 Training acc= 0.538060 Val acc= 0.538425\n",
            "Epoch 58: Training loss= 2.532692 Val loss= 5.809436 Training acc= 0.537965 Val acc= 0.538440\n",
            "Epoch 59: Training loss= 2.474469 Val loss= 5.713028 Training acc= 0.537635 Val acc= 0.538120\n",
            "Epoch 60: Training loss= 2.418667 Val loss= 5.620283 Training acc= 0.537420 Val acc= 0.537935\n",
            "Epoch 61: Training loss= 2.365144 Val loss= 5.530999 Training acc= 0.537150 Val acc= 0.537740\n",
            "Epoch 62: Training loss= 2.313767 Val loss= 5.444986 Training acc= 0.537110 Val acc= 0.537790\n",
            "Epoch 63: Training loss= 2.264412 Val loss= 5.362069 Training acc= 0.537260 Val acc= 0.537855\n",
            "Epoch 64: Training loss= 2.216966 Val loss= 5.282085 Training acc= 0.536935 Val acc= 0.537625\n",
            "Epoch 65: Training loss= 2.171324 Val loss= 5.204883 Training acc= 0.537085 Val acc= 0.537620\n",
            "Epoch 66: Training loss= 2.127387 Val loss= 5.130321 Training acc= 0.536860 Val acc= 0.537530\n",
            "Epoch 67: Training loss= 2.085065 Val loss= 5.058267 Training acc= 0.536930 Val acc= 0.537600\n",
            "Epoch 68: Training loss= 2.044271 Val loss= 4.988596 Training acc= 0.537110 Val acc= 0.537655\n",
            "Epoch 69: Training loss= 2.004928 Val loss= 4.921195 Training acc= 0.537045 Val acc= 0.537525\n",
            "Epoch 70: Training loss= 1.966961 Val loss= 4.855954 Training acc= 0.537075 Val acc= 0.537590\n",
            "Epoch 71: Training loss= 1.930302 Val loss= 4.792773 Training acc= 0.537130 Val acc= 0.537570\n",
            "Epoch 72: Training loss= 1.894886 Val loss= 4.731555 Training acc= 0.537235 Val acc= 0.537585\n",
            "Epoch 73: Training loss= 1.860652 Val loss= 4.672212 Training acc= 0.537395 Val acc= 0.537850\n",
            "Epoch 74: Training loss= 1.827546 Val loss= 4.614660 Training acc= 0.537495 Val acc= 0.537980\n",
            "Epoch 75: Training loss= 1.795512 Val loss= 4.558818 Training acc= 0.537450 Val acc= 0.538015\n",
            "Epoch 76: Training loss= 1.764503 Val loss= 4.504614 Training acc= 0.537570 Val acc= 0.538030\n",
            "Epoch 77: Training loss= 1.734471 Val loss= 4.451976 Training acc= 0.537755 Val acc= 0.538225\n",
            "Epoch 78: Training loss= 1.705372 Val loss= 4.400839 Training acc= 0.537965 Val acc= 0.538420\n",
            "Epoch 79: Training loss= 1.677166 Val loss= 4.351138 Training acc= 0.538260 Val acc= 0.538700\n",
            "Epoch 80: Training loss= 1.649813 Val loss= 4.302816 Training acc= 0.538465 Val acc= 0.538960\n",
            "Epoch 81: Training loss= 1.623276 Val loss= 4.255816 Training acc= 0.538725 Val acc= 0.539195\n",
            "Epoch 82: Training loss= 1.597522 Val loss= 4.210085 Training acc= 0.538985 Val acc= 0.539580\n",
            "Epoch 83: Training loss= 1.572517 Val loss= 4.165573 Training acc= 0.539475 Val acc= 0.540120\n",
            "Epoch 84: Training loss= 1.548231 Val loss= 4.122232 Training acc= 0.539680 Val acc= 0.540440\n",
            "Epoch 85: Training loss= 1.524635 Val loss= 4.080016 Training acc= 0.539805 Val acc= 0.540615\n",
            "Epoch 86: Training loss= 1.501700 Val loss= 4.038883 Training acc= 0.539915 Val acc= 0.540730\n",
            "Epoch 87: Training loss= 1.479400 Val loss= 3.998792 Training acc= 0.540330 Val acc= 0.541070\n",
            "Epoch 88: Training loss= 1.457712 Val loss= 3.959703 Training acc= 0.540750 Val acc= 0.541345\n",
            "Epoch 89: Training loss= 1.436611 Val loss= 3.921581 Training acc= 0.541150 Val acc= 0.541775\n",
            "Epoch 90: Training loss= 1.416075 Val loss= 3.884389 Training acc= 0.541440 Val acc= 0.542035\n",
            "Epoch 91: Training loss= 1.396083 Val loss= 3.848093 Training acc= 0.541940 Val acc= 0.542480\n",
            "Epoch 92: Training loss= 1.376614 Val loss= 3.812663 Training acc= 0.542315 Val acc= 0.542935\n",
            "Epoch 93: Training loss= 1.357650 Val loss= 3.778068 Training acc= 0.542780 Val acc= 0.543370\n",
            "Epoch 94: Training loss= 1.339172 Val loss= 3.744277 Training acc= 0.543285 Val acc= 0.543880\n",
            "Epoch 95: Training loss= 1.321162 Val loss= 3.711264 Training acc= 0.543525 Val acc= 0.544250\n",
            "Epoch 96: Training loss= 1.303605 Val loss= 3.679002 Training acc= 0.543945 Val acc= 0.544765\n",
            "Epoch 97: Training loss= 1.286484 Val loss= 3.647465 Training acc= 0.544255 Val acc= 0.544865\n",
            "Epoch 98: Training loss= 1.269783 Val loss= 3.616629 Training acc= 0.544550 Val acc= 0.545190\n",
            "Epoch 99: Training loss= 1.253490 Val loss= 3.586471 Training acc= 0.544890 Val acc= 0.545545\n",
            "Epoch 100: Training loss= 1.237590 Val loss= 3.556968 Training acc= 0.545245 Val acc= 0.545845\n",
            "Epoch 101: Training loss= 1.222069 Val loss= 3.528099 Training acc= 0.545885 Val acc= 0.546420\n",
            "Epoch 102: Training loss= 1.206915 Val loss= 3.499844 Training acc= 0.546260 Val acc= 0.546905\n",
            "Epoch 103: Training loss= 1.192117 Val loss= 3.472183 Training acc= 0.546615 Val acc= 0.547250\n",
            "Epoch 104: Training loss= 1.177661 Val loss= 3.445096 Training acc= 0.547045 Val acc= 0.547695\n",
            "Epoch 105: Training loss= 1.163539 Val loss= 3.418567 Training acc= 0.547445 Val acc= 0.548175\n",
            "Epoch 106: Training loss= 1.149738 Val loss= 3.392578 Training acc= 0.547830 Val acc= 0.548685\n",
            "Epoch 107: Training loss= 1.136249 Val loss= 3.367112 Training acc= 0.548310 Val acc= 0.549045\n",
            "Epoch 108: Training loss= 1.123061 Val loss= 3.342152 Training acc= 0.548660 Val acc= 0.549395\n",
            "Epoch 109: Training loss= 1.110166 Val loss= 3.317685 Training acc= 0.549180 Val acc= 0.549810\n",
            "Epoch 110: Training loss= 1.097555 Val loss= 3.293694 Training acc= 0.549625 Val acc= 0.550275\n",
            "Epoch 111: Training loss= 1.085219 Val loss= 3.270166 Training acc= 0.550105 Val acc= 0.550630\n",
            "Epoch 112: Training loss= 1.073149 Val loss= 3.247087 Training acc= 0.550480 Val acc= 0.551075\n",
            "Epoch 113: Training loss= 1.061337 Val loss= 3.224444 Training acc= 0.551045 Val acc= 0.551665\n",
            "Epoch 114: Training loss= 1.049777 Val loss= 3.202224 Training acc= 0.551545 Val acc= 0.552015\n",
            "Epoch 115: Training loss= 1.038460 Val loss= 3.180416 Training acc= 0.551960 Val acc= 0.552430\n",
            "Epoch 116: Training loss= 1.027380 Val loss= 3.159006 Training acc= 0.552350 Val acc= 0.552790\n",
            "Epoch 117: Training loss= 1.016529 Val loss= 3.137984 Training acc= 0.552860 Val acc= 0.553165\n",
            "Epoch 118: Training loss= 1.005901 Val loss= 3.117340 Training acc= 0.553250 Val acc= 0.553670\n",
            "Epoch 119: Training loss= 0.995490 Val loss= 3.097062 Training acc= 0.553680 Val acc= 0.554185\n",
            "Epoch 120: Training loss= 0.985289 Val loss= 3.077140 Training acc= 0.554105 Val acc= 0.554570\n",
            "Epoch 121: Training loss= 0.975293 Val loss= 3.057565 Training acc= 0.554405 Val acc= 0.554705\n",
            "Epoch 122: Training loss= 0.965496 Val loss= 3.038326 Training acc= 0.554730 Val acc= 0.554990\n",
            "Epoch 123: Training loss= 0.955892 Val loss= 3.019416 Training acc= 0.555410 Val acc= 0.555535\n",
            "Epoch 124: Training loss= 0.946477 Val loss= 3.000826 Training acc= 0.555910 Val acc= 0.556055\n",
            "Epoch 125: Training loss= 0.937244 Val loss= 2.982545 Training acc= 0.556160 Val acc= 0.556305\n",
            "Epoch 126: Training loss= 0.928189 Val loss= 2.964568 Training acc= 0.556515 Val acc= 0.556665\n",
            "Epoch 127: Training loss= 0.919308 Val loss= 2.946885 Training acc= 0.556910 Val acc= 0.557150\n",
            "Epoch 128: Training loss= 0.910595 Val loss= 2.929488 Training acc= 0.557300 Val acc= 0.557580\n",
            "Epoch 129: Training loss= 0.902047 Val loss= 2.912372 Training acc= 0.557845 Val acc= 0.558150\n",
            "Epoch 130: Training loss= 0.893658 Val loss= 2.895527 Training acc= 0.558305 Val acc= 0.558580\n",
            "Epoch 131: Training loss= 0.885425 Val loss= 2.878948 Training acc= 0.558670 Val acc= 0.559080\n",
            "Epoch 132: Training loss= 0.877344 Val loss= 2.862628 Training acc= 0.559110 Val acc= 0.559500\n",
            "Epoch 133: Training loss= 0.869410 Val loss= 2.846560 Training acc= 0.559465 Val acc= 0.559915\n",
            "Epoch 134: Training loss= 0.861621 Val loss= 2.830738 Training acc= 0.559900 Val acc= 0.560430\n",
            "Epoch 135: Training loss= 0.853971 Val loss= 2.815155 Training acc= 0.560395 Val acc= 0.560950\n",
            "Epoch 136: Training loss= 0.846459 Val loss= 2.799807 Training acc= 0.560710 Val acc= 0.561205\n",
            "Epoch 137: Training loss= 0.839080 Val loss= 2.784687 Training acc= 0.561125 Val acc= 0.561590\n",
            "Epoch 138: Training loss= 0.831831 Val loss= 2.769790 Training acc= 0.561680 Val acc= 0.562170\n",
            "Epoch 139: Training loss= 0.824709 Val loss= 2.755110 Training acc= 0.562075 Val acc= 0.562515\n",
            "Epoch 140: Training loss= 0.817710 Val loss= 2.740642 Training acc= 0.562620 Val acc= 0.562920\n",
            "Epoch 141: Training loss= 0.810833 Val loss= 2.726382 Training acc= 0.563010 Val acc= 0.563200\n",
            "Epoch 142: Training loss= 0.804073 Val loss= 2.712324 Training acc= 0.563510 Val acc= 0.563795\n",
            "Epoch 143: Training loss= 0.797428 Val loss= 2.698463 Training acc= 0.564020 Val acc= 0.564230\n",
            "Epoch 144: Training loss= 0.790895 Val loss= 2.684796 Training acc= 0.564535 Val acc= 0.564765\n",
            "Epoch 145: Training loss= 0.784471 Val loss= 2.671317 Training acc= 0.565040 Val acc= 0.565150\n",
            "Epoch 146: Training loss= 0.778155 Val loss= 2.658023 Training acc= 0.565430 Val acc= 0.565600\n",
            "Epoch 147: Training loss= 0.771942 Val loss= 2.644909 Training acc= 0.566065 Val acc= 0.566125\n",
            "Epoch 148: Training loss= 0.765832 Val loss= 2.631971 Training acc= 0.566365 Val acc= 0.566455\n",
            "Epoch 149: Training loss= 0.759821 Val loss= 2.619205 Training acc= 0.566795 Val acc= 0.566900\n",
            "Epoch 150: Training loss= 0.753908 Val loss= 2.606608 Training acc= 0.567365 Val acc= 0.567430\n",
            "Epoch 151: Training loss= 0.748089 Val loss= 2.594175 Training acc= 0.567780 Val acc= 0.567935\n",
            "Epoch 152: Training loss= 0.742364 Val loss= 2.581903 Training acc= 0.568205 Val acc= 0.568435\n",
            "Epoch 153: Training loss= 0.736729 Val loss= 2.569789 Training acc= 0.568705 Val acc= 0.568970\n",
            "Epoch 154: Training loss= 0.731182 Val loss= 2.557829 Training acc= 0.569100 Val acc= 0.569265\n",
            "Epoch 155: Training loss= 0.725723 Val loss= 2.546020 Training acc= 0.569635 Val acc= 0.569790\n",
            "Epoch 156: Training loss= 0.720348 Val loss= 2.534358 Training acc= 0.570015 Val acc= 0.570225\n",
            "Epoch 157: Training loss= 0.715056 Val loss= 2.522842 Training acc= 0.570465 Val acc= 0.570725\n",
            "Epoch 158: Training loss= 0.709845 Val loss= 2.511466 Training acc= 0.570880 Val acc= 0.571055\n",
            "Epoch 159: Training loss= 0.704713 Val loss= 2.500230 Training acc= 0.571375 Val acc= 0.571505\n",
            "Epoch 160: Training loss= 0.699659 Val loss= 2.489129 Training acc= 0.571820 Val acc= 0.571910\n",
            "Epoch 161: Training loss= 0.694680 Val loss= 2.478161 Training acc= 0.572265 Val acc= 0.572310\n",
            "Epoch 162: Training loss= 0.689776 Val loss= 2.467323 Training acc= 0.572615 Val acc= 0.572705\n",
            "Epoch 163: Training loss= 0.684944 Val loss= 2.456613 Training acc= 0.573170 Val acc= 0.573200\n",
            "Epoch 164: Training loss= 0.680184 Val loss= 2.446027 Training acc= 0.573585 Val acc= 0.573645\n",
            "Epoch 165: Training loss= 0.675493 Val loss= 2.435565 Training acc= 0.574015 Val acc= 0.574090\n",
            "Epoch 166: Training loss= 0.670870 Val loss= 2.425222 Training acc= 0.574355 Val acc= 0.574450\n",
            "Epoch 167: Training loss= 0.666313 Val loss= 2.414998 Training acc= 0.574775 Val acc= 0.574795\n",
            "Epoch 168: Training loss= 0.661822 Val loss= 2.404888 Training acc= 0.575100 Val acc= 0.575150\n",
            "Epoch 169: Training loss= 0.657394 Val loss= 2.394892 Training acc= 0.575470 Val acc= 0.575595\n",
            "Epoch 170: Training loss= 0.653029 Val loss= 2.385007 Training acc= 0.576055 Val acc= 0.576045\n",
            "Epoch 171: Training loss= 0.648726 Val loss= 2.375231 Training acc= 0.576440 Val acc= 0.576455\n",
            "Epoch 172: Training loss= 0.644482 Val loss= 2.365562 Training acc= 0.576750 Val acc= 0.576755\n",
            "Epoch 173: Training loss= 0.640297 Val loss= 2.355998 Training acc= 0.577250 Val acc= 0.577110\n",
            "Epoch 174: Training loss= 0.636170 Val loss= 2.346536 Training acc= 0.577605 Val acc= 0.577430\n",
            "Epoch 175: Training loss= 0.632099 Val loss= 2.337176 Training acc= 0.577930 Val acc= 0.577770\n",
            "Epoch 176: Training loss= 0.628083 Val loss= 2.327915 Training acc= 0.578260 Val acc= 0.578235\n",
            "Epoch 177: Training loss= 0.624122 Val loss= 2.318750 Training acc= 0.578445 Val acc= 0.578440\n",
            "Epoch 178: Training loss= 0.620213 Val loss= 2.309682 Training acc= 0.578875 Val acc= 0.578825\n",
            "Epoch 179: Training loss= 0.616357 Val loss= 2.300707 Training acc= 0.579295 Val acc= 0.579210\n",
            "Epoch 180: Training loss= 0.612552 Val loss= 2.291824 Training acc= 0.579565 Val acc= 0.579545\n",
            "Epoch 181: Training loss= 0.608797 Val loss= 2.283032 Training acc= 0.579890 Val acc= 0.579930\n",
            "Epoch 182: Training loss= 0.605090 Val loss= 2.274329 Training acc= 0.580365 Val acc= 0.580435\n",
            "Epoch 183: Training loss= 0.601432 Val loss= 2.265712 Training acc= 0.580725 Val acc= 0.580855\n",
            "Epoch 184: Training loss= 0.597821 Val loss= 2.257182 Training acc= 0.581110 Val acc= 0.581275\n",
            "Epoch 185: Training loss= 0.594257 Val loss= 2.248736 Training acc= 0.581475 Val acc= 0.581570\n",
            "Epoch 186: Training loss= 0.590737 Val loss= 2.240373 Training acc= 0.581835 Val acc= 0.581905\n",
            "Epoch 187: Training loss= 0.587263 Val loss= 2.232091 Training acc= 0.582215 Val acc= 0.582260\n",
            "Epoch 188: Training loss= 0.583832 Val loss= 2.223889 Training acc= 0.582585 Val acc= 0.582725\n",
            "Epoch 189: Training loss= 0.580444 Val loss= 2.215766 Training acc= 0.583000 Val acc= 0.583150\n",
            "Epoch 190: Training loss= 0.577097 Val loss= 2.207720 Training acc= 0.583380 Val acc= 0.583550\n",
            "Epoch 191: Training loss= 0.573793 Val loss= 2.199750 Training acc= 0.583780 Val acc= 0.583995\n",
            "Epoch 192: Training loss= 0.570528 Val loss= 2.191855 Training acc= 0.584230 Val acc= 0.584465\n",
            "Epoch 193: Training loss= 0.567304 Val loss= 2.184034 Training acc= 0.584720 Val acc= 0.584850\n",
            "Epoch 194: Training loss= 0.564119 Val loss= 2.176284 Training acc= 0.584900 Val acc= 0.584995\n",
            "Epoch 195: Training loss= 0.560972 Val loss= 2.168607 Training acc= 0.585270 Val acc= 0.585415\n",
            "Epoch 196: Training loss= 0.557862 Val loss= 2.160999 Training acc= 0.585715 Val acc= 0.585800\n",
            "Epoch 197: Training loss= 0.554790 Val loss= 2.153460 Training acc= 0.586060 Val acc= 0.586145\n",
            "Epoch 198: Training loss= 0.551754 Val loss= 2.145989 Training acc= 0.586340 Val acc= 0.586425\n",
            "Epoch 199: Training loss= 0.548753 Val loss= 2.138584 Training acc= 0.586660 Val acc= 0.586750\n",
            "Epoch 200: Training loss= 0.545788 Val loss= 2.131246 Training acc= 0.586990 Val acc= 0.587005\n",
            "Epoch 201: Training loss= 0.542857 Val loss= 2.123972 Training acc= 0.587270 Val acc= 0.587330\n",
            "Epoch 202: Training loss= 0.539960 Val loss= 2.116761 Training acc= 0.587455 Val acc= 0.587595\n",
            "Epoch 203: Training loss= 0.537096 Val loss= 2.109614 Training acc= 0.587695 Val acc= 0.587780\n",
            "Epoch 204: Training loss= 0.534265 Val loss= 2.102528 Training acc= 0.588070 Val acc= 0.588145\n",
            "Epoch 205: Training loss= 0.531466 Val loss= 2.095503 Training acc= 0.588365 Val acc= 0.588465\n",
            "Epoch 206: Training loss= 0.528698 Val loss= 2.088538 Training acc= 0.588760 Val acc= 0.588815\n",
            "Epoch 207: Training loss= 0.525961 Val loss= 2.081632 Training acc= 0.589045 Val acc= 0.589110\n",
            "Epoch 208: Training loss= 0.523255 Val loss= 2.074784 Training acc= 0.589265 Val acc= 0.589305\n",
            "Epoch 209: Training loss= 0.520579 Val loss= 2.067993 Training acc= 0.589645 Val acc= 0.589695\n",
            "Epoch 210: Training loss= 0.517932 Val loss= 2.061259 Training acc= 0.589995 Val acc= 0.590005\n",
            "Epoch 211: Training loss= 0.515314 Val loss= 2.054580 Training acc= 0.590360 Val acc= 0.590270\n",
            "Epoch 212: Training loss= 0.512725 Val loss= 2.047956 Training acc= 0.590670 Val acc= 0.590600\n",
            "Epoch 213: Training loss= 0.510164 Val loss= 2.041386 Training acc= 0.591020 Val acc= 0.591005\n",
            "Epoch 214: Training loss= 0.507630 Val loss= 2.034869 Training acc= 0.591230 Val acc= 0.591290\n",
            "Epoch 215: Training loss= 0.505123 Val loss= 2.028405 Training acc= 0.591550 Val acc= 0.591575\n",
            "Epoch 216: Training loss= 0.502643 Val loss= 2.021992 Training acc= 0.591815 Val acc= 0.591785\n",
            "Epoch 217: Training loss= 0.500189 Val loss= 2.015631 Training acc= 0.592085 Val acc= 0.592095\n",
            "Epoch 218: Training loss= 0.497761 Val loss= 2.009320 Training acc= 0.592380 Val acc= 0.592410\n",
            "Epoch 219: Training loss= 0.495358 Val loss= 2.003058 Training acc= 0.592730 Val acc= 0.592745\n",
            "Epoch 220: Training loss= 0.492981 Val loss= 1.996845 Training acc= 0.593125 Val acc= 0.593085\n",
            "Epoch 221: Training loss= 0.490628 Val loss= 1.990681 Training acc= 0.593385 Val acc= 0.593390\n",
            "Epoch 222: Training loss= 0.488299 Val loss= 1.984564 Training acc= 0.593630 Val acc= 0.593595\n",
            "Epoch 223: Training loss= 0.485993 Val loss= 1.978494 Training acc= 0.593815 Val acc= 0.593800\n",
            "Epoch 224: Training loss= 0.483712 Val loss= 1.972470 Training acc= 0.594050 Val acc= 0.594065\n",
            "Epoch 225: Training loss= 0.481453 Val loss= 1.966492 Training acc= 0.594365 Val acc= 0.594415\n",
            "Epoch 226: Training loss= 0.479217 Val loss= 1.960559 Training acc= 0.594625 Val acc= 0.594655\n",
            "Epoch 227: Training loss= 0.477004 Val loss= 1.954671 Training acc= 0.594950 Val acc= 0.594995\n",
            "Epoch 228: Training loss= 0.474812 Val loss= 1.948827 Training acc= 0.595260 Val acc= 0.595355\n",
            "Epoch 229: Training loss= 0.472642 Val loss= 1.943026 Training acc= 0.595550 Val acc= 0.595610\n",
            "Epoch 230: Training loss= 0.470494 Val loss= 1.937267 Training acc= 0.595890 Val acc= 0.595865\n",
            "Epoch 231: Training loss= 0.468366 Val loss= 1.931551 Training acc= 0.596220 Val acc= 0.596180\n",
            "Epoch 232: Training loss= 0.466259 Val loss= 1.925877 Training acc= 0.596585 Val acc= 0.596540\n",
            "Epoch 233: Training loss= 0.464173 Val loss= 1.920244 Training acc= 0.596890 Val acc= 0.596830\n",
            "Epoch 234: Training loss= 0.462106 Val loss= 1.914651 Training acc= 0.597185 Val acc= 0.597080\n",
            "Epoch 235: Training loss= 0.460060 Val loss= 1.909098 Training acc= 0.597400 Val acc= 0.597295\n",
            "Epoch 236: Training loss= 0.458033 Val loss= 1.903586 Training acc= 0.597695 Val acc= 0.597530\n",
            "Epoch 237: Training loss= 0.456025 Val loss= 1.898112 Training acc= 0.598015 Val acc= 0.597850\n",
            "Epoch 238: Training loss= 0.454036 Val loss= 1.892677 Training acc= 0.598315 Val acc= 0.598155\n",
            "Epoch 239: Training loss= 0.452066 Val loss= 1.887280 Training acc= 0.598655 Val acc= 0.598485\n",
            "Epoch 240: Training loss= 0.450114 Val loss= 1.881921 Training acc= 0.598895 Val acc= 0.598700\n",
            "Epoch 241: Training loss= 0.448181 Val loss= 1.876599 Training acc= 0.599165 Val acc= 0.598935\n",
            "Epoch 242: Training loss= 0.446265 Val loss= 1.871314 Training acc= 0.599375 Val acc= 0.599190\n",
            "Epoch 243: Training loss= 0.444367 Val loss= 1.866066 Training acc= 0.599690 Val acc= 0.599520\n",
            "Epoch 244: Training loss= 0.442486 Val loss= 1.860853 Training acc= 0.599965 Val acc= 0.599775\n",
            "Epoch 245: Training loss= 0.440623 Val loss= 1.855676 Training acc= 0.600205 Val acc= 0.600025\n",
            "Epoch 246: Training loss= 0.438776 Val loss= 1.850534 Training acc= 0.600405 Val acc= 0.600220\n",
            "Epoch 247: Training loss= 0.436946 Val loss= 1.845426 Training acc= 0.600625 Val acc= 0.600445\n",
            "Epoch 248: Training loss= 0.435132 Val loss= 1.840353 Training acc= 0.600820 Val acc= 0.600680\n",
            "Epoch 249: Training loss= 0.433335 Val loss= 1.835314 Training acc= 0.601095 Val acc= 0.600915\n",
            "Epoch 250: Training loss= 0.431553 Val loss= 1.830309 Training acc= 0.601375 Val acc= 0.601100\n",
            "Epoch 251: Training loss= 0.429787 Val loss= 1.825336 Training acc= 0.601580 Val acc= 0.601275\n",
            "Epoch 252: Training loss= 0.428037 Val loss= 1.820396 Training acc= 0.601985 Val acc= 0.601640\n",
            "Epoch 253: Training loss= 0.426302 Val loss= 1.815489 Training acc= 0.602250 Val acc= 0.601870\n",
            "Epoch 254: Training loss= 0.424583 Val loss= 1.810614 Training acc= 0.602520 Val acc= 0.602135\n",
            "Epoch 255: Training loss= 0.422878 Val loss= 1.805770 Training acc= 0.602760 Val acc= 0.602345\n",
            "Epoch 256: Training loss= 0.421188 Val loss= 1.800957 Training acc= 0.602925 Val acc= 0.602510\n",
            "Epoch 257: Training loss= 0.419512 Val loss= 1.796176 Training acc= 0.603200 Val acc= 0.602775\n",
            "Epoch 258: Training loss= 0.417851 Val loss= 1.791425 Training acc= 0.603400 Val acc= 0.602990\n",
            "Epoch 259: Training loss= 0.416204 Val loss= 1.786705 Training acc= 0.603635 Val acc= 0.603200\n",
            "Epoch 260: Training loss= 0.414571 Val loss= 1.782014 Training acc= 0.603885 Val acc= 0.603465\n",
            "Epoch 261: Training loss= 0.412952 Val loss= 1.777353 Training acc= 0.604230 Val acc= 0.603775\n",
            "Epoch 262: Training loss= 0.411346 Val loss= 1.772722 Training acc= 0.604515 Val acc= 0.604100\n",
            "Epoch 263: Training loss= 0.409754 Val loss= 1.768119 Training acc= 0.604835 Val acc= 0.604410\n",
            "Epoch 264: Training loss= 0.408175 Val loss= 1.763545 Training acc= 0.605145 Val acc= 0.604745\n",
            "Epoch 265: Training loss= 0.406609 Val loss= 1.759000 Training acc= 0.605530 Val acc= 0.605090\n",
            "Epoch 266: Training loss= 0.405056 Val loss= 1.754482 Training acc= 0.605850 Val acc= 0.605395\n",
            "Epoch 267: Training loss= 0.403516 Val loss= 1.749993 Training acc= 0.606160 Val acc= 0.605725\n",
            "Epoch 268: Training loss= 0.401988 Val loss= 1.745531 Training acc= 0.606405 Val acc= 0.605985\n",
            "Epoch 269: Training loss= 0.400473 Val loss= 1.741096 Training acc= 0.606610 Val acc= 0.606210\n",
            "Epoch 270: Training loss= 0.398970 Val loss= 1.736688 Training acc= 0.606960 Val acc= 0.606575\n",
            "Epoch 271: Training loss= 0.397479 Val loss= 1.732307 Training acc= 0.607110 Val acc= 0.606670\n",
            "Epoch 272: Training loss= 0.396001 Val loss= 1.727952 Training acc= 0.607430 Val acc= 0.606915\n",
            "Epoch 273: Training loss= 0.394534 Val loss= 1.723624 Training acc= 0.607740 Val acc= 0.607195\n",
            "Epoch 274: Training loss= 0.393079 Val loss= 1.719321 Training acc= 0.607970 Val acc= 0.607390\n",
            "Epoch 275: Training loss= 0.391635 Val loss= 1.715044 Training acc= 0.608235 Val acc= 0.607650\n",
            "Epoch 276: Training loss= 0.390203 Val loss= 1.710792 Training acc= 0.608485 Val acc= 0.607900\n",
            "Epoch 277: Training loss= 0.388782 Val loss= 1.706565 Training acc= 0.608615 Val acc= 0.608050\n",
            "Epoch 278: Training loss= 0.387372 Val loss= 1.702364 Training acc= 0.608825 Val acc= 0.608330\n",
            "Epoch 279: Training loss= 0.385974 Val loss= 1.698186 Training acc= 0.608945 Val acc= 0.608455\n",
            "Epoch 280: Training loss= 0.384586 Val loss= 1.694034 Training acc= 0.609205 Val acc= 0.608695\n",
            "Epoch 281: Training loss= 0.383209 Val loss= 1.689905 Training acc= 0.609445 Val acc= 0.608870\n",
            "Epoch 282: Training loss= 0.381842 Val loss= 1.685800 Training acc= 0.609690 Val acc= 0.609065\n",
            "Epoch 283: Training loss= 0.380486 Val loss= 1.681719 Training acc= 0.609930 Val acc= 0.609335\n",
            "Epoch 284: Training loss= 0.379141 Val loss= 1.677662 Training acc= 0.610155 Val acc= 0.609525\n",
            "Epoch 285: Training loss= 0.377805 Val loss= 1.673627 Training acc= 0.610310 Val acc= 0.609750\n",
            "Epoch 286: Training loss= 0.376480 Val loss= 1.669616 Training acc= 0.610495 Val acc= 0.609975\n",
            "Epoch 287: Training loss= 0.375165 Val loss= 1.665627 Training acc= 0.610655 Val acc= 0.610110\n",
            "Epoch 288: Training loss= 0.373860 Val loss= 1.661661 Training acc= 0.610875 Val acc= 0.610360\n",
            "Epoch 289: Training loss= 0.372565 Val loss= 1.657718 Training acc= 0.611185 Val acc= 0.610625\n",
            "Epoch 290: Training loss= 0.371279 Val loss= 1.653796 Training acc= 0.611410 Val acc= 0.610885\n",
            "Epoch 291: Training loss= 0.370003 Val loss= 1.649897 Training acc= 0.611620 Val acc= 0.611175\n",
            "Epoch 292: Training loss= 0.368736 Val loss= 1.646019 Training acc= 0.611815 Val acc= 0.611435\n",
            "Epoch 293: Training loss= 0.367479 Val loss= 1.642163 Training acc= 0.611925 Val acc= 0.611580\n",
            "Epoch 294: Training loss= 0.366231 Val loss= 1.638328 Training acc= 0.612155 Val acc= 0.611780\n",
            "Epoch 295: Training loss= 0.364992 Val loss= 1.634515 Training acc= 0.612425 Val acc= 0.612030\n",
            "Epoch 296: Training loss= 0.363763 Val loss= 1.630722 Training acc= 0.612655 Val acc= 0.612245\n",
            "Epoch 297: Training loss= 0.362542 Val loss= 1.626950 Training acc= 0.612870 Val acc= 0.612360\n",
            "Epoch 298: Training loss= 0.361330 Val loss= 1.623199 Training acc= 0.613100 Val acc= 0.612615\n",
            "Epoch 299: Training loss= 0.360127 Val loss= 1.619468 Training acc= 0.613305 Val acc= 0.612760\n",
            "Epoch 300: Training loss= 0.358933 Val loss= 1.615758 Training acc= 0.613500 Val acc= 0.612945\n",
            "Epoch 301: Training loss= 0.357747 Val loss= 1.612067 Training acc= 0.613715 Val acc= 0.613185\n",
            "Epoch 302: Training loss= 0.356569 Val loss= 1.608396 Training acc= 0.613875 Val acc= 0.613350\n",
            "Epoch 303: Training loss= 0.355401 Val loss= 1.604745 Training acc= 0.614150 Val acc= 0.613555\n",
            "Epoch 304: Training loss= 0.354240 Val loss= 1.601114 Training acc= 0.614345 Val acc= 0.613755\n",
            "Epoch 305: Training loss= 0.353088 Val loss= 1.597502 Training acc= 0.614535 Val acc= 0.613895\n",
            "Epoch 306: Training loss= 0.351943 Val loss= 1.593909 Training acc= 0.614710 Val acc= 0.614115\n",
            "Epoch 307: Training loss= 0.350807 Val loss= 1.590335 Training acc= 0.614925 Val acc= 0.614385\n",
            "Epoch 308: Training loss= 0.349679 Val loss= 1.586780 Training acc= 0.615095 Val acc= 0.614570\n",
            "Epoch 309: Training loss= 0.348559 Val loss= 1.583244 Training acc= 0.615295 Val acc= 0.614755\n",
            "Epoch 310: Training loss= 0.347446 Val loss= 1.579727 Training acc= 0.615565 Val acc= 0.615000\n",
            "Epoch 311: Training loss= 0.346342 Val loss= 1.576227 Training acc= 0.615725 Val acc= 0.615190\n",
            "Epoch 312: Training loss= 0.345244 Val loss= 1.572746 Training acc= 0.615910 Val acc= 0.615385\n",
            "Epoch 313: Training loss= 0.344155 Val loss= 1.569283 Training acc= 0.616065 Val acc= 0.615525\n",
            "Epoch 314: Training loss= 0.343073 Val loss= 1.565838 Training acc= 0.616305 Val acc= 0.615705\n",
            "Epoch 315: Training loss= 0.341998 Val loss= 1.562411 Training acc= 0.616455 Val acc= 0.615785\n",
            "Epoch 316: Training loss= 0.340931 Val loss= 1.559002 Training acc= 0.616750 Val acc= 0.616050\n",
            "Epoch 317: Training loss= 0.339871 Val loss= 1.555610 Training acc= 0.616970 Val acc= 0.616225\n",
            "Epoch 318: Training loss= 0.338818 Val loss= 1.552235 Training acc= 0.617125 Val acc= 0.616475\n",
            "Epoch 319: Training loss= 0.337773 Val loss= 1.548878 Training acc= 0.617300 Val acc= 0.616660\n",
            "Epoch 320: Training loss= 0.336734 Val loss= 1.545537 Training acc= 0.617460 Val acc= 0.616840\n",
            "Epoch 321: Training loss= 0.335702 Val loss= 1.542214 Training acc= 0.617630 Val acc= 0.617025\n",
            "Epoch 322: Training loss= 0.334678 Val loss= 1.538907 Training acc= 0.617775 Val acc= 0.617200\n",
            "Epoch 323: Training loss= 0.333660 Val loss= 1.535617 Training acc= 0.618070 Val acc= 0.617460\n",
            "Epoch 324: Training loss= 0.332649 Val loss= 1.532344 Training acc= 0.618205 Val acc= 0.617625\n",
            "Epoch 325: Training loss= 0.331645 Val loss= 1.529087 Training acc= 0.618395 Val acc= 0.617850\n",
            "Epoch 326: Training loss= 0.330647 Val loss= 1.525846 Training acc= 0.618640 Val acc= 0.618100\n",
            "Epoch 327: Training loss= 0.329656 Val loss= 1.522621 Training acc= 0.618875 Val acc= 0.618355\n",
            "Epoch 328: Training loss= 0.328671 Val loss= 1.519413 Training acc= 0.619115 Val acc= 0.618575\n",
            "Epoch 329: Training loss= 0.327693 Val loss= 1.516220 Training acc= 0.619285 Val acc= 0.618700\n",
            "Epoch 330: Training loss= 0.326722 Val loss= 1.513043 Training acc= 0.619520 Val acc= 0.618900\n",
            "Epoch 331: Training loss= 0.325756 Val loss= 1.509882 Training acc= 0.619700 Val acc= 0.619050\n",
            "Epoch 332: Training loss= 0.324797 Val loss= 1.506736 Training acc= 0.619925 Val acc= 0.619245\n",
            "Epoch 333: Training loss= 0.323845 Val loss= 1.503606 Training acc= 0.620160 Val acc= 0.619490\n",
            "Epoch 334: Training loss= 0.322898 Val loss= 1.500490 Training acc= 0.620375 Val acc= 0.619705\n",
            "Epoch 335: Training loss= 0.321957 Val loss= 1.497391 Training acc= 0.620430 Val acc= 0.619815\n",
            "Epoch 336: Training loss= 0.321023 Val loss= 1.494306 Training acc= 0.620640 Val acc= 0.620020\n",
            "Epoch 337: Training loss= 0.320094 Val loss= 1.491236 Training acc= 0.620830 Val acc= 0.620215\n",
            "Epoch 338: Training loss= 0.319172 Val loss= 1.488181 Training acc= 0.621020 Val acc= 0.620415\n",
            "Epoch 339: Training loss= 0.318255 Val loss= 1.485140 Training acc= 0.621145 Val acc= 0.620555\n",
            "Epoch 340: Training loss= 0.317345 Val loss= 1.482114 Training acc= 0.621390 Val acc= 0.620775\n",
            "Epoch 341: Training loss= 0.316440 Val loss= 1.479103 Training acc= 0.621660 Val acc= 0.621055\n",
            "Epoch 342: Training loss= 0.315540 Val loss= 1.476106 Training acc= 0.621825 Val acc= 0.621220\n",
            "Epoch 343: Training loss= 0.314647 Val loss= 1.473124 Training acc= 0.622130 Val acc= 0.621540\n",
            "Epoch 344: Training loss= 0.313759 Val loss= 1.470155 Training acc= 0.622335 Val acc= 0.621695\n",
            "Epoch 345: Training loss= 0.312876 Val loss= 1.467201 Training acc= 0.622530 Val acc= 0.621885\n",
            "Epoch 346: Training loss= 0.311999 Val loss= 1.464260 Training acc= 0.622755 Val acc= 0.622120\n",
            "Epoch 347: Training loss= 0.311128 Val loss= 1.461334 Training acc= 0.623035 Val acc= 0.622335\n",
            "Epoch 348: Training loss= 0.310262 Val loss= 1.458421 Training acc= 0.623255 Val acc= 0.622475\n",
            "Epoch 349: Training loss= 0.309402 Val loss= 1.455522 Training acc= 0.623510 Val acc= 0.622680\n",
            "Epoch 350: Training loss= 0.308546 Val loss= 1.452636 Training acc= 0.623735 Val acc= 0.622885\n",
            "Epoch 351: Training loss= 0.307696 Val loss= 1.449764 Training acc= 0.623895 Val acc= 0.623050\n",
            "Epoch 352: Training loss= 0.306852 Val loss= 1.446906 Training acc= 0.624140 Val acc= 0.623255\n",
            "Epoch 353: Training loss= 0.306012 Val loss= 1.444060 Training acc= 0.624305 Val acc= 0.623400\n",
            "Epoch 354: Training loss= 0.305178 Val loss= 1.441228 Training acc= 0.624505 Val acc= 0.623630\n",
            "Epoch 355: Training loss= 0.304349 Val loss= 1.438409 Training acc= 0.624625 Val acc= 0.623860\n",
            "Epoch 356: Training loss= 0.303524 Val loss= 1.435603 Training acc= 0.624825 Val acc= 0.624065\n",
            "Epoch 357: Training loss= 0.302705 Val loss= 1.432809 Training acc= 0.624940 Val acc= 0.624180\n",
            "Epoch 358: Training loss= 0.301891 Val loss= 1.430029 Training acc= 0.625180 Val acc= 0.624445\n",
            "Epoch 359: Training loss= 0.301082 Val loss= 1.427261 Training acc= 0.625260 Val acc= 0.624545\n",
            "Epoch 360: Training loss= 0.300277 Val loss= 1.424506 Training acc= 0.625455 Val acc= 0.624740\n",
            "Epoch 361: Training loss= 0.299478 Val loss= 1.421764 Training acc= 0.625645 Val acc= 0.624890\n",
            "Epoch 362: Training loss= 0.298683 Val loss= 1.419034 Training acc= 0.625825 Val acc= 0.625065\n",
            "Epoch 363: Training loss= 0.297893 Val loss= 1.416316 Training acc= 0.625985 Val acc= 0.625235\n",
            "Epoch 364: Training loss= 0.297108 Val loss= 1.413610 Training acc= 0.626090 Val acc= 0.625345\n",
            "Epoch 365: Training loss= 0.296327 Val loss= 1.410917 Training acc= 0.626250 Val acc= 0.625520\n",
            "Epoch 366: Training loss= 0.295552 Val loss= 1.408236 Training acc= 0.626480 Val acc= 0.625730\n",
            "Epoch 367: Training loss= 0.294780 Val loss= 1.405567 Training acc= 0.626505 Val acc= 0.625770\n",
            "Epoch 368: Training loss= 0.294014 Val loss= 1.402910 Training acc= 0.626700 Val acc= 0.626010\n",
            "Epoch 369: Training loss= 0.293251 Val loss= 1.400265 Training acc= 0.626825 Val acc= 0.626080\n",
            "Epoch 370: Training loss= 0.292494 Val loss= 1.397631 Training acc= 0.627025 Val acc= 0.626310\n",
            "Epoch 371: Training loss= 0.291741 Val loss= 1.395009 Training acc= 0.627250 Val acc= 0.626540\n",
            "Epoch 372: Training loss= 0.290992 Val loss= 1.392399 Training acc= 0.627335 Val acc= 0.626660\n",
            "Epoch 373: Training loss= 0.290247 Val loss= 1.389801 Training acc= 0.627475 Val acc= 0.626875\n",
            "Epoch 374: Training loss= 0.289507 Val loss= 1.387214 Training acc= 0.627600 Val acc= 0.627035\n",
            "Epoch 375: Training loss= 0.288772 Val loss= 1.384638 Training acc= 0.627765 Val acc= 0.627175\n",
            "Epoch 376: Training loss= 0.288040 Val loss= 1.382074 Training acc= 0.627875 Val acc= 0.627335\n",
            "Epoch 377: Training loss= 0.287313 Val loss= 1.379521 Training acc= 0.628045 Val acc= 0.627535\n",
            "Epoch 378: Training loss= 0.286590 Val loss= 1.376979 Training acc= 0.628190 Val acc= 0.627645\n",
            "Epoch 379: Training loss= 0.285871 Val loss= 1.374448 Training acc= 0.628440 Val acc= 0.627900\n",
            "Epoch 380: Training loss= 0.285157 Val loss= 1.371928 Training acc= 0.628605 Val acc= 0.628020\n",
            "Epoch 381: Training loss= 0.284446 Val loss= 1.369419 Training acc= 0.628760 Val acc= 0.628190\n",
            "Epoch 382: Training loss= 0.283740 Val loss= 1.366921 Training acc= 0.628920 Val acc= 0.628330\n",
            "Epoch 383: Training loss= 0.283037 Val loss= 1.364434 Training acc= 0.629110 Val acc= 0.628515\n",
            "Epoch 384: Training loss= 0.282339 Val loss= 1.361958 Training acc= 0.629290 Val acc= 0.628700\n",
            "Epoch 385: Training loss= 0.281645 Val loss= 1.359492 Training acc= 0.629440 Val acc= 0.628855\n",
            "Epoch 386: Training loss= 0.280954 Val loss= 1.357037 Training acc= 0.629555 Val acc= 0.628985\n",
            "Epoch 387: Training loss= 0.280268 Val loss= 1.354593 Training acc= 0.629800 Val acc= 0.629185\n",
            "Epoch 388: Training loss= 0.279585 Val loss= 1.352159 Training acc= 0.629910 Val acc= 0.629325\n",
            "Epoch 389: Training loss= 0.278906 Val loss= 1.349735 Training acc= 0.630020 Val acc= 0.629390\n",
            "Epoch 390: Training loss= 0.278231 Val loss= 1.347322 Training acc= 0.630095 Val acc= 0.629475\n",
            "Epoch 391: Training loss= 0.277560 Val loss= 1.344919 Training acc= 0.630225 Val acc= 0.629610\n",
            "Epoch 392: Training loss= 0.276893 Val loss= 1.342526 Training acc= 0.630395 Val acc= 0.629775\n",
            "Epoch 393: Training loss= 0.276229 Val loss= 1.340143 Training acc= 0.630530 Val acc= 0.629910\n",
            "Epoch 394: Training loss= 0.275569 Val loss= 1.337771 Training acc= 0.630750 Val acc= 0.630105\n",
            "Epoch 395: Training loss= 0.274913 Val loss= 1.335408 Training acc= 0.630920 Val acc= 0.630255\n",
            "Epoch 396: Training loss= 0.274261 Val loss= 1.333055 Training acc= 0.631045 Val acc= 0.630360\n",
            "Epoch 397: Training loss= 0.273612 Val loss= 1.330713 Training acc= 0.631190 Val acc= 0.630505\n",
            "Epoch 398: Training loss= 0.272966 Val loss= 1.328380 Training acc= 0.631375 Val acc= 0.630655\n",
            "Epoch 399: Training loss= 0.272325 Val loss= 1.326057 Training acc= 0.631430 Val acc= 0.630770\n",
            "Epoch 400: Training loss= 0.271687 Val loss= 1.323743 Training acc= 0.631540 Val acc= 0.630965\n",
            "Epoch 401: Training loss= 0.271052 Val loss= 1.321439 Training acc= 0.631720 Val acc= 0.631170\n",
            "Epoch 402: Training loss= 0.270421 Val loss= 1.319145 Training acc= 0.631850 Val acc= 0.631345\n",
            "Epoch 403: Training loss= 0.269793 Val loss= 1.316861 Training acc= 0.631980 Val acc= 0.631465\n",
            "Epoch 404: Training loss= 0.269169 Val loss= 1.314586 Training acc= 0.632160 Val acc= 0.631610\n",
            "Epoch 405: Training loss= 0.268548 Val loss= 1.312320 Training acc= 0.632355 Val acc= 0.631785\n",
            "Epoch 406: Training loss= 0.267931 Val loss= 1.310063 Training acc= 0.632540 Val acc= 0.631990\n",
            "Epoch 407: Training loss= 0.267317 Val loss= 1.307816 Training acc= 0.632755 Val acc= 0.632230\n",
            "Epoch 408: Training loss= 0.266706 Val loss= 1.305579 Training acc= 0.633000 Val acc= 0.632430\n",
            "Epoch 409: Training loss= 0.266098 Val loss= 1.303350 Training acc= 0.633080 Val acc= 0.632525\n",
            "Epoch 410: Training loss= 0.265494 Val loss= 1.301130 Training acc= 0.633300 Val acc= 0.632735\n",
            "Epoch 411: Training loss= 0.264894 Val loss= 1.298920 Training acc= 0.633440 Val acc= 0.632855\n",
            "Epoch 412: Training loss= 0.264296 Val loss= 1.296719 Training acc= 0.633575 Val acc= 0.633020\n",
            "Epoch 413: Training loss= 0.263702 Val loss= 1.294526 Training acc= 0.633740 Val acc= 0.633190\n",
            "Epoch 414: Training loss= 0.263110 Val loss= 1.292343 Training acc= 0.633885 Val acc= 0.633285\n",
            "Epoch 415: Training loss= 0.262522 Val loss= 1.290168 Training acc= 0.634050 Val acc= 0.633500\n",
            "Epoch 416: Training loss= 0.261938 Val loss= 1.288002 Training acc= 0.634300 Val acc= 0.633720\n",
            "Epoch 417: Training loss= 0.261356 Val loss= 1.285845 Training acc= 0.634425 Val acc= 0.633895\n",
            "Epoch 418: Training loss= 0.260777 Val loss= 1.283697 Training acc= 0.634560 Val acc= 0.634065\n",
            "Epoch 419: Training loss= 0.260202 Val loss= 1.281557 Training acc= 0.634695 Val acc= 0.634250\n",
            "Epoch 420: Training loss= 0.259629 Val loss= 1.279426 Training acc= 0.634870 Val acc= 0.634435\n",
            "Epoch 421: Training loss= 0.259060 Val loss= 1.277304 Training acc= 0.635000 Val acc= 0.634585\n",
            "Epoch 422: Training loss= 0.258494 Val loss= 1.275190 Training acc= 0.635145 Val acc= 0.634735\n",
            "Epoch 423: Training loss= 0.257930 Val loss= 1.273084 Training acc= 0.635285 Val acc= 0.634830\n",
            "Epoch 424: Training loss= 0.257370 Val loss= 1.270987 Training acc= 0.635340 Val acc= 0.634905\n",
            "Epoch 425: Training loss= 0.256812 Val loss= 1.268898 Training acc= 0.635430 Val acc= 0.635045\n",
            "Epoch 426: Training loss= 0.256258 Val loss= 1.266818 Training acc= 0.635575 Val acc= 0.635240\n",
            "Epoch 427: Training loss= 0.255706 Val loss= 1.264745 Training acc= 0.635745 Val acc= 0.635415\n",
            "Epoch 428: Training loss= 0.255158 Val loss= 1.262682 Training acc= 0.635925 Val acc= 0.635650\n",
            "Epoch 429: Training loss= 0.254612 Val loss= 1.260626 Training acc= 0.636130 Val acc= 0.635870\n",
            "Epoch 430: Training loss= 0.254069 Val loss= 1.258578 Training acc= 0.636310 Val acc= 0.636055\n",
            "Epoch 431: Training loss= 0.253529 Val loss= 1.256538 Training acc= 0.636455 Val acc= 0.636200\n",
            "Epoch 432: Training loss= 0.252991 Val loss= 1.254507 Training acc= 0.636665 Val acc= 0.636390\n",
            "Epoch 433: Training loss= 0.252457 Val loss= 1.252483 Training acc= 0.636785 Val acc= 0.636525\n",
            "Epoch 434: Training loss= 0.251925 Val loss= 1.250468 Training acc= 0.636885 Val acc= 0.636640\n",
            "Epoch 435: Training loss= 0.251396 Val loss= 1.248460 Training acc= 0.637025 Val acc= 0.636810\n",
            "Epoch 436: Training loss= 0.250870 Val loss= 1.246460 Training acc= 0.637145 Val acc= 0.636925\n",
            "Epoch 437: Training loss= 0.250346 Val loss= 1.244468 Training acc= 0.637290 Val acc= 0.637015\n",
            "Epoch 438: Training loss= 0.249826 Val loss= 1.242483 Training acc= 0.637415 Val acc= 0.637125\n",
            "Epoch 439: Training loss= 0.249307 Val loss= 1.240507 Training acc= 0.637520 Val acc= 0.637200\n",
            "Epoch 440: Training loss= 0.248792 Val loss= 1.238538 Training acc= 0.637695 Val acc= 0.637340\n",
            "Epoch 441: Training loss= 0.248279 Val loss= 1.236576 Training acc= 0.637810 Val acc= 0.637430\n",
            "Epoch 442: Training loss= 0.247769 Val loss= 1.234623 Training acc= 0.638030 Val acc= 0.637625\n",
            "Epoch 443: Training loss= 0.247261 Val loss= 1.232677 Training acc= 0.638185 Val acc= 0.637735\n",
            "Epoch 444: Training loss= 0.246756 Val loss= 1.230738 Training acc= 0.638340 Val acc= 0.637900\n",
            "Epoch 445: Training loss= 0.246254 Val loss= 1.228807 Training acc= 0.638480 Val acc= 0.638100\n",
            "Epoch 446: Training loss= 0.245754 Val loss= 1.226883 Training acc= 0.638630 Val acc= 0.638270\n",
            "Epoch 447: Training loss= 0.245257 Val loss= 1.224966 Training acc= 0.638750 Val acc= 0.638360\n",
            "Epoch 448: Training loss= 0.244762 Val loss= 1.223057 Training acc= 0.638950 Val acc= 0.638600\n",
            "Epoch 449: Training loss= 0.244269 Val loss= 1.221156 Training acc= 0.639190 Val acc= 0.638835\n",
            "Epoch 450: Training loss= 0.243780 Val loss= 1.219261 Training acc= 0.639360 Val acc= 0.639015\n",
            "Epoch 451: Training loss= 0.243292 Val loss= 1.217374 Training acc= 0.639640 Val acc= 0.639255\n",
            "Epoch 452: Training loss= 0.242807 Val loss= 1.215494 Training acc= 0.639825 Val acc= 0.639440\n",
            "Epoch 453: Training loss= 0.242325 Val loss= 1.213621 Training acc= 0.639990 Val acc= 0.639620\n",
            "Epoch 454: Training loss= 0.241845 Val loss= 1.211755 Training acc= 0.640145 Val acc= 0.639775\n",
            "Epoch 455: Training loss= 0.241367 Val loss= 1.209896 Training acc= 0.640285 Val acc= 0.639935\n",
            "Epoch 456: Training loss= 0.240892 Val loss= 1.208044 Training acc= 0.640410 Val acc= 0.640015\n",
            "Epoch 457: Training loss= 0.240419 Val loss= 1.206200 Training acc= 0.640495 Val acc= 0.640085\n",
            "Epoch 458: Training loss= 0.239948 Val loss= 1.204362 Training acc= 0.640640 Val acc= 0.640255\n",
            "Epoch 459: Training loss= 0.239480 Val loss= 1.202531 Training acc= 0.640725 Val acc= 0.640370\n",
            "Epoch 460: Training loss= 0.239014 Val loss= 1.200707 Training acc= 0.640830 Val acc= 0.640500\n",
            "Epoch 461: Training loss= 0.238551 Val loss= 1.198890 Training acc= 0.640895 Val acc= 0.640555\n",
            "Epoch 462: Training loss= 0.238090 Val loss= 1.197079 Training acc= 0.641050 Val acc= 0.640715\n",
            "Epoch 463: Training loss= 0.237631 Val loss= 1.195276 Training acc= 0.641265 Val acc= 0.640905\n",
            "Epoch 464: Training loss= 0.237174 Val loss= 1.193479 Training acc= 0.641420 Val acc= 0.641030\n",
            "Epoch 465: Training loss= 0.236720 Val loss= 1.191689 Training acc= 0.641570 Val acc= 0.641175\n",
            "Epoch 466: Training loss= 0.236267 Val loss= 1.189905 Training acc= 0.641675 Val acc= 0.641240\n",
            "Epoch 467: Training loss= 0.235817 Val loss= 1.188128 Training acc= 0.641775 Val acc= 0.641335\n",
            "Epoch 468: Training loss= 0.235370 Val loss= 1.186358 Training acc= 0.641825 Val acc= 0.641470\n",
            "Epoch 469: Training loss= 0.234924 Val loss= 1.184594 Training acc= 0.641965 Val acc= 0.641620\n",
            "Epoch 470: Training loss= 0.234481 Val loss= 1.182837 Training acc= 0.642085 Val acc= 0.641755\n",
            "Epoch 471: Training loss= 0.234039 Val loss= 1.181086 Training acc= 0.642215 Val acc= 0.641860\n",
            "Epoch 472: Training loss= 0.233600 Val loss= 1.179342 Training acc= 0.642330 Val acc= 0.641970\n",
            "Epoch 473: Training loss= 0.233163 Val loss= 1.177604 Training acc= 0.642445 Val acc= 0.642045\n",
            "Epoch 474: Training loss= 0.232728 Val loss= 1.175873 Training acc= 0.642615 Val acc= 0.642250\n",
            "Epoch 475: Training loss= 0.232296 Val loss= 1.174147 Training acc= 0.642770 Val acc= 0.642375\n",
            "Epoch 476: Training loss= 0.231865 Val loss= 1.172429 Training acc= 0.642920 Val acc= 0.642480\n",
            "Epoch 477: Training loss= 0.231437 Val loss= 1.170716 Training acc= 0.643015 Val acc= 0.642575\n",
            "Epoch 478: Training loss= 0.231010 Val loss= 1.169010 Training acc= 0.643155 Val acc= 0.642700\n",
            "Epoch 479: Training loss= 0.230586 Val loss= 1.167310 Training acc= 0.643280 Val acc= 0.642815\n",
            "Epoch 480: Training loss= 0.230163 Val loss= 1.165616 Training acc= 0.643480 Val acc= 0.642995\n",
            "Epoch 481: Training loss= 0.229743 Val loss= 1.163928 Training acc= 0.643590 Val acc= 0.643130\n",
            "Epoch 482: Training loss= 0.229325 Val loss= 1.162247 Training acc= 0.643695 Val acc= 0.643265\n",
            "Epoch 483: Training loss= 0.228908 Val loss= 1.160571 Training acc= 0.643785 Val acc= 0.643360\n",
            "Epoch 484: Training loss= 0.228494 Val loss= 1.158902 Training acc= 0.643845 Val acc= 0.643430\n",
            "Epoch 485: Training loss= 0.228082 Val loss= 1.157239 Training acc= 0.643885 Val acc= 0.643550\n",
            "Epoch 486: Training loss= 0.227671 Val loss= 1.155581 Training acc= 0.644015 Val acc= 0.643660\n",
            "Epoch 487: Training loss= 0.227263 Val loss= 1.153930 Training acc= 0.644150 Val acc= 0.643855\n",
            "Epoch 488: Training loss= 0.226857 Val loss= 1.152284 Training acc= 0.644295 Val acc= 0.644055\n",
            "Epoch 489: Training loss= 0.226452 Val loss= 1.150645 Training acc= 0.644410 Val acc= 0.644185\n",
            "Epoch 490: Training loss= 0.226049 Val loss= 1.149011 Training acc= 0.644565 Val acc= 0.644345\n",
            "Epoch 491: Training loss= 0.225649 Val loss= 1.147384 Training acc= 0.644750 Val acc= 0.644500\n",
            "Epoch 492: Training loss= 0.225250 Val loss= 1.145762 Training acc= 0.644875 Val acc= 0.644620\n",
            "Epoch 493: Training loss= 0.224853 Val loss= 1.144145 Training acc= 0.645020 Val acc= 0.644730\n",
            "Epoch 494: Training loss= 0.224458 Val loss= 1.142535 Training acc= 0.645120 Val acc= 0.644900\n",
            "Epoch 495: Training loss= 0.224065 Val loss= 1.140930 Training acc= 0.645280 Val acc= 0.645055\n",
            "Epoch 496: Training loss= 0.223673 Val loss= 1.139331 Training acc= 0.645355 Val acc= 0.645160\n",
            "Epoch 497: Training loss= 0.223284 Val loss= 1.137738 Training acc= 0.645495 Val acc= 0.645285\n",
            "Epoch 498: Training loss= 0.222896 Val loss= 1.136151 Training acc= 0.645650 Val acc= 0.645445\n",
            "Epoch 499: Training loss= 0.222510 Val loss= 1.134568 Training acc= 0.645835 Val acc= 0.645650\n",
            "Epoch 500: Training loss= 0.222126 Val loss= 1.132992 Training acc= 0.645970 Val acc= 0.645785\n",
            "Epoch 501: Training loss= 0.221744 Val loss= 1.131421 Training acc= 0.646055 Val acc= 0.645870\n",
            "Epoch 502: Training loss= 0.221364 Val loss= 1.129856 Training acc= 0.646180 Val acc= 0.645995\n",
            "Epoch 503: Training loss= 0.220985 Val loss= 1.128296 Training acc= 0.646340 Val acc= 0.646135\n",
            "Epoch 504: Training loss= 0.220608 Val loss= 1.126742 Training acc= 0.646510 Val acc= 0.646310\n",
            "Epoch 505: Training loss= 0.220233 Val loss= 1.125193 Training acc= 0.646610 Val acc= 0.646400\n",
            "Epoch 506: Training loss= 0.219859 Val loss= 1.123650 Training acc= 0.646785 Val acc= 0.646540\n",
            "Epoch 507: Training loss= 0.219488 Val loss= 1.122112 Training acc= 0.646940 Val acc= 0.646675\n",
            "Epoch 508: Training loss= 0.219118 Val loss= 1.120579 Training acc= 0.647085 Val acc= 0.646810\n",
            "Epoch 509: Training loss= 0.218749 Val loss= 1.119052 Training acc= 0.647195 Val acc= 0.646935\n",
            "Epoch 510: Training loss= 0.218383 Val loss= 1.117530 Training acc= 0.647235 Val acc= 0.646995\n",
            "Epoch 511: Training loss= 0.218018 Val loss= 1.116013 Training acc= 0.647315 Val acc= 0.647100\n",
            "Epoch 512: Training loss= 0.217655 Val loss= 1.114502 Training acc= 0.647405 Val acc= 0.647215\n",
            "Epoch 513: Training loss= 0.217293 Val loss= 1.112996 Training acc= 0.647510 Val acc= 0.647330\n",
            "Epoch 514: Training loss= 0.216933 Val loss= 1.111495 Training acc= 0.647635 Val acc= 0.647440\n",
            "Epoch 515: Training loss= 0.216575 Val loss= 1.109999 Training acc= 0.647705 Val acc= 0.647530\n",
            "Epoch 516: Training loss= 0.216218 Val loss= 1.108508 Training acc= 0.647745 Val acc= 0.647575\n",
            "Epoch 517: Training loss= 0.215863 Val loss= 1.107023 Training acc= 0.647840 Val acc= 0.647655\n",
            "Epoch 518: Training loss= 0.215510 Val loss= 1.105543 Training acc= 0.647945 Val acc= 0.647810\n",
            "Epoch 519: Training loss= 0.215158 Val loss= 1.104067 Training acc= 0.648025 Val acc= 0.647875\n",
            "Epoch 520: Training loss= 0.214808 Val loss= 1.102597 Training acc= 0.648155 Val acc= 0.648025\n",
            "Epoch 521: Training loss= 0.214459 Val loss= 1.101132 Training acc= 0.648300 Val acc= 0.648185\n",
            "Epoch 522: Training loss= 0.214112 Val loss= 1.099672 Training acc= 0.648470 Val acc= 0.648380\n",
            "Epoch 523: Training loss= 0.213767 Val loss= 1.098217 Training acc= 0.648610 Val acc= 0.648575\n",
            "Epoch 524: Training loss= 0.213423 Val loss= 1.096767 Training acc= 0.648660 Val acc= 0.648620\n",
            "Epoch 525: Training loss= 0.213080 Val loss= 1.095322 Training acc= 0.648830 Val acc= 0.648770\n",
            "Epoch 526: Training loss= 0.212740 Val loss= 1.093882 Training acc= 0.648940 Val acc= 0.648895\n",
            "Epoch 527: Training loss= 0.212400 Val loss= 1.092447 Training acc= 0.649065 Val acc= 0.648985\n",
            "Epoch 528: Training loss= 0.212063 Val loss= 1.091016 Training acc= 0.649160 Val acc= 0.649115\n",
            "Epoch 529: Training loss= 0.211726 Val loss= 1.089591 Training acc= 0.649260 Val acc= 0.649215\n",
            "Epoch 530: Training loss= 0.211392 Val loss= 1.088170 Training acc= 0.649345 Val acc= 0.649245\n",
            "Epoch 531: Training loss= 0.211058 Val loss= 1.086754 Training acc= 0.649475 Val acc= 0.649385\n",
            "Epoch 532: Training loss= 0.210727 Val loss= 1.085343 Training acc= 0.649630 Val acc= 0.649520\n",
            "Epoch 533: Training loss= 0.210396 Val loss= 1.083937 Training acc= 0.649770 Val acc= 0.649645\n",
            "Epoch 534: Training loss= 0.210068 Val loss= 1.082535 Training acc= 0.649885 Val acc= 0.649765\n",
            "Epoch 535: Training loss= 0.209740 Val loss= 1.081138 Training acc= 0.650000 Val acc= 0.649870\n",
            "Epoch 536: Training loss= 0.209415 Val loss= 1.079746 Training acc= 0.650120 Val acc= 0.649945\n",
            "Epoch 537: Training loss= 0.209090 Val loss= 1.078359 Training acc= 0.650235 Val acc= 0.650105\n",
            "Epoch 538: Training loss= 0.208767 Val loss= 1.076976 Training acc= 0.650325 Val acc= 0.650195\n",
            "Epoch 539: Training loss= 0.208446 Val loss= 1.075598 Training acc= 0.650465 Val acc= 0.650275\n",
            "Epoch 540: Training loss= 0.208125 Val loss= 1.074224 Training acc= 0.650580 Val acc= 0.650340\n",
            "Epoch 541: Training loss= 0.207807 Val loss= 1.072855 Training acc= 0.650675 Val acc= 0.650450\n",
            "Epoch 542: Training loss= 0.207489 Val loss= 1.071491 Training acc= 0.650760 Val acc= 0.650560\n",
            "Epoch 543: Training loss= 0.207174 Val loss= 1.070131 Training acc= 0.650865 Val acc= 0.650615\n",
            "Epoch 544: Training loss= 0.206859 Val loss= 1.068776 Training acc= 0.651045 Val acc= 0.650800\n",
            "Epoch 545: Training loss= 0.206546 Val loss= 1.067425 Training acc= 0.651165 Val acc= 0.650865\n",
            "Epoch 546: Training loss= 0.206234 Val loss= 1.066079 Training acc= 0.651250 Val acc= 0.650980\n",
            "Epoch 547: Training loss= 0.205924 Val loss= 1.064737 Training acc= 0.651375 Val acc= 0.651120\n",
            "Epoch 548: Training loss= 0.205615 Val loss= 1.063399 Training acc= 0.651450 Val acc= 0.651205\n",
            "Epoch 549: Training loss= 0.205307 Val loss= 1.062066 Training acc= 0.651555 Val acc= 0.651305\n",
            "Epoch 550: Training loss= 0.205001 Val loss= 1.060738 Training acc= 0.651680 Val acc= 0.651440\n",
            "Epoch 551: Training loss= 0.204696 Val loss= 1.059413 Training acc= 0.651780 Val acc= 0.651505\n",
            "Epoch 552: Training loss= 0.204392 Val loss= 1.058094 Training acc= 0.651925 Val acc= 0.651635\n",
            "Epoch 553: Training loss= 0.204089 Val loss= 1.056778 Training acc= 0.652060 Val acc= 0.651790\n",
            "Epoch 554: Training loss= 0.203788 Val loss= 1.055467 Training acc= 0.652210 Val acc= 0.651920\n",
            "Epoch 555: Training loss= 0.203489 Val loss= 1.054160 Training acc= 0.652305 Val acc= 0.651970\n",
            "Epoch 556: Training loss= 0.203190 Val loss= 1.052858 Training acc= 0.652395 Val acc= 0.652075\n",
            "Epoch 557: Training loss= 0.202893 Val loss= 1.051559 Training acc= 0.652560 Val acc= 0.652260\n",
            "Epoch 558: Training loss= 0.202597 Val loss= 1.050265 Training acc= 0.652695 Val acc= 0.652425\n",
            "Epoch 559: Training loss= 0.202302 Val loss= 1.048975 Training acc= 0.652805 Val acc= 0.652545\n",
            "Epoch 560: Training loss= 0.202009 Val loss= 1.047690 Training acc= 0.652820 Val acc= 0.652595\n",
            "Epoch 561: Training loss= 0.201717 Val loss= 1.046408 Training acc= 0.652940 Val acc= 0.652680\n",
            "Epoch 562: Training loss= 0.201426 Val loss= 1.045131 Training acc= 0.653170 Val acc= 0.652880\n",
            "Epoch 563: Training loss= 0.201136 Val loss= 1.043858 Training acc= 0.653250 Val acc= 0.652940\n",
            "Epoch 564: Training loss= 0.200848 Val loss= 1.042589 Training acc= 0.653375 Val acc= 0.653030\n",
            "Epoch 565: Training loss= 0.200561 Val loss= 1.041324 Training acc= 0.653505 Val acc= 0.653135\n",
            "Epoch 566: Training loss= 0.200275 Val loss= 1.040063 Training acc= 0.653600 Val acc= 0.653205\n",
            "Epoch 567: Training loss= 0.199990 Val loss= 1.038806 Training acc= 0.653735 Val acc= 0.653310\n",
            "Epoch 568: Training loss= 0.199707 Val loss= 1.037554 Training acc= 0.653835 Val acc= 0.653420\n",
            "Epoch 569: Training loss= 0.199425 Val loss= 1.036305 Training acc= 0.654015 Val acc= 0.653600\n",
            "Epoch 570: Training loss= 0.199144 Val loss= 1.035061 Training acc= 0.654190 Val acc= 0.653735\n",
            "Epoch 571: Training loss= 0.198864 Val loss= 1.033820 Training acc= 0.654385 Val acc= 0.653905\n",
            "Epoch 572: Training loss= 0.198585 Val loss= 1.032583 Training acc= 0.654520 Val acc= 0.654020\n",
            "Epoch 573: Training loss= 0.198307 Val loss= 1.031351 Training acc= 0.654630 Val acc= 0.654170\n",
            "Epoch 574: Training loss= 0.198031 Val loss= 1.030122 Training acc= 0.654710 Val acc= 0.654250\n",
            "Epoch 575: Training loss= 0.197756 Val loss= 1.028897 Training acc= 0.654820 Val acc= 0.654365\n",
            "Epoch 576: Training loss= 0.197482 Val loss= 1.027676 Training acc= 0.654965 Val acc= 0.654515\n",
            "Epoch 577: Training loss= 0.197209 Val loss= 1.026460 Training acc= 0.655075 Val acc= 0.654630\n",
            "Epoch 578: Training loss= 0.196937 Val loss= 1.025247 Training acc= 0.655200 Val acc= 0.654705\n",
            "Epoch 579: Training loss= 0.196667 Val loss= 1.024037 Training acc= 0.655275 Val acc= 0.654770\n",
            "Epoch 580: Training loss= 0.196397 Val loss= 1.022832 Training acc= 0.655355 Val acc= 0.654870\n",
            "Epoch 581: Training loss= 0.196129 Val loss= 1.021630 Training acc= 0.655450 Val acc= 0.654975\n",
            "Epoch 582: Training loss= 0.195862 Val loss= 1.020433 Training acc= 0.655590 Val acc= 0.655100\n",
            "Epoch 583: Training loss= 0.195596 Val loss= 1.019239 Training acc= 0.655705 Val acc= 0.655205\n",
            "Epoch 584: Training loss= 0.195331 Val loss= 1.018049 Training acc= 0.655820 Val acc= 0.655350\n",
            "Epoch 585: Training loss= 0.195067 Val loss= 1.016862 Training acc= 0.655920 Val acc= 0.655445\n",
            "Epoch 586: Training loss= 0.194804 Val loss= 1.015680 Training acc= 0.656065 Val acc= 0.655580\n",
            "Epoch 587: Training loss= 0.194542 Val loss= 1.014501 Training acc= 0.656105 Val acc= 0.655655\n",
            "Epoch 588: Training loss= 0.194282 Val loss= 1.013326 Training acc= 0.656165 Val acc= 0.655755\n",
            "Epoch 589: Training loss= 0.194022 Val loss= 1.012154 Training acc= 0.656270 Val acc= 0.655870\n",
            "Epoch 590: Training loss= 0.193764 Val loss= 1.010986 Training acc= 0.656330 Val acc= 0.655935\n",
            "Epoch 591: Training loss= 0.193506 Val loss= 1.009822 Training acc= 0.656465 Val acc= 0.656070\n",
            "Epoch 592: Training loss= 0.193250 Val loss= 1.008662 Training acc= 0.656545 Val acc= 0.656170\n",
            "Epoch 593: Training loss= 0.192995 Val loss= 1.007505 Training acc= 0.656710 Val acc= 0.656335\n",
            "Epoch 594: Training loss= 0.192740 Val loss= 1.006352 Training acc= 0.656755 Val acc= 0.656345\n",
            "Epoch 595: Training loss= 0.192487 Val loss= 1.005202 Training acc= 0.656905 Val acc= 0.656440\n",
            "Epoch 596: Training loss= 0.192235 Val loss= 1.004056 Training acc= 0.657000 Val acc= 0.656495\n",
            "Epoch 597: Training loss= 0.191984 Val loss= 1.002913 Training acc= 0.657105 Val acc= 0.656585\n",
            "Epoch 598: Training loss= 0.191734 Val loss= 1.001774 Training acc= 0.657220 Val acc= 0.656735\n",
            "Epoch 599: Training loss= 0.191485 Val loss= 1.000639 Training acc= 0.657310 Val acc= 0.656845\n",
            "Epoch 600: Training loss= 0.191237 Val loss= 0.999507 Training acc= 0.657440 Val acc= 0.656960\n",
            "Epoch 601: Training loss= 0.190990 Val loss= 0.998379 Training acc= 0.657570 Val acc= 0.657050\n",
            "Epoch 602: Training loss= 0.190744 Val loss= 0.997254 Training acc= 0.657700 Val acc= 0.657185\n",
            "Epoch 603: Training loss= 0.190499 Val loss= 0.996133 Training acc= 0.657770 Val acc= 0.657295\n",
            "Epoch 604: Training loss= 0.190255 Val loss= 0.995015 Training acc= 0.657865 Val acc= 0.657400\n",
            "Epoch 605: Training loss= 0.190012 Val loss= 0.993900 Training acc= 0.657945 Val acc= 0.657450\n",
            "Epoch 606: Training loss= 0.189770 Val loss= 0.992789 Training acc= 0.658010 Val acc= 0.657515\n",
            "Epoch 607: Training loss= 0.189529 Val loss= 0.991681 Training acc= 0.658070 Val acc= 0.657640\n",
            "Epoch 608: Training loss= 0.189288 Val loss= 0.990577 Training acc= 0.658145 Val acc= 0.657755\n",
            "Epoch 609: Training loss= 0.189049 Val loss= 0.989476 Training acc= 0.658235 Val acc= 0.657820\n",
            "Epoch 610: Training loss= 0.188811 Val loss= 0.988379 Training acc= 0.658285 Val acc= 0.657885\n",
            "Epoch 611: Training loss= 0.188574 Val loss= 0.987285 Training acc= 0.658425 Val acc= 0.658010\n",
            "Epoch 612: Training loss= 0.188338 Val loss= 0.986194 Training acc= 0.658535 Val acc= 0.658090\n",
            "Epoch 613: Training loss= 0.188102 Val loss= 0.985107 Training acc= 0.658620 Val acc= 0.658170\n",
            "Epoch 614: Training loss= 0.187868 Val loss= 0.984023 Training acc= 0.658745 Val acc= 0.658320\n",
            "Epoch 615: Training loss= 0.187635 Val loss= 0.982942 Training acc= 0.658895 Val acc= 0.658460\n",
            "Epoch 616: Training loss= 0.187402 Val loss= 0.981864 Training acc= 0.659050 Val acc= 0.658595\n",
            "Epoch 617: Training loss= 0.187170 Val loss= 0.980790 Training acc= 0.659120 Val acc= 0.658670\n",
            "Epoch 618: Training loss= 0.186940 Val loss= 0.979719 Training acc= 0.659195 Val acc= 0.658805\n",
            "Epoch 619: Training loss= 0.186710 Val loss= 0.978651 Training acc= 0.659300 Val acc= 0.658910\n",
            "Epoch 620: Training loss= 0.186481 Val loss= 0.977587 Training acc= 0.659410 Val acc= 0.658990\n",
            "Epoch 621: Training loss= 0.186253 Val loss= 0.976526 Training acc= 0.659485 Val acc= 0.659070\n",
            "Epoch 622: Training loss= 0.186026 Val loss= 0.975468 Training acc= 0.659595 Val acc= 0.659185\n",
            "Epoch 623: Training loss= 0.185800 Val loss= 0.974413 Training acc= 0.659755 Val acc= 0.659380\n",
            "Epoch 624: Training loss= 0.185575 Val loss= 0.973361 Training acc= 0.659840 Val acc= 0.659475\n",
            "Epoch 625: Training loss= 0.185351 Val loss= 0.972312 Training acc= 0.659950 Val acc= 0.659575\n",
            "Epoch 626: Training loss= 0.185127 Val loss= 0.971267 Training acc= 0.660025 Val acc= 0.659655\n",
            "Epoch 627: Training loss= 0.184905 Val loss= 0.970225 Training acc= 0.660150 Val acc= 0.659770\n",
            "Epoch 628: Training loss= 0.184683 Val loss= 0.969186 Training acc= 0.660240 Val acc= 0.659870\n",
            "Epoch 629: Training loss= 0.184462 Val loss= 0.968150 Training acc= 0.660410 Val acc= 0.660005\n",
            "Epoch 630: Training loss= 0.184242 Val loss= 0.967117 Training acc= 0.660495 Val acc= 0.660085\n",
            "Epoch 631: Training loss= 0.184023 Val loss= 0.966087 Training acc= 0.660615 Val acc= 0.660225\n",
            "Epoch 632: Training loss= 0.183805 Val loss= 0.965060 Training acc= 0.660740 Val acc= 0.660315\n",
            "Epoch 633: Training loss= 0.183588 Val loss= 0.964037 Training acc= 0.660850 Val acc= 0.660475\n",
            "Epoch 634: Training loss= 0.183371 Val loss= 0.963016 Training acc= 0.660930 Val acc= 0.660535\n",
            "Epoch 635: Training loss= 0.183156 Val loss= 0.961999 Training acc= 0.661075 Val acc= 0.660695\n",
            "Epoch 636: Training loss= 0.182941 Val loss= 0.960984 Training acc= 0.661175 Val acc= 0.660800\n",
            "Epoch 637: Training loss= 0.182727 Val loss= 0.959972 Training acc= 0.661285 Val acc= 0.660930\n",
            "Epoch 638: Training loss= 0.182514 Val loss= 0.958964 Training acc= 0.661400 Val acc= 0.661020\n",
            "Epoch 639: Training loss= 0.182301 Val loss= 0.957958 Training acc= 0.661520 Val acc= 0.661130\n",
            "Epoch 640: Training loss= 0.182090 Val loss= 0.956956 Training acc= 0.661690 Val acc= 0.661305\n",
            "Epoch 641: Training loss= 0.181879 Val loss= 0.955956 Training acc= 0.661785 Val acc= 0.661405\n",
            "Epoch 642: Training loss= 0.181669 Val loss= 0.954959 Training acc= 0.661860 Val acc= 0.661500\n",
            "Epoch 643: Training loss= 0.181460 Val loss= 0.953966 Training acc= 0.662015 Val acc= 0.661645\n",
            "Epoch 644: Training loss= 0.181252 Val loss= 0.952975 Training acc= 0.662105 Val acc= 0.661755\n",
            "Epoch 645: Training loss= 0.181045 Val loss= 0.951987 Training acc= 0.662225 Val acc= 0.661845\n",
            "Epoch 646: Training loss= 0.180838 Val loss= 0.951002 Training acc= 0.662320 Val acc= 0.661925\n",
            "Epoch 647: Training loss= 0.180632 Val loss= 0.950020 Training acc= 0.662450 Val acc= 0.662065\n",
            "Epoch 648: Training loss= 0.180427 Val loss= 0.949041 Training acc= 0.662500 Val acc= 0.662150\n",
            "Epoch 649: Training loss= 0.180223 Val loss= 0.948064 Training acc= 0.662545 Val acc= 0.662195\n",
            "Epoch 650: Training loss= 0.180019 Val loss= 0.947091 Training acc= 0.662670 Val acc= 0.662325\n",
            "Epoch 651: Training loss= 0.179816 Val loss= 0.946120 Training acc= 0.662790 Val acc= 0.662470\n",
            "Epoch 652: Training loss= 0.179615 Val loss= 0.945152 Training acc= 0.662845 Val acc= 0.662550\n",
            "Epoch 653: Training loss= 0.179413 Val loss= 0.944187 Training acc= 0.663010 Val acc= 0.662670\n",
            "Epoch 654: Training loss= 0.179213 Val loss= 0.943225 Training acc= 0.663140 Val acc= 0.662760\n",
            "Epoch 655: Training loss= 0.179013 Val loss= 0.942266 Training acc= 0.663245 Val acc= 0.662875\n",
            "Epoch 656: Training loss= 0.178814 Val loss= 0.941309 Training acc= 0.663335 Val acc= 0.662995\n",
            "Epoch 657: Training loss= 0.178616 Val loss= 0.940355 Training acc= 0.663410 Val acc= 0.663110\n",
            "Epoch 658: Training loss= 0.178419 Val loss= 0.939404 Training acc= 0.663465 Val acc= 0.663165\n",
            "Epoch 659: Training loss= 0.178222 Val loss= 0.938456 Training acc= 0.663585 Val acc= 0.663260\n",
            "Epoch 660: Training loss= 0.178026 Val loss= 0.937510 Training acc= 0.663740 Val acc= 0.663405\n",
            "Epoch 661: Training loss= 0.177831 Val loss= 0.936567 Training acc= 0.663830 Val acc= 0.663480\n",
            "Epoch 662: Training loss= 0.177637 Val loss= 0.935627 Training acc= 0.663915 Val acc= 0.663570\n",
            "Epoch 663: Training loss= 0.177443 Val loss= 0.934690 Training acc= 0.664010 Val acc= 0.663700\n",
            "Epoch 664: Training loss= 0.177250 Val loss= 0.933755 Training acc= 0.664160 Val acc= 0.663815\n",
            "Epoch 665: Training loss= 0.177058 Val loss= 0.932823 Training acc= 0.664280 Val acc= 0.663945\n",
            "Epoch 666: Training loss= 0.176867 Val loss= 0.931893 Training acc= 0.664340 Val acc= 0.664015\n",
            "Epoch 667: Training loss= 0.176676 Val loss= 0.930967 Training acc= 0.664430 Val acc= 0.664075\n",
            "Epoch 668: Training loss= 0.176486 Val loss= 0.930043 Training acc= 0.664590 Val acc= 0.664245\n",
            "Epoch 669: Training loss= 0.176296 Val loss= 0.929121 Training acc= 0.664670 Val acc= 0.664340\n",
            "Epoch 670: Training loss= 0.176108 Val loss= 0.928202 Training acc= 0.664860 Val acc= 0.664510\n",
            "Epoch 671: Training loss= 0.175920 Val loss= 0.927286 Training acc= 0.664910 Val acc= 0.664565\n",
            "Epoch 672: Training loss= 0.175733 Val loss= 0.926373 Training acc= 0.665025 Val acc= 0.664665\n",
            "Epoch 673: Training loss= 0.175546 Val loss= 0.925462 Training acc= 0.665080 Val acc= 0.664735\n",
            "Epoch 674: Training loss= 0.175360 Val loss= 0.924553 Training acc= 0.665145 Val acc= 0.664810\n",
            "Epoch 675: Training loss= 0.175175 Val loss= 0.923647 Training acc= 0.665190 Val acc= 0.664840\n",
            "Epoch 676: Training loss= 0.174991 Val loss= 0.922744 Training acc= 0.665215 Val acc= 0.664840\n",
            "Epoch 677: Training loss= 0.174807 Val loss= 0.921843 Training acc= 0.665260 Val acc= 0.664870\n",
            "Epoch 678: Training loss= 0.174624 Val loss= 0.920945 Training acc= 0.665380 Val acc= 0.664985\n",
            "Epoch 679: Training loss= 0.174441 Val loss= 0.920050 Training acc= 0.665500 Val acc= 0.665100\n",
            "Epoch 680: Training loss= 0.174259 Val loss= 0.919157 Training acc= 0.665555 Val acc= 0.665175\n",
            "Epoch 681: Training loss= 0.174078 Val loss= 0.918266 Training acc= 0.665640 Val acc= 0.665285\n",
            "Epoch 682: Training loss= 0.173898 Val loss= 0.917378 Training acc= 0.665700 Val acc= 0.665370\n",
            "Epoch 683: Training loss= 0.173718 Val loss= 0.916492 Training acc= 0.665850 Val acc= 0.665510\n",
            "Epoch 684: Training loss= 0.173539 Val loss= 0.915609 Training acc= 0.666055 Val acc= 0.665725\n",
            "Epoch 685: Training loss= 0.173361 Val loss= 0.914729 Training acc= 0.666225 Val acc= 0.665890\n",
            "Epoch 686: Training loss= 0.173183 Val loss= 0.913851 Training acc= 0.666250 Val acc= 0.665915\n",
            "Epoch 687: Training loss= 0.173006 Val loss= 0.912975 Training acc= 0.666380 Val acc= 0.666045\n",
            "Epoch 688: Training loss= 0.172829 Val loss= 0.912102 Training acc= 0.666450 Val acc= 0.666100\n",
            "Epoch 689: Training loss= 0.172653 Val loss= 0.911231 Training acc= 0.666570 Val acc= 0.666245\n",
            "Epoch 690: Training loss= 0.172478 Val loss= 0.910362 Training acc= 0.666635 Val acc= 0.666315\n",
            "Epoch 691: Training loss= 0.172304 Val loss= 0.909497 Training acc= 0.666685 Val acc= 0.666380\n",
            "Epoch 692: Training loss= 0.172130 Val loss= 0.908633 Training acc= 0.666750 Val acc= 0.666450\n",
            "Epoch 693: Training loss= 0.171956 Val loss= 0.907772 Training acc= 0.666850 Val acc= 0.666555\n",
            "Epoch 694: Training loss= 0.171784 Val loss= 0.906913 Training acc= 0.666910 Val acc= 0.666630\n",
            "Epoch 695: Training loss= 0.171612 Val loss= 0.906057 Training acc= 0.667015 Val acc= 0.666720\n",
            "Epoch 696: Training loss= 0.171440 Val loss= 0.905203 Training acc= 0.667090 Val acc= 0.666830\n",
            "Epoch 697: Training loss= 0.171269 Val loss= 0.904351 Training acc= 0.667180 Val acc= 0.666905\n",
            "Epoch 698: Training loss= 0.171099 Val loss= 0.903502 Training acc= 0.667270 Val acc= 0.666975\n",
            "Epoch 699: Training loss= 0.170930 Val loss= 0.902655 Training acc= 0.667390 Val acc= 0.667100\n",
            "Epoch 700: Training loss= 0.170761 Val loss= 0.901810 Training acc= 0.667535 Val acc= 0.667240\n",
            "Epoch 701: Training loss= 0.170592 Val loss= 0.900968 Training acc= 0.667655 Val acc= 0.667315\n",
            "Epoch 702: Training loss= 0.170425 Val loss= 0.900128 Training acc= 0.667720 Val acc= 0.667385\n",
            "Epoch 703: Training loss= 0.170258 Val loss= 0.899290 Training acc= 0.667810 Val acc= 0.667495\n",
            "Epoch 704: Training loss= 0.170091 Val loss= 0.898455 Training acc= 0.667900 Val acc= 0.667625\n",
            "Epoch 705: Training loss= 0.169925 Val loss= 0.897622 Training acc= 0.668060 Val acc= 0.667750\n",
            "Epoch 706: Training loss= 0.169760 Val loss= 0.896791 Training acc= 0.668160 Val acc= 0.667865\n",
            "Epoch 707: Training loss= 0.169595 Val loss= 0.895963 Training acc= 0.668245 Val acc= 0.667955\n",
            "Epoch 708: Training loss= 0.169431 Val loss= 0.895136 Training acc= 0.668320 Val acc= 0.667995\n",
            "Epoch 709: Training loss= 0.169267 Val loss= 0.894312 Training acc= 0.668430 Val acc= 0.668100\n",
            "Epoch 710: Training loss= 0.169104 Val loss= 0.893491 Training acc= 0.668520 Val acc= 0.668200\n",
            "Epoch 711: Training loss= 0.168942 Val loss= 0.892671 Training acc= 0.668585 Val acc= 0.668235\n",
            "Epoch 712: Training loss= 0.168780 Val loss= 0.891854 Training acc= 0.668680 Val acc= 0.668345\n",
            "Epoch 713: Training loss= 0.168619 Val loss= 0.891039 Training acc= 0.668750 Val acc= 0.668440\n",
            "Epoch 714: Training loss= 0.168458 Val loss= 0.890226 Training acc= 0.668825 Val acc= 0.668485\n",
            "Epoch 715: Training loss= 0.168298 Val loss= 0.889415 Training acc= 0.668950 Val acc= 0.668610\n",
            "Epoch 716: Training loss= 0.168138 Val loss= 0.888607 Training acc= 0.669065 Val acc= 0.668710\n",
            "Epoch 717: Training loss= 0.167979 Val loss= 0.887801 Training acc= 0.669110 Val acc= 0.668755\n",
            "Epoch 718: Training loss= 0.167821 Val loss= 0.886996 Training acc= 0.669175 Val acc= 0.668855\n",
            "Epoch 719: Training loss= 0.167663 Val loss= 0.886194 Training acc= 0.669230 Val acc= 0.668880\n",
            "Epoch 720: Training loss= 0.167505 Val loss= 0.885395 Training acc= 0.669330 Val acc= 0.668970\n",
            "Epoch 721: Training loss= 0.167349 Val loss= 0.884597 Training acc= 0.669430 Val acc= 0.669050\n",
            "Epoch 722: Training loss= 0.167192 Val loss= 0.883802 Training acc= 0.669530 Val acc= 0.669145\n",
            "Epoch 723: Training loss= 0.167037 Val loss= 0.883008 Training acc= 0.669655 Val acc= 0.669255\n",
            "Epoch 724: Training loss= 0.166882 Val loss= 0.882217 Training acc= 0.669735 Val acc= 0.669330\n",
            "Epoch 725: Training loss= 0.166727 Val loss= 0.881428 Training acc= 0.669840 Val acc= 0.669410\n",
            "Epoch 726: Training loss= 0.166573 Val loss= 0.880641 Training acc= 0.669950 Val acc= 0.669505\n",
            "Epoch 727: Training loss= 0.166419 Val loss= 0.879856 Training acc= 0.670060 Val acc= 0.669580\n",
            "Epoch 728: Training loss= 0.166266 Val loss= 0.879073 Training acc= 0.670165 Val acc= 0.669700\n",
            "Epoch 729: Training loss= 0.166114 Val loss= 0.878292 Training acc= 0.670280 Val acc= 0.669780\n",
            "Epoch 730: Training loss= 0.165962 Val loss= 0.877514 Training acc= 0.670375 Val acc= 0.669850\n",
            "Epoch 731: Training loss= 0.165811 Val loss= 0.876737 Training acc= 0.670430 Val acc= 0.669950\n",
            "Epoch 732: Training loss= 0.165660 Val loss= 0.875963 Training acc= 0.670495 Val acc= 0.670050\n",
            "Epoch 733: Training loss= 0.165509 Val loss= 0.875190 Training acc= 0.670590 Val acc= 0.670140\n",
            "Epoch 734: Training loss= 0.165359 Val loss= 0.874420 Training acc= 0.670625 Val acc= 0.670165\n",
            "Epoch 735: Training loss= 0.165210 Val loss= 0.873651 Training acc= 0.670680 Val acc= 0.670235\n",
            "Epoch 736: Training loss= 0.165061 Val loss= 0.872885 Training acc= 0.670820 Val acc= 0.670370\n",
            "Epoch 737: Training loss= 0.164913 Val loss= 0.872121 Training acc= 0.670900 Val acc= 0.670425\n",
            "Epoch 738: Training loss= 0.164765 Val loss= 0.871358 Training acc= 0.670985 Val acc= 0.670505\n",
            "Epoch 739: Training loss= 0.164618 Val loss= 0.870598 Training acc= 0.671055 Val acc= 0.670590\n",
            "Epoch 740: Training loss= 0.164471 Val loss= 0.869840 Training acc= 0.671150 Val acc= 0.670690\n",
            "Epoch 741: Training loss= 0.164325 Val loss= 0.869084 Training acc= 0.671235 Val acc= 0.670785\n",
            "Epoch 742: Training loss= 0.164179 Val loss= 0.868329 Training acc= 0.671350 Val acc= 0.670905\n",
            "Epoch 743: Training loss= 0.164034 Val loss= 0.867577 Training acc= 0.671475 Val acc= 0.671035\n",
            "Epoch 744: Training loss= 0.163889 Val loss= 0.866826 Training acc= 0.671540 Val acc= 0.671130\n",
            "Epoch 745: Training loss= 0.163745 Val loss= 0.866078 Training acc= 0.671635 Val acc= 0.671220\n",
            "Epoch 746: Training loss= 0.163601 Val loss= 0.865332 Training acc= 0.671735 Val acc= 0.671330\n",
            "Epoch 747: Training loss= 0.163458 Val loss= 0.864587 Training acc= 0.671840 Val acc= 0.671455\n",
            "Epoch 748: Training loss= 0.163315 Val loss= 0.863844 Training acc= 0.671910 Val acc= 0.671530\n",
            "Epoch 749: Training loss= 0.163173 Val loss= 0.863104 Training acc= 0.672025 Val acc= 0.671650\n",
            "Epoch 750: Training loss= 0.163031 Val loss= 0.862365 Training acc= 0.672100 Val acc= 0.671765\n",
            "Epoch 751: Training loss= 0.162889 Val loss= 0.861628 Training acc= 0.672195 Val acc= 0.671880\n",
            "Epoch 752: Training loss= 0.162748 Val loss= 0.860893 Training acc= 0.672160 Val acc= 0.671910\n",
            "Epoch 753: Training loss= 0.162608 Val loss= 0.860160 Training acc= 0.672210 Val acc= 0.671990\n",
            "Epoch 754: Training loss= 0.162468 Val loss= 0.859429 Training acc= 0.672310 Val acc= 0.672075\n",
            "Epoch 755: Training loss= 0.162329 Val loss= 0.858700 Training acc= 0.672395 Val acc= 0.672120\n",
            "Epoch 756: Training loss= 0.162190 Val loss= 0.857973 Training acc= 0.672440 Val acc= 0.672220\n",
            "Epoch 757: Training loss= 0.162051 Val loss= 0.857247 Training acc= 0.672545 Val acc= 0.672300\n",
            "Epoch 758: Training loss= 0.161913 Val loss= 0.856524 Training acc= 0.672650 Val acc= 0.672390\n",
            "Epoch 759: Training loss= 0.161775 Val loss= 0.855802 Training acc= 0.672690 Val acc= 0.672430\n",
            "Epoch 760: Training loss= 0.161638 Val loss= 0.855082 Training acc= 0.672735 Val acc= 0.672490\n",
            "Epoch 761: Training loss= 0.161502 Val loss= 0.854364 Training acc= 0.672860 Val acc= 0.672585\n",
            "Epoch 762: Training loss= 0.161365 Val loss= 0.853648 Training acc= 0.672980 Val acc= 0.672690\n",
            "Epoch 763: Training loss= 0.161230 Val loss= 0.852934 Training acc= 0.673045 Val acc= 0.672735\n",
            "Epoch 764: Training loss= 0.161094 Val loss= 0.852221 Training acc= 0.673080 Val acc= 0.672795\n",
            "Epoch 765: Training loss= 0.160959 Val loss= 0.851510 Training acc= 0.673205 Val acc= 0.672900\n",
            "Epoch 766: Training loss= 0.160825 Val loss= 0.850802 Training acc= 0.673305 Val acc= 0.673000\n",
            "Epoch 767: Training loss= 0.160691 Val loss= 0.850094 Training acc= 0.673370 Val acc= 0.673065\n",
            "Epoch 768: Training loss= 0.160557 Val loss= 0.849389 Training acc= 0.673425 Val acc= 0.673145\n",
            "Epoch 769: Training loss= 0.160424 Val loss= 0.848686 Training acc= 0.673515 Val acc= 0.673230\n",
            "Epoch 770: Training loss= 0.160292 Val loss= 0.847984 Training acc= 0.673630 Val acc= 0.673370\n",
            "Epoch 771: Training loss= 0.160159 Val loss= 0.847284 Training acc= 0.673700 Val acc= 0.673410\n",
            "Epoch 772: Training loss= 0.160028 Val loss= 0.846586 Training acc= 0.673785 Val acc= 0.673515\n",
            "Epoch 773: Training loss= 0.159896 Val loss= 0.845889 Training acc= 0.673890 Val acc= 0.673590\n",
            "Epoch 774: Training loss= 0.159765 Val loss= 0.845195 Training acc= 0.673945 Val acc= 0.673665\n",
            "Epoch 775: Training loss= 0.159635 Val loss= 0.844502 Training acc= 0.674015 Val acc= 0.673735\n",
            "Epoch 776: Training loss= 0.159505 Val loss= 0.843811 Training acc= 0.674075 Val acc= 0.673795\n",
            "Epoch 777: Training loss= 0.159375 Val loss= 0.843121 Training acc= 0.674135 Val acc= 0.673910\n",
            "Epoch 778: Training loss= 0.159246 Val loss= 0.842434 Training acc= 0.674190 Val acc= 0.673940\n",
            "Epoch 779: Training loss= 0.159117 Val loss= 0.841748 Training acc= 0.674270 Val acc= 0.674000\n",
            "Epoch 780: Training loss= 0.158989 Val loss= 0.841064 Training acc= 0.674370 Val acc= 0.674130\n",
            "Epoch 781: Training loss= 0.158861 Val loss= 0.840381 Training acc= 0.674445 Val acc= 0.674200\n",
            "Epoch 782: Training loss= 0.158734 Val loss= 0.839700 Training acc= 0.674535 Val acc= 0.674290\n",
            "Epoch 783: Training loss= 0.158606 Val loss= 0.839021 Training acc= 0.674645 Val acc= 0.674395\n",
            "Epoch 784: Training loss= 0.158480 Val loss= 0.838344 Training acc= 0.674700 Val acc= 0.674440\n",
            "Epoch 785: Training loss= 0.158353 Val loss= 0.837668 Training acc= 0.674770 Val acc= 0.674520\n",
            "Epoch 786: Training loss= 0.158228 Val loss= 0.836994 Training acc= 0.674875 Val acc= 0.674605\n",
            "Epoch 787: Training loss= 0.158102 Val loss= 0.836322 Training acc= 0.674970 Val acc= 0.674715\n",
            "Epoch 788: Training loss= 0.157977 Val loss= 0.835651 Training acc= 0.675030 Val acc= 0.674775\n",
            "Epoch 789: Training loss= 0.157852 Val loss= 0.834982 Training acc= 0.675100 Val acc= 0.674800\n",
            "Epoch 790: Training loss= 0.157728 Val loss= 0.834315 Training acc= 0.675180 Val acc= 0.674895\n",
            "Epoch 791: Training loss= 0.157604 Val loss= 0.833649 Training acc= 0.675250 Val acc= 0.674950\n",
            "Epoch 792: Training loss= 0.157481 Val loss= 0.832985 Training acc= 0.675360 Val acc= 0.675050\n",
            "Epoch 793: Training loss= 0.157358 Val loss= 0.832323 Training acc= 0.675430 Val acc= 0.675135\n",
            "Epoch 794: Training loss= 0.157235 Val loss= 0.831662 Training acc= 0.675495 Val acc= 0.675200\n",
            "Epoch 795: Training loss= 0.157113 Val loss= 0.831003 Training acc= 0.675600 Val acc= 0.675290\n",
            "Epoch 796: Training loss= 0.156991 Val loss= 0.830345 Training acc= 0.675680 Val acc= 0.675380\n",
            "Epoch 797: Training loss= 0.156870 Val loss= 0.829689 Training acc= 0.675710 Val acc= 0.675460\n",
            "Epoch 798: Training loss= 0.156748 Val loss= 0.829035 Training acc= 0.675805 Val acc= 0.675545\n",
            "Epoch 799: Training loss= 0.156628 Val loss= 0.828382 Training acc= 0.675915 Val acc= 0.675640\n",
            "Epoch 800: Training loss= 0.156507 Val loss= 0.827731 Training acc= 0.675980 Val acc= 0.675745\n",
            "Epoch 801: Training loss= 0.156387 Val loss= 0.827082 Training acc= 0.676010 Val acc= 0.675760\n",
            "Epoch 802: Training loss= 0.156268 Val loss= 0.826434 Training acc= 0.676060 Val acc= 0.675825\n",
            "Epoch 803: Training loss= 0.156149 Val loss= 0.825787 Training acc= 0.676100 Val acc= 0.675875\n",
            "Epoch 804: Training loss= 0.156030 Val loss= 0.825143 Training acc= 0.676205 Val acc= 0.675935\n",
            "Epoch 805: Training loss= 0.155912 Val loss= 0.824500 Training acc= 0.676280 Val acc= 0.675975\n",
            "Epoch 806: Training loss= 0.155794 Val loss= 0.823858 Training acc= 0.676365 Val acc= 0.676075\n",
            "Epoch 807: Training loss= 0.155676 Val loss= 0.823218 Training acc= 0.676445 Val acc= 0.676155\n",
            "Epoch 808: Training loss= 0.155559 Val loss= 0.822579 Training acc= 0.676550 Val acc= 0.676240\n",
            "Epoch 809: Training loss= 0.155442 Val loss= 0.821942 Training acc= 0.676600 Val acc= 0.676310\n",
            "Epoch 810: Training loss= 0.155325 Val loss= 0.821307 Training acc= 0.676695 Val acc= 0.676375\n",
            "Epoch 811: Training loss= 0.155209 Val loss= 0.820673 Training acc= 0.676760 Val acc= 0.676455\n",
            "Epoch 812: Training loss= 0.155093 Val loss= 0.820041 Training acc= 0.676900 Val acc= 0.676575\n",
            "Epoch 813: Training loss= 0.154978 Val loss= 0.819410 Training acc= 0.676995 Val acc= 0.676620\n",
            "Epoch 814: Training loss= 0.154862 Val loss= 0.818781 Training acc= 0.677095 Val acc= 0.676705\n",
            "Epoch 815: Training loss= 0.154748 Val loss= 0.818153 Training acc= 0.677145 Val acc= 0.676740\n",
            "Epoch 816: Training loss= 0.154633 Val loss= 0.817526 Training acc= 0.677175 Val acc= 0.676780\n",
            "Epoch 817: Training loss= 0.154519 Val loss= 0.816902 Training acc= 0.677195 Val acc= 0.676790\n",
            "Epoch 818: Training loss= 0.154406 Val loss= 0.816278 Training acc= 0.677305 Val acc= 0.676915\n",
            "Epoch 819: Training loss= 0.154292 Val loss= 0.815657 Training acc= 0.677405 Val acc= 0.677005\n",
            "Epoch 820: Training loss= 0.154179 Val loss= 0.815036 Training acc= 0.677445 Val acc= 0.677020\n",
            "Epoch 821: Training loss= 0.154067 Val loss= 0.814417 Training acc= 0.677485 Val acc= 0.677040\n",
            "Epoch 822: Training loss= 0.153955 Val loss= 0.813800 Training acc= 0.677595 Val acc= 0.677165\n",
            "Epoch 823: Training loss= 0.153843 Val loss= 0.813184 Training acc= 0.677670 Val acc= 0.677240\n",
            "Epoch 824: Training loss= 0.153731 Val loss= 0.812570 Training acc= 0.677750 Val acc= 0.677350\n",
            "Epoch 825: Training loss= 0.153620 Val loss= 0.811957 Training acc= 0.677820 Val acc= 0.677395\n",
            "Epoch 826: Training loss= 0.153509 Val loss= 0.811345 Training acc= 0.677900 Val acc= 0.677475\n",
            "Epoch 827: Training loss= 0.153398 Val loss= 0.810735 Training acc= 0.677960 Val acc= 0.677550\n",
            "Epoch 828: Training loss= 0.153288 Val loss= 0.810127 Training acc= 0.677965 Val acc= 0.677570\n",
            "Epoch 829: Training loss= 0.153178 Val loss= 0.809520 Training acc= 0.678010 Val acc= 0.677600\n",
            "Epoch 830: Training loss= 0.153069 Val loss= 0.808914 Training acc= 0.678120 Val acc= 0.677690\n",
            "Epoch 831: Training loss= 0.152960 Val loss= 0.808310 Training acc= 0.678200 Val acc= 0.677795\n",
            "Epoch 832: Training loss= 0.152851 Val loss= 0.807707 Training acc= 0.678330 Val acc= 0.677895\n",
            "Epoch 833: Training loss= 0.152742 Val loss= 0.807105 Training acc= 0.678310 Val acc= 0.677905\n",
            "Epoch 834: Training loss= 0.152634 Val loss= 0.806505 Training acc= 0.678425 Val acc= 0.678020\n",
            "Epoch 835: Training loss= 0.152526 Val loss= 0.805907 Training acc= 0.678500 Val acc= 0.678095\n",
            "Epoch 836: Training loss= 0.152419 Val loss= 0.805309 Training acc= 0.678570 Val acc= 0.678165\n",
            "Epoch 837: Training loss= 0.152312 Val loss= 0.804714 Training acc= 0.678610 Val acc= 0.678230\n",
            "Epoch 838: Training loss= 0.152205 Val loss= 0.804119 Training acc= 0.678675 Val acc= 0.678295\n",
            "Epoch 839: Training loss= 0.152098 Val loss= 0.803526 Training acc= 0.678750 Val acc= 0.678335\n",
            "Epoch 840: Training loss= 0.151992 Val loss= 0.802934 Training acc= 0.678785 Val acc= 0.678365\n",
            "Epoch 841: Training loss= 0.151886 Val loss= 0.802344 Training acc= 0.678855 Val acc= 0.678455\n",
            "Epoch 842: Training loss= 0.151781 Val loss= 0.801755 Training acc= 0.678960 Val acc= 0.678550\n",
            "Epoch 843: Training loss= 0.151675 Val loss= 0.801168 Training acc= 0.678995 Val acc= 0.678610\n",
            "Epoch 844: Training loss= 0.151570 Val loss= 0.800581 Training acc= 0.679055 Val acc= 0.678665\n",
            "Epoch 845: Training loss= 0.151466 Val loss= 0.799997 Training acc= 0.679125 Val acc= 0.678745\n",
            "Epoch 846: Training loss= 0.151362 Val loss= 0.799413 Training acc= 0.679205 Val acc= 0.678845\n",
            "Epoch 847: Training loss= 0.151258 Val loss= 0.798831 Training acc= 0.679320 Val acc= 0.678950\n",
            "Epoch 848: Training loss= 0.151154 Val loss= 0.798250 Training acc= 0.679370 Val acc= 0.679015\n",
            "Epoch 849: Training loss= 0.151051 Val loss= 0.797671 Training acc= 0.679435 Val acc= 0.679065\n",
            "Epoch 850: Training loss= 0.150948 Val loss= 0.797093 Training acc= 0.679510 Val acc= 0.679200\n",
            "Epoch 851: Training loss= 0.150845 Val loss= 0.796516 Training acc= 0.679650 Val acc= 0.679365\n",
            "Epoch 852: Training loss= 0.150742 Val loss= 0.795941 Training acc= 0.679715 Val acc= 0.679460\n",
            "Epoch 853: Training loss= 0.150640 Val loss= 0.795367 Training acc= 0.679770 Val acc= 0.679490\n",
            "Epoch 854: Training loss= 0.150538 Val loss= 0.794794 Training acc= 0.679860 Val acc= 0.679625\n",
            "Epoch 855: Training loss= 0.150437 Val loss= 0.794222 Training acc= 0.679885 Val acc= 0.679655\n",
            "Epoch 856: Training loss= 0.150336 Val loss= 0.793652 Training acc= 0.679970 Val acc= 0.679750\n",
            "Epoch 857: Training loss= 0.150235 Val loss= 0.793083 Training acc= 0.680045 Val acc= 0.679845\n",
            "Epoch 858: Training loss= 0.150134 Val loss= 0.792516 Training acc= 0.680135 Val acc= 0.679935\n",
            "Epoch 859: Training loss= 0.150034 Val loss= 0.791950 Training acc= 0.680240 Val acc= 0.680060\n",
            "Epoch 860: Training loss= 0.149934 Val loss= 0.791385 Training acc= 0.680295 Val acc= 0.680110\n",
            "Epoch 861: Training loss= 0.149834 Val loss= 0.790821 Training acc= 0.680385 Val acc= 0.680230\n",
            "Epoch 862: Training loss= 0.149735 Val loss= 0.790258 Training acc= 0.680425 Val acc= 0.680260\n",
            "Epoch 863: Training loss= 0.149636 Val loss= 0.789697 Training acc= 0.680495 Val acc= 0.680315\n",
            "Epoch 864: Training loss= 0.149537 Val loss= 0.789137 Training acc= 0.680590 Val acc= 0.680375\n",
            "Epoch 865: Training loss= 0.149438 Val loss= 0.788579 Training acc= 0.680600 Val acc= 0.680390\n",
            "Epoch 866: Training loss= 0.149340 Val loss= 0.788022 Training acc= 0.680670 Val acc= 0.680465\n",
            "Epoch 867: Training loss= 0.149242 Val loss= 0.787466 Training acc= 0.680730 Val acc= 0.680530\n",
            "Epoch 868: Training loss= 0.149144 Val loss= 0.786911 Training acc= 0.680780 Val acc= 0.680590\n",
            "Epoch 869: Training loss= 0.149047 Val loss= 0.786357 Training acc= 0.680815 Val acc= 0.680620\n",
            "Epoch 870: Training loss= 0.148950 Val loss= 0.785805 Training acc= 0.680880 Val acc= 0.680670\n",
            "Epoch 871: Training loss= 0.148853 Val loss= 0.785254 Training acc= 0.680925 Val acc= 0.680715\n",
            "Epoch 872: Training loss= 0.148757 Val loss= 0.784704 Training acc= 0.681000 Val acc= 0.680775\n",
            "Epoch 873: Training loss= 0.148660 Val loss= 0.784155 Training acc= 0.681095 Val acc= 0.680875\n",
            "Epoch 874: Training loss= 0.148564 Val loss= 0.783608 Training acc= 0.681180 Val acc= 0.680950\n",
            "Epoch 875: Training loss= 0.148469 Val loss= 0.783062 Training acc= 0.681265 Val acc= 0.681050\n",
            "Epoch 876: Training loss= 0.148373 Val loss= 0.782517 Training acc= 0.681290 Val acc= 0.681075\n",
            "Epoch 877: Training loss= 0.148278 Val loss= 0.781973 Training acc= 0.681340 Val acc= 0.681120\n",
            "Epoch 878: Training loss= 0.148183 Val loss= 0.781431 Training acc= 0.681430 Val acc= 0.681160\n",
            "Epoch 879: Training loss= 0.148089 Val loss= 0.780889 Training acc= 0.681520 Val acc= 0.681250\n",
            "Epoch 880: Training loss= 0.147994 Val loss= 0.780349 Training acc= 0.681630 Val acc= 0.681365\n",
            "Epoch 881: Training loss= 0.147900 Val loss= 0.779810 Training acc= 0.681675 Val acc= 0.681415\n",
            "Epoch 882: Training loss= 0.147807 Val loss= 0.779273 Training acc= 0.681710 Val acc= 0.681465\n",
            "Epoch 883: Training loss= 0.147713 Val loss= 0.778736 Training acc= 0.681800 Val acc= 0.681555\n",
            "Epoch 884: Training loss= 0.147620 Val loss= 0.778201 Training acc= 0.681870 Val acc= 0.681635\n",
            "Epoch 885: Training loss= 0.147527 Val loss= 0.777667 Training acc= 0.681950 Val acc= 0.681700\n",
            "Epoch 886: Training loss= 0.147434 Val loss= 0.777134 Training acc= 0.682005 Val acc= 0.681785\n",
            "Epoch 887: Training loss= 0.147342 Val loss= 0.776602 Training acc= 0.682120 Val acc= 0.681860\n",
            "Epoch 888: Training loss= 0.147250 Val loss= 0.776071 Training acc= 0.682165 Val acc= 0.681935\n",
            "Epoch 889: Training loss= 0.147158 Val loss= 0.775542 Training acc= 0.682265 Val acc= 0.682035\n",
            "Epoch 890: Training loss= 0.147066 Val loss= 0.775014 Training acc= 0.682345 Val acc= 0.682090\n",
            "Epoch 891: Training loss= 0.146975 Val loss= 0.774487 Training acc= 0.682395 Val acc= 0.682130\n",
            "Epoch 892: Training loss= 0.146884 Val loss= 0.773961 Training acc= 0.682485 Val acc= 0.682235\n",
            "Epoch 893: Training loss= 0.146793 Val loss= 0.773436 Training acc= 0.682545 Val acc= 0.682285\n",
            "Epoch 894: Training loss= 0.146702 Val loss= 0.772912 Training acc= 0.682595 Val acc= 0.682350\n",
            "Epoch 895: Training loss= 0.146612 Val loss= 0.772390 Training acc= 0.682675 Val acc= 0.682410\n",
            "Epoch 896: Training loss= 0.146522 Val loss= 0.771868 Training acc= 0.682755 Val acc= 0.682480\n",
            "Epoch 897: Training loss= 0.146432 Val loss= 0.771348 Training acc= 0.682845 Val acc= 0.682565\n",
            "Epoch 898: Training loss= 0.146343 Val loss= 0.770829 Training acc= 0.682910 Val acc= 0.682595\n",
            "Epoch 899: Training loss= 0.146253 Val loss= 0.770311 Training acc= 0.682955 Val acc= 0.682655\n",
            "Epoch 900: Training loss= 0.146164 Val loss= 0.769794 Training acc= 0.683035 Val acc= 0.682685\n",
            "Epoch 901: Training loss= 0.146076 Val loss= 0.769278 Training acc= 0.683135 Val acc= 0.682770\n",
            "Epoch 902: Training loss= 0.145987 Val loss= 0.768764 Training acc= 0.683195 Val acc= 0.682840\n",
            "Epoch 903: Training loss= 0.145899 Val loss= 0.768250 Training acc= 0.683270 Val acc= 0.682935\n",
            "Epoch 904: Training loss= 0.145811 Val loss= 0.767738 Training acc= 0.683320 Val acc= 0.682960\n",
            "Epoch 905: Training loss= 0.145723 Val loss= 0.767226 Training acc= 0.683390 Val acc= 0.682965\n",
            "Epoch 906: Training loss= 0.145635 Val loss= 0.766716 Training acc= 0.683430 Val acc= 0.683035\n",
            "Epoch 907: Training loss= 0.145548 Val loss= 0.766207 Training acc= 0.683455 Val acc= 0.683110\n",
            "Epoch 908: Training loss= 0.145461 Val loss= 0.765699 Training acc= 0.683580 Val acc= 0.683225\n",
            "Epoch 909: Training loss= 0.145374 Val loss= 0.765192 Training acc= 0.683650 Val acc= 0.683255\n",
            "Epoch 910: Training loss= 0.145288 Val loss= 0.764686 Training acc= 0.683670 Val acc= 0.683260\n",
            "Epoch 911: Training loss= 0.145201 Val loss= 0.764181 Training acc= 0.683700 Val acc= 0.683280\n",
            "Epoch 912: Training loss= 0.145115 Val loss= 0.763678 Training acc= 0.683750 Val acc= 0.683320\n",
            "Epoch 913: Training loss= 0.145029 Val loss= 0.763175 Training acc= 0.683805 Val acc= 0.683405\n",
            "Epoch 914: Training loss= 0.144944 Val loss= 0.762674 Training acc= 0.683845 Val acc= 0.683440\n",
            "Epoch 915: Training loss= 0.144858 Val loss= 0.762173 Training acc= 0.683845 Val acc= 0.683440\n",
            "Epoch 916: Training loss= 0.144773 Val loss= 0.761674 Training acc= 0.683950 Val acc= 0.683525\n",
            "Epoch 917: Training loss= 0.144688 Val loss= 0.761175 Training acc= 0.683975 Val acc= 0.683560\n",
            "Epoch 918: Training loss= 0.144604 Val loss= 0.760678 Training acc= 0.684010 Val acc= 0.683610\n",
            "Epoch 919: Training loss= 0.144519 Val loss= 0.760182 Training acc= 0.684070 Val acc= 0.683665\n",
            "Epoch 920: Training loss= 0.144435 Val loss= 0.759687 Training acc= 0.684120 Val acc= 0.683710\n",
            "Epoch 921: Training loss= 0.144351 Val loss= 0.759193 Training acc= 0.684175 Val acc= 0.683775\n",
            "Epoch 922: Training loss= 0.144267 Val loss= 0.758700 Training acc= 0.684210 Val acc= 0.683830\n",
            "Epoch 923: Training loss= 0.144184 Val loss= 0.758207 Training acc= 0.684255 Val acc= 0.683865\n",
            "Epoch 924: Training loss= 0.144101 Val loss= 0.757716 Training acc= 0.684275 Val acc= 0.683895\n",
            "Epoch 925: Training loss= 0.144018 Val loss= 0.757226 Training acc= 0.684375 Val acc= 0.683965\n",
            "Epoch 926: Training loss= 0.143935 Val loss= 0.756738 Training acc= 0.684440 Val acc= 0.683995\n",
            "Epoch 927: Training loss= 0.143852 Val loss= 0.756250 Training acc= 0.684540 Val acc= 0.684095\n",
            "Epoch 928: Training loss= 0.143770 Val loss= 0.755763 Training acc= 0.684635 Val acc= 0.684180\n",
            "Epoch 929: Training loss= 0.143688 Val loss= 0.755277 Training acc= 0.684665 Val acc= 0.684230\n",
            "Epoch 930: Training loss= 0.143606 Val loss= 0.754792 Training acc= 0.684750 Val acc= 0.684305\n",
            "Epoch 931: Training loss= 0.143524 Val loss= 0.754308 Training acc= 0.684775 Val acc= 0.684330\n",
            "Epoch 932: Training loss= 0.143443 Val loss= 0.753825 Training acc= 0.684850 Val acc= 0.684385\n",
            "Epoch 933: Training loss= 0.143361 Val loss= 0.753343 Training acc= 0.684920 Val acc= 0.684430\n",
            "Epoch 934: Training loss= 0.143280 Val loss= 0.752863 Training acc= 0.685010 Val acc= 0.684525\n",
            "Epoch 935: Training loss= 0.143200 Val loss= 0.752383 Training acc= 0.685085 Val acc= 0.684625\n",
            "Epoch 936: Training loss= 0.143119 Val loss= 0.751904 Training acc= 0.685200 Val acc= 0.684735\n",
            "Epoch 937: Training loss= 0.143039 Val loss= 0.751426 Training acc= 0.685245 Val acc= 0.684790\n",
            "Epoch 938: Training loss= 0.142959 Val loss= 0.750949 Training acc= 0.685325 Val acc= 0.684865\n",
            "Epoch 939: Training loss= 0.142879 Val loss= 0.750473 Training acc= 0.685425 Val acc= 0.684970\n",
            "Epoch 940: Training loss= 0.142799 Val loss= 0.749998 Training acc= 0.685480 Val acc= 0.685025\n",
            "Epoch 941: Training loss= 0.142719 Val loss= 0.749524 Training acc= 0.685500 Val acc= 0.685080\n",
            "Epoch 942: Training loss= 0.142640 Val loss= 0.749051 Training acc= 0.685610 Val acc= 0.685175\n",
            "Epoch 943: Training loss= 0.142561 Val loss= 0.748580 Training acc= 0.685645 Val acc= 0.685230\n",
            "Epoch 944: Training loss= 0.142482 Val loss= 0.748109 Training acc= 0.685670 Val acc= 0.685250\n",
            "Epoch 945: Training loss= 0.142404 Val loss= 0.747638 Training acc= 0.685735 Val acc= 0.685300\n",
            "Epoch 946: Training loss= 0.142325 Val loss= 0.747169 Training acc= 0.685810 Val acc= 0.685380\n",
            "Epoch 947: Training loss= 0.142247 Val loss= 0.746701 Training acc= 0.685850 Val acc= 0.685420\n",
            "Epoch 948: Training loss= 0.142169 Val loss= 0.746234 Training acc= 0.685905 Val acc= 0.685490\n",
            "Epoch 949: Training loss= 0.142091 Val loss= 0.745768 Training acc= 0.685965 Val acc= 0.685540\n",
            "Epoch 950: Training loss= 0.142013 Val loss= 0.745303 Training acc= 0.686010 Val acc= 0.685575\n",
            "Epoch 951: Training loss= 0.141936 Val loss= 0.744838 Training acc= 0.686055 Val acc= 0.685650\n",
            "Epoch 952: Training loss= 0.141859 Val loss= 0.744375 Training acc= 0.686125 Val acc= 0.685725\n",
            "Epoch 953: Training loss= 0.141782 Val loss= 0.743913 Training acc= 0.686210 Val acc= 0.685830\n",
            "Epoch 954: Training loss= 0.141705 Val loss= 0.743451 Training acc= 0.686250 Val acc= 0.685895\n",
            "Epoch 955: Training loss= 0.141629 Val loss= 0.742991 Training acc= 0.686340 Val acc= 0.686000\n",
            "Epoch 956: Training loss= 0.141552 Val loss= 0.742531 Training acc= 0.686460 Val acc= 0.686110\n",
            "Epoch 957: Training loss= 0.141476 Val loss= 0.742072 Training acc= 0.686505 Val acc= 0.686135\n",
            "Epoch 958: Training loss= 0.141400 Val loss= 0.741614 Training acc= 0.686560 Val acc= 0.686195\n",
            "Epoch 959: Training loss= 0.141324 Val loss= 0.741158 Training acc= 0.686615 Val acc= 0.686190\n",
            "Epoch 960: Training loss= 0.141249 Val loss= 0.740702 Training acc= 0.686730 Val acc= 0.686300\n",
            "Epoch 961: Training loss= 0.141173 Val loss= 0.740247 Training acc= 0.686835 Val acc= 0.686405\n",
            "Epoch 962: Training loss= 0.141098 Val loss= 0.739793 Training acc= 0.686910 Val acc= 0.686450\n",
            "Epoch 963: Training loss= 0.141023 Val loss= 0.739339 Training acc= 0.686965 Val acc= 0.686500\n",
            "Epoch 964: Training loss= 0.140948 Val loss= 0.738887 Training acc= 0.686960 Val acc= 0.686490\n",
            "Epoch 965: Training loss= 0.140874 Val loss= 0.738436 Training acc= 0.687020 Val acc= 0.686555\n",
            "Epoch 966: Training loss= 0.140799 Val loss= 0.737985 Training acc= 0.687110 Val acc= 0.686645\n",
            "Epoch 967: Training loss= 0.140725 Val loss= 0.737536 Training acc= 0.687175 Val acc= 0.686705\n",
            "Epoch 968: Training loss= 0.140651 Val loss= 0.737087 Training acc= 0.687215 Val acc= 0.686735\n",
            "Epoch 969: Training loss= 0.140577 Val loss= 0.736639 Training acc= 0.687230 Val acc= 0.686795\n",
            "Epoch 970: Training loss= 0.140504 Val loss= 0.736192 Training acc= 0.687290 Val acc= 0.686870\n",
            "Epoch 971: Training loss= 0.140430 Val loss= 0.735746 Training acc= 0.687365 Val acc= 0.686920\n",
            "Epoch 972: Training loss= 0.140357 Val loss= 0.735301 Training acc= 0.687460 Val acc= 0.687000\n",
            "Epoch 973: Training loss= 0.140284 Val loss= 0.734857 Training acc= 0.687565 Val acc= 0.687085\n",
            "Epoch 974: Training loss= 0.140211 Val loss= 0.734414 Training acc= 0.687635 Val acc= 0.687145\n",
            "Epoch 975: Training loss= 0.140139 Val loss= 0.733971 Training acc= 0.687685 Val acc= 0.687195\n",
            "Epoch 976: Training loss= 0.140066 Val loss= 0.733529 Training acc= 0.687750 Val acc= 0.687260\n",
            "Epoch 977: Training loss= 0.139994 Val loss= 0.733089 Training acc= 0.687845 Val acc= 0.687380\n",
            "Epoch 978: Training loss= 0.139922 Val loss= 0.732649 Training acc= 0.687905 Val acc= 0.687425\n",
            "Epoch 979: Training loss= 0.139850 Val loss= 0.732210 Training acc= 0.687915 Val acc= 0.687465\n",
            "Epoch 980: Training loss= 0.139778 Val loss= 0.731772 Training acc= 0.687985 Val acc= 0.687550\n",
            "Epoch 981: Training loss= 0.139707 Val loss= 0.731334 Training acc= 0.688065 Val acc= 0.687630\n",
            "Epoch 982: Training loss= 0.139635 Val loss= 0.730898 Training acc= 0.688095 Val acc= 0.687690\n",
            "Epoch 983: Training loss= 0.139564 Val loss= 0.730462 Training acc= 0.688170 Val acc= 0.687755\n",
            "Epoch 984: Training loss= 0.139493 Val loss= 0.730028 Training acc= 0.688245 Val acc= 0.687860\n",
            "Epoch 985: Training loss= 0.139422 Val loss= 0.729594 Training acc= 0.688315 Val acc= 0.687920\n",
            "Epoch 986: Training loss= 0.139352 Val loss= 0.729161 Training acc= 0.688335 Val acc= 0.687925\n",
            "Epoch 987: Training loss= 0.139281 Val loss= 0.728729 Training acc= 0.688395 Val acc= 0.688015\n",
            "Epoch 988: Training loss= 0.139211 Val loss= 0.728297 Training acc= 0.688400 Val acc= 0.688015\n",
            "Epoch 989: Training loss= 0.139141 Val loss= 0.727867 Training acc= 0.688470 Val acc= 0.688095\n",
            "Epoch 990: Training loss= 0.139071 Val loss= 0.727437 Training acc= 0.688505 Val acc= 0.688145\n",
            "Epoch 991: Training loss= 0.139001 Val loss= 0.727008 Training acc= 0.688570 Val acc= 0.688205\n",
            "Epoch 992: Training loss= 0.138932 Val loss= 0.726580 Training acc= 0.688630 Val acc= 0.688265\n",
            "Epoch 993: Training loss= 0.138862 Val loss= 0.726153 Training acc= 0.688705 Val acc= 0.688340\n",
            "Epoch 994: Training loss= 0.138793 Val loss= 0.725726 Training acc= 0.688725 Val acc= 0.688370\n",
            "Epoch 995: Training loss= 0.138724 Val loss= 0.725301 Training acc= 0.688810 Val acc= 0.688440\n",
            "Epoch 996: Training loss= 0.138655 Val loss= 0.724876 Training acc= 0.688880 Val acc= 0.688535\n",
            "Epoch 997: Training loss= 0.138586 Val loss= 0.724452 Training acc= 0.688940 Val acc= 0.688600\n",
            "Epoch 998: Training loss= 0.138518 Val loss= 0.724029 Training acc= 0.688975 Val acc= 0.688660\n",
            "Epoch 999: Training loss= 0.138450 Val loss= 0.723607 Training acc= 0.688965 Val acc= 0.688655\n",
            "Epoch 1000: Training loss= 0.138381 Val loss= 0.723185 Training acc= 0.689000 Val acc= 0.688685\n",
            "Epoch 1001: Training loss= 0.138313 Val loss= 0.722765 Training acc= 0.689090 Val acc= 0.688765\n",
            "Epoch 1002: Training loss= 0.138246 Val loss= 0.722345 Training acc= 0.689155 Val acc= 0.688840\n",
            "Epoch 1003: Training loss= 0.138178 Val loss= 0.721926 Training acc= 0.689250 Val acc= 0.688925\n",
            "Epoch 1004: Training loss= 0.138110 Val loss= 0.721507 Training acc= 0.689290 Val acc= 0.688965\n",
            "Epoch 1005: Training loss= 0.138043 Val loss= 0.721090 Training acc= 0.689325 Val acc= 0.689005\n",
            "Epoch 1006: Training loss= 0.137976 Val loss= 0.720673 Training acc= 0.689355 Val acc= 0.689035\n",
            "Epoch 1007: Training loss= 0.137909 Val loss= 0.720257 Training acc= 0.689465 Val acc= 0.689140\n",
            "Epoch 1008: Training loss= 0.137842 Val loss= 0.719842 Training acc= 0.689530 Val acc= 0.689230\n",
            "Epoch 1009: Training loss= 0.137775 Val loss= 0.719428 Training acc= 0.689600 Val acc= 0.689275\n",
            "Epoch 1010: Training loss= 0.137709 Val loss= 0.719014 Training acc= 0.689660 Val acc= 0.689290\n",
            "Epoch 1011: Training loss= 0.137643 Val loss= 0.718601 Training acc= 0.689760 Val acc= 0.689350\n",
            "Epoch 1012: Training loss= 0.137576 Val loss= 0.718189 Training acc= 0.689900 Val acc= 0.689455\n",
            "Epoch 1013: Training loss= 0.137511 Val loss= 0.717778 Training acc= 0.689930 Val acc= 0.689490\n",
            "Epoch 1014: Training loss= 0.137445 Val loss= 0.717368 Training acc= 0.690050 Val acc= 0.689580\n",
            "Epoch 1015: Training loss= 0.137379 Val loss= 0.716958 Training acc= 0.690110 Val acc= 0.689625\n",
            "Epoch 1016: Training loss= 0.137314 Val loss= 0.716549 Training acc= 0.690125 Val acc= 0.689635\n",
            "Epoch 1017: Training loss= 0.137248 Val loss= 0.716141 Training acc= 0.690185 Val acc= 0.689710\n",
            "Epoch 1018: Training loss= 0.137183 Val loss= 0.715734 Training acc= 0.690250 Val acc= 0.689770\n",
            "Epoch 1019: Training loss= 0.137118 Val loss= 0.715327 Training acc= 0.690275 Val acc= 0.689790\n",
            "Epoch 1020: Training loss= 0.137053 Val loss= 0.714921 Training acc= 0.690315 Val acc= 0.689805\n",
            "Epoch 1021: Training loss= 0.136988 Val loss= 0.714516 Training acc= 0.690395 Val acc= 0.689890\n",
            "Epoch 1022: Training loss= 0.136924 Val loss= 0.714112 Training acc= 0.690425 Val acc= 0.689915\n",
            "Epoch 1023: Training loss= 0.136859 Val loss= 0.713708 Training acc= 0.690530 Val acc= 0.690015\n",
            "Epoch 1024: Training loss= 0.136795 Val loss= 0.713305 Training acc= 0.690540 Val acc= 0.690070\n",
            "Epoch 1025: Training loss= 0.136731 Val loss= 0.712903 Training acc= 0.690605 Val acc= 0.690170\n",
            "Epoch 1026: Training loss= 0.136667 Val loss= 0.712502 Training acc= 0.690635 Val acc= 0.690185\n",
            "Epoch 1027: Training loss= 0.136603 Val loss= 0.712101 Training acc= 0.690735 Val acc= 0.690250\n",
            "Epoch 1028: Training loss= 0.136540 Val loss= 0.711701 Training acc= 0.690790 Val acc= 0.690330\n",
            "Epoch 1029: Training loss= 0.136476 Val loss= 0.711302 Training acc= 0.690835 Val acc= 0.690380\n",
            "Epoch 1030: Training loss= 0.136413 Val loss= 0.710904 Training acc= 0.690930 Val acc= 0.690440\n",
            "Epoch 1031: Training loss= 0.136350 Val loss= 0.710506 Training acc= 0.690970 Val acc= 0.690500\n",
            "Epoch 1032: Training loss= 0.136287 Val loss= 0.710109 Training acc= 0.691025 Val acc= 0.690575\n",
            "Epoch 1033: Training loss= 0.136224 Val loss= 0.709713 Training acc= 0.691060 Val acc= 0.690585\n",
            "Epoch 1034: Training loss= 0.136161 Val loss= 0.709317 Training acc= 0.691135 Val acc= 0.690650\n",
            "Epoch 1035: Training loss= 0.136099 Val loss= 0.708923 Training acc= 0.691170 Val acc= 0.690685\n",
            "Epoch 1036: Training loss= 0.136037 Val loss= 0.708529 Training acc= 0.691250 Val acc= 0.690755\n",
            "Epoch 1037: Training loss= 0.135974 Val loss= 0.708135 Training acc= 0.691275 Val acc= 0.690775\n",
            "Epoch 1038: Training loss= 0.135912 Val loss= 0.707743 Training acc= 0.691360 Val acc= 0.690860\n",
            "Epoch 1039: Training loss= 0.135850 Val loss= 0.707351 Training acc= 0.691405 Val acc= 0.690920\n",
            "Epoch 1040: Training loss= 0.135789 Val loss= 0.706960 Training acc= 0.691455 Val acc= 0.690940\n",
            "Epoch 1041: Training loss= 0.135727 Val loss= 0.706569 Training acc= 0.691500 Val acc= 0.690975\n",
            "Epoch 1042: Training loss= 0.135665 Val loss= 0.706179 Training acc= 0.691540 Val acc= 0.690995\n",
            "Epoch 1043: Training loss= 0.135604 Val loss= 0.705790 Training acc= 0.691605 Val acc= 0.691060\n",
            "Epoch 1044: Training loss= 0.135543 Val loss= 0.705402 Training acc= 0.691660 Val acc= 0.691110\n",
            "Epoch 1045: Training loss= 0.135482 Val loss= 0.705014 Training acc= 0.691775 Val acc= 0.691245\n",
            "Epoch 1046: Training loss= 0.135421 Val loss= 0.704627 Training acc= 0.691840 Val acc= 0.691285\n",
            "Epoch 1047: Training loss= 0.135360 Val loss= 0.704241 Training acc= 0.691840 Val acc= 0.691300\n",
            "Epoch 1048: Training loss= 0.135299 Val loss= 0.703855 Training acc= 0.691885 Val acc= 0.691355\n",
            "Epoch 1049: Training loss= 0.135239 Val loss= 0.703471 Training acc= 0.691925 Val acc= 0.691385\n",
            "Epoch 1050: Training loss= 0.135179 Val loss= 0.703086 Training acc= 0.691975 Val acc= 0.691435\n",
            "Epoch 1051: Training loss= 0.135118 Val loss= 0.702703 Training acc= 0.692025 Val acc= 0.691470\n",
            "Epoch 1052: Training loss= 0.135058 Val loss= 0.702320 Training acc= 0.692065 Val acc= 0.691560\n",
            "Epoch 1053: Training loss= 0.134999 Val loss= 0.701938 Training acc= 0.692115 Val acc= 0.691595\n",
            "Epoch 1054: Training loss= 0.134939 Val loss= 0.701556 Training acc= 0.692180 Val acc= 0.691635\n",
            "Epoch 1055: Training loss= 0.134879 Val loss= 0.701176 Training acc= 0.692240 Val acc= 0.691690\n",
            "Epoch 1056: Training loss= 0.134820 Val loss= 0.700796 Training acc= 0.692265 Val acc= 0.691725\n",
            "Epoch 1057: Training loss= 0.134760 Val loss= 0.700416 Training acc= 0.692350 Val acc= 0.691805\n",
            "Epoch 1058: Training loss= 0.134701 Val loss= 0.700037 Training acc= 0.692415 Val acc= 0.691865\n",
            "Epoch 1059: Training loss= 0.134642 Val loss= 0.699659 Training acc= 0.692470 Val acc= 0.691890\n",
            "Epoch 1060: Training loss= 0.134583 Val loss= 0.699282 Training acc= 0.692505 Val acc= 0.691925\n",
            "Epoch 1061: Training loss= 0.134524 Val loss= 0.698905 Training acc= 0.692565 Val acc= 0.692005\n",
            "Epoch 1062: Training loss= 0.134466 Val loss= 0.698529 Training acc= 0.692615 Val acc= 0.692035\n",
            "Epoch 1063: Training loss= 0.134407 Val loss= 0.698154 Training acc= 0.692670 Val acc= 0.692090\n",
            "Epoch 1064: Training loss= 0.134349 Val loss= 0.697779 Training acc= 0.692740 Val acc= 0.692165\n",
            "Epoch 1065: Training loss= 0.134291 Val loss= 0.697405 Training acc= 0.692820 Val acc= 0.692200\n",
            "Epoch 1066: Training loss= 0.134232 Val loss= 0.697032 Training acc= 0.692885 Val acc= 0.692260\n",
            "Epoch 1067: Training loss= 0.134174 Val loss= 0.696659 Training acc= 0.692960 Val acc= 0.692335\n",
            "Epoch 1068: Training loss= 0.134117 Val loss= 0.696287 Training acc= 0.693010 Val acc= 0.692370\n",
            "Epoch 1069: Training loss= 0.134059 Val loss= 0.695915 Training acc= 0.693050 Val acc= 0.692435\n",
            "Epoch 1070: Training loss= 0.134001 Val loss= 0.695544 Training acc= 0.693100 Val acc= 0.692490\n",
            "Epoch 1071: Training loss= 0.133944 Val loss= 0.695174 Training acc= 0.693140 Val acc= 0.692495\n",
            "Epoch 1072: Training loss= 0.133887 Val loss= 0.694805 Training acc= 0.693190 Val acc= 0.692530\n",
            "Epoch 1073: Training loss= 0.133829 Val loss= 0.694436 Training acc= 0.693235 Val acc= 0.692525\n",
            "Epoch 1074: Training loss= 0.133772 Val loss= 0.694068 Training acc= 0.693260 Val acc= 0.692565\n",
            "Epoch 1075: Training loss= 0.133715 Val loss= 0.693700 Training acc= 0.693340 Val acc= 0.692650\n",
            "Epoch 1076: Training loss= 0.133659 Val loss= 0.693333 Training acc= 0.693430 Val acc= 0.692715\n",
            "Epoch 1077: Training loss= 0.133602 Val loss= 0.692967 Training acc= 0.693435 Val acc= 0.692730\n",
            "Epoch 1078: Training loss= 0.133546 Val loss= 0.692601 Training acc= 0.693485 Val acc= 0.692810\n",
            "Epoch 1079: Training loss= 0.133489 Val loss= 0.692236 Training acc= 0.693540 Val acc= 0.692880\n",
            "Epoch 1080: Training loss= 0.133433 Val loss= 0.691872 Training acc= 0.693610 Val acc= 0.692950\n",
            "Epoch 1081: Training loss= 0.133377 Val loss= 0.691508 Training acc= 0.693660 Val acc= 0.693010\n",
            "Epoch 1082: Training loss= 0.133321 Val loss= 0.691145 Training acc= 0.693745 Val acc= 0.693060\n",
            "Epoch 1083: Training loss= 0.133265 Val loss= 0.690782 Training acc= 0.693825 Val acc= 0.693105\n",
            "Epoch 1084: Training loss= 0.133209 Val loss= 0.690420 Training acc= 0.693890 Val acc= 0.693165\n",
            "Epoch 1085: Training loss= 0.133154 Val loss= 0.690059 Training acc= 0.693955 Val acc= 0.693225\n",
            "Epoch 1086: Training loss= 0.133098 Val loss= 0.689698 Training acc= 0.694010 Val acc= 0.693275\n",
            "Epoch 1087: Training loss= 0.133043 Val loss= 0.689338 Training acc= 0.694015 Val acc= 0.693285\n",
            "Epoch 1088: Training loss= 0.132987 Val loss= 0.688979 Training acc= 0.694100 Val acc= 0.693320\n",
            "Epoch 1089: Training loss= 0.132932 Val loss= 0.688620 Training acc= 0.694185 Val acc= 0.693395\n",
            "Epoch 1090: Training loss= 0.132877 Val loss= 0.688262 Training acc= 0.694210 Val acc= 0.693415\n",
            "Epoch 1091: Training loss= 0.132822 Val loss= 0.687904 Training acc= 0.694265 Val acc= 0.693465\n",
            "Epoch 1092: Training loss= 0.132768 Val loss= 0.687547 Training acc= 0.694360 Val acc= 0.693580\n",
            "Epoch 1093: Training loss= 0.132713 Val loss= 0.687191 Training acc= 0.694400 Val acc= 0.693650\n",
            "Epoch 1094: Training loss= 0.132659 Val loss= 0.686835 Training acc= 0.694460 Val acc= 0.693655\n",
            "Epoch 1095: Training loss= 0.132604 Val loss= 0.686480 Training acc= 0.694490 Val acc= 0.693685\n",
            "Epoch 1096: Training loss= 0.132550 Val loss= 0.686125 Training acc= 0.694525 Val acc= 0.693745\n",
            "Epoch 1097: Training loss= 0.132496 Val loss= 0.685771 Training acc= 0.694585 Val acc= 0.693805\n",
            "Epoch 1098: Training loss= 0.132442 Val loss= 0.685418 Training acc= 0.694615 Val acc= 0.693820\n",
            "Epoch 1099: Training loss= 0.132388 Val loss= 0.685065 Training acc= 0.694645 Val acc= 0.693875\n",
            "Epoch 1100: Training loss= 0.132334 Val loss= 0.684713 Training acc= 0.694725 Val acc= 0.693950\n",
            "Epoch 1101: Training loss= 0.132280 Val loss= 0.684361 Training acc= 0.694740 Val acc= 0.693965\n",
            "Epoch 1102: Training loss= 0.132227 Val loss= 0.684010 Training acc= 0.694815 Val acc= 0.694020\n",
            "Epoch 1103: Training loss= 0.132173 Val loss= 0.683660 Training acc= 0.694850 Val acc= 0.694040\n",
            "Epoch 1104: Training loss= 0.132120 Val loss= 0.683310 Training acc= 0.694935 Val acc= 0.694105\n",
            "Epoch 1105: Training loss= 0.132067 Val loss= 0.682960 Training acc= 0.694985 Val acc= 0.694175\n",
            "Epoch 1106: Training loss= 0.132014 Val loss= 0.682612 Training acc= 0.694995 Val acc= 0.694195\n",
            "Epoch 1107: Training loss= 0.131961 Val loss= 0.682264 Training acc= 0.694995 Val acc= 0.694240\n",
            "Epoch 1108: Training loss= 0.131908 Val loss= 0.681916 Training acc= 0.695035 Val acc= 0.694295\n",
            "Epoch 1109: Training loss= 0.131855 Val loss= 0.681569 Training acc= 0.695080 Val acc= 0.694340\n",
            "Epoch 1110: Training loss= 0.131803 Val loss= 0.681223 Training acc= 0.695160 Val acc= 0.694415\n",
            "Epoch 1111: Training loss= 0.131750 Val loss= 0.680877 Training acc= 0.695210 Val acc= 0.694455\n",
            "Epoch 1112: Training loss= 0.131698 Val loss= 0.680532 Training acc= 0.695280 Val acc= 0.694535\n",
            "Epoch 1113: Training loss= 0.131646 Val loss= 0.680187 Training acc= 0.695335 Val acc= 0.694555\n",
            "Epoch 1114: Training loss= 0.131594 Val loss= 0.679843 Training acc= 0.695395 Val acc= 0.694610\n",
            "Epoch 1115: Training loss= 0.131542 Val loss= 0.679500 Training acc= 0.695420 Val acc= 0.694645\n",
            "Epoch 1116: Training loss= 0.131490 Val loss= 0.679157 Training acc= 0.695455 Val acc= 0.694720\n",
            "Epoch 1117: Training loss= 0.131438 Val loss= 0.678814 Training acc= 0.695510 Val acc= 0.694765\n",
            "Epoch 1118: Training loss= 0.131386 Val loss= 0.678472 Training acc= 0.695565 Val acc= 0.694810\n",
            "Epoch 1119: Training loss= 0.131335 Val loss= 0.678131 Training acc= 0.695630 Val acc= 0.694885\n",
            "Epoch 1120: Training loss= 0.131283 Val loss= 0.677791 Training acc= 0.695680 Val acc= 0.694920\n",
            "Epoch 1121: Training loss= 0.131232 Val loss= 0.677450 Training acc= 0.695740 Val acc= 0.694940\n",
            "Epoch 1122: Training loss= 0.131181 Val loss= 0.677111 Training acc= 0.695780 Val acc= 0.695005\n",
            "Epoch 1123: Training loss= 0.131130 Val loss= 0.676772 Training acc= 0.695805 Val acc= 0.695025\n",
            "Epoch 1124: Training loss= 0.131079 Val loss= 0.676433 Training acc= 0.695855 Val acc= 0.695060\n",
            "Epoch 1125: Training loss= 0.131028 Val loss= 0.676095 Training acc= 0.695885 Val acc= 0.695095\n",
            "Epoch 1126: Training loss= 0.130977 Val loss= 0.675758 Training acc= 0.695890 Val acc= 0.695115\n",
            "Epoch 1127: Training loss= 0.130926 Val loss= 0.675421 Training acc= 0.695935 Val acc= 0.695135\n",
            "Epoch 1128: Training loss= 0.130876 Val loss= 0.675085 Training acc= 0.696010 Val acc= 0.695180\n",
            "Epoch 1129: Training loss= 0.130825 Val loss= 0.674749 Training acc= 0.696045 Val acc= 0.695220\n",
            "Epoch 1130: Training loss= 0.130775 Val loss= 0.674414 Training acc= 0.696140 Val acc= 0.695295\n",
            "Epoch 1131: Training loss= 0.130725 Val loss= 0.674079 Training acc= 0.696140 Val acc= 0.695290\n",
            "Epoch 1132: Training loss= 0.130675 Val loss= 0.673745 Training acc= 0.696190 Val acc= 0.695330\n",
            "Epoch 1133: Training loss= 0.130625 Val loss= 0.673412 Training acc= 0.696250 Val acc= 0.695385\n",
            "Epoch 1134: Training loss= 0.130575 Val loss= 0.673079 Training acc= 0.696325 Val acc= 0.695445\n",
            "Epoch 1135: Training loss= 0.130525 Val loss= 0.672746 Training acc= 0.696380 Val acc= 0.695490\n",
            "Epoch 1136: Training loss= 0.130475 Val loss= 0.672414 Training acc= 0.696465 Val acc= 0.695550\n",
            "Epoch 1137: Training loss= 0.130426 Val loss= 0.672083 Training acc= 0.696545 Val acc= 0.695625\n",
            "Epoch 1138: Training loss= 0.130376 Val loss= 0.671752 Training acc= 0.696585 Val acc= 0.695670\n",
            "Epoch 1139: Training loss= 0.130327 Val loss= 0.671421 Training acc= 0.696625 Val acc= 0.695710\n",
            "Epoch 1140: Training loss= 0.130277 Val loss= 0.671092 Training acc= 0.696680 Val acc= 0.695775\n",
            "Epoch 1141: Training loss= 0.130228 Val loss= 0.670762 Training acc= 0.696755 Val acc= 0.695805\n",
            "Epoch 1142: Training loss= 0.130179 Val loss= 0.670434 Training acc= 0.696770 Val acc= 0.695830\n",
            "Epoch 1143: Training loss= 0.130130 Val loss= 0.670105 Training acc= 0.696830 Val acc= 0.695900\n",
            "Epoch 1144: Training loss= 0.130081 Val loss= 0.669778 Training acc= 0.696875 Val acc= 0.695925\n",
            "Epoch 1145: Training loss= 0.130033 Val loss= 0.669450 Training acc= 0.696980 Val acc= 0.696020\n",
            "Epoch 1146: Training loss= 0.129984 Val loss= 0.669124 Training acc= 0.697035 Val acc= 0.696110\n",
            "Epoch 1147: Training loss= 0.129935 Val loss= 0.668797 Training acc= 0.697060 Val acc= 0.696145\n",
            "Epoch 1148: Training loss= 0.129887 Val loss= 0.668472 Training acc= 0.697090 Val acc= 0.696185\n",
            "Epoch 1149: Training loss= 0.129839 Val loss= 0.668147 Training acc= 0.697135 Val acc= 0.696230\n",
            "Epoch 1150: Training loss= 0.129790 Val loss= 0.667822 Training acc= 0.697190 Val acc= 0.696310\n",
            "Epoch 1151: Training loss= 0.129742 Val loss= 0.667498 Training acc= 0.697240 Val acc= 0.696410\n",
            "Epoch 1152: Training loss= 0.129694 Val loss= 0.667174 Training acc= 0.697280 Val acc= 0.696435\n",
            "Epoch 1153: Training loss= 0.129646 Val loss= 0.666851 Training acc= 0.697340 Val acc= 0.696480\n",
            "Epoch 1154: Training loss= 0.129598 Val loss= 0.666528 Training acc= 0.697375 Val acc= 0.696525\n",
            "Epoch 1155: Training loss= 0.129551 Val loss= 0.666206 Training acc= 0.697415 Val acc= 0.696565\n",
            "Epoch 1156: Training loss= 0.129503 Val loss= 0.665885 Training acc= 0.697480 Val acc= 0.696630\n",
            "Epoch 1157: Training loss= 0.129455 Val loss= 0.665564 Training acc= 0.697500 Val acc= 0.696680\n",
            "Epoch 1158: Training loss= 0.129408 Val loss= 0.665243 Training acc= 0.697540 Val acc= 0.696730\n",
            "Epoch 1159: Training loss= 0.129361 Val loss= 0.664923 Training acc= 0.697545 Val acc= 0.696710\n",
            "Epoch 1160: Training loss= 0.129313 Val loss= 0.664603 Training acc= 0.697635 Val acc= 0.696785\n",
            "Epoch 1161: Training loss= 0.129266 Val loss= 0.664284 Training acc= 0.697700 Val acc= 0.696875\n",
            "Epoch 1162: Training loss= 0.129219 Val loss= 0.663966 Training acc= 0.697775 Val acc= 0.696940\n",
            "Epoch 1163: Training loss= 0.129172 Val loss= 0.663648 Training acc= 0.697795 Val acc= 0.696960\n",
            "Epoch 1164: Training loss= 0.129125 Val loss= 0.663330 Training acc= 0.697845 Val acc= 0.697025\n",
            "Epoch 1165: Training loss= 0.129079 Val loss= 0.663013 Training acc= 0.697905 Val acc= 0.697080\n",
            "Epoch 1166: Training loss= 0.129032 Val loss= 0.662696 Training acc= 0.697935 Val acc= 0.697110\n",
            "Epoch 1167: Training loss= 0.128985 Val loss= 0.662380 Training acc= 0.697975 Val acc= 0.697160\n",
            "Epoch 1168: Training loss= 0.128939 Val loss= 0.662064 Training acc= 0.698025 Val acc= 0.697225\n",
            "Epoch 1169: Training loss= 0.128893 Val loss= 0.661749 Training acc= 0.698085 Val acc= 0.697260\n",
            "Epoch 1170: Training loss= 0.128846 Val loss= 0.661435 Training acc= 0.698135 Val acc= 0.697315\n",
            "Epoch 1171: Training loss= 0.128800 Val loss= 0.661120 Training acc= 0.698200 Val acc= 0.697355\n",
            "Epoch 1172: Training loss= 0.128754 Val loss= 0.660807 Training acc= 0.698215 Val acc= 0.697375\n",
            "Epoch 1173: Training loss= 0.128708 Val loss= 0.660493 Training acc= 0.698295 Val acc= 0.697430\n",
            "Epoch 1174: Training loss= 0.128662 Val loss= 0.660181 Training acc= 0.698330 Val acc= 0.697470\n",
            "Epoch 1175: Training loss= 0.128616 Val loss= 0.659868 Training acc= 0.698405 Val acc= 0.697515\n",
            "Epoch 1176: Training loss= 0.128571 Val loss= 0.659557 Training acc= 0.698470 Val acc= 0.697585\n",
            "Epoch 1177: Training loss= 0.128525 Val loss= 0.659245 Training acc= 0.698520 Val acc= 0.697645\n",
            "Epoch 1178: Training loss= 0.128480 Val loss= 0.658934 Training acc= 0.698560 Val acc= 0.697700\n",
            "Epoch 1179: Training loss= 0.128434 Val loss= 0.658624 Training acc= 0.698605 Val acc= 0.697730\n",
            "Epoch 1180: Training loss= 0.128389 Val loss= 0.658314 Training acc= 0.698665 Val acc= 0.697775\n",
            "Epoch 1181: Training loss= 0.128344 Val loss= 0.658005 Training acc= 0.698715 Val acc= 0.697805\n",
            "Epoch 1182: Training loss= 0.128298 Val loss= 0.657696 Training acc= 0.698735 Val acc= 0.697830\n",
            "Epoch 1183: Training loss= 0.128253 Val loss= 0.657387 Training acc= 0.698780 Val acc= 0.697870\n",
            "Epoch 1184: Training loss= 0.128208 Val loss= 0.657079 Training acc= 0.698795 Val acc= 0.697915\n",
            "Epoch 1185: Training loss= 0.128163 Val loss= 0.656771 Training acc= 0.698835 Val acc= 0.697955\n",
            "Epoch 1186: Training loss= 0.128119 Val loss= 0.656464 Training acc= 0.698855 Val acc= 0.697985\n",
            "Epoch 1187: Training loss= 0.128074 Val loss= 0.656158 Training acc= 0.698910 Val acc= 0.698045\n",
            "Epoch 1188: Training loss= 0.128029 Val loss= 0.655852 Training acc= 0.698925 Val acc= 0.698055\n",
            "Epoch 1189: Training loss= 0.127985 Val loss= 0.655546 Training acc= 0.698980 Val acc= 0.698150\n",
            "Epoch 1190: Training loss= 0.127940 Val loss= 0.655241 Training acc= 0.699035 Val acc= 0.698175\n",
            "Epoch 1191: Training loss= 0.127896 Val loss= 0.654936 Training acc= 0.699060 Val acc= 0.698210\n",
            "Epoch 1192: Training loss= 0.127852 Val loss= 0.654631 Training acc= 0.699175 Val acc= 0.698330\n",
            "Epoch 1193: Training loss= 0.127808 Val loss= 0.654327 Training acc= 0.699220 Val acc= 0.698355\n",
            "Epoch 1194: Training loss= 0.127764 Val loss= 0.654024 Training acc= 0.699280 Val acc= 0.698390\n",
            "Epoch 1195: Training loss= 0.127720 Val loss= 0.653721 Training acc= 0.699325 Val acc= 0.698440\n",
            "Epoch 1196: Training loss= 0.127676 Val loss= 0.653418 Training acc= 0.699385 Val acc= 0.698500\n",
            "Epoch 1197: Training loss= 0.127632 Val loss= 0.653116 Training acc= 0.699420 Val acc= 0.698510\n",
            "Epoch 1198: Training loss= 0.127588 Val loss= 0.652815 Training acc= 0.699470 Val acc= 0.698545\n",
            "Epoch 1199: Training loss= 0.127545 Val loss= 0.652513 Training acc= 0.699485 Val acc= 0.698580\n",
            "Epoch 1200: Training loss= 0.127501 Val loss= 0.652213 Training acc= 0.699470 Val acc= 0.698585\n",
            "Epoch 1201: Training loss= 0.127457 Val loss= 0.651912 Training acc= 0.699575 Val acc= 0.698690\n",
            "Epoch 1202: Training loss= 0.127414 Val loss= 0.651613 Training acc= 0.699610 Val acc= 0.698745\n",
            "Epoch 1203: Training loss= 0.127371 Val loss= 0.651313 Training acc= 0.699630 Val acc= 0.698770\n",
            "Epoch 1204: Training loss= 0.127328 Val loss= 0.651014 Training acc= 0.699710 Val acc= 0.698830\n",
            "Epoch 1205: Training loss= 0.127284 Val loss= 0.650716 Training acc= 0.699745 Val acc= 0.698880\n",
            "Epoch 1206: Training loss= 0.127241 Val loss= 0.650417 Training acc= 0.699780 Val acc= 0.698895\n",
            "Epoch 1207: Training loss= 0.127199 Val loss= 0.650120 Training acc= 0.699820 Val acc= 0.698935\n",
            "Epoch 1208: Training loss= 0.127156 Val loss= 0.649823 Training acc= 0.699875 Val acc= 0.698960\n",
            "Epoch 1209: Training loss= 0.127113 Val loss= 0.649526 Training acc= 0.699925 Val acc= 0.699005\n",
            "Epoch 1210: Training loss= 0.127070 Val loss= 0.649229 Training acc= 0.699950 Val acc= 0.699020\n",
            "Epoch 1211: Training loss= 0.127028 Val loss= 0.648933 Training acc= 0.699975 Val acc= 0.699055\n",
            "Epoch 1212: Training loss= 0.126985 Val loss= 0.648638 Training acc= 0.700035 Val acc= 0.699150\n",
            "Epoch 1213: Training loss= 0.126943 Val loss= 0.648343 Training acc= 0.700085 Val acc= 0.699180\n",
            "Epoch 1214: Training loss= 0.126900 Val loss= 0.648048 Training acc= 0.700115 Val acc= 0.699225\n",
            "Epoch 1215: Training loss= 0.126858 Val loss= 0.647754 Training acc= 0.700100 Val acc= 0.699215\n",
            "Epoch 1216: Training loss= 0.126816 Val loss= 0.647460 Training acc= 0.700175 Val acc= 0.699290\n",
            "Epoch 1217: Training loss= 0.126774 Val loss= 0.647167 Training acc= 0.700205 Val acc= 0.699320\n",
            "Epoch 1218: Training loss= 0.126732 Val loss= 0.646874 Training acc= 0.700245 Val acc= 0.699370\n",
            "Epoch 1219: Training loss= 0.126690 Val loss= 0.646581 Training acc= 0.700285 Val acc= 0.699380\n",
            "Epoch 1220: Training loss= 0.126648 Val loss= 0.646289 Training acc= 0.700300 Val acc= 0.699395\n",
            "Epoch 1221: Training loss= 0.126606 Val loss= 0.645998 Training acc= 0.700320 Val acc= 0.699420\n",
            "Epoch 1222: Training loss= 0.126564 Val loss= 0.645706 Training acc= 0.700380 Val acc= 0.699490\n",
            "Epoch 1223: Training loss= 0.126523 Val loss= 0.645415 Training acc= 0.700445 Val acc= 0.699560\n",
            "Epoch 1224: Training loss= 0.126481 Val loss= 0.645125 Training acc= 0.700485 Val acc= 0.699590\n",
            "Epoch 1225: Training loss= 0.126440 Val loss= 0.644835 Training acc= 0.700540 Val acc= 0.699640\n",
            "Epoch 1226: Training loss= 0.126398 Val loss= 0.644545 Training acc= 0.700590 Val acc= 0.699675\n",
            "Epoch 1227: Training loss= 0.126357 Val loss= 0.644256 Training acc= 0.700620 Val acc= 0.699710\n",
            "Epoch 1228: Training loss= 0.126316 Val loss= 0.643968 Training acc= 0.700645 Val acc= 0.699735\n",
            "Epoch 1229: Training loss= 0.126275 Val loss= 0.643679 Training acc= 0.700710 Val acc= 0.699810\n",
            "Epoch 1230: Training loss= 0.126233 Val loss= 0.643391 Training acc= 0.700770 Val acc= 0.699875\n",
            "Epoch 1231: Training loss= 0.126192 Val loss= 0.643104 Training acc= 0.700815 Val acc= 0.699915\n",
            "Epoch 1232: Training loss= 0.126152 Val loss= 0.642817 Training acc= 0.700845 Val acc= 0.699950\n",
            "Epoch 1233: Training loss= 0.126111 Val loss= 0.642530 Training acc= 0.700880 Val acc= 0.699970\n",
            "Epoch 1234: Training loss= 0.126070 Val loss= 0.642244 Training acc= 0.700960 Val acc= 0.700030\n",
            "Epoch 1235: Training loss= 0.126029 Val loss= 0.641958 Training acc= 0.701010 Val acc= 0.700095\n",
            "Epoch 1236: Training loss= 0.125989 Val loss= 0.641672 Training acc= 0.701045 Val acc= 0.700130\n",
            "Epoch 1237: Training loss= 0.125948 Val loss= 0.641387 Training acc= 0.701080 Val acc= 0.700155\n",
            "Epoch 1238: Training loss= 0.125908 Val loss= 0.641102 Training acc= 0.701130 Val acc= 0.700210\n",
            "Epoch 1239: Training loss= 0.125867 Val loss= 0.640818 Training acc= 0.701195 Val acc= 0.700300\n",
            "Epoch 1240: Training loss= 0.125827 Val loss= 0.640534 Training acc= 0.701230 Val acc= 0.700310\n",
            "Epoch 1241: Training loss= 0.125787 Val loss= 0.640251 Training acc= 0.701250 Val acc= 0.700355\n",
            "Epoch 1242: Training loss= 0.125747 Val loss= 0.639968 Training acc= 0.701285 Val acc= 0.700355\n",
            "Epoch 1243: Training loss= 0.125707 Val loss= 0.639685 Training acc= 0.701330 Val acc= 0.700395\n",
            "Epoch 1244: Training loss= 0.125667 Val loss= 0.639403 Training acc= 0.701410 Val acc= 0.700485\n",
            "Epoch 1245: Training loss= 0.125627 Val loss= 0.639121 Training acc= 0.701420 Val acc= 0.700520\n",
            "Epoch 1246: Training loss= 0.125587 Val loss= 0.638839 Training acc= 0.701460 Val acc= 0.700580\n",
            "Epoch 1247: Training loss= 0.125547 Val loss= 0.638558 Training acc= 0.701485 Val acc= 0.700595\n",
            "Epoch 1248: Training loss= 0.125507 Val loss= 0.638277 Training acc= 0.701530 Val acc= 0.700655\n",
            "Epoch 1249: Training loss= 0.125468 Val loss= 0.637997 Training acc= 0.701550 Val acc= 0.700695\n",
            "Epoch 1250: Training loss= 0.125428 Val loss= 0.637717 Training acc= 0.701575 Val acc= 0.700715\n",
            "Epoch 1251: Training loss= 0.125389 Val loss= 0.637438 Training acc= 0.701605 Val acc= 0.700730\n",
            "Epoch 1252: Training loss= 0.125349 Val loss= 0.637158 Training acc= 0.701650 Val acc= 0.700770\n",
            "Epoch 1253: Training loss= 0.125310 Val loss= 0.636880 Training acc= 0.701675 Val acc= 0.700810\n",
            "Epoch 1254: Training loss= 0.125271 Val loss= 0.636601 Training acc= 0.701710 Val acc= 0.700850\n",
            "Epoch 1255: Training loss= 0.125232 Val loss= 0.636323 Training acc= 0.701780 Val acc= 0.700920\n",
            "Epoch 1256: Training loss= 0.125193 Val loss= 0.636046 Training acc= 0.701830 Val acc= 0.700970\n",
            "Epoch 1257: Training loss= 0.125154 Val loss= 0.635768 Training acc= 0.701855 Val acc= 0.701010\n",
            "Epoch 1258: Training loss= 0.125115 Val loss= 0.635491 Training acc= 0.701905 Val acc= 0.701065\n",
            "Epoch 1259: Training loss= 0.125076 Val loss= 0.635215 Training acc= 0.701900 Val acc= 0.701095\n",
            "Epoch 1260: Training loss= 0.125037 Val loss= 0.634939 Training acc= 0.701905 Val acc= 0.701100\n",
            "Epoch 1261: Training loss= 0.124998 Val loss= 0.634663 Training acc= 0.701965 Val acc= 0.701165\n",
            "Epoch 1262: Training loss= 0.124959 Val loss= 0.634388 Training acc= 0.701995 Val acc= 0.701170\n",
            "Epoch 1263: Training loss= 0.124921 Val loss= 0.634113 Training acc= 0.702010 Val acc= 0.701210\n",
            "Epoch 1264: Training loss= 0.124882 Val loss= 0.633838 Training acc= 0.702050 Val acc= 0.701235\n",
            "Epoch 1265: Training loss= 0.124844 Val loss= 0.633564 Training acc= 0.702125 Val acc= 0.701325\n",
            "Epoch 1266: Training loss= 0.124806 Val loss= 0.633290 Training acc= 0.702175 Val acc= 0.701380\n",
            "Epoch 1267: Training loss= 0.124767 Val loss= 0.633017 Training acc= 0.702200 Val acc= 0.701425\n",
            "Epoch 1268: Training loss= 0.124729 Val loss= 0.632743 Training acc= 0.702235 Val acc= 0.701490\n",
            "Epoch 1269: Training loss= 0.124691 Val loss= 0.632471 Training acc= 0.702240 Val acc= 0.701500\n",
            "Epoch 1270: Training loss= 0.124653 Val loss= 0.632198 Training acc= 0.702300 Val acc= 0.701555\n",
            "Epoch 1271: Training loss= 0.124615 Val loss= 0.631926 Training acc= 0.702340 Val acc= 0.701600\n",
            "Epoch 1272: Training loss= 0.124577 Val loss= 0.631655 Training acc= 0.702395 Val acc= 0.701650\n",
            "Epoch 1273: Training loss= 0.124539 Val loss= 0.631383 Training acc= 0.702430 Val acc= 0.701695\n",
            "Epoch 1274: Training loss= 0.124501 Val loss= 0.631113 Training acc= 0.702465 Val acc= 0.701725\n",
            "Epoch 1275: Training loss= 0.124463 Val loss= 0.630842 Training acc= 0.702450 Val acc= 0.701725\n",
            "Epoch 1276: Training loss= 0.124426 Val loss= 0.630572 Training acc= 0.702490 Val acc= 0.701770\n",
            "Epoch 1277: Training loss= 0.124388 Val loss= 0.630302 Training acc= 0.702470 Val acc= 0.701760\n",
            "Epoch 1278: Training loss= 0.124350 Val loss= 0.630033 Training acc= 0.702510 Val acc= 0.701775\n",
            "Epoch 1279: Training loss= 0.124313 Val loss= 0.629763 Training acc= 0.702575 Val acc= 0.701835\n",
            "Epoch 1280: Training loss= 0.124276 Val loss= 0.629495 Training acc= 0.702610 Val acc= 0.701855\n",
            "Epoch 1281: Training loss= 0.124238 Val loss= 0.629226 Training acc= 0.702635 Val acc= 0.701865\n",
            "Epoch 1282: Training loss= 0.124201 Val loss= 0.628958 Training acc= 0.702690 Val acc= 0.701930\n",
            "Epoch 1283: Training loss= 0.124164 Val loss= 0.628691 Training acc= 0.702690 Val acc= 0.701945\n",
            "Epoch 1284: Training loss= 0.124127 Val loss= 0.628423 Training acc= 0.702760 Val acc= 0.702020\n",
            "Epoch 1285: Training loss= 0.124089 Val loss= 0.628156 Training acc= 0.702800 Val acc= 0.702065\n",
            "Epoch 1286: Training loss= 0.124052 Val loss= 0.627890 Training acc= 0.702845 Val acc= 0.702110\n",
            "Epoch 1287: Training loss= 0.124016 Val loss= 0.627624 Training acc= 0.702860 Val acc= 0.702110\n",
            "Epoch 1288: Training loss= 0.123979 Val loss= 0.627358 Training acc= 0.702880 Val acc= 0.702150\n",
            "Epoch 1289: Training loss= 0.123942 Val loss= 0.627092 Training acc= 0.702940 Val acc= 0.702220\n",
            "Epoch 1290: Training loss= 0.123905 Val loss= 0.626827 Training acc= 0.702995 Val acc= 0.702275\n",
            "Epoch 1291: Training loss= 0.123868 Val loss= 0.626562 Training acc= 0.703005 Val acc= 0.702305\n",
            "Epoch 1292: Training loss= 0.123832 Val loss= 0.626298 Training acc= 0.703035 Val acc= 0.702365\n",
            "Epoch 1293: Training loss= 0.123795 Val loss= 0.626034 Training acc= 0.703095 Val acc= 0.702400\n",
            "Epoch 1294: Training loss= 0.123759 Val loss= 0.625770 Training acc= 0.703145 Val acc= 0.702420\n",
            "Epoch 1295: Training loss= 0.123722 Val loss= 0.625506 Training acc= 0.703230 Val acc= 0.702495\n",
            "Epoch 1296: Training loss= 0.123686 Val loss= 0.625243 Training acc= 0.703260 Val acc= 0.702515\n",
            "Epoch 1297: Training loss= 0.123650 Val loss= 0.624981 Training acc= 0.703255 Val acc= 0.702560\n",
            "Epoch 1298: Training loss= 0.123613 Val loss= 0.624718 Training acc= 0.703245 Val acc= 0.702570\n",
            "Epoch 1299: Training loss= 0.123577 Val loss= 0.624456 Training acc= 0.703280 Val acc= 0.702605\n",
            "Epoch 1300: Training loss= 0.123541 Val loss= 0.624194 Training acc= 0.703310 Val acc= 0.702635\n",
            "Epoch 1301: Training loss= 0.123505 Val loss= 0.623933 Training acc= 0.703330 Val acc= 0.702650\n",
            "Epoch 1302: Training loss= 0.123469 Val loss= 0.623672 Training acc= 0.703355 Val acc= 0.702665\n",
            "Epoch 1303: Training loss= 0.123433 Val loss= 0.623411 Training acc= 0.703370 Val acc= 0.702670\n",
            "Epoch 1304: Training loss= 0.123398 Val loss= 0.623151 Training acc= 0.703415 Val acc= 0.702700\n",
            "Epoch 1305: Training loss= 0.123362 Val loss= 0.622891 Training acc= 0.703475 Val acc= 0.702750\n",
            "Epoch 1306: Training loss= 0.123326 Val loss= 0.622631 Training acc= 0.703530 Val acc= 0.702805\n",
            "Epoch 1307: Training loss= 0.123290 Val loss= 0.622372 Training acc= 0.703555 Val acc= 0.702830\n",
            "Epoch 1308: Training loss= 0.123255 Val loss= 0.622113 Training acc= 0.703580 Val acc= 0.702845\n",
            "Epoch 1309: Training loss= 0.123219 Val loss= 0.621854 Training acc= 0.703645 Val acc= 0.702855\n",
            "Epoch 1310: Training loss= 0.123184 Val loss= 0.621596 Training acc= 0.703670 Val acc= 0.702885\n",
            "Epoch 1311: Training loss= 0.123148 Val loss= 0.621338 Training acc= 0.703705 Val acc= 0.702920\n",
            "Epoch 1312: Training loss= 0.123113 Val loss= 0.621080 Training acc= 0.703745 Val acc= 0.702950\n",
            "Epoch 1313: Training loss= 0.123078 Val loss= 0.620823 Training acc= 0.703750 Val acc= 0.702970\n",
            "Epoch 1314: Training loss= 0.123043 Val loss= 0.620566 Training acc= 0.703810 Val acc= 0.703030\n",
            "Epoch 1315: Training loss= 0.123007 Val loss= 0.620309 Training acc= 0.703825 Val acc= 0.703065\n",
            "Epoch 1316: Training loss= 0.122972 Val loss= 0.620053 Training acc= 0.703855 Val acc= 0.703130\n",
            "Epoch 1317: Training loss= 0.122937 Val loss= 0.619797 Training acc= 0.703895 Val acc= 0.703170\n",
            "Epoch 1318: Training loss= 0.122902 Val loss= 0.619541 Training acc= 0.703915 Val acc= 0.703195\n",
            "Epoch 1319: Training loss= 0.122867 Val loss= 0.619286 Training acc= 0.703990 Val acc= 0.703255\n",
            "Epoch 1320: Training loss= 0.122833 Val loss= 0.619031 Training acc= 0.704015 Val acc= 0.703280\n",
            "Epoch 1321: Training loss= 0.122798 Val loss= 0.618776 Training acc= 0.704065 Val acc= 0.703315\n",
            "Epoch 1322: Training loss= 0.122763 Val loss= 0.618522 Training acc= 0.704130 Val acc= 0.703385\n",
            "Epoch 1323: Training loss= 0.122728 Val loss= 0.618268 Training acc= 0.704140 Val acc= 0.703410\n",
            "Epoch 1324: Training loss= 0.122694 Val loss= 0.618014 Training acc= 0.704195 Val acc= 0.703450\n",
            "Epoch 1325: Training loss= 0.122659 Val loss= 0.617760 Training acc= 0.704220 Val acc= 0.703475\n",
            "Epoch 1326: Training loss= 0.122625 Val loss= 0.617507 Training acc= 0.704230 Val acc= 0.703490\n",
            "Epoch 1327: Training loss= 0.122590 Val loss= 0.617254 Training acc= 0.704245 Val acc= 0.703520\n",
            "Epoch 1328: Training loss= 0.122556 Val loss= 0.617002 Training acc= 0.704295 Val acc= 0.703580\n",
            "Epoch 1329: Training loss= 0.122522 Val loss= 0.616750 Training acc= 0.704310 Val acc= 0.703595\n",
            "Epoch 1330: Training loss= 0.122487 Val loss= 0.616498 Training acc= 0.704355 Val acc= 0.703640\n",
            "Epoch 1331: Training loss= 0.122453 Val loss= 0.616246 Training acc= 0.704420 Val acc= 0.703720\n",
            "Epoch 1332: Training loss= 0.122419 Val loss= 0.615995 Training acc= 0.704455 Val acc= 0.703745\n",
            "Epoch 1333: Training loss= 0.122385 Val loss= 0.615744 Training acc= 0.704480 Val acc= 0.703770\n",
            "Epoch 1334: Training loss= 0.122351 Val loss= 0.615494 Training acc= 0.704525 Val acc= 0.703800\n",
            "Epoch 1335: Training loss= 0.122317 Val loss= 0.615244 Training acc= 0.704545 Val acc= 0.703835\n",
            "Epoch 1336: Training loss= 0.122283 Val loss= 0.614994 Training acc= 0.704600 Val acc= 0.703865\n",
            "Epoch 1337: Training loss= 0.122249 Val loss= 0.614744 Training acc= 0.704635 Val acc= 0.703890\n",
            "Epoch 1338: Training loss= 0.122215 Val loss= 0.614495 Training acc= 0.704670 Val acc= 0.703950\n",
            "Epoch 1339: Training loss= 0.122182 Val loss= 0.614246 Training acc= 0.704705 Val acc= 0.703975\n",
            "Epoch 1340: Training loss= 0.122148 Val loss= 0.613997 Training acc= 0.704730 Val acc= 0.704000\n",
            "Epoch 1341: Training loss= 0.122114 Val loss= 0.613749 Training acc= 0.704745 Val acc= 0.703990\n",
            "Epoch 1342: Training loss= 0.122081 Val loss= 0.613500 Training acc= 0.704775 Val acc= 0.704005\n",
            "Epoch 1343: Training loss= 0.122047 Val loss= 0.613253 Training acc= 0.704840 Val acc= 0.704055\n",
            "Epoch 1344: Training loss= 0.122014 Val loss= 0.613005 Training acc= 0.704900 Val acc= 0.704140\n",
            "Epoch 1345: Training loss= 0.121980 Val loss= 0.612758 Training acc= 0.704920 Val acc= 0.704180\n",
            "Epoch 1346: Training loss= 0.121947 Val loss= 0.612511 Training acc= 0.704970 Val acc= 0.704230\n",
            "Epoch 1347: Training loss= 0.121914 Val loss= 0.612265 Training acc= 0.705010 Val acc= 0.704295\n",
            "Epoch 1348: Training loss= 0.121881 Val loss= 0.612018 Training acc= 0.705080 Val acc= 0.704345\n",
            "Epoch 1349: Training loss= 0.121847 Val loss= 0.611772 Training acc= 0.705100 Val acc= 0.704355\n",
            "Epoch 1350: Training loss= 0.121814 Val loss= 0.611527 Training acc= 0.705105 Val acc= 0.704365\n",
            "Epoch 1351: Training loss= 0.121781 Val loss= 0.611281 Training acc= 0.705150 Val acc= 0.704410\n",
            "Epoch 1352: Training loss= 0.121748 Val loss= 0.611036 Training acc= 0.705200 Val acc= 0.704470\n",
            "Epoch 1353: Training loss= 0.121715 Val loss= 0.610792 Training acc= 0.705235 Val acc= 0.704520\n",
            "Epoch 1354: Training loss= 0.121682 Val loss= 0.610547 Training acc= 0.705255 Val acc= 0.704540\n",
            "Epoch 1355: Training loss= 0.121650 Val loss= 0.610303 Training acc= 0.705300 Val acc= 0.704585\n",
            "Epoch 1356: Training loss= 0.121617 Val loss= 0.610059 Training acc= 0.705370 Val acc= 0.704650\n",
            "Epoch 1357: Training loss= 0.121584 Val loss= 0.609816 Training acc= 0.705385 Val acc= 0.704675\n",
            "Epoch 1358: Training loss= 0.121551 Val loss= 0.609572 Training acc= 0.705380 Val acc= 0.704685\n",
            "Epoch 1359: Training loss= 0.121519 Val loss= 0.609329 Training acc= 0.705385 Val acc= 0.704685\n",
            "Epoch 1360: Training loss= 0.121486 Val loss= 0.609087 Training acc= 0.705420 Val acc= 0.704705\n",
            "Epoch 1361: Training loss= 0.121454 Val loss= 0.608844 Training acc= 0.705445 Val acc= 0.704735\n",
            "Epoch 1362: Training loss= 0.121421 Val loss= 0.608602 Training acc= 0.705505 Val acc= 0.704775\n",
            "Epoch 1363: Training loss= 0.121389 Val loss= 0.608361 Training acc= 0.705605 Val acc= 0.704865\n",
            "Epoch 1364: Training loss= 0.121357 Val loss= 0.608119 Training acc= 0.705630 Val acc= 0.704890\n",
            "Epoch 1365: Training loss= 0.121324 Val loss= 0.607878 Training acc= 0.705690 Val acc= 0.704970\n",
            "Epoch 1366: Training loss= 0.121292 Val loss= 0.607637 Training acc= 0.705690 Val acc= 0.704965\n",
            "Epoch 1367: Training loss= 0.121260 Val loss= 0.607396 Training acc= 0.705715 Val acc= 0.704980\n",
            "Epoch 1368: Training loss= 0.121228 Val loss= 0.607156 Training acc= 0.705700 Val acc= 0.704995\n",
            "Epoch 1369: Training loss= 0.121196 Val loss= 0.606916 Training acc= 0.705740 Val acc= 0.705025\n",
            "Epoch 1370: Training loss= 0.121164 Val loss= 0.606676 Training acc= 0.705775 Val acc= 0.705055\n",
            "Epoch 1371: Training loss= 0.121132 Val loss= 0.606437 Training acc= 0.705810 Val acc= 0.705080\n",
            "Epoch 1372: Training loss= 0.121100 Val loss= 0.606198 Training acc= 0.705830 Val acc= 0.705115\n",
            "Epoch 1373: Training loss= 0.121068 Val loss= 0.605959 Training acc= 0.705865 Val acc= 0.705170\n",
            "Epoch 1374: Training loss= 0.121036 Val loss= 0.605720 Training acc= 0.705920 Val acc= 0.705235\n",
            "Epoch 1375: Training loss= 0.121004 Val loss= 0.605482 Training acc= 0.705950 Val acc= 0.705265\n",
            "Epoch 1376: Training loss= 0.120973 Val loss= 0.605244 Training acc= 0.706020 Val acc= 0.705325\n",
            "Epoch 1377: Training loss= 0.120941 Val loss= 0.605006 Training acc= 0.706080 Val acc= 0.705385\n",
            "Epoch 1378: Training loss= 0.120909 Val loss= 0.604768 Training acc= 0.706150 Val acc= 0.705440\n",
            "Epoch 1379: Training loss= 0.120878 Val loss= 0.604531 Training acc= 0.706155 Val acc= 0.705460\n",
            "Epoch 1380: Training loss= 0.120846 Val loss= 0.604294 Training acc= 0.706170 Val acc= 0.705490\n",
            "Epoch 1381: Training loss= 0.120815 Val loss= 0.604058 Training acc= 0.706180 Val acc= 0.705505\n",
            "Epoch 1382: Training loss= 0.120783 Val loss= 0.603821 Training acc= 0.706220 Val acc= 0.705535\n",
            "Epoch 1383: Training loss= 0.120752 Val loss= 0.603585 Training acc= 0.706280 Val acc= 0.705595\n",
            "Epoch 1384: Training loss= 0.120721 Val loss= 0.603350 Training acc= 0.706305 Val acc= 0.705610\n",
            "Epoch 1385: Training loss= 0.120689 Val loss= 0.603114 Training acc= 0.706340 Val acc= 0.705660\n",
            "Epoch 1386: Training loss= 0.120658 Val loss= 0.602879 Training acc= 0.706390 Val acc= 0.705710\n",
            "Epoch 1387: Training loss= 0.120627 Val loss= 0.602644 Training acc= 0.706405 Val acc= 0.705750\n",
            "Epoch 1388: Training loss= 0.120596 Val loss= 0.602409 Training acc= 0.706435 Val acc= 0.705780\n",
            "Epoch 1389: Training loss= 0.120565 Val loss= 0.602175 Training acc= 0.706435 Val acc= 0.705780\n",
            "Epoch 1390: Training loss= 0.120534 Val loss= 0.601941 Training acc= 0.706470 Val acc= 0.705815\n",
            "Epoch 1391: Training loss= 0.120503 Val loss= 0.601707 Training acc= 0.706465 Val acc= 0.705825\n",
            "Epoch 1392: Training loss= 0.120472 Val loss= 0.601473 Training acc= 0.706465 Val acc= 0.705800\n",
            "Epoch 1393: Training loss= 0.120441 Val loss= 0.601240 Training acc= 0.706500 Val acc= 0.705835\n",
            "Epoch 1394: Training loss= 0.120410 Val loss= 0.601007 Training acc= 0.706545 Val acc= 0.705860\n",
            "Epoch 1395: Training loss= 0.120380 Val loss= 0.600774 Training acc= 0.706600 Val acc= 0.705910\n",
            "Epoch 1396: Training loss= 0.120349 Val loss= 0.600542 Training acc= 0.706620 Val acc= 0.705950\n",
            "Epoch 1397: Training loss= 0.120318 Val loss= 0.600309 Training acc= 0.706645 Val acc= 0.706010\n",
            "Epoch 1398: Training loss= 0.120288 Val loss= 0.600077 Training acc= 0.706680 Val acc= 0.706065\n",
            "Epoch 1399: Training loss= 0.120257 Val loss= 0.599846 Training acc= 0.706700 Val acc= 0.706100\n",
            "Epoch 1400: Training loss= 0.120226 Val loss= 0.599614 Training acc= 0.706735 Val acc= 0.706145\n",
            "Epoch 1401: Training loss= 0.120196 Val loss= 0.599383 Training acc= 0.706750 Val acc= 0.706150\n",
            "Epoch 1402: Training loss= 0.120166 Val loss= 0.599152 Training acc= 0.706760 Val acc= 0.706160\n",
            "Epoch 1403: Training loss= 0.120135 Val loss= 0.598922 Training acc= 0.706800 Val acc= 0.706210\n",
            "Epoch 1404: Training loss= 0.120105 Val loss= 0.598691 Training acc= 0.706830 Val acc= 0.706230\n",
            "Epoch 1405: Training loss= 0.120075 Val loss= 0.598461 Training acc= 0.706840 Val acc= 0.706255\n",
            "Epoch 1406: Training loss= 0.120044 Val loss= 0.598232 Training acc= 0.706910 Val acc= 0.706290\n",
            "Epoch 1407: Training loss= 0.120014 Val loss= 0.598002 Training acc= 0.706950 Val acc= 0.706325\n",
            "Epoch 1408: Training loss= 0.119984 Val loss= 0.597773 Training acc= 0.706950 Val acc= 0.706360\n",
            "Epoch 1409: Training loss= 0.119954 Val loss= 0.597544 Training acc= 0.707000 Val acc= 0.706385\n",
            "Epoch 1410: Training loss= 0.119924 Val loss= 0.597315 Training acc= 0.707050 Val acc= 0.706425\n",
            "Epoch 1411: Training loss= 0.119894 Val loss= 0.597086 Training acc= 0.707050 Val acc= 0.706420\n",
            "Epoch 1412: Training loss= 0.119864 Val loss= 0.596858 Training acc= 0.707040 Val acc= 0.706430\n",
            "Epoch 1413: Training loss= 0.119834 Val loss= 0.596630 Training acc= 0.707125 Val acc= 0.706515\n",
            "Epoch 1414: Training loss= 0.119804 Val loss= 0.596402 Training acc= 0.707190 Val acc= 0.706575\n",
            "Epoch 1415: Training loss= 0.119774 Val loss= 0.596175 Training acc= 0.707260 Val acc= 0.706660\n",
            "Epoch 1416: Training loss= 0.119745 Val loss= 0.595948 Training acc= 0.707285 Val acc= 0.706705\n",
            "Epoch 1417: Training loss= 0.119715 Val loss= 0.595721 Training acc= 0.707335 Val acc= 0.706735\n",
            "Epoch 1418: Training loss= 0.119685 Val loss= 0.595494 Training acc= 0.707380 Val acc= 0.706780\n",
            "Epoch 1419: Training loss= 0.119656 Val loss= 0.595268 Training acc= 0.707405 Val acc= 0.706800\n",
            "Epoch 1420: Training loss= 0.119626 Val loss= 0.595042 Training acc= 0.707445 Val acc= 0.706855\n",
            "Epoch 1421: Training loss= 0.119597 Val loss= 0.594816 Training acc= 0.707470 Val acc= 0.706880\n",
            "Epoch 1422: Training loss= 0.119567 Val loss= 0.594590 Training acc= 0.707470 Val acc= 0.706895\n",
            "Epoch 1423: Training loss= 0.119538 Val loss= 0.594365 Training acc= 0.707485 Val acc= 0.706925\n",
            "Epoch 1424: Training loss= 0.119508 Val loss= 0.594139 Training acc= 0.707535 Val acc= 0.706970\n",
            "Epoch 1425: Training loss= 0.119479 Val loss= 0.593915 Training acc= 0.707555 Val acc= 0.707010\n",
            "Epoch 1426: Training loss= 0.119450 Val loss= 0.593690 Training acc= 0.707625 Val acc= 0.707060\n",
            "Epoch 1427: Training loss= 0.119420 Val loss= 0.593466 Training acc= 0.707680 Val acc= 0.707115\n",
            "Epoch 1428: Training loss= 0.119391 Val loss= 0.593241 Training acc= 0.707750 Val acc= 0.707165\n",
            "Epoch 1429: Training loss= 0.119362 Val loss= 0.593018 Training acc= 0.707775 Val acc= 0.707195\n",
            "Epoch 1430: Training loss= 0.119333 Val loss= 0.592794 Training acc= 0.707775 Val acc= 0.707205\n",
            "Epoch 1431: Training loss= 0.119304 Val loss= 0.592571 Training acc= 0.707815 Val acc= 0.707255\n",
            "Epoch 1432: Training loss= 0.119275 Val loss= 0.592347 Training acc= 0.707865 Val acc= 0.707305\n",
            "Epoch 1433: Training loss= 0.119246 Val loss= 0.592124 Training acc= 0.707935 Val acc= 0.707365\n",
            "Epoch 1434: Training loss= 0.119217 Val loss= 0.591902 Training acc= 0.707960 Val acc= 0.707415\n",
            "Epoch 1435: Training loss= 0.119188 Val loss= 0.591679 Training acc= 0.708015 Val acc= 0.707465\n",
            "Epoch 1436: Training loss= 0.119159 Val loss= 0.591457 Training acc= 0.708055 Val acc= 0.707505\n",
            "Epoch 1437: Training loss= 0.119130 Val loss= 0.591235 Training acc= 0.708105 Val acc= 0.707570\n",
            "Epoch 1438: Training loss= 0.119102 Val loss= 0.591014 Training acc= 0.708145 Val acc= 0.707610\n",
            "Epoch 1439: Training loss= 0.119073 Val loss= 0.590792 Training acc= 0.708135 Val acc= 0.707600\n",
            "Epoch 1440: Training loss= 0.119044 Val loss= 0.590571 Training acc= 0.708125 Val acc= 0.707600\n",
            "Epoch 1441: Training loss= 0.119016 Val loss= 0.590350 Training acc= 0.708170 Val acc= 0.707645\n",
            "Epoch 1442: Training loss= 0.118987 Val loss= 0.590130 Training acc= 0.708195 Val acc= 0.707665\n",
            "Epoch 1443: Training loss= 0.118958 Val loss= 0.589909 Training acc= 0.708195 Val acc= 0.707665\n",
            "Epoch 1444: Training loss= 0.118930 Val loss= 0.589689 Training acc= 0.708230 Val acc= 0.707710\n",
            "Epoch 1445: Training loss= 0.118901 Val loss= 0.589469 Training acc= 0.708220 Val acc= 0.707735\n",
            "Epoch 1446: Training loss= 0.118873 Val loss= 0.589249 Training acc= 0.708225 Val acc= 0.707745\n",
            "Epoch 1447: Training loss= 0.118845 Val loss= 0.589030 Training acc= 0.708260 Val acc= 0.707775\n",
            "Epoch 1448: Training loss= 0.118816 Val loss= 0.588811 Training acc= 0.708295 Val acc= 0.707810\n",
            "Epoch 1449: Training loss= 0.118788 Val loss= 0.588592 Training acc= 0.708330 Val acc= 0.707815\n",
            "Epoch 1450: Training loss= 0.118760 Val loss= 0.588373 Training acc= 0.708350 Val acc= 0.707840\n",
            "Epoch 1451: Training loss= 0.118732 Val loss= 0.588155 Training acc= 0.708400 Val acc= 0.707860\n",
            "Epoch 1452: Training loss= 0.118703 Val loss= 0.587936 Training acc= 0.708430 Val acc= 0.707875\n",
            "Epoch 1453: Training loss= 0.118675 Val loss= 0.587718 Training acc= 0.708430 Val acc= 0.707885\n",
            "Epoch 1454: Training loss= 0.118647 Val loss= 0.587501 Training acc= 0.708455 Val acc= 0.707915\n",
            "Epoch 1455: Training loss= 0.118619 Val loss= 0.587283 Training acc= 0.708465 Val acc= 0.707930\n",
            "Epoch 1456: Training loss= 0.118591 Val loss= 0.587066 Training acc= 0.708525 Val acc= 0.707955\n",
            "Epoch 1457: Training loss= 0.118563 Val loss= 0.586849 Training acc= 0.708525 Val acc= 0.707975\n",
            "Epoch 1458: Training loss= 0.118535 Val loss= 0.586632 Training acc= 0.708550 Val acc= 0.707990\n",
            "Epoch 1459: Training loss= 0.118507 Val loss= 0.586415 Training acc= 0.708535 Val acc= 0.708000\n",
            "Epoch 1460: Training loss= 0.118480 Val loss= 0.586199 Training acc= 0.708600 Val acc= 0.708070\n",
            "Epoch 1461: Training loss= 0.118452 Val loss= 0.585983 Training acc= 0.708630 Val acc= 0.708085\n",
            "Epoch 1462: Training loss= 0.118424 Val loss= 0.585767 Training acc= 0.708695 Val acc= 0.708165\n",
            "Epoch 1463: Training loss= 0.118396 Val loss= 0.585551 Training acc= 0.708710 Val acc= 0.708200\n",
            "Epoch 1464: Training loss= 0.118369 Val loss= 0.585336 Training acc= 0.708740 Val acc= 0.708240\n",
            "Epoch 1465: Training loss= 0.118341 Val loss= 0.585121 Training acc= 0.708740 Val acc= 0.708260\n",
            "Epoch 1466: Training loss= 0.118314 Val loss= 0.584906 Training acc= 0.708760 Val acc= 0.708280\n",
            "Epoch 1467: Training loss= 0.118286 Val loss= 0.584691 Training acc= 0.708785 Val acc= 0.708330\n",
            "Epoch 1468: Training loss= 0.118258 Val loss= 0.584476 Training acc= 0.708830 Val acc= 0.708385\n",
            "Epoch 1469: Training loss= 0.118231 Val loss= 0.584262 Training acc= 0.708860 Val acc= 0.708400\n",
            "Epoch 1470: Training loss= 0.118204 Val loss= 0.584048 Training acc= 0.708940 Val acc= 0.708450\n",
            "Epoch 1471: Training loss= 0.118176 Val loss= 0.583834 Training acc= 0.708915 Val acc= 0.708415\n",
            "Epoch 1472: Training loss= 0.118149 Val loss= 0.583621 Training acc= 0.708935 Val acc= 0.708445\n",
            "Epoch 1473: Training loss= 0.118122 Val loss= 0.583407 Training acc= 0.708965 Val acc= 0.708510\n",
            "Epoch 1474: Training loss= 0.118094 Val loss= 0.583194 Training acc= 0.708995 Val acc= 0.708555\n",
            "Epoch 1475: Training loss= 0.118067 Val loss= 0.582981 Training acc= 0.709020 Val acc= 0.708595\n",
            "Epoch 1476: Training loss= 0.118040 Val loss= 0.582769 Training acc= 0.709060 Val acc= 0.708650\n",
            "Epoch 1477: Training loss= 0.118013 Val loss= 0.582556 Training acc= 0.709120 Val acc= 0.708695\n",
            "Epoch 1478: Training loss= 0.117986 Val loss= 0.582344 Training acc= 0.709170 Val acc= 0.708725\n",
            "Epoch 1479: Training loss= 0.117959 Val loss= 0.582132 Training acc= 0.709225 Val acc= 0.708770\n",
            "Epoch 1480: Training loss= 0.117932 Val loss= 0.581920 Training acc= 0.709270 Val acc= 0.708835\n",
            "Epoch 1481: Training loss= 0.117905 Val loss= 0.581709 Training acc= 0.709285 Val acc= 0.708870\n",
            "Epoch 1482: Training loss= 0.117878 Val loss= 0.581497 Training acc= 0.709290 Val acc= 0.708885\n",
            "Epoch 1483: Training loss= 0.117851 Val loss= 0.581286 Training acc= 0.709310 Val acc= 0.708910\n",
            "Epoch 1484: Training loss= 0.117824 Val loss= 0.581075 Training acc= 0.709315 Val acc= 0.708935\n",
            "Epoch 1485: Training loss= 0.117797 Val loss= 0.580865 Training acc= 0.709375 Val acc= 0.709000\n",
            "Epoch 1486: Training loss= 0.117770 Val loss= 0.580654 Training acc= 0.709435 Val acc= 0.709065\n",
            "Epoch 1487: Training loss= 0.117744 Val loss= 0.580444 Training acc= 0.709465 Val acc= 0.709120\n",
            "Epoch 1488: Training loss= 0.117717 Val loss= 0.580234 Training acc= 0.709525 Val acc= 0.709185\n",
            "Epoch 1489: Training loss= 0.117690 Val loss= 0.580024 Training acc= 0.709565 Val acc= 0.709215\n",
            "Epoch 1490: Training loss= 0.117664 Val loss= 0.579815 Training acc= 0.709585 Val acc= 0.709240\n",
            "Epoch 1491: Training loss= 0.117637 Val loss= 0.579605 Training acc= 0.709575 Val acc= 0.709225\n",
            "Epoch 1492: Training loss= 0.117611 Val loss= 0.579396 Training acc= 0.709625 Val acc= 0.709285\n",
            "Epoch 1493: Training loss= 0.117584 Val loss= 0.579187 Training acc= 0.709645 Val acc= 0.709310\n",
            "Epoch 1494: Training loss= 0.117558 Val loss= 0.578979 Training acc= 0.709705 Val acc= 0.709350\n",
            "Epoch 1495: Training loss= 0.117531 Val loss= 0.578770 Training acc= 0.709685 Val acc= 0.709350\n",
            "Epoch 1496: Training loss= 0.117505 Val loss= 0.578562 Training acc= 0.709690 Val acc= 0.709385\n",
            "Epoch 1497: Training loss= 0.117478 Val loss= 0.578354 Training acc= 0.709725 Val acc= 0.709410\n",
            "Epoch 1498: Training loss= 0.117452 Val loss= 0.578146 Training acc= 0.709775 Val acc= 0.709445\n",
            "Epoch 1499: Training loss= 0.117426 Val loss= 0.577939 Training acc= 0.709840 Val acc= 0.709495\n",
            "Epoch 1500: Training loss= 0.117399 Val loss= 0.577731 Training acc= 0.709845 Val acc= 0.709500\n",
            "Epoch 1501: Training loss= 0.117373 Val loss= 0.577524 Training acc= 0.709880 Val acc= 0.709540\n",
            "Epoch 1502: Training loss= 0.117347 Val loss= 0.577317 Training acc= 0.709900 Val acc= 0.709565\n",
            "Epoch 1503: Training loss= 0.117321 Val loss= 0.577110 Training acc= 0.709920 Val acc= 0.709585\n",
            "Epoch 1504: Training loss= 0.117295 Val loss= 0.576904 Training acc= 0.709945 Val acc= 0.709625\n",
            "Epoch 1505: Training loss= 0.117269 Val loss= 0.576698 Training acc= 0.709980 Val acc= 0.709635\n",
            "Epoch 1506: Training loss= 0.117243 Val loss= 0.576491 Training acc= 0.710015 Val acc= 0.709675\n",
            "Epoch 1507: Training loss= 0.117217 Val loss= 0.576286 Training acc= 0.710025 Val acc= 0.709690\n",
            "Epoch 1508: Training loss= 0.117191 Val loss= 0.576080 Training acc= 0.710040 Val acc= 0.709695\n",
            "Epoch 1509: Training loss= 0.117165 Val loss= 0.575874 Training acc= 0.710075 Val acc= 0.709695\n",
            "Epoch 1510: Training loss= 0.117139 Val loss= 0.575669 Training acc= 0.710115 Val acc= 0.709730\n",
            "Epoch 1511: Training loss= 0.117113 Val loss= 0.575464 Training acc= 0.710155 Val acc= 0.709775\n",
            "Epoch 1512: Training loss= 0.117087 Val loss= 0.575259 Training acc= 0.710180 Val acc= 0.709775\n",
            "Epoch 1513: Training loss= 0.117062 Val loss= 0.575055 Training acc= 0.710180 Val acc= 0.709765\n",
            "Epoch 1514: Training loss= 0.117036 Val loss= 0.574850 Training acc= 0.710215 Val acc= 0.709795\n",
            "Epoch 1515: Training loss= 0.117010 Val loss= 0.574646 Training acc= 0.710250 Val acc= 0.709815\n",
            "Epoch 1516: Training loss= 0.116985 Val loss= 0.574442 Training acc= 0.710280 Val acc= 0.709860\n",
            "Epoch 1517: Training loss= 0.116959 Val loss= 0.574238 Training acc= 0.710315 Val acc= 0.709880\n",
            "Epoch 1518: Training loss= 0.116933 Val loss= 0.574035 Training acc= 0.710345 Val acc= 0.709910\n",
            "Epoch 1519: Training loss= 0.116908 Val loss= 0.573831 Training acc= 0.710330 Val acc= 0.709900\n",
            "Epoch 1520: Training loss= 0.116882 Val loss= 0.573628 Training acc= 0.710380 Val acc= 0.709925\n",
            "Epoch 1521: Training loss= 0.116857 Val loss= 0.573425 Training acc= 0.710435 Val acc= 0.709980\n",
            "Epoch 1522: Training loss= 0.116831 Val loss= 0.573223 Training acc= 0.710460 Val acc= 0.710025\n",
            "Epoch 1523: Training loss= 0.116806 Val loss= 0.573020 Training acc= 0.710480 Val acc= 0.710045\n",
            "Epoch 1524: Training loss= 0.116781 Val loss= 0.572818 Training acc= 0.710505 Val acc= 0.710070\n",
            "Epoch 1525: Training loss= 0.116755 Val loss= 0.572616 Training acc= 0.710565 Val acc= 0.710120\n",
            "Epoch 1526: Training loss= 0.116730 Val loss= 0.572414 Training acc= 0.710615 Val acc= 0.710165\n",
            "Epoch 1527: Training loss= 0.116705 Val loss= 0.572212 Training acc= 0.710625 Val acc= 0.710190\n",
            "Epoch 1528: Training loss= 0.116679 Val loss= 0.572010 Training acc= 0.710675 Val acc= 0.710245\n",
            "Epoch 1529: Training loss= 0.116654 Val loss= 0.571809 Training acc= 0.710710 Val acc= 0.710285\n",
            "Epoch 1530: Training loss= 0.116629 Val loss= 0.571608 Training acc= 0.710710 Val acc= 0.710300\n",
            "Epoch 1531: Training loss= 0.116604 Val loss= 0.571407 Training acc= 0.710710 Val acc= 0.710315\n",
            "Epoch 1532: Training loss= 0.116579 Val loss= 0.571206 Training acc= 0.710760 Val acc= 0.710355\n",
            "Epoch 1533: Training loss= 0.116554 Val loss= 0.571006 Training acc= 0.710795 Val acc= 0.710375\n",
            "Epoch 1534: Training loss= 0.116529 Val loss= 0.570806 Training acc= 0.710795 Val acc= 0.710375\n",
            "Epoch 1535: Training loss= 0.116504 Val loss= 0.570605 Training acc= 0.710830 Val acc= 0.710395\n",
            "Epoch 1536: Training loss= 0.116479 Val loss= 0.570406 Training acc= 0.710860 Val acc= 0.710435\n",
            "Epoch 1537: Training loss= 0.116454 Val loss= 0.570206 Training acc= 0.710880 Val acc= 0.710475\n",
            "Epoch 1538: Training loss= 0.116429 Val loss= 0.570006 Training acc= 0.710935 Val acc= 0.710545\n",
            "Epoch 1539: Training loss= 0.116404 Val loss= 0.569807 Training acc= 0.710930 Val acc= 0.710525\n",
            "Epoch 1540: Training loss= 0.116379 Val loss= 0.569608 Training acc= 0.710950 Val acc= 0.710555\n",
            "Epoch 1541: Training loss= 0.116355 Val loss= 0.569409 Training acc= 0.710955 Val acc= 0.710590\n",
            "Epoch 1542: Training loss= 0.116330 Val loss= 0.569210 Training acc= 0.710985 Val acc= 0.710630\n",
            "Epoch 1543: Training loss= 0.116305 Val loss= 0.569012 Training acc= 0.711015 Val acc= 0.710650\n",
            "Epoch 1544: Training loss= 0.116280 Val loss= 0.568813 Training acc= 0.711035 Val acc= 0.710660\n",
            "Epoch 1545: Training loss= 0.116256 Val loss= 0.568615 Training acc= 0.711080 Val acc= 0.710700\n",
            "Epoch 1546: Training loss= 0.116231 Val loss= 0.568417 Training acc= 0.711090 Val acc= 0.710720\n",
            "Epoch 1547: Training loss= 0.116207 Val loss= 0.568220 Training acc= 0.711130 Val acc= 0.710765\n",
            "Epoch 1548: Training loss= 0.116182 Val loss= 0.568022 Training acc= 0.711160 Val acc= 0.710795\n",
            "Epoch 1549: Training loss= 0.116158 Val loss= 0.567825 Training acc= 0.711165 Val acc= 0.710785\n",
            "Epoch 1550: Training loss= 0.116133 Val loss= 0.567628 Training acc= 0.711225 Val acc= 0.710855\n",
            "Epoch 1551: Training loss= 0.116109 Val loss= 0.567431 Training acc= 0.711225 Val acc= 0.710855\n",
            "Epoch 1552: Training loss= 0.116084 Val loss= 0.567234 Training acc= 0.711235 Val acc= 0.710855\n",
            "Epoch 1553: Training loss= 0.116060 Val loss= 0.567037 Training acc= 0.711235 Val acc= 0.710865\n",
            "Epoch 1554: Training loss= 0.116035 Val loss= 0.566841 Training acc= 0.711235 Val acc= 0.710865\n",
            "Epoch 1555: Training loss= 0.116011 Val loss= 0.566645 Training acc= 0.711245 Val acc= 0.710880\n",
            "Epoch 1556: Training loss= 0.115987 Val loss= 0.566449 Training acc= 0.711295 Val acc= 0.710925\n",
            "Epoch 1557: Training loss= 0.115963 Val loss= 0.566253 Training acc= 0.711325 Val acc= 0.710950\n",
            "Epoch 1558: Training loss= 0.115938 Val loss= 0.566057 Training acc= 0.711340 Val acc= 0.710940\n",
            "Epoch 1559: Training loss= 0.115914 Val loss= 0.565862 Training acc= 0.711355 Val acc= 0.710945\n",
            "Epoch 1560: Training loss= 0.115890 Val loss= 0.565667 Training acc= 0.711390 Val acc= 0.710975\n",
            "Epoch 1561: Training loss= 0.115866 Val loss= 0.565472 Training acc= 0.711410 Val acc= 0.711005\n",
            "Epoch 1562: Training loss= 0.115842 Val loss= 0.565277 Training acc= 0.711440 Val acc= 0.711045\n",
            "Epoch 1563: Training loss= 0.115818 Val loss= 0.565082 Training acc= 0.711470 Val acc= 0.711050\n",
            "Epoch 1564: Training loss= 0.115794 Val loss= 0.564888 Training acc= 0.711510 Val acc= 0.711090\n",
            "Epoch 1565: Training loss= 0.115770 Val loss= 0.564694 Training acc= 0.711540 Val acc= 0.711125\n",
            "Epoch 1566: Training loss= 0.115746 Val loss= 0.564499 Training acc= 0.711565 Val acc= 0.711175\n",
            "Epoch 1567: Training loss= 0.115722 Val loss= 0.564306 Training acc= 0.711605 Val acc= 0.711220\n",
            "Epoch 1568: Training loss= 0.115698 Val loss= 0.564112 Training acc= 0.711635 Val acc= 0.711250\n",
            "Epoch 1569: Training loss= 0.115674 Val loss= 0.563918 Training acc= 0.711635 Val acc= 0.711255\n",
            "Epoch 1570: Training loss= 0.115650 Val loss= 0.563725 Training acc= 0.711645 Val acc= 0.711255\n",
            "Epoch 1571: Training loss= 0.115627 Val loss= 0.563532 Training acc= 0.711680 Val acc= 0.711280\n",
            "Epoch 1572: Training loss= 0.115603 Val loss= 0.563339 Training acc= 0.711710 Val acc= 0.711305\n",
            "Epoch 1573: Training loss= 0.115579 Val loss= 0.563146 Training acc= 0.711735 Val acc= 0.711340\n",
            "Epoch 1574: Training loss= 0.115555 Val loss= 0.562954 Training acc= 0.711805 Val acc= 0.711395\n",
            "Epoch 1575: Training loss= 0.115532 Val loss= 0.562761 Training acc= 0.711870 Val acc= 0.711465\n",
            "Epoch 1576: Training loss= 0.115508 Val loss= 0.562569 Training acc= 0.711940 Val acc= 0.711510\n",
            "Epoch 1577: Training loss= 0.115484 Val loss= 0.562377 Training acc= 0.711995 Val acc= 0.711570\n",
            "Epoch 1578: Training loss= 0.115461 Val loss= 0.562185 Training acc= 0.712040 Val acc= 0.711610\n",
            "Epoch 1579: Training loss= 0.115437 Val loss= 0.561993 Training acc= 0.712055 Val acc= 0.711595\n",
            "Epoch 1580: Training loss= 0.115414 Val loss= 0.561802 Training acc= 0.712070 Val acc= 0.711620\n",
            "Epoch 1581: Training loss= 0.115390 Val loss= 0.561611 Training acc= 0.712135 Val acc= 0.711690\n",
            "Epoch 1582: Training loss= 0.115367 Val loss= 0.561419 Training acc= 0.712155 Val acc= 0.711705\n",
            "Epoch 1583: Training loss= 0.115343 Val loss= 0.561229 Training acc= 0.712205 Val acc= 0.711730\n",
            "Epoch 1584: Training loss= 0.115320 Val loss= 0.561038 Training acc= 0.712250 Val acc= 0.711780\n",
            "Epoch 1585: Training loss= 0.115297 Val loss= 0.560847 Training acc= 0.712270 Val acc= 0.711825\n",
            "Epoch 1586: Training loss= 0.115273 Val loss= 0.560657 Training acc= 0.712300 Val acc= 0.711845\n",
            "Epoch 1587: Training loss= 0.115250 Val loss= 0.560467 Training acc= 0.712345 Val acc= 0.711895\n",
            "Epoch 1588: Training loss= 0.115227 Val loss= 0.560277 Training acc= 0.712365 Val acc= 0.711920\n",
            "Epoch 1589: Training loss= 0.115204 Val loss= 0.560087 Training acc= 0.712420 Val acc= 0.711965\n",
            "Epoch 1590: Training loss= 0.115180 Val loss= 0.559897 Training acc= 0.712455 Val acc= 0.712010\n",
            "Epoch 1591: Training loss= 0.115157 Val loss= 0.559708 Training acc= 0.712495 Val acc= 0.712050\n",
            "Epoch 1592: Training loss= 0.115134 Val loss= 0.559518 Training acc= 0.712520 Val acc= 0.712075\n",
            "Epoch 1593: Training loss= 0.115111 Val loss= 0.559329 Training acc= 0.712535 Val acc= 0.712085\n",
            "Epoch 1594: Training loss= 0.115088 Val loss= 0.559140 Training acc= 0.712580 Val acc= 0.712145\n",
            "Epoch 1595: Training loss= 0.115065 Val loss= 0.558951 Training acc= 0.712600 Val acc= 0.712185\n",
            "Epoch 1596: Training loss= 0.115042 Val loss= 0.558763 Training acc= 0.712620 Val acc= 0.712230\n",
            "Epoch 1597: Training loss= 0.115019 Val loss= 0.558574 Training acc= 0.712615 Val acc= 0.712215\n",
            "Epoch 1598: Training loss= 0.114996 Val loss= 0.558386 Training acc= 0.712635 Val acc= 0.712230\n",
            "Epoch 1599: Training loss= 0.114973 Val loss= 0.558198 Training acc= 0.712650 Val acc= 0.712245\n",
            "Epoch 1600: Training loss= 0.114950 Val loss= 0.558010 Training acc= 0.712690 Val acc= 0.712270\n",
            "Epoch 1601: Training loss= 0.114927 Val loss= 0.557822 Training acc= 0.712725 Val acc= 0.712310\n",
            "Epoch 1602: Training loss= 0.114904 Val loss= 0.557635 Training acc= 0.712755 Val acc= 0.712325\n",
            "Epoch 1603: Training loss= 0.114881 Val loss= 0.557448 Training acc= 0.712810 Val acc= 0.712385\n",
            "Epoch 1604: Training loss= 0.114859 Val loss= 0.557260 Training acc= 0.712820 Val acc= 0.712420\n",
            "Epoch 1605: Training loss= 0.114836 Val loss= 0.557073 Training acc= 0.712830 Val acc= 0.712430\n",
            "Epoch 1606: Training loss= 0.114813 Val loss= 0.556887 Training acc= 0.712870 Val acc= 0.712465\n",
            "Epoch 1607: Training loss= 0.114790 Val loss= 0.556700 Training acc= 0.712910 Val acc= 0.712510\n",
            "Epoch 1608: Training loss= 0.114768 Val loss= 0.556513 Training acc= 0.712950 Val acc= 0.712540\n",
            "Epoch 1609: Training loss= 0.114745 Val loss= 0.556327 Training acc= 0.712985 Val acc= 0.712570\n",
            "Epoch 1610: Training loss= 0.114723 Val loss= 0.556141 Training acc= 0.713035 Val acc= 0.712620\n",
            "Epoch 1611: Training loss= 0.114700 Val loss= 0.555955 Training acc= 0.713090 Val acc= 0.712670\n",
            "Epoch 1612: Training loss= 0.114677 Val loss= 0.555769 Training acc= 0.713125 Val acc= 0.712695\n",
            "Epoch 1613: Training loss= 0.114655 Val loss= 0.555584 Training acc= 0.713170 Val acc= 0.712730\n",
            "Epoch 1614: Training loss= 0.114632 Val loss= 0.555398 Training acc= 0.713185 Val acc= 0.712765\n",
            "Epoch 1615: Training loss= 0.114610 Val loss= 0.555213 Training acc= 0.713180 Val acc= 0.712775\n",
            "Epoch 1616: Training loss= 0.114587 Val loss= 0.555028 Training acc= 0.713215 Val acc= 0.712820\n",
            "Epoch 1617: Training loss= 0.114565 Val loss= 0.554843 Training acc= 0.713240 Val acc= 0.712850\n",
            "Epoch 1618: Training loss= 0.114543 Val loss= 0.554658 Training acc= 0.713245 Val acc= 0.712845\n",
            "Epoch 1619: Training loss= 0.114520 Val loss= 0.554473 Training acc= 0.713280 Val acc= 0.712875\n",
            "Epoch 1620: Training loss= 0.114498 Val loss= 0.554289 Training acc= 0.713315 Val acc= 0.712895\n",
            "Epoch 1621: Training loss= 0.114476 Val loss= 0.554105 Training acc= 0.713385 Val acc= 0.712950\n",
            "Epoch 1622: Training loss= 0.114453 Val loss= 0.553921 Training acc= 0.713380 Val acc= 0.712935\n",
            "Epoch 1623: Training loss= 0.114431 Val loss= 0.553737 Training acc= 0.713425 Val acc= 0.712990\n",
            "Epoch 1624: Training loss= 0.114409 Val loss= 0.553553 Training acc= 0.713465 Val acc= 0.713030\n",
            "Epoch 1625: Training loss= 0.114387 Val loss= 0.553369 Training acc= 0.713485 Val acc= 0.713035\n",
            "Epoch 1626: Training loss= 0.114365 Val loss= 0.553186 Training acc= 0.713550 Val acc= 0.713095\n",
            "Epoch 1627: Training loss= 0.114343 Val loss= 0.553003 Training acc= 0.713595 Val acc= 0.713150\n",
            "Epoch 1628: Training loss= 0.114320 Val loss= 0.552820 Training acc= 0.713615 Val acc= 0.713150\n",
            "Epoch 1629: Training loss= 0.114298 Val loss= 0.552637 Training acc= 0.713630 Val acc= 0.713195\n",
            "Epoch 1630: Training loss= 0.114276 Val loss= 0.552454 Training acc= 0.713670 Val acc= 0.713235\n",
            "Epoch 1631: Training loss= 0.114254 Val loss= 0.552271 Training acc= 0.713675 Val acc= 0.713245\n",
            "Epoch 1632: Training loss= 0.114232 Val loss= 0.552089 Training acc= 0.713700 Val acc= 0.713300\n",
            "Epoch 1633: Training loss= 0.114210 Val loss= 0.551907 Training acc= 0.713710 Val acc= 0.713300\n",
            "Epoch 1634: Training loss= 0.114188 Val loss= 0.551725 Training acc= 0.713725 Val acc= 0.713310\n",
            "Epoch 1635: Training loss= 0.114166 Val loss= 0.551543 Training acc= 0.713760 Val acc= 0.713345\n",
            "Epoch 1636: Training loss= 0.114145 Val loss= 0.551361 Training acc= 0.713780 Val acc= 0.713365\n",
            "Epoch 1637: Training loss= 0.114123 Val loss= 0.551179 Training acc= 0.713785 Val acc= 0.713370\n",
            "Epoch 1638: Training loss= 0.114101 Val loss= 0.550998 Training acc= 0.713800 Val acc= 0.713390\n",
            "Epoch 1639: Training loss= 0.114079 Val loss= 0.550817 Training acc= 0.713825 Val acc= 0.713430\n",
            "Epoch 1640: Training loss= 0.114057 Val loss= 0.550636 Training acc= 0.713855 Val acc= 0.713440\n",
            "Epoch 1641: Training loss= 0.114036 Val loss= 0.550455 Training acc= 0.713865 Val acc= 0.713460\n",
            "Epoch 1642: Training loss= 0.114014 Val loss= 0.550274 Training acc= 0.713875 Val acc= 0.713475\n",
            "Epoch 1643: Training loss= 0.113992 Val loss= 0.550093 Training acc= 0.713885 Val acc= 0.713475\n",
            "Epoch 1644: Training loss= 0.113971 Val loss= 0.549913 Training acc= 0.713925 Val acc= 0.713515\n",
            "Epoch 1645: Training loss= 0.113949 Val loss= 0.549733 Training acc= 0.713985 Val acc= 0.713570\n",
            "Epoch 1646: Training loss= 0.113927 Val loss= 0.549553 Training acc= 0.714015 Val acc= 0.713615\n",
            "Epoch 1647: Training loss= 0.113906 Val loss= 0.549373 Training acc= 0.714045 Val acc= 0.713655\n",
            "Epoch 1648: Training loss= 0.113884 Val loss= 0.549193 Training acc= 0.714085 Val acc= 0.713680\n",
            "Epoch 1649: Training loss= 0.113863 Val loss= 0.549013 Training acc= 0.714125 Val acc= 0.713725\n",
            "Epoch 1650: Training loss= 0.113841 Val loss= 0.548834 Training acc= 0.714130 Val acc= 0.713725\n",
            "Epoch 1651: Training loss= 0.113820 Val loss= 0.548654 Training acc= 0.714165 Val acc= 0.713760\n",
            "Epoch 1652: Training loss= 0.113798 Val loss= 0.548475 Training acc= 0.714180 Val acc= 0.713770\n",
            "Epoch 1653: Training loss= 0.113777 Val loss= 0.548296 Training acc= 0.714225 Val acc= 0.713840\n",
            "Epoch 1654: Training loss= 0.113755 Val loss= 0.548118 Training acc= 0.714235 Val acc= 0.713850\n",
            "Epoch 1655: Training loss= 0.113734 Val loss= 0.547939 Training acc= 0.714260 Val acc= 0.713860\n",
            "Epoch 1656: Training loss= 0.113713 Val loss= 0.547760 Training acc= 0.714265 Val acc= 0.713875\n",
            "Epoch 1657: Training loss= 0.113691 Val loss= 0.547582 Training acc= 0.714275 Val acc= 0.713890\n",
            "Epoch 1658: Training loss= 0.113670 Val loss= 0.547404 Training acc= 0.714285 Val acc= 0.713865\n",
            "Epoch 1659: Training loss= 0.113649 Val loss= 0.547226 Training acc= 0.714320 Val acc= 0.713915\n",
            "Epoch 1660: Training loss= 0.113628 Val loss= 0.547048 Training acc= 0.714315 Val acc= 0.713930\n",
            "Epoch 1661: Training loss= 0.113606 Val loss= 0.546870 Training acc= 0.714350 Val acc= 0.713990\n",
            "Epoch 1662: Training loss= 0.113585 Val loss= 0.546693 Training acc= 0.714400 Val acc= 0.714045\n",
            "Epoch 1663: Training loss= 0.113564 Val loss= 0.546515 Training acc= 0.714445 Val acc= 0.714080\n",
            "Epoch 1664: Training loss= 0.113543 Val loss= 0.546338 Training acc= 0.714465 Val acc= 0.714070\n",
            "Epoch 1665: Training loss= 0.113522 Val loss= 0.546161 Training acc= 0.714495 Val acc= 0.714120\n",
            "Epoch 1666: Training loss= 0.113501 Val loss= 0.545984 Training acc= 0.714520 Val acc= 0.714155\n",
            "Epoch 1667: Training loss= 0.113480 Val loss= 0.545807 Training acc= 0.714550 Val acc= 0.714165\n",
            "Epoch 1668: Training loss= 0.113459 Val loss= 0.545631 Training acc= 0.714545 Val acc= 0.714175\n",
            "Epoch 1669: Training loss= 0.113438 Val loss= 0.545454 Training acc= 0.714585 Val acc= 0.714195\n",
            "Epoch 1670: Training loss= 0.113417 Val loss= 0.545278 Training acc= 0.714625 Val acc= 0.714220\n",
            "Epoch 1671: Training loss= 0.113396 Val loss= 0.545102 Training acc= 0.714650 Val acc= 0.714250\n",
            "Epoch 1672: Training loss= 0.113375 Val loss= 0.544926 Training acc= 0.714695 Val acc= 0.714310\n",
            "Epoch 1673: Training loss= 0.113354 Val loss= 0.544750 Training acc= 0.714700 Val acc= 0.714325\n",
            "Epoch 1674: Training loss= 0.113333 Val loss= 0.544574 Training acc= 0.714715 Val acc= 0.714340\n",
            "Epoch 1675: Training loss= 0.113312 Val loss= 0.544399 Training acc= 0.714730 Val acc= 0.714370\n",
            "Epoch 1676: Training loss= 0.113291 Val loss= 0.544223 Training acc= 0.714750 Val acc= 0.714370\n",
            "Epoch 1677: Training loss= 0.113270 Val loss= 0.544048 Training acc= 0.714800 Val acc= 0.714410\n",
            "Epoch 1678: Training loss= 0.113250 Val loss= 0.543873 Training acc= 0.714785 Val acc= 0.714420\n",
            "Epoch 1679: Training loss= 0.113229 Val loss= 0.543698 Training acc= 0.714825 Val acc= 0.714455\n",
            "Epoch 1680: Training loss= 0.113208 Val loss= 0.543523 Training acc= 0.714855 Val acc= 0.714470\n",
            "Epoch 1681: Training loss= 0.113188 Val loss= 0.543349 Training acc= 0.714900 Val acc= 0.714530\n",
            "Epoch 1682: Training loss= 0.113167 Val loss= 0.543174 Training acc= 0.714920 Val acc= 0.714550\n",
            "Epoch 1683: Training loss= 0.113146 Val loss= 0.543000 Training acc= 0.714950 Val acc= 0.714575\n",
            "Epoch 1684: Training loss= 0.113126 Val loss= 0.542826 Training acc= 0.714970 Val acc= 0.714605\n",
            "Epoch 1685: Training loss= 0.113105 Val loss= 0.542652 Training acc= 0.715000 Val acc= 0.714625\n",
            "Epoch 1686: Training loss= 0.113084 Val loss= 0.542478 Training acc= 0.715030 Val acc= 0.714650\n",
            "Epoch 1687: Training loss= 0.113064 Val loss= 0.542304 Training acc= 0.715065 Val acc= 0.714695\n",
            "Epoch 1688: Training loss= 0.113043 Val loss= 0.542131 Training acc= 0.715105 Val acc= 0.714735\n",
            "Epoch 1689: Training loss= 0.113023 Val loss= 0.541957 Training acc= 0.715170 Val acc= 0.714780\n",
            "Epoch 1690: Training loss= 0.113002 Val loss= 0.541784 Training acc= 0.715190 Val acc= 0.714800\n",
            "Epoch 1691: Training loss= 0.112982 Val loss= 0.541611 Training acc= 0.715215 Val acc= 0.714830\n",
            "Epoch 1692: Training loss= 0.112961 Val loss= 0.541438 Training acc= 0.715225 Val acc= 0.714845\n",
            "Epoch 1693: Training loss= 0.112941 Val loss= 0.541265 Training acc= 0.715280 Val acc= 0.714890\n",
            "Epoch 1694: Training loss= 0.112921 Val loss= 0.541092 Training acc= 0.715285 Val acc= 0.714895\n",
            "Epoch 1695: Training loss= 0.112900 Val loss= 0.540920 Training acc= 0.715285 Val acc= 0.714895\n",
            "Epoch 1696: Training loss= 0.112880 Val loss= 0.540747 Training acc= 0.715320 Val acc= 0.714925\n",
            "Epoch 1697: Training loss= 0.112860 Val loss= 0.540575 Training acc= 0.715315 Val acc= 0.714935\n",
            "Epoch 1698: Training loss= 0.112839 Val loss= 0.540403 Training acc= 0.715355 Val acc= 0.715005\n",
            "Epoch 1699: Training loss= 0.112819 Val loss= 0.540231 Training acc= 0.715415 Val acc= 0.715070\n",
            "Epoch 1700: Training loss= 0.112799 Val loss= 0.540060 Training acc= 0.715480 Val acc= 0.715105\n",
            "Epoch 1701: Training loss= 0.112779 Val loss= 0.539888 Training acc= 0.715500 Val acc= 0.715110\n",
            "Epoch 1702: Training loss= 0.112758 Val loss= 0.539716 Training acc= 0.715535 Val acc= 0.715155\n",
            "Epoch 1703: Training loss= 0.112738 Val loss= 0.539545 Training acc= 0.715545 Val acc= 0.715160\n",
            "Epoch 1704: Training loss= 0.112718 Val loss= 0.539374 Training acc= 0.715570 Val acc= 0.715190\n",
            "Epoch 1705: Training loss= 0.112698 Val loss= 0.539203 Training acc= 0.715615 Val acc= 0.715235\n",
            "Epoch 1706: Training loss= 0.112678 Val loss= 0.539032 Training acc= 0.715625 Val acc= 0.715235\n",
            "Epoch 1707: Training loss= 0.112658 Val loss= 0.538861 Training acc= 0.715665 Val acc= 0.715245\n",
            "Epoch 1708: Training loss= 0.112638 Val loss= 0.538691 Training acc= 0.715720 Val acc= 0.715280\n",
            "Epoch 1709: Training loss= 0.112618 Val loss= 0.538520 Training acc= 0.715720 Val acc= 0.715280\n",
            "Epoch 1710: Training loss= 0.112598 Val loss= 0.538350 Training acc= 0.715765 Val acc= 0.715320\n",
            "Epoch 1711: Training loss= 0.112578 Val loss= 0.538180 Training acc= 0.715785 Val acc= 0.715330\n",
            "Epoch 1712: Training loss= 0.112558 Val loss= 0.538010 Training acc= 0.715810 Val acc= 0.715355\n",
            "Epoch 1713: Training loss= 0.112538 Val loss= 0.537840 Training acc= 0.715840 Val acc= 0.715375\n",
            "Epoch 1714: Training loss= 0.112518 Val loss= 0.537670 Training acc= 0.715860 Val acc= 0.715390\n",
            "Epoch 1715: Training loss= 0.112498 Val loss= 0.537501 Training acc= 0.715870 Val acc= 0.715400\n",
            "Epoch 1716: Training loss= 0.112478 Val loss= 0.537331 Training acc= 0.715885 Val acc= 0.715425\n",
            "Epoch 1717: Training loss= 0.112458 Val loss= 0.537162 Training acc= 0.715925 Val acc= 0.715475\n",
            "Epoch 1718: Training loss= 0.112439 Val loss= 0.536993 Training acc= 0.715935 Val acc= 0.715475\n",
            "Epoch 1719: Training loss= 0.112419 Val loss= 0.536824 Training acc= 0.715975 Val acc= 0.715535\n",
            "Epoch 1720: Training loss= 0.112399 Val loss= 0.536655 Training acc= 0.715995 Val acc= 0.715560\n",
            "Epoch 1721: Training loss= 0.112379 Val loss= 0.536486 Training acc= 0.716000 Val acc= 0.715555\n",
            "Epoch 1722: Training loss= 0.112360 Val loss= 0.536317 Training acc= 0.716005 Val acc= 0.715570\n",
            "Epoch 1723: Training loss= 0.112340 Val loss= 0.536149 Training acc= 0.716070 Val acc= 0.715610\n",
            "Epoch 1724: Training loss= 0.112320 Val loss= 0.535981 Training acc= 0.716110 Val acc= 0.715645\n",
            "Epoch 1725: Training loss= 0.112301 Val loss= 0.535813 Training acc= 0.716145 Val acc= 0.715665\n",
            "Epoch 1726: Training loss= 0.112281 Val loss= 0.535644 Training acc= 0.716175 Val acc= 0.715680\n",
            "Epoch 1727: Training loss= 0.112261 Val loss= 0.535477 Training acc= 0.716165 Val acc= 0.715650\n",
            "Epoch 1728: Training loss= 0.112242 Val loss= 0.535309 Training acc= 0.716200 Val acc= 0.715675\n",
            "Epoch 1729: Training loss= 0.112222 Val loss= 0.535141 Training acc= 0.716235 Val acc= 0.715705\n",
            "Epoch 1730: Training loss= 0.112203 Val loss= 0.534974 Training acc= 0.716280 Val acc= 0.715765\n",
            "Epoch 1731: Training loss= 0.112183 Val loss= 0.534806 Training acc= 0.716305 Val acc= 0.715770\n",
            "Epoch 1732: Training loss= 0.112164 Val loss= 0.534639 Training acc= 0.716335 Val acc= 0.715795\n",
            "Epoch 1733: Training loss= 0.112144 Val loss= 0.534472 Training acc= 0.716370 Val acc= 0.715830\n",
            "Epoch 1734: Training loss= 0.112125 Val loss= 0.534305 Training acc= 0.716375 Val acc= 0.715845\n",
            "Epoch 1735: Training loss= 0.112105 Val loss= 0.534139 Training acc= 0.716370 Val acc= 0.715845\n",
            "Epoch 1736: Training loss= 0.112086 Val loss= 0.533972 Training acc= 0.716420 Val acc= 0.715895\n",
            "Epoch 1737: Training loss= 0.112066 Val loss= 0.533806 Training acc= 0.716450 Val acc= 0.715915\n",
            "Epoch 1738: Training loss= 0.112047 Val loss= 0.533639 Training acc= 0.716480 Val acc= 0.715935\n",
            "Epoch 1739: Training loss= 0.112028 Val loss= 0.533473 Training acc= 0.716505 Val acc= 0.715965\n",
            "Epoch 1740: Training loss= 0.112008 Val loss= 0.533307 Training acc= 0.716545 Val acc= 0.716015\n",
            "Epoch 1741: Training loss= 0.111989 Val loss= 0.533141 Training acc= 0.716590 Val acc= 0.716050\n",
            "Epoch 1742: Training loss= 0.111970 Val loss= 0.532975 Training acc= 0.716595 Val acc= 0.716055\n",
            "Epoch 1743: Training loss= 0.111951 Val loss= 0.532809 Training acc= 0.716635 Val acc= 0.716095\n",
            "Epoch 1744: Training loss= 0.111931 Val loss= 0.532644 Training acc= 0.716660 Val acc= 0.716105\n",
            "Epoch 1745: Training loss= 0.111912 Val loss= 0.532479 Training acc= 0.716690 Val acc= 0.716110\n",
            "Epoch 1746: Training loss= 0.111893 Val loss= 0.532313 Training acc= 0.716740 Val acc= 0.716155\n",
            "Epoch 1747: Training loss= 0.111874 Val loss= 0.532148 Training acc= 0.716750 Val acc= 0.716190\n",
            "Epoch 1748: Training loss= 0.111855 Val loss= 0.531983 Training acc= 0.716775 Val acc= 0.716205\n",
            "Epoch 1749: Training loss= 0.111836 Val loss= 0.531818 Training acc= 0.716795 Val acc= 0.716220\n",
            "Epoch 1750: Training loss= 0.111816 Val loss= 0.531654 Training acc= 0.716845 Val acc= 0.716275\n",
            "Epoch 1751: Training loss= 0.111797 Val loss= 0.531489 Training acc= 0.716890 Val acc= 0.716325\n",
            "Epoch 1752: Training loss= 0.111778 Val loss= 0.531325 Training acc= 0.716885 Val acc= 0.716310\n",
            "Epoch 1753: Training loss= 0.111759 Val loss= 0.531160 Training acc= 0.716900 Val acc= 0.716325\n",
            "Epoch 1754: Training loss= 0.111740 Val loss= 0.530996 Training acc= 0.716925 Val acc= 0.716355\n",
            "Epoch 1755: Training loss= 0.111721 Val loss= 0.530832 Training acc= 0.716960 Val acc= 0.716395\n",
            "Epoch 1756: Training loss= 0.111702 Val loss= 0.530668 Training acc= 0.717000 Val acc= 0.716425\n",
            "Epoch 1757: Training loss= 0.111683 Val loss= 0.530505 Training acc= 0.717005 Val acc= 0.716445\n",
            "Epoch 1758: Training loss= 0.111664 Val loss= 0.530341 Training acc= 0.717035 Val acc= 0.716465\n",
            "Epoch 1759: Training loss= 0.111646 Val loss= 0.530177 Training acc= 0.717065 Val acc= 0.716500\n",
            "Epoch 1760: Training loss= 0.111627 Val loss= 0.530014 Training acc= 0.717080 Val acc= 0.716500\n",
            "Epoch 1761: Training loss= 0.111608 Val loss= 0.529851 Training acc= 0.717095 Val acc= 0.716520\n",
            "Epoch 1762: Training loss= 0.111589 Val loss= 0.529688 Training acc= 0.717140 Val acc= 0.716545\n",
            "Epoch 1763: Training loss= 0.111570 Val loss= 0.529525 Training acc= 0.717155 Val acc= 0.716550\n",
            "Epoch 1764: Training loss= 0.111551 Val loss= 0.529362 Training acc= 0.717180 Val acc= 0.716565\n",
            "Epoch 1765: Training loss= 0.111533 Val loss= 0.529199 Training acc= 0.717175 Val acc= 0.716560\n",
            "Epoch 1766: Training loss= 0.111514 Val loss= 0.529037 Training acc= 0.717220 Val acc= 0.716615\n",
            "Epoch 1767: Training loss= 0.111495 Val loss= 0.528874 Training acc= 0.717280 Val acc= 0.716675\n",
            "Epoch 1768: Training loss= 0.111476 Val loss= 0.528712 Training acc= 0.717295 Val acc= 0.716695\n",
            "Epoch 1769: Training loss= 0.111458 Val loss= 0.528550 Training acc= 0.717310 Val acc= 0.716700\n",
            "Epoch 1770: Training loss= 0.111439 Val loss= 0.528388 Training acc= 0.717335 Val acc= 0.716715\n",
            "Epoch 1771: Training loss= 0.111420 Val loss= 0.528226 Training acc= 0.717355 Val acc= 0.716740\n",
            "Epoch 1772: Training loss= 0.111402 Val loss= 0.528064 Training acc= 0.717365 Val acc= 0.716760\n",
            "Epoch 1773: Training loss= 0.111383 Val loss= 0.527903 Training acc= 0.717370 Val acc= 0.716775\n",
            "Epoch 1774: Training loss= 0.111364 Val loss= 0.527741 Training acc= 0.717400 Val acc= 0.716815\n",
            "Epoch 1775: Training loss= 0.111346 Val loss= 0.527580 Training acc= 0.717415 Val acc= 0.716820\n",
            "Epoch 1776: Training loss= 0.111327 Val loss= 0.527418 Training acc= 0.717455 Val acc= 0.716850\n",
            "Epoch 1777: Training loss= 0.111309 Val loss= 0.527257 Training acc= 0.717510 Val acc= 0.716910\n",
            "Epoch 1778: Training loss= 0.111290 Val loss= 0.527096 Training acc= 0.717570 Val acc= 0.716955\n",
            "Epoch 1779: Training loss= 0.111272 Val loss= 0.526935 Training acc= 0.717605 Val acc= 0.716995\n",
            "Epoch 1780: Training loss= 0.111253 Val loss= 0.526775 Training acc= 0.717630 Val acc= 0.717005\n",
            "Epoch 1781: Training loss= 0.111235 Val loss= 0.526614 Training acc= 0.717620 Val acc= 0.717020\n",
            "Epoch 1782: Training loss= 0.111216 Val loss= 0.526454 Training acc= 0.717685 Val acc= 0.717080\n",
            "Epoch 1783: Training loss= 0.111198 Val loss= 0.526293 Training acc= 0.717730 Val acc= 0.717110\n",
            "Epoch 1784: Training loss= 0.111180 Val loss= 0.526133 Training acc= 0.717755 Val acc= 0.717130\n",
            "Epoch 1785: Training loss= 0.111161 Val loss= 0.525973 Training acc= 0.717790 Val acc= 0.717160\n",
            "Epoch 1786: Training loss= 0.111143 Val loss= 0.525813 Training acc= 0.717820 Val acc= 0.717185\n",
            "Epoch 1787: Training loss= 0.111125 Val loss= 0.525653 Training acc= 0.717850 Val acc= 0.717210\n",
            "Epoch 1788: Training loss= 0.111106 Val loss= 0.525494 Training acc= 0.717880 Val acc= 0.717255\n",
            "Epoch 1789: Training loss= 0.111088 Val loss= 0.525334 Training acc= 0.717910 Val acc= 0.717275\n",
            "Epoch 1790: Training loss= 0.111070 Val loss= 0.525174 Training acc= 0.717920 Val acc= 0.717270\n",
            "Epoch 1791: Training loss= 0.111052 Val loss= 0.525015 Training acc= 0.717955 Val acc= 0.717290\n",
            "Epoch 1792: Training loss= 0.111033 Val loss= 0.524856 Training acc= 0.717975 Val acc= 0.717305\n",
            "Epoch 1793: Training loss= 0.111015 Val loss= 0.524697 Training acc= 0.717995 Val acc= 0.717315\n",
            "Epoch 1794: Training loss= 0.110997 Val loss= 0.524538 Training acc= 0.718020 Val acc= 0.717340\n",
            "Epoch 1795: Training loss= 0.110979 Val loss= 0.524379 Training acc= 0.718060 Val acc= 0.717375\n",
            "Epoch 1796: Training loss= 0.110961 Val loss= 0.524220 Training acc= 0.718095 Val acc= 0.717390\n",
            "Epoch 1797: Training loss= 0.110942 Val loss= 0.524062 Training acc= 0.718115 Val acc= 0.717420\n",
            "Epoch 1798: Training loss= 0.110924 Val loss= 0.523903 Training acc= 0.718160 Val acc= 0.717435\n",
            "Epoch 1799: Training loss= 0.110906 Val loss= 0.523745 Training acc= 0.718185 Val acc= 0.717465\n",
            "Epoch 1800: Training loss= 0.110888 Val loss= 0.523587 Training acc= 0.718225 Val acc= 0.717515\n",
            "Epoch 1801: Training loss= 0.110870 Val loss= 0.523429 Training acc= 0.718245 Val acc= 0.717535\n",
            "Epoch 1802: Training loss= 0.110852 Val loss= 0.523271 Training acc= 0.718240 Val acc= 0.717545\n",
            "Epoch 1803: Training loss= 0.110834 Val loss= 0.523113 Training acc= 0.718270 Val acc= 0.717595\n",
            "Epoch 1804: Training loss= 0.110816 Val loss= 0.522955 Training acc= 0.718285 Val acc= 0.717610\n",
            "Epoch 1805: Training loss= 0.110798 Val loss= 0.522798 Training acc= 0.718270 Val acc= 0.717595\n",
            "Epoch 1806: Training loss= 0.110780 Val loss= 0.522640 Training acc= 0.718290 Val acc= 0.717600\n",
            "Epoch 1807: Training loss= 0.110762 Val loss= 0.522483 Training acc= 0.718335 Val acc= 0.717635\n",
            "Epoch 1808: Training loss= 0.110744 Val loss= 0.522326 Training acc= 0.718375 Val acc= 0.717680\n",
            "Epoch 1809: Training loss= 0.110726 Val loss= 0.522169 Training acc= 0.718390 Val acc= 0.717685\n",
            "Epoch 1810: Training loss= 0.110709 Val loss= 0.522012 Training acc= 0.718400 Val acc= 0.717685\n",
            "Epoch 1811: Training loss= 0.110691 Val loss= 0.521855 Training acc= 0.718420 Val acc= 0.717705\n",
            "Epoch 1812: Training loss= 0.110673 Val loss= 0.521698 Training acc= 0.718415 Val acc= 0.717700\n",
            "Epoch 1813: Training loss= 0.110655 Val loss= 0.521542 Training acc= 0.718425 Val acc= 0.717715\n",
            "Epoch 1814: Training loss= 0.110637 Val loss= 0.521385 Training acc= 0.718425 Val acc= 0.717720\n",
            "Epoch 1815: Training loss= 0.110620 Val loss= 0.521229 Training acc= 0.718455 Val acc= 0.717765\n",
            "Epoch 1816: Training loss= 0.110602 Val loss= 0.521073 Training acc= 0.718465 Val acc= 0.717800\n",
            "Epoch 1817: Training loss= 0.110584 Val loss= 0.520917 Training acc= 0.718490 Val acc= 0.717825\n",
            "Epoch 1818: Training loss= 0.110566 Val loss= 0.520761 Training acc= 0.718515 Val acc= 0.717840\n",
            "Epoch 1819: Training loss= 0.110549 Val loss= 0.520605 Training acc= 0.718580 Val acc= 0.717875\n",
            "Epoch 1820: Training loss= 0.110531 Val loss= 0.520449 Training acc= 0.718590 Val acc= 0.717880\n",
            "Epoch 1821: Training loss= 0.110513 Val loss= 0.520294 Training acc= 0.718630 Val acc= 0.717895\n",
            "Epoch 1822: Training loss= 0.110496 Val loss= 0.520138 Training acc= 0.718665 Val acc= 0.717925\n",
            "Epoch 1823: Training loss= 0.110478 Val loss= 0.519983 Training acc= 0.718680 Val acc= 0.717930\n",
            "Epoch 1824: Training loss= 0.110460 Val loss= 0.519828 Training acc= 0.718730 Val acc= 0.717975\n",
            "Epoch 1825: Training loss= 0.110443 Val loss= 0.519673 Training acc= 0.718775 Val acc= 0.718015\n",
            "Epoch 1826: Training loss= 0.110425 Val loss= 0.519518 Training acc= 0.718780 Val acc= 0.718010\n",
            "Epoch 1827: Training loss= 0.110408 Val loss= 0.519363 Training acc= 0.718780 Val acc= 0.718025\n",
            "Epoch 1828: Training loss= 0.110390 Val loss= 0.519208 Training acc= 0.718805 Val acc= 0.718060\n",
            "Epoch 1829: Training loss= 0.110373 Val loss= 0.519053 Training acc= 0.718840 Val acc= 0.718085\n",
            "Epoch 1830: Training loss= 0.110355 Val loss= 0.518899 Training acc= 0.718835 Val acc= 0.718095\n",
            "Epoch 1831: Training loss= 0.110338 Val loss= 0.518744 Training acc= 0.718830 Val acc= 0.718105\n",
            "Epoch 1832: Training loss= 0.110320 Val loss= 0.518590 Training acc= 0.718835 Val acc= 0.718115\n",
            "Epoch 1833: Training loss= 0.110303 Val loss= 0.518436 Training acc= 0.718845 Val acc= 0.718120\n",
            "Epoch 1834: Training loss= 0.110285 Val loss= 0.518282 Training acc= 0.718905 Val acc= 0.718155\n",
            "Epoch 1835: Training loss= 0.110268 Val loss= 0.518128 Training acc= 0.718940 Val acc= 0.718195\n",
            "Epoch 1836: Training loss= 0.110251 Val loss= 0.517974 Training acc= 0.718940 Val acc= 0.718185\n",
            "Epoch 1837: Training loss= 0.110233 Val loss= 0.517821 Training acc= 0.718985 Val acc= 0.718225\n",
            "Epoch 1838: Training loss= 0.110216 Val loss= 0.517667 Training acc= 0.719020 Val acc= 0.718265\n",
            "Epoch 1839: Training loss= 0.110198 Val loss= 0.517514 Training acc= 0.719060 Val acc= 0.718300\n",
            "Epoch 1840: Training loss= 0.110181 Val loss= 0.517360 Training acc= 0.719105 Val acc= 0.718315\n",
            "Epoch 1841: Training loss= 0.110164 Val loss= 0.517207 Training acc= 0.719105 Val acc= 0.718310\n",
            "Epoch 1842: Training loss= 0.110147 Val loss= 0.517054 Training acc= 0.719115 Val acc= 0.718335\n",
            "Epoch 1843: Training loss= 0.110129 Val loss= 0.516901 Training acc= 0.719135 Val acc= 0.718360\n",
            "Epoch 1844: Training loss= 0.110112 Val loss= 0.516748 Training acc= 0.719145 Val acc= 0.718375\n",
            "Epoch 1845: Training loss= 0.110095 Val loss= 0.516595 Training acc= 0.719185 Val acc= 0.718390\n",
            "Epoch 1846: Training loss= 0.110078 Val loss= 0.516443 Training acc= 0.719180 Val acc= 0.718380\n",
            "Epoch 1847: Training loss= 0.110061 Val loss= 0.516290 Training acc= 0.719195 Val acc= 0.718375\n",
            "Epoch 1848: Training loss= 0.110043 Val loss= 0.516138 Training acc= 0.719245 Val acc= 0.718425\n",
            "Epoch 1849: Training loss= 0.110026 Val loss= 0.515986 Training acc= 0.719255 Val acc= 0.718435\n",
            "Epoch 1850: Training loss= 0.110009 Val loss= 0.515834 Training acc= 0.719250 Val acc= 0.718435\n",
            "Epoch 1851: Training loss= 0.109992 Val loss= 0.515681 Training acc= 0.719275 Val acc= 0.718455\n",
            "Epoch 1852: Training loss= 0.109975 Val loss= 0.515530 Training acc= 0.719320 Val acc= 0.718500\n",
            "Epoch 1853: Training loss= 0.109958 Val loss= 0.515378 Training acc= 0.719335 Val acc= 0.718530\n",
            "Epoch 1854: Training loss= 0.109941 Val loss= 0.515226 Training acc= 0.719360 Val acc= 0.718550\n",
            "Epoch 1855: Training loss= 0.109924 Val loss= 0.515075 Training acc= 0.719390 Val acc= 0.718560\n",
            "Epoch 1856: Training loss= 0.109907 Val loss= 0.514923 Training acc= 0.719430 Val acc= 0.718585\n",
            "Epoch 1857: Training loss= 0.109890 Val loss= 0.514772 Training acc= 0.719460 Val acc= 0.718605\n",
            "Epoch 1858: Training loss= 0.109873 Val loss= 0.514621 Training acc= 0.719470 Val acc= 0.718625\n",
            "Epoch 1859: Training loss= 0.109856 Val loss= 0.514469 Training acc= 0.719515 Val acc= 0.718665\n",
            "Epoch 1860: Training loss= 0.109839 Val loss= 0.514318 Training acc= 0.719530 Val acc= 0.718675\n",
            "Epoch 1861: Training loss= 0.109822 Val loss= 0.514168 Training acc= 0.719490 Val acc= 0.718670\n",
            "Epoch 1862: Training loss= 0.109805 Val loss= 0.514017 Training acc= 0.719535 Val acc= 0.718715\n",
            "Epoch 1863: Training loss= 0.109788 Val loss= 0.513866 Training acc= 0.719570 Val acc= 0.718750\n",
            "Epoch 1864: Training loss= 0.109771 Val loss= 0.513716 Training acc= 0.719590 Val acc= 0.718775\n",
            "Epoch 1865: Training loss= 0.109754 Val loss= 0.513565 Training acc= 0.719550 Val acc= 0.718765\n",
            "Epoch 1866: Training loss= 0.109737 Val loss= 0.513415 Training acc= 0.719555 Val acc= 0.718780\n",
            "Epoch 1867: Training loss= 0.109721 Val loss= 0.513265 Training acc= 0.719605 Val acc= 0.718825\n",
            "Epoch 1868: Training loss= 0.109704 Val loss= 0.513115 Training acc= 0.719625 Val acc= 0.718845\n",
            "Epoch 1869: Training loss= 0.109687 Val loss= 0.512965 Training acc= 0.719655 Val acc= 0.718890\n",
            "Epoch 1870: Training loss= 0.109670 Val loss= 0.512815 Training acc= 0.719680 Val acc= 0.718890\n",
            "Epoch 1871: Training loss= 0.109653 Val loss= 0.512665 Training acc= 0.719700 Val acc= 0.718895\n",
            "Epoch 1872: Training loss= 0.109637 Val loss= 0.512515 Training acc= 0.719705 Val acc= 0.718900\n",
            "Epoch 1873: Training loss= 0.109620 Val loss= 0.512366 Training acc= 0.719730 Val acc= 0.718935\n",
            "Epoch 1874: Training loss= 0.109603 Val loss= 0.512216 Training acc= 0.719760 Val acc= 0.718975\n",
            "Epoch 1875: Training loss= 0.109587 Val loss= 0.512067 Training acc= 0.719770 Val acc= 0.719000\n",
            "Epoch 1876: Training loss= 0.109570 Val loss= 0.511918 Training acc= 0.719765 Val acc= 0.719000\n",
            "Epoch 1877: Training loss= 0.109553 Val loss= 0.511769 Training acc= 0.719805 Val acc= 0.719010\n",
            "Epoch 1878: Training loss= 0.109537 Val loss= 0.511620 Training acc= 0.719850 Val acc= 0.719055\n",
            "Epoch 1879: Training loss= 0.109520 Val loss= 0.511471 Training acc= 0.719895 Val acc= 0.719095\n",
            "Epoch 1880: Training loss= 0.109503 Val loss= 0.511322 Training acc= 0.719920 Val acc= 0.719130\n",
            "Epoch 1881: Training loss= 0.109487 Val loss= 0.511174 Training acc= 0.719945 Val acc= 0.719150\n",
            "Epoch 1882: Training loss= 0.109470 Val loss= 0.511025 Training acc= 0.719995 Val acc= 0.719185\n",
            "Epoch 1883: Training loss= 0.109454 Val loss= 0.510877 Training acc= 0.720040 Val acc= 0.719240\n",
            "Epoch 1884: Training loss= 0.109437 Val loss= 0.510728 Training acc= 0.720075 Val acc= 0.719285\n",
            "Epoch 1885: Training loss= 0.109421 Val loss= 0.510580 Training acc= 0.720085 Val acc= 0.719320\n",
            "Epoch 1886: Training loss= 0.109404 Val loss= 0.510432 Training acc= 0.720100 Val acc= 0.719335\n",
            "Epoch 1887: Training loss= 0.109388 Val loss= 0.510284 Training acc= 0.720125 Val acc= 0.719360\n",
            "Epoch 1888: Training loss= 0.109371 Val loss= 0.510136 Training acc= 0.720165 Val acc= 0.719400\n",
            "Epoch 1889: Training loss= 0.109355 Val loss= 0.509989 Training acc= 0.720175 Val acc= 0.719410\n",
            "Epoch 1890: Training loss= 0.109338 Val loss= 0.509841 Training acc= 0.720185 Val acc= 0.719415\n",
            "Epoch 1891: Training loss= 0.109322 Val loss= 0.509694 Training acc= 0.720220 Val acc= 0.719440\n",
            "Epoch 1892: Training loss= 0.109305 Val loss= 0.509546 Training acc= 0.720235 Val acc= 0.719450\n",
            "Epoch 1893: Training loss= 0.109289 Val loss= 0.509399 Training acc= 0.720280 Val acc= 0.719490\n",
            "Epoch 1894: Training loss= 0.109273 Val loss= 0.509252 Training acc= 0.720315 Val acc= 0.719520\n",
            "Epoch 1895: Training loss= 0.109256 Val loss= 0.509105 Training acc= 0.720325 Val acc= 0.719535\n",
            "Epoch 1896: Training loss= 0.109240 Val loss= 0.508958 Training acc= 0.720360 Val acc= 0.719550\n",
            "Epoch 1897: Training loss= 0.109224 Val loss= 0.508811 Training acc= 0.720380 Val acc= 0.719560\n",
            "Epoch 1898: Training loss= 0.109207 Val loss= 0.508664 Training acc= 0.720395 Val acc= 0.719565\n",
            "Epoch 1899: Training loss= 0.109191 Val loss= 0.508517 Training acc= 0.720425 Val acc= 0.719595\n",
            "Epoch 1900: Training loss= 0.109175 Val loss= 0.508371 Training acc= 0.720420 Val acc= 0.719585\n",
            "Epoch 1901: Training loss= 0.109159 Val loss= 0.508224 Training acc= 0.720465 Val acc= 0.719630\n",
            "Epoch 1902: Training loss= 0.109142 Val loss= 0.508078 Training acc= 0.720480 Val acc= 0.719630\n",
            "Epoch 1903: Training loss= 0.109126 Val loss= 0.507932 Training acc= 0.720505 Val acc= 0.719645\n",
            "Epoch 1904: Training loss= 0.109110 Val loss= 0.507786 Training acc= 0.720530 Val acc= 0.719670\n",
            "Epoch 1905: Training loss= 0.109094 Val loss= 0.507640 Training acc= 0.720530 Val acc= 0.719670\n",
            "Epoch 1906: Training loss= 0.109078 Val loss= 0.507494 Training acc= 0.720545 Val acc= 0.719705\n",
            "Epoch 1907: Training loss= 0.109061 Val loss= 0.507348 Training acc= 0.720535 Val acc= 0.719705\n",
            "Epoch 1908: Training loss= 0.109045 Val loss= 0.507202 Training acc= 0.720545 Val acc= 0.719710\n",
            "Epoch 1909: Training loss= 0.109029 Val loss= 0.507057 Training acc= 0.720580 Val acc= 0.719735\n",
            "Epoch 1910: Training loss= 0.109013 Val loss= 0.506911 Training acc= 0.720620 Val acc= 0.719785\n",
            "Epoch 1911: Training loss= 0.108997 Val loss= 0.506766 Training acc= 0.720605 Val acc= 0.719760\n",
            "Epoch 1912: Training loss= 0.108981 Val loss= 0.506621 Training acc= 0.720585 Val acc= 0.719720\n",
            "Epoch 1913: Training loss= 0.108965 Val loss= 0.506476 Training acc= 0.720620 Val acc= 0.719755\n",
            "Epoch 1914: Training loss= 0.108949 Val loss= 0.506330 Training acc= 0.720655 Val acc= 0.719775\n",
            "Epoch 1915: Training loss= 0.108933 Val loss= 0.506186 Training acc= 0.720680 Val acc= 0.719800\n",
            "Epoch 1916: Training loss= 0.108917 Val loss= 0.506041 Training acc= 0.720725 Val acc= 0.719835\n",
            "Epoch 1917: Training loss= 0.108901 Val loss= 0.505896 Training acc= 0.720715 Val acc= 0.719825\n",
            "Epoch 1918: Training loss= 0.108885 Val loss= 0.505751 Training acc= 0.720755 Val acc= 0.719850\n",
            "Epoch 1919: Training loss= 0.108869 Val loss= 0.505607 Training acc= 0.720775 Val acc= 0.719880\n",
            "Epoch 1920: Training loss= 0.108853 Val loss= 0.505462 Training acc= 0.720815 Val acc= 0.719910\n",
            "Epoch 1921: Training loss= 0.108837 Val loss= 0.505318 Training acc= 0.720825 Val acc= 0.719925\n",
            "Epoch 1922: Training loss= 0.108821 Val loss= 0.505174 Training acc= 0.720850 Val acc= 0.719955\n",
            "Epoch 1923: Training loss= 0.108805 Val loss= 0.505030 Training acc= 0.720855 Val acc= 0.719960\n",
            "Epoch 1924: Training loss= 0.108789 Val loss= 0.504886 Training acc= 0.720860 Val acc= 0.719965\n",
            "Epoch 1925: Training loss= 0.108773 Val loss= 0.504742 Training acc= 0.720870 Val acc= 0.719980\n",
            "Epoch 1926: Training loss= 0.108757 Val loss= 0.504598 Training acc= 0.720880 Val acc= 0.719995\n",
            "Epoch 1927: Training loss= 0.108742 Val loss= 0.504455 Training acc= 0.720900 Val acc= 0.720015\n",
            "Epoch 1928: Training loss= 0.108726 Val loss= 0.504311 Training acc= 0.720925 Val acc= 0.720045\n",
            "Epoch 1929: Training loss= 0.108710 Val loss= 0.504168 Training acc= 0.720950 Val acc= 0.720065\n",
            "Epoch 1930: Training loss= 0.108694 Val loss= 0.504024 Training acc= 0.720990 Val acc= 0.720095\n",
            "Epoch 1931: Training loss= 0.108678 Val loss= 0.503881 Training acc= 0.721010 Val acc= 0.720115\n",
            "Epoch 1932: Training loss= 0.108663 Val loss= 0.503738 Training acc= 0.721070 Val acc= 0.720175\n",
            "Epoch 1933: Training loss= 0.108647 Val loss= 0.503595 Training acc= 0.721085 Val acc= 0.720195\n",
            "Epoch 1934: Training loss= 0.108631 Val loss= 0.503452 Training acc= 0.721065 Val acc= 0.720180\n",
            "Epoch 1935: Training loss= 0.108615 Val loss= 0.503309 Training acc= 0.721090 Val acc= 0.720210\n",
            "Epoch 1936: Training loss= 0.108600 Val loss= 0.503166 Training acc= 0.721090 Val acc= 0.720235\n",
            "Epoch 1937: Training loss= 0.108584 Val loss= 0.503024 Training acc= 0.721145 Val acc= 0.720265\n",
            "Epoch 1938: Training loss= 0.108568 Val loss= 0.502881 Training acc= 0.721145 Val acc= 0.720265\n",
            "Epoch 1939: Training loss= 0.108553 Val loss= 0.502739 Training acc= 0.721175 Val acc= 0.720285\n",
            "Epoch 1940: Training loss= 0.108537 Val loss= 0.502596 Training acc= 0.721215 Val acc= 0.720320\n",
            "Epoch 1941: Training loss= 0.108521 Val loss= 0.502454 Training acc= 0.721235 Val acc= 0.720345\n",
            "Epoch 1942: Training loss= 0.108506 Val loss= 0.502312 Training acc= 0.721260 Val acc= 0.720365\n",
            "Epoch 1943: Training loss= 0.108490 Val loss= 0.502170 Training acc= 0.721280 Val acc= 0.720385\n",
            "Epoch 1944: Training loss= 0.108475 Val loss= 0.502028 Training acc= 0.721290 Val acc= 0.720415\n",
            "Epoch 1945: Training loss= 0.108459 Val loss= 0.501886 Training acc= 0.721315 Val acc= 0.720450\n",
            "Epoch 1946: Training loss= 0.108444 Val loss= 0.501744 Training acc= 0.721335 Val acc= 0.720480\n",
            "Epoch 1947: Training loss= 0.108428 Val loss= 0.501603 Training acc= 0.721320 Val acc= 0.720475\n",
            "Epoch 1948: Training loss= 0.108413 Val loss= 0.501461 Training acc= 0.721335 Val acc= 0.720485\n",
            "Epoch 1949: Training loss= 0.108397 Val loss= 0.501320 Training acc= 0.721370 Val acc= 0.720515\n",
            "Epoch 1950: Training loss= 0.108382 Val loss= 0.501179 Training acc= 0.721395 Val acc= 0.720545\n",
            "Epoch 1951: Training loss= 0.108366 Val loss= 0.501037 Training acc= 0.721440 Val acc= 0.720610\n",
            "Epoch 1952: Training loss= 0.108351 Val loss= 0.500896 Training acc= 0.721440 Val acc= 0.720615\n",
            "Epoch 1953: Training loss= 0.108335 Val loss= 0.500755 Training acc= 0.721435 Val acc= 0.720620\n",
            "Epoch 1954: Training loss= 0.108320 Val loss= 0.500614 Training acc= 0.721445 Val acc= 0.720640\n",
            "Epoch 1955: Training loss= 0.108304 Val loss= 0.500474 Training acc= 0.721470 Val acc= 0.720665\n",
            "Epoch 1956: Training loss= 0.108289 Val loss= 0.500333 Training acc= 0.721465 Val acc= 0.720655\n",
            "Epoch 1957: Training loss= 0.108274 Val loss= 0.500192 Training acc= 0.721510 Val acc= 0.720700\n",
            "Epoch 1958: Training loss= 0.108258 Val loss= 0.500052 Training acc= 0.721555 Val acc= 0.720735\n",
            "Epoch 1959: Training loss= 0.108243 Val loss= 0.499911 Training acc= 0.721585 Val acc= 0.720755\n",
            "Epoch 1960: Training loss= 0.108227 Val loss= 0.499771 Training acc= 0.721655 Val acc= 0.720835\n",
            "Epoch 1961: Training loss= 0.108212 Val loss= 0.499631 Training acc= 0.721655 Val acc= 0.720845\n",
            "Epoch 1962: Training loss= 0.108197 Val loss= 0.499491 Training acc= 0.721685 Val acc= 0.720860\n",
            "Epoch 1963: Training loss= 0.108182 Val loss= 0.499351 Training acc= 0.721685 Val acc= 0.720865\n",
            "Epoch 1964: Training loss= 0.108166 Val loss= 0.499211 Training acc= 0.721725 Val acc= 0.720905\n",
            "Epoch 1965: Training loss= 0.108151 Val loss= 0.499071 Training acc= 0.721760 Val acc= 0.720940\n",
            "Epoch 1966: Training loss= 0.108136 Val loss= 0.498931 Training acc= 0.721805 Val acc= 0.720980\n",
            "Epoch 1967: Training loss= 0.108121 Val loss= 0.498792 Training acc= 0.721810 Val acc= 0.720985\n",
            "Epoch 1968: Training loss= 0.108105 Val loss= 0.498652 Training acc= 0.721820 Val acc= 0.721000\n",
            "Epoch 1969: Training loss= 0.108090 Val loss= 0.498513 Training acc= 0.721860 Val acc= 0.721025\n",
            "Epoch 1970: Training loss= 0.108075 Val loss= 0.498374 Training acc= 0.721900 Val acc= 0.721070\n",
            "Epoch 1971: Training loss= 0.108060 Val loss= 0.498234 Training acc= 0.721945 Val acc= 0.721110\n",
            "Epoch 1972: Training loss= 0.108045 Val loss= 0.498095 Training acc= 0.721965 Val acc= 0.721125\n",
            "Epoch 1973: Training loss= 0.108029 Val loss= 0.497956 Training acc= 0.721995 Val acc= 0.721150\n",
            "Epoch 1974: Training loss= 0.108014 Val loss= 0.497817 Training acc= 0.722010 Val acc= 0.721170\n",
            "Epoch 1975: Training loss= 0.107999 Val loss= 0.497678 Training acc= 0.722035 Val acc= 0.721195\n",
            "Epoch 1976: Training loss= 0.107984 Val loss= 0.497540 Training acc= 0.722045 Val acc= 0.721205\n",
            "Epoch 1977: Training loss= 0.107969 Val loss= 0.497401 Training acc= 0.722065 Val acc= 0.721215\n",
            "Epoch 1978: Training loss= 0.107954 Val loss= 0.497263 Training acc= 0.722080 Val acc= 0.721235\n",
            "Epoch 1979: Training loss= 0.107939 Val loss= 0.497124 Training acc= 0.722115 Val acc= 0.721245\n",
            "Epoch 1980: Training loss= 0.107924 Val loss= 0.496986 Training acc= 0.722150 Val acc= 0.721275\n",
            "Epoch 1981: Training loss= 0.107909 Val loss= 0.496848 Training acc= 0.722180 Val acc= 0.721345\n",
            "Epoch 1982: Training loss= 0.107894 Val loss= 0.496709 Training acc= 0.722215 Val acc= 0.721385\n",
            "Epoch 1983: Training loss= 0.107879 Val loss= 0.496571 Training acc= 0.722235 Val acc= 0.721415\n",
            "Epoch 1984: Training loss= 0.107864 Val loss= 0.496433 Training acc= 0.722245 Val acc= 0.721425\n",
            "Epoch 1985: Training loss= 0.107849 Val loss= 0.496296 Training acc= 0.722275 Val acc= 0.721450\n",
            "Epoch 1986: Training loss= 0.107834 Val loss= 0.496158 Training acc= 0.722300 Val acc= 0.721465\n",
            "Epoch 1987: Training loss= 0.107819 Val loss= 0.496020 Training acc= 0.722305 Val acc= 0.721460\n",
            "Epoch 1988: Training loss= 0.107804 Val loss= 0.495883 Training acc= 0.722310 Val acc= 0.721465\n",
            "Epoch 1989: Training loss= 0.107789 Val loss= 0.495745 Training acc= 0.722300 Val acc= 0.721465\n",
            "Epoch 1990: Training loss= 0.107774 Val loss= 0.495608 Training acc= 0.722325 Val acc= 0.721490\n",
            "Epoch 1991: Training loss= 0.107759 Val loss= 0.495471 Training acc= 0.722350 Val acc= 0.721495\n",
            "Epoch 1992: Training loss= 0.107744 Val loss= 0.495333 Training acc= 0.722370 Val acc= 0.721535\n",
            "Epoch 1993: Training loss= 0.107730 Val loss= 0.495196 Training acc= 0.722395 Val acc= 0.721565\n",
            "Epoch 1994: Training loss= 0.107715 Val loss= 0.495059 Training acc= 0.722375 Val acc= 0.721550\n",
            "Epoch 1995: Training loss= 0.107700 Val loss= 0.494922 Training acc= 0.722415 Val acc= 0.721600\n",
            "Epoch 1996: Training loss= 0.107685 Val loss= 0.494786 Training acc= 0.722430 Val acc= 0.721625\n",
            "Epoch 1997: Training loss= 0.107670 Val loss= 0.494649 Training acc= 0.722450 Val acc= 0.721660\n",
            "Epoch 1998: Training loss= 0.107655 Val loss= 0.494512 Training acc= 0.722490 Val acc= 0.721700\n",
            "Epoch 1999: Training loss= 0.107641 Val loss= 0.494376 Training acc= 0.722500 Val acc= 0.721715\n",
            "Epoch 2000: Training loss= 0.107626 Val loss= 0.494239 Training acc= 0.722495 Val acc= 0.721730\n",
            "Epoch 2001: Training loss= 0.107611 Val loss= 0.494103 Training acc= 0.722540 Val acc= 0.721750\n",
            "Epoch 2002: Training loss= 0.107596 Val loss= 0.493967 Training acc= 0.722535 Val acc= 0.721740\n",
            "Epoch 2003: Training loss= 0.107582 Val loss= 0.493831 Training acc= 0.722565 Val acc= 0.721755\n",
            "Epoch 2004: Training loss= 0.107567 Val loss= 0.493695 Training acc= 0.722575 Val acc= 0.721760\n",
            "Epoch 2005: Training loss= 0.107552 Val loss= 0.493559 Training acc= 0.722605 Val acc= 0.721790\n",
            "Epoch 2006: Training loss= 0.107538 Val loss= 0.493423 Training acc= 0.722590 Val acc= 0.721780\n",
            "Epoch 2007: Training loss= 0.107523 Val loss= 0.493287 Training acc= 0.722635 Val acc= 0.721815\n",
            "Epoch 2008: Training loss= 0.107508 Val loss= 0.493152 Training acc= 0.722640 Val acc= 0.721835\n",
            "Epoch 2009: Training loss= 0.107494 Val loss= 0.493016 Training acc= 0.722645 Val acc= 0.721845\n",
            "Epoch 2010: Training loss= 0.107479 Val loss= 0.492880 Training acc= 0.722685 Val acc= 0.721865\n",
            "Epoch 2011: Training loss= 0.107464 Val loss= 0.492745 Training acc= 0.722700 Val acc= 0.721865\n",
            "Epoch 2012: Training loss= 0.107450 Val loss= 0.492610 Training acc= 0.722740 Val acc= 0.721890\n",
            "Epoch 2013: Training loss= 0.107435 Val loss= 0.492475 Training acc= 0.722760 Val acc= 0.721915\n",
            "Epoch 2014: Training loss= 0.107421 Val loss= 0.492340 Training acc= 0.722800 Val acc= 0.721955\n",
            "Epoch 2015: Training loss= 0.107406 Val loss= 0.492205 Training acc= 0.722840 Val acc= 0.721975\n",
            "Epoch 2016: Training loss= 0.107392 Val loss= 0.492070 Training acc= 0.722870 Val acc= 0.721995\n",
            "Epoch 2017: Training loss= 0.107377 Val loss= 0.491935 Training acc= 0.722860 Val acc= 0.721995\n",
            "Epoch 2018: Training loss= 0.107363 Val loss= 0.491800 Training acc= 0.722860 Val acc= 0.722000\n",
            "Epoch 2019: Training loss= 0.107348 Val loss= 0.491665 Training acc= 0.722860 Val acc= 0.721995\n",
            "Epoch 2020: Training loss= 0.107334 Val loss= 0.491531 Training acc= 0.722895 Val acc= 0.722030\n",
            "Epoch 2021: Training loss= 0.107319 Val loss= 0.491396 Training acc= 0.722900 Val acc= 0.722050\n",
            "Epoch 2022: Training loss= 0.107305 Val loss= 0.491262 Training acc= 0.722905 Val acc= 0.722050\n",
            "Epoch 2023: Training loss= 0.107290 Val loss= 0.491128 Training acc= 0.722920 Val acc= 0.722075\n",
            "Epoch 2024: Training loss= 0.107276 Val loss= 0.490994 Training acc= 0.722935 Val acc= 0.722085\n",
            "Epoch 2025: Training loss= 0.107261 Val loss= 0.490860 Training acc= 0.722955 Val acc= 0.722115\n",
            "Epoch 2026: Training loss= 0.107247 Val loss= 0.490726 Training acc= 0.722985 Val acc= 0.722125\n",
            "Epoch 2027: Training loss= 0.107232 Val loss= 0.490592 Training acc= 0.722985 Val acc= 0.722135\n",
            "Epoch 2028: Training loss= 0.107218 Val loss= 0.490458 Training acc= 0.723010 Val acc= 0.722175\n",
            "Epoch 2029: Training loss= 0.107204 Val loss= 0.490324 Training acc= 0.723030 Val acc= 0.722190\n",
            "Epoch 2030: Training loss= 0.107189 Val loss= 0.490191 Training acc= 0.723055 Val acc= 0.722215\n",
            "Epoch 2031: Training loss= 0.107175 Val loss= 0.490057 Training acc= 0.723060 Val acc= 0.722235\n",
            "Epoch 2032: Training loss= 0.107161 Val loss= 0.489924 Training acc= 0.723070 Val acc= 0.722240\n",
            "Epoch 2033: Training loss= 0.107146 Val loss= 0.489790 Training acc= 0.723110 Val acc= 0.722295\n",
            "Epoch 2034: Training loss= 0.107132 Val loss= 0.489657 Training acc= 0.723120 Val acc= 0.722305\n",
            "Epoch 2035: Training loss= 0.107118 Val loss= 0.489524 Training acc= 0.723130 Val acc= 0.722325\n",
            "Epoch 2036: Training loss= 0.107104 Val loss= 0.489391 Training acc= 0.723140 Val acc= 0.722325\n",
            "Epoch 2037: Training loss= 0.107089 Val loss= 0.489258 Training acc= 0.723170 Val acc= 0.722350\n",
            "Epoch 2038: Training loss= 0.107075 Val loss= 0.489125 Training acc= 0.723195 Val acc= 0.722360\n",
            "Epoch 2039: Training loss= 0.107061 Val loss= 0.488992 Training acc= 0.723225 Val acc= 0.722390\n",
            "Epoch 2040: Training loss= 0.107047 Val loss= 0.488859 Training acc= 0.723225 Val acc= 0.722405\n",
            "Epoch 2041: Training loss= 0.107032 Val loss= 0.488727 Training acc= 0.723225 Val acc= 0.722405\n",
            "Epoch 2042: Training loss= 0.107018 Val loss= 0.488594 Training acc= 0.723240 Val acc= 0.722415\n",
            "Epoch 2043: Training loss= 0.107004 Val loss= 0.488462 Training acc= 0.723260 Val acc= 0.722420\n",
            "Epoch 2044: Training loss= 0.106990 Val loss= 0.488329 Training acc= 0.723280 Val acc= 0.722445\n",
            "Epoch 2045: Training loss= 0.106976 Val loss= 0.488197 Training acc= 0.723295 Val acc= 0.722470\n",
            "Epoch 2046: Training loss= 0.106961 Val loss= 0.488065 Training acc= 0.723315 Val acc= 0.722505\n",
            "Epoch 2047: Training loss= 0.106947 Val loss= 0.487933 Training acc= 0.723385 Val acc= 0.722555\n",
            "Epoch 2048: Training loss= 0.106933 Val loss= 0.487801 Training acc= 0.723395 Val acc= 0.722570\n",
            "Epoch 2049: Training loss= 0.106919 Val loss= 0.487669 Training acc= 0.723380 Val acc= 0.722585\n",
            "Epoch 2050: Training loss= 0.106905 Val loss= 0.487537 Training acc= 0.723390 Val acc= 0.722580\n",
            "Epoch 2051: Training loss= 0.106891 Val loss= 0.487405 Training acc= 0.723415 Val acc= 0.722605\n",
            "Epoch 2052: Training loss= 0.106877 Val loss= 0.487274 Training acc= 0.723440 Val acc= 0.722640\n",
            "Epoch 2053: Training loss= 0.106863 Val loss= 0.487142 Training acc= 0.723440 Val acc= 0.722650\n",
            "Epoch 2054: Training loss= 0.106849 Val loss= 0.487011 Training acc= 0.723440 Val acc= 0.722655\n",
            "Epoch 2055: Training loss= 0.106835 Val loss= 0.486879 Training acc= 0.723455 Val acc= 0.722680\n",
            "Epoch 2056: Training loss= 0.106821 Val loss= 0.486748 Training acc= 0.723495 Val acc= 0.722700\n",
            "Epoch 2057: Training loss= 0.106807 Val loss= 0.486617 Training acc= 0.723505 Val acc= 0.722710\n",
            "Epoch 2058: Training loss= 0.106793 Val loss= 0.486486 Training acc= 0.723515 Val acc= 0.722730\n",
            "Epoch 2059: Training loss= 0.106779 Val loss= 0.486355 Training acc= 0.723515 Val acc= 0.722745\n",
            "Epoch 2060: Training loss= 0.106765 Val loss= 0.486224 Training acc= 0.723545 Val acc= 0.722770\n",
            "Epoch 2061: Training loss= 0.106751 Val loss= 0.486093 Training acc= 0.723530 Val acc= 0.722780\n",
            "Epoch 2062: Training loss= 0.106737 Val loss= 0.485962 Training acc= 0.723580 Val acc= 0.722835\n",
            "Epoch 2063: Training loss= 0.106723 Val loss= 0.485832 Training acc= 0.723585 Val acc= 0.722845\n",
            "Epoch 2064: Training loss= 0.106709 Val loss= 0.485701 Training acc= 0.723615 Val acc= 0.722865\n",
            "Epoch 2065: Training loss= 0.106695 Val loss= 0.485571 Training acc= 0.723610 Val acc= 0.722875\n",
            "Epoch 2066: Training loss= 0.106681 Val loss= 0.485440 Training acc= 0.723645 Val acc= 0.722885\n",
            "Epoch 2067: Training loss= 0.106667 Val loss= 0.485310 Training acc= 0.723655 Val acc= 0.722890\n",
            "Epoch 2068: Training loss= 0.106653 Val loss= 0.485180 Training acc= 0.723710 Val acc= 0.722930\n",
            "Epoch 2069: Training loss= 0.106640 Val loss= 0.485049 Training acc= 0.723720 Val acc= 0.722930\n",
            "Epoch 2070: Training loss= 0.106626 Val loss= 0.484919 Training acc= 0.723725 Val acc= 0.722945\n",
            "Epoch 2071: Training loss= 0.106612 Val loss= 0.484789 Training acc= 0.723740 Val acc= 0.722965\n",
            "Epoch 2072: Training loss= 0.106598 Val loss= 0.484660 Training acc= 0.723745 Val acc= 0.722975\n",
            "Epoch 2073: Training loss= 0.106584 Val loss= 0.484530 Training acc= 0.723765 Val acc= 0.722975\n",
            "Epoch 2074: Training loss= 0.106571 Val loss= 0.484400 Training acc= 0.723755 Val acc= 0.722975\n",
            "Epoch 2075: Training loss= 0.106557 Val loss= 0.484270 Training acc= 0.723770 Val acc= 0.722985\n",
            "Epoch 2076: Training loss= 0.106543 Val loss= 0.484141 Training acc= 0.723805 Val acc= 0.723015\n",
            "Epoch 2077: Training loss= 0.106529 Val loss= 0.484011 Training acc= 0.723835 Val acc= 0.723045\n",
            "Epoch 2078: Training loss= 0.106515 Val loss= 0.483882 Training acc= 0.723835 Val acc= 0.723065\n",
            "Epoch 2079: Training loss= 0.106502 Val loss= 0.483753 Training acc= 0.723855 Val acc= 0.723080\n",
            "Epoch 2080: Training loss= 0.106488 Val loss= 0.483624 Training acc= 0.723875 Val acc= 0.723070\n",
            "Epoch 2081: Training loss= 0.106474 Val loss= 0.483495 Training acc= 0.723880 Val acc= 0.723070\n",
            "Epoch 2082: Training loss= 0.106461 Val loss= 0.483365 Training acc= 0.723880 Val acc= 0.723100\n",
            "Epoch 2083: Training loss= 0.106447 Val loss= 0.483237 Training acc= 0.723895 Val acc= 0.723095\n",
            "Epoch 2084: Training loss= 0.106433 Val loss= 0.483108 Training acc= 0.723970 Val acc= 0.723175\n",
            "Epoch 2085: Training loss= 0.106420 Val loss= 0.482979 Training acc= 0.723985 Val acc= 0.723205\n",
            "Epoch 2086: Training loss= 0.106406 Val loss= 0.482850 Training acc= 0.724015 Val acc= 0.723230\n",
            "Epoch 2087: Training loss= 0.106392 Val loss= 0.482722 Training acc= 0.724065 Val acc= 0.723295\n",
            "Epoch 2088: Training loss= 0.106379 Val loss= 0.482593 Training acc= 0.724105 Val acc= 0.723340\n",
            "Epoch 2089: Training loss= 0.106365 Val loss= 0.482465 Training acc= 0.724140 Val acc= 0.723375\n",
            "Epoch 2090: Training loss= 0.106351 Val loss= 0.482336 Training acc= 0.724190 Val acc= 0.723410\n",
            "Epoch 2091: Training loss= 0.106338 Val loss= 0.482208 Training acc= 0.724245 Val acc= 0.723445\n",
            "Epoch 2092: Training loss= 0.106324 Val loss= 0.482080 Training acc= 0.724275 Val acc= 0.723465\n",
            "Epoch 2093: Training loss= 0.106311 Val loss= 0.481952 Training acc= 0.724305 Val acc= 0.723485\n",
            "Epoch 2094: Training loss= 0.106297 Val loss= 0.481824 Training acc= 0.724320 Val acc= 0.723495\n",
            "Epoch 2095: Training loss= 0.106284 Val loss= 0.481696 Training acc= 0.724325 Val acc= 0.723490\n",
            "Epoch 2096: Training loss= 0.106270 Val loss= 0.481568 Training acc= 0.724340 Val acc= 0.723520\n",
            "Epoch 2097: Training loss= 0.106257 Val loss= 0.481440 Training acc= 0.724375 Val acc= 0.723550\n",
            "Epoch 2098: Training loss= 0.106243 Val loss= 0.481313 Training acc= 0.724430 Val acc= 0.723580\n",
            "Epoch 2099: Training loss= 0.106230 Val loss= 0.481185 Training acc= 0.724460 Val acc= 0.723615\n",
            "Epoch 2100: Training loss= 0.106216 Val loss= 0.481058 Training acc= 0.724465 Val acc= 0.723620\n",
            "Epoch 2101: Training loss= 0.106203 Val loss= 0.480930 Training acc= 0.724480 Val acc= 0.723635\n",
            "Epoch 2102: Training loss= 0.106189 Val loss= 0.480803 Training acc= 0.724500 Val acc= 0.723650\n",
            "Epoch 2103: Training loss= 0.106176 Val loss= 0.480676 Training acc= 0.724500 Val acc= 0.723660\n",
            "Epoch 2104: Training loss= 0.106162 Val loss= 0.480549 Training acc= 0.724510 Val acc= 0.723660\n",
            "Epoch 2105: Training loss= 0.106149 Val loss= 0.480422 Training acc= 0.724530 Val acc= 0.723680\n",
            "Epoch 2106: Training loss= 0.106136 Val loss= 0.480295 Training acc= 0.724530 Val acc= 0.723700\n",
            "Epoch 2107: Training loss= 0.106122 Val loss= 0.480168 Training acc= 0.724550 Val acc= 0.723720\n",
            "Epoch 2108: Training loss= 0.106109 Val loss= 0.480041 Training acc= 0.724575 Val acc= 0.723760\n",
            "Epoch 2109: Training loss= 0.106095 Val loss= 0.479914 Training acc= 0.724610 Val acc= 0.723790\n",
            "Epoch 2110: Training loss= 0.106082 Val loss= 0.479787 Training acc= 0.724630 Val acc= 0.723825\n",
            "Epoch 2111: Training loss= 0.106069 Val loss= 0.479661 Training acc= 0.724650 Val acc= 0.723855\n",
            "Epoch 2112: Training loss= 0.106055 Val loss= 0.479534 Training acc= 0.724655 Val acc= 0.723870\n",
            "Epoch 2113: Training loss= 0.106042 Val loss= 0.479408 Training acc= 0.724695 Val acc= 0.723890\n",
            "Epoch 2114: Training loss= 0.106029 Val loss= 0.479282 Training acc= 0.724740 Val acc= 0.723930\n",
            "Epoch 2115: Training loss= 0.106015 Val loss= 0.479155 Training acc= 0.724780 Val acc= 0.723960\n",
            "Epoch 2116: Training loss= 0.106002 Val loss= 0.479029 Training acc= 0.724790 Val acc= 0.723970\n",
            "Epoch 2117: Training loss= 0.105989 Val loss= 0.478903 Training acc= 0.724815 Val acc= 0.723985\n",
            "Epoch 2118: Training loss= 0.105976 Val loss= 0.478777 Training acc= 0.724820 Val acc= 0.723970\n",
            "Epoch 2119: Training loss= 0.105962 Val loss= 0.478651 Training acc= 0.724845 Val acc= 0.723980\n",
            "Epoch 2120: Training loss= 0.105949 Val loss= 0.478525 Training acc= 0.724860 Val acc= 0.723995\n",
            "Epoch 2121: Training loss= 0.105936 Val loss= 0.478400 Training acc= 0.724885 Val acc= 0.724010\n",
            "Epoch 2122: Training loss= 0.105923 Val loss= 0.478274 Training acc= 0.724915 Val acc= 0.724045\n",
            "Epoch 2123: Training loss= 0.105909 Val loss= 0.478148 Training acc= 0.724935 Val acc= 0.724045\n",
            "Epoch 2124: Training loss= 0.105896 Val loss= 0.478023 Training acc= 0.724940 Val acc= 0.724070\n",
            "Epoch 2125: Training loss= 0.105883 Val loss= 0.477898 Training acc= 0.724950 Val acc= 0.724080\n",
            "Epoch 2126: Training loss= 0.105870 Val loss= 0.477772 Training acc= 0.724940 Val acc= 0.724105\n",
            "Epoch 2127: Training loss= 0.105857 Val loss= 0.477647 Training acc= 0.724955 Val acc= 0.724120\n",
            "Epoch 2128: Training loss= 0.105844 Val loss= 0.477522 Training acc= 0.724970 Val acc= 0.724135\n",
            "Epoch 2129: Training loss= 0.105830 Val loss= 0.477397 Training acc= 0.724985 Val acc= 0.724155\n",
            "Epoch 2130: Training loss= 0.105817 Val loss= 0.477272 Training acc= 0.724985 Val acc= 0.724175\n",
            "Epoch 2131: Training loss= 0.105804 Val loss= 0.477147 Training acc= 0.725005 Val acc= 0.724185\n",
            "Epoch 2132: Training loss= 0.105791 Val loss= 0.477022 Training acc= 0.725035 Val acc= 0.724200\n",
            "Epoch 2133: Training loss= 0.105778 Val loss= 0.476897 Training acc= 0.725055 Val acc= 0.724200\n",
            "Epoch 2134: Training loss= 0.105765 Val loss= 0.476772 Training acc= 0.725095 Val acc= 0.724235\n",
            "Epoch 2135: Training loss= 0.105752 Val loss= 0.476648 Training acc= 0.725125 Val acc= 0.724260\n",
            "Epoch 2136: Training loss= 0.105739 Val loss= 0.476523 Training acc= 0.725135 Val acc= 0.724270\n",
            "Epoch 2137: Training loss= 0.105726 Val loss= 0.476399 Training acc= 0.725155 Val acc= 0.724290\n",
            "Epoch 2138: Training loss= 0.105713 Val loss= 0.476274 Training acc= 0.725195 Val acc= 0.724320\n",
            "Epoch 2139: Training loss= 0.105700 Val loss= 0.476150 Training acc= 0.725210 Val acc= 0.724335\n",
            "Epoch 2140: Training loss= 0.105687 Val loss= 0.476026 Training acc= 0.725210 Val acc= 0.724335\n",
            "Epoch 2141: Training loss= 0.105674 Val loss= 0.475902 Training acc= 0.725230 Val acc= 0.724355\n",
            "Epoch 2142: Training loss= 0.105661 Val loss= 0.475778 Training acc= 0.725250 Val acc= 0.724355\n",
            "Epoch 2143: Training loss= 0.105648 Val loss= 0.475654 Training acc= 0.725260 Val acc= 0.724385\n",
            "Epoch 2144: Training loss= 0.105635 Val loss= 0.475530 Training acc= 0.725280 Val acc= 0.724400\n",
            "Epoch 2145: Training loss= 0.105622 Val loss= 0.475406 Training acc= 0.725310 Val acc= 0.724430\n",
            "Epoch 2146: Training loss= 0.105609 Val loss= 0.475282 Training acc= 0.725320 Val acc= 0.724445\n",
            "Epoch 2147: Training loss= 0.105596 Val loss= 0.475159 Training acc= 0.725355 Val acc= 0.724480\n",
            "Epoch 2148: Training loss= 0.105583 Val loss= 0.475035 Training acc= 0.725345 Val acc= 0.724490\n",
            "Epoch 2149: Training loss= 0.105570 Val loss= 0.474912 Training acc= 0.725355 Val acc= 0.724485\n",
            "Epoch 2150: Training loss= 0.105557 Val loss= 0.474788 Training acc= 0.725350 Val acc= 0.724485\n",
            "Epoch 2151: Training loss= 0.105544 Val loss= 0.474665 Training acc= 0.725380 Val acc= 0.724520\n",
            "Epoch 2152: Training loss= 0.105531 Val loss= 0.474542 Training acc= 0.725420 Val acc= 0.724570\n",
            "Epoch 2153: Training loss= 0.105518 Val loss= 0.474419 Training acc= 0.725440 Val acc= 0.724605\n",
            "Epoch 2154: Training loss= 0.105506 Val loss= 0.474295 Training acc= 0.725470 Val acc= 0.724630\n",
            "Epoch 2155: Training loss= 0.105493 Val loss= 0.474172 Training acc= 0.725480 Val acc= 0.724635\n",
            "Epoch 2156: Training loss= 0.105480 Val loss= 0.474049 Training acc= 0.725500 Val acc= 0.724635\n",
            "Epoch 2157: Training loss= 0.105467 Val loss= 0.473927 Training acc= 0.725500 Val acc= 0.724635\n",
            "Epoch 2158: Training loss= 0.105454 Val loss= 0.473804 Training acc= 0.725520 Val acc= 0.724680\n",
            "Epoch 2159: Training loss= 0.105441 Val loss= 0.473681 Training acc= 0.725505 Val acc= 0.724695\n",
            "Epoch 2160: Training loss= 0.105429 Val loss= 0.473559 Training acc= 0.725530 Val acc= 0.724725\n",
            "Epoch 2161: Training loss= 0.105416 Val loss= 0.473436 Training acc= 0.725560 Val acc= 0.724770\n",
            "Epoch 2162: Training loss= 0.105403 Val loss= 0.473314 Training acc= 0.725575 Val acc= 0.724785\n",
            "Epoch 2163: Training loss= 0.105390 Val loss= 0.473191 Training acc= 0.725585 Val acc= 0.724790\n",
            "Epoch 2164: Training loss= 0.105378 Val loss= 0.473069 Training acc= 0.725570 Val acc= 0.724780\n",
            "Epoch 2165: Training loss= 0.105365 Val loss= 0.472947 Training acc= 0.725590 Val acc= 0.724810\n",
            "Epoch 2166: Training loss= 0.105352 Val loss= 0.472824 Training acc= 0.725585 Val acc= 0.724805\n",
            "Epoch 2167: Training loss= 0.105339 Val loss= 0.472702 Training acc= 0.725625 Val acc= 0.724845\n",
            "Epoch 2168: Training loss= 0.105327 Val loss= 0.472580 Training acc= 0.725640 Val acc= 0.724850\n",
            "Epoch 2169: Training loss= 0.105314 Val loss= 0.472458 Training acc= 0.725645 Val acc= 0.724845\n",
            "Epoch 2170: Training loss= 0.105301 Val loss= 0.472337 Training acc= 0.725660 Val acc= 0.724865\n",
            "Epoch 2171: Training loss= 0.105289 Val loss= 0.472215 Training acc= 0.725670 Val acc= 0.724865\n",
            "Epoch 2172: Training loss= 0.105276 Val loss= 0.472093 Training acc= 0.725695 Val acc= 0.724885\n",
            "Epoch 2173: Training loss= 0.105263 Val loss= 0.471972 Training acc= 0.725715 Val acc= 0.724915\n",
            "Epoch 2174: Training loss= 0.105251 Val loss= 0.471850 Training acc= 0.725725 Val acc= 0.724935\n",
            "Epoch 2175: Training loss= 0.105238 Val loss= 0.471729 Training acc= 0.725715 Val acc= 0.724935\n",
            "Epoch 2176: Training loss= 0.105225 Val loss= 0.471607 Training acc= 0.725745 Val acc= 0.724960\n",
            "Epoch 2177: Training loss= 0.105213 Val loss= 0.471486 Training acc= 0.725780 Val acc= 0.725005\n",
            "Epoch 2178: Training loss= 0.105200 Val loss= 0.471365 Training acc= 0.725785 Val acc= 0.725010\n",
            "Epoch 2179: Training loss= 0.105188 Val loss= 0.471244 Training acc= 0.725790 Val acc= 0.725015\n",
            "Epoch 2180: Training loss= 0.105175 Val loss= 0.471123 Training acc= 0.725800 Val acc= 0.725020\n",
            "Epoch 2181: Training loss= 0.105162 Val loss= 0.471002 Training acc= 0.725810 Val acc= 0.725030\n",
            "Epoch 2182: Training loss= 0.105150 Val loss= 0.470881 Training acc= 0.725825 Val acc= 0.725060\n",
            "Epoch 2183: Training loss= 0.105137 Val loss= 0.470760 Training acc= 0.725860 Val acc= 0.725090\n",
            "Epoch 2184: Training loss= 0.105125 Val loss= 0.470639 Training acc= 0.725860 Val acc= 0.725090\n",
            "Epoch 2185: Training loss= 0.105112 Val loss= 0.470518 Training acc= 0.725880 Val acc= 0.725120\n",
            "Epoch 2186: Training loss= 0.105100 Val loss= 0.470398 Training acc= 0.725925 Val acc= 0.725160\n",
            "Epoch 2187: Training loss= 0.105087 Val loss= 0.470277 Training acc= 0.725920 Val acc= 0.725160\n",
            "Epoch 2188: Training loss= 0.105075 Val loss= 0.470157 Training acc= 0.725940 Val acc= 0.725175\n",
            "Epoch 2189: Training loss= 0.105062 Val loss= 0.470036 Training acc= 0.725945 Val acc= 0.725195\n",
            "Epoch 2190: Training loss= 0.105050 Val loss= 0.469916 Training acc= 0.725945 Val acc= 0.725195\n",
            "Epoch 2191: Training loss= 0.105037 Val loss= 0.469796 Training acc= 0.725960 Val acc= 0.725220\n",
            "Epoch 2192: Training loss= 0.105025 Val loss= 0.469676 Training acc= 0.725975 Val acc= 0.725250\n",
            "Epoch 2193: Training loss= 0.105012 Val loss= 0.469556 Training acc= 0.726020 Val acc= 0.725275\n",
            "Epoch 2194: Training loss= 0.105000 Val loss= 0.469436 Training acc= 0.726065 Val acc= 0.725320\n",
            "Epoch 2195: Training loss= 0.104988 Val loss= 0.469316 Training acc= 0.726070 Val acc= 0.725345\n",
            "Epoch 2196: Training loss= 0.104975 Val loss= 0.469196 Training acc= 0.726090 Val acc= 0.725345\n",
            "Epoch 2197: Training loss= 0.104963 Val loss= 0.469076 Training acc= 0.726125 Val acc= 0.725385\n",
            "Epoch 2198: Training loss= 0.104950 Val loss= 0.468956 Training acc= 0.726120 Val acc= 0.725390\n",
            "Epoch 2199: Training loss= 0.104938 Val loss= 0.468837 Training acc= 0.726150 Val acc= 0.725415\n",
            "Epoch 2200: Training loss= 0.104926 Val loss= 0.468717 Training acc= 0.726175 Val acc= 0.725425\n",
            "Epoch 2201: Training loss= 0.104913 Val loss= 0.468598 Training acc= 0.726205 Val acc= 0.725460\n",
            "Epoch 2202: Training loss= 0.104901 Val loss= 0.468478 Training acc= 0.726210 Val acc= 0.725470\n",
            "Epoch 2203: Training loss= 0.104889 Val loss= 0.468359 Training acc= 0.726245 Val acc= 0.725480\n",
            "Epoch 2204: Training loss= 0.104876 Val loss= 0.468240 Training acc= 0.726280 Val acc= 0.725515\n",
            "Epoch 2205: Training loss= 0.104864 Val loss= 0.468121 Training acc= 0.726280 Val acc= 0.725530\n",
            "Epoch 2206: Training loss= 0.104852 Val loss= 0.468002 Training acc= 0.726320 Val acc= 0.725575\n",
            "Epoch 2207: Training loss= 0.104839 Val loss= 0.467882 Training acc= 0.726345 Val acc= 0.725615\n",
            "Epoch 2208: Training loss= 0.104827 Val loss= 0.467764 Training acc= 0.726390 Val acc= 0.725655\n",
            "Epoch 2209: Training loss= 0.104815 Val loss= 0.467645 Training acc= 0.726410 Val acc= 0.725660\n",
            "Epoch 2210: Training loss= 0.104802 Val loss= 0.467526 Training acc= 0.726410 Val acc= 0.725665\n",
            "Epoch 2211: Training loss= 0.104790 Val loss= 0.467407 Training acc= 0.726425 Val acc= 0.725685\n",
            "Epoch 2212: Training loss= 0.104778 Val loss= 0.467288 Training acc= 0.726425 Val acc= 0.725690\n",
            "Epoch 2213: Training loss= 0.104766 Val loss= 0.467170 Training acc= 0.726450 Val acc= 0.725715\n",
            "Epoch 2214: Training loss= 0.104753 Val loss= 0.467051 Training acc= 0.726465 Val acc= 0.725730\n",
            "Epoch 2215: Training loss= 0.104741 Val loss= 0.466933 Training acc= 0.726470 Val acc= 0.725740\n",
            "Epoch 2216: Training loss= 0.104729 Val loss= 0.466815 Training acc= 0.726475 Val acc= 0.725735\n",
            "Epoch 2217: Training loss= 0.104717 Val loss= 0.466696 Training acc= 0.726490 Val acc= 0.725760\n",
            "Epoch 2218: Training loss= 0.104705 Val loss= 0.466578 Training acc= 0.726495 Val acc= 0.725775\n",
            "Epoch 2219: Training loss= 0.104692 Val loss= 0.466460 Training acc= 0.726510 Val acc= 0.725795\n",
            "Epoch 2220: Training loss= 0.104680 Val loss= 0.466342 Training acc= 0.726545 Val acc= 0.725830\n",
            "Epoch 2221: Training loss= 0.104668 Val loss= 0.466224 Training acc= 0.726545 Val acc= 0.725825\n",
            "Epoch 2222: Training loss= 0.104656 Val loss= 0.466106 Training acc= 0.726555 Val acc= 0.725835\n",
            "Epoch 2223: Training loss= 0.104644 Val loss= 0.465988 Training acc= 0.726575 Val acc= 0.725860\n",
            "Epoch 2224: Training loss= 0.104632 Val loss= 0.465870 Training acc= 0.726585 Val acc= 0.725870\n",
            "Epoch 2225: Training loss= 0.104620 Val loss= 0.465753 Training acc= 0.726620 Val acc= 0.725910\n",
            "Epoch 2226: Training loss= 0.104608 Val loss= 0.465635 Training acc= 0.726625 Val acc= 0.725935\n",
            "Epoch 2227: Training loss= 0.104595 Val loss= 0.465518 Training acc= 0.726655 Val acc= 0.725955\n",
            "Epoch 2228: Training loss= 0.104583 Val loss= 0.465400 Training acc= 0.726675 Val acc= 0.725965\n",
            "Epoch 2229: Training loss= 0.104571 Val loss= 0.465283 Training acc= 0.726675 Val acc= 0.725975\n",
            "Epoch 2230: Training loss= 0.104559 Val loss= 0.465165 Training acc= 0.726660 Val acc= 0.725980\n",
            "Epoch 2231: Training loss= 0.104547 Val loss= 0.465048 Training acc= 0.726685 Val acc= 0.725995\n",
            "Epoch 2232: Training loss= 0.104535 Val loss= 0.464931 Training acc= 0.726695 Val acc= 0.725995\n",
            "Epoch 2233: Training loss= 0.104523 Val loss= 0.464814 Training acc= 0.726690 Val acc= 0.725995\n",
            "Epoch 2234: Training loss= 0.104511 Val loss= 0.464697 Training acc= 0.726700 Val acc= 0.725995\n",
            "Epoch 2235: Training loss= 0.104499 Val loss= 0.464580 Training acc= 0.726705 Val acc= 0.726000\n",
            "Epoch 2236: Training loss= 0.104487 Val loss= 0.464463 Training acc= 0.726740 Val acc= 0.726045\n",
            "Epoch 2237: Training loss= 0.104475 Val loss= 0.464346 Training acc= 0.726755 Val acc= 0.726060\n",
            "Epoch 2238: Training loss= 0.104463 Val loss= 0.464229 Training acc= 0.726770 Val acc= 0.726085\n",
            "Epoch 2239: Training loss= 0.104451 Val loss= 0.464113 Training acc= 0.726795 Val acc= 0.726100\n",
            "Epoch 2240: Training loss= 0.104439 Val loss= 0.463996 Training acc= 0.726820 Val acc= 0.726125\n",
            "Epoch 2241: Training loss= 0.104427 Val loss= 0.463880 Training acc= 0.726840 Val acc= 0.726150\n",
            "Epoch 2242: Training loss= 0.104415 Val loss= 0.463763 Training acc= 0.726845 Val acc= 0.726145\n",
            "Epoch 2243: Training loss= 0.104403 Val loss= 0.463647 Training acc= 0.726860 Val acc= 0.726160\n",
            "Epoch 2244: Training loss= 0.104391 Val loss= 0.463530 Training acc= 0.726865 Val acc= 0.726165\n",
            "Epoch 2245: Training loss= 0.104379 Val loss= 0.463414 Training acc= 0.726870 Val acc= 0.726195\n",
            "Epoch 2246: Training loss= 0.104367 Val loss= 0.463298 Training acc= 0.726870 Val acc= 0.726185\n",
            "Epoch 2247: Training loss= 0.104356 Val loss= 0.463182 Training acc= 0.726915 Val acc= 0.726225\n",
            "Epoch 2248: Training loss= 0.104344 Val loss= 0.463066 Training acc= 0.726940 Val acc= 0.726275\n",
            "Epoch 2249: Training loss= 0.104332 Val loss= 0.462950 Training acc= 0.726925 Val acc= 0.726290\n",
            "Epoch 2250: Training loss= 0.104320 Val loss= 0.462834 Training acc= 0.726935 Val acc= 0.726310\n",
            "Epoch 2251: Training loss= 0.104308 Val loss= 0.462718 Training acc= 0.726965 Val acc= 0.726335\n",
            "Epoch 2252: Training loss= 0.104296 Val loss= 0.462602 Training acc= 0.727010 Val acc= 0.726365\n",
            "Epoch 2253: Training loss= 0.104284 Val loss= 0.462487 Training acc= 0.727020 Val acc= 0.726380\n",
            "Epoch 2254: Training loss= 0.104272 Val loss= 0.462371 Training acc= 0.727035 Val acc= 0.726380\n",
            "Epoch 2255: Training loss= 0.104261 Val loss= 0.462256 Training acc= 0.727055 Val acc= 0.726405\n",
            "Epoch 2256: Training loss= 0.104249 Val loss= 0.462140 Training acc= 0.727055 Val acc= 0.726405\n",
            "Epoch 2257: Training loss= 0.104237 Val loss= 0.462025 Training acc= 0.727050 Val acc= 0.726405\n",
            "Epoch 2258: Training loss= 0.104225 Val loss= 0.461909 Training acc= 0.727050 Val acc= 0.726410\n",
            "Epoch 2259: Training loss= 0.104213 Val loss= 0.461794 Training acc= 0.727065 Val acc= 0.726420\n",
            "Epoch 2260: Training loss= 0.104202 Val loss= 0.461679 Training acc= 0.727070 Val acc= 0.726430\n",
            "Epoch 2261: Training loss= 0.104190 Val loss= 0.461564 Training acc= 0.727105 Val acc= 0.726470\n",
            "Epoch 2262: Training loss= 0.104178 Val loss= 0.461449 Training acc= 0.727140 Val acc= 0.726495\n",
            "Epoch 2263: Training loss= 0.104166 Val loss= 0.461334 Training acc= 0.727160 Val acc= 0.726510\n",
            "Epoch 2264: Training loss= 0.104155 Val loss= 0.461219 Training acc= 0.727165 Val acc= 0.726515\n",
            "Epoch 2265: Training loss= 0.104143 Val loss= 0.461104 Training acc= 0.727180 Val acc= 0.726520\n",
            "Epoch 2266: Training loss= 0.104131 Val loss= 0.460989 Training acc= 0.727200 Val acc= 0.726535\n",
            "Epoch 2267: Training loss= 0.104119 Val loss= 0.460875 Training acc= 0.727230 Val acc= 0.726555\n",
            "Epoch 2268: Training loss= 0.104108 Val loss= 0.460760 Training acc= 0.727260 Val acc= 0.726570\n",
            "Epoch 2269: Training loss= 0.104096 Val loss= 0.460646 Training acc= 0.727315 Val acc= 0.726635\n",
            "Epoch 2270: Training loss= 0.104084 Val loss= 0.460531 Training acc= 0.727340 Val acc= 0.726645\n",
            "Epoch 2271: Training loss= 0.104073 Val loss= 0.460417 Training acc= 0.727360 Val acc= 0.726655\n",
            "Epoch 2272: Training loss= 0.104061 Val loss= 0.460302 Training acc= 0.727360 Val acc= 0.726650\n",
            "Epoch 2273: Training loss= 0.104049 Val loss= 0.460188 Training acc= 0.727380 Val acc= 0.726670\n",
            "Epoch 2274: Training loss= 0.104038 Val loss= 0.460074 Training acc= 0.727405 Val acc= 0.726705\n",
            "Epoch 2275: Training loss= 0.104026 Val loss= 0.459960 Training acc= 0.727440 Val acc= 0.726745\n",
            "Epoch 2276: Training loss= 0.104014 Val loss= 0.459846 Training acc= 0.727475 Val acc= 0.726775\n",
            "Epoch 2277: Training loss= 0.104003 Val loss= 0.459732 Training acc= 0.727500 Val acc= 0.726800\n",
            "Epoch 2278: Training loss= 0.103991 Val loss= 0.459618 Training acc= 0.727515 Val acc= 0.726835\n",
            "Epoch 2279: Training loss= 0.103980 Val loss= 0.459504 Training acc= 0.727515 Val acc= 0.726860\n",
            "Epoch 2280: Training loss= 0.103968 Val loss= 0.459390 Training acc= 0.727510 Val acc= 0.726875\n",
            "Epoch 2281: Training loss= 0.103957 Val loss= 0.459277 Training acc= 0.727550 Val acc= 0.726905\n",
            "Epoch 2282: Training loss= 0.103945 Val loss= 0.459163 Training acc= 0.727565 Val acc= 0.726935\n",
            "Epoch 2283: Training loss= 0.103933 Val loss= 0.459049 Training acc= 0.727570 Val acc= 0.726975\n",
            "Epoch 2284: Training loss= 0.103922 Val loss= 0.458936 Training acc= 0.727595 Val acc= 0.726990\n",
            "Epoch 2285: Training loss= 0.103910 Val loss= 0.458822 Training acc= 0.727610 Val acc= 0.727005\n",
            "Epoch 2286: Training loss= 0.103899 Val loss= 0.458709 Training acc= 0.727620 Val acc= 0.727015\n",
            "Epoch 2287: Training loss= 0.103887 Val loss= 0.458596 Training acc= 0.727655 Val acc= 0.727030\n",
            "Epoch 2288: Training loss= 0.103876 Val loss= 0.458483 Training acc= 0.727660 Val acc= 0.727030\n",
            "Epoch 2289: Training loss= 0.103864 Val loss= 0.458369 Training acc= 0.727695 Val acc= 0.727060\n",
            "Epoch 2290: Training loss= 0.103853 Val loss= 0.458256 Training acc= 0.727720 Val acc= 0.727070\n",
            "Epoch 2291: Training loss= 0.103841 Val loss= 0.458143 Training acc= 0.727735 Val acc= 0.727075\n",
            "Epoch 2292: Training loss= 0.103830 Val loss= 0.458030 Training acc= 0.727760 Val acc= 0.727100\n",
            "Epoch 2293: Training loss= 0.103818 Val loss= 0.457917 Training acc= 0.727780 Val acc= 0.727125\n",
            "Epoch 2294: Training loss= 0.103807 Val loss= 0.457805 Training acc= 0.727810 Val acc= 0.727165\n",
            "Epoch 2295: Training loss= 0.103795 Val loss= 0.457692 Training acc= 0.727825 Val acc= 0.727195\n",
            "Epoch 2296: Training loss= 0.103784 Val loss= 0.457579 Training acc= 0.727840 Val acc= 0.727205\n",
            "Epoch 2297: Training loss= 0.103772 Val loss= 0.457467 Training acc= 0.727880 Val acc= 0.727230\n",
            "Epoch 2298: Training loss= 0.103761 Val loss= 0.457354 Training acc= 0.727890 Val acc= 0.727240\n",
            "Epoch 2299: Training loss= 0.103750 Val loss= 0.457242 Training acc= 0.727900 Val acc= 0.727245\n",
            "Epoch 2300: Training loss= 0.103738 Val loss= 0.457129 Training acc= 0.727910 Val acc= 0.727255\n",
            "Epoch 2301: Training loss= 0.103727 Val loss= 0.457017 Training acc= 0.727925 Val acc= 0.727290\n",
            "Epoch 2302: Training loss= 0.103715 Val loss= 0.456904 Training acc= 0.727940 Val acc= 0.727305\n",
            "Epoch 2303: Training loss= 0.103704 Val loss= 0.456792 Training acc= 0.727940 Val acc= 0.727310\n",
            "Epoch 2304: Training loss= 0.103693 Val loss= 0.456680 Training acc= 0.727960 Val acc= 0.727315\n",
            "Epoch 2305: Training loss= 0.103681 Val loss= 0.456568 Training acc= 0.727980 Val acc= 0.727335\n",
            "Epoch 2306: Training loss= 0.103670 Val loss= 0.456456 Training acc= 0.728015 Val acc= 0.727365\n",
            "Epoch 2307: Training loss= 0.103659 Val loss= 0.456344 Training acc= 0.728030 Val acc= 0.727380\n",
            "Epoch 2308: Training loss= 0.103647 Val loss= 0.456232 Training acc= 0.728070 Val acc= 0.727415\n",
            "Epoch 2309: Training loss= 0.103636 Val loss= 0.456120 Training acc= 0.728090 Val acc= 0.727445\n",
            "Epoch 2310: Training loss= 0.103625 Val loss= 0.456009 Training acc= 0.728115 Val acc= 0.727470\n",
            "Epoch 2311: Training loss= 0.103613 Val loss= 0.455897 Training acc= 0.728120 Val acc= 0.727475\n",
            "Epoch 2312: Training loss= 0.103602 Val loss= 0.455785 Training acc= 0.728140 Val acc= 0.727495\n",
            "Epoch 2313: Training loss= 0.103591 Val loss= 0.455674 Training acc= 0.728135 Val acc= 0.727505\n",
            "Epoch 2314: Training loss= 0.103579 Val loss= 0.455562 Training acc= 0.728145 Val acc= 0.727525\n",
            "Epoch 2315: Training loss= 0.103568 Val loss= 0.455451 Training acc= 0.728160 Val acc= 0.727555\n",
            "Epoch 2316: Training loss= 0.103557 Val loss= 0.455340 Training acc= 0.728200 Val acc= 0.727595\n",
            "Epoch 2317: Training loss= 0.103546 Val loss= 0.455228 Training acc= 0.728220 Val acc= 0.727600\n",
            "Epoch 2318: Training loss= 0.103534 Val loss= 0.455117 Training acc= 0.728235 Val acc= 0.727630\n",
            "Epoch 2319: Training loss= 0.103523 Val loss= 0.455006 Training acc= 0.728260 Val acc= 0.727655\n",
            "Epoch 2320: Training loss= 0.103512 Val loss= 0.454895 Training acc= 0.728280 Val acc= 0.727680\n",
            "Epoch 2321: Training loss= 0.103501 Val loss= 0.454784 Training acc= 0.728300 Val acc= 0.727680\n",
            "Epoch 2322: Training loss= 0.103489 Val loss= 0.454673 Training acc= 0.728345 Val acc= 0.727720\n",
            "Epoch 2323: Training loss= 0.103478 Val loss= 0.454562 Training acc= 0.728360 Val acc= 0.727725\n",
            "Epoch 2324: Training loss= 0.103467 Val loss= 0.454451 Training acc= 0.728360 Val acc= 0.727705\n",
            "Epoch 2325: Training loss= 0.103456 Val loss= 0.454341 Training acc= 0.728375 Val acc= 0.727715\n",
            "Epoch 2326: Training loss= 0.103445 Val loss= 0.454230 Training acc= 0.728385 Val acc= 0.727730\n",
            "Epoch 2327: Training loss= 0.103434 Val loss= 0.454119 Training acc= 0.728420 Val acc= 0.727760\n",
            "Epoch 2328: Training loss= 0.103422 Val loss= 0.454009 Training acc= 0.728460 Val acc= 0.727790\n",
            "Epoch 2329: Training loss= 0.103411 Val loss= 0.453898 Training acc= 0.728475 Val acc= 0.727800\n",
            "Epoch 2330: Training loss= 0.103400 Val loss= 0.453788 Training acc= 0.728480 Val acc= 0.727805\n",
            "Epoch 2331: Training loss= 0.103389 Val loss= 0.453678 Training acc= 0.728500 Val acc= 0.727840\n",
            "Epoch 2332: Training loss= 0.103378 Val loss= 0.453567 Training acc= 0.728515 Val acc= 0.727840\n",
            "Epoch 2333: Training loss= 0.103367 Val loss= 0.453457 Training acc= 0.728515 Val acc= 0.727845\n",
            "Epoch 2334: Training loss= 0.103356 Val loss= 0.453347 Training acc= 0.728545 Val acc= 0.727865\n",
            "Epoch 2335: Training loss= 0.103345 Val loss= 0.453237 Training acc= 0.728580 Val acc= 0.727905\n",
            "Epoch 2336: Training loss= 0.103333 Val loss= 0.453127 Training acc= 0.728590 Val acc= 0.727910\n",
            "Epoch 2337: Training loss= 0.103322 Val loss= 0.453017 Training acc= 0.728605 Val acc= 0.727935\n",
            "Epoch 2338: Training loss= 0.103311 Val loss= 0.452907 Training acc= 0.728640 Val acc= 0.727970\n",
            "Epoch 2339: Training loss= 0.103300 Val loss= 0.452797 Training acc= 0.728665 Val acc= 0.727990\n",
            "Epoch 2340: Training loss= 0.103289 Val loss= 0.452688 Training acc= 0.728655 Val acc= 0.727990\n",
            "Epoch 2341: Training loss= 0.103278 Val loss= 0.452578 Training acc= 0.728695 Val acc= 0.728025\n",
            "Epoch 2342: Training loss= 0.103267 Val loss= 0.452468 Training acc= 0.728685 Val acc= 0.728030\n",
            "Epoch 2343: Training loss= 0.103256 Val loss= 0.452359 Training acc= 0.728690 Val acc= 0.728035\n",
            "Epoch 2344: Training loss= 0.103245 Val loss= 0.452249 Training acc= 0.728695 Val acc= 0.728045\n",
            "Epoch 2345: Training loss= 0.103234 Val loss= 0.452140 Training acc= 0.728710 Val acc= 0.728055\n",
            "Epoch 2346: Training loss= 0.103223 Val loss= 0.452030 Training acc= 0.728720 Val acc= 0.728065\n",
            "Epoch 2347: Training loss= 0.103212 Val loss= 0.451921 Training acc= 0.728720 Val acc= 0.728075\n",
            "Epoch 2348: Training loss= 0.103201 Val loss= 0.451812 Training acc= 0.728730 Val acc= 0.728090\n",
            "Epoch 2349: Training loss= 0.103190 Val loss= 0.451703 Training acc= 0.728785 Val acc= 0.728125\n",
            "Epoch 2350: Training loss= 0.103179 Val loss= 0.451594 Training acc= 0.728800 Val acc= 0.728150\n",
            "Epoch 2351: Training loss= 0.103168 Val loss= 0.451485 Training acc= 0.728825 Val acc= 0.728170\n",
            "Epoch 2352: Training loss= 0.103157 Val loss= 0.451376 Training acc= 0.728830 Val acc= 0.728195\n",
            "Epoch 2353: Training loss= 0.103146 Val loss= 0.451267 Training acc= 0.728830 Val acc= 0.728205\n",
            "Epoch 2354: Training loss= 0.103135 Val loss= 0.451158 Training acc= 0.728885 Val acc= 0.728260\n",
            "Epoch 2355: Training loss= 0.103124 Val loss= 0.451049 Training acc= 0.728905 Val acc= 0.728290\n",
            "Epoch 2356: Training loss= 0.103113 Val loss= 0.450940 Training acc= 0.728930 Val acc= 0.728310\n",
            "Epoch 2357: Training loss= 0.103103 Val loss= 0.450832 Training acc= 0.728940 Val acc= 0.728315\n",
            "Epoch 2358: Training loss= 0.103092 Val loss= 0.450723 Training acc= 0.728980 Val acc= 0.728350\n",
            "Epoch 2359: Training loss= 0.103081 Val loss= 0.450615 Training acc= 0.728990 Val acc= 0.728360\n",
            "Epoch 2360: Training loss= 0.103070 Val loss= 0.450506 Training acc= 0.728980 Val acc= 0.728355\n",
            "Epoch 2361: Training loss= 0.103059 Val loss= 0.450398 Training acc= 0.728985 Val acc= 0.728385\n",
            "Epoch 2362: Training loss= 0.103048 Val loss= 0.450289 Training acc= 0.728995 Val acc= 0.728385\n",
            "Epoch 2363: Training loss= 0.103037 Val loss= 0.450181 Training acc= 0.729000 Val acc= 0.728415\n",
            "Epoch 2364: Training loss= 0.103026 Val loss= 0.450073 Training acc= 0.729045 Val acc= 0.728455\n",
            "Epoch 2365: Training loss= 0.103016 Val loss= 0.449965 Training acc= 0.729070 Val acc= 0.728475\n",
            "Epoch 2366: Training loss= 0.103005 Val loss= 0.449857 Training acc= 0.729100 Val acc= 0.728505\n",
            "Epoch 2367: Training loss= 0.102994 Val loss= 0.449749 Training acc= 0.729120 Val acc= 0.728515\n",
            "Epoch 2368: Training loss= 0.102983 Val loss= 0.449641 Training acc= 0.729115 Val acc= 0.728505\n",
            "Epoch 2369: Training loss= 0.102972 Val loss= 0.449533 Training acc= 0.729120 Val acc= 0.728505\n",
            "Epoch 2370: Training loss= 0.102961 Val loss= 0.449425 Training acc= 0.729135 Val acc= 0.728520\n",
            "Epoch 2371: Training loss= 0.102951 Val loss= 0.449317 Training acc= 0.729135 Val acc= 0.728525\n",
            "Epoch 2372: Training loss= 0.102940 Val loss= 0.449210 Training acc= 0.729150 Val acc= 0.728540\n",
            "Epoch 2373: Training loss= 0.102929 Val loss= 0.449102 Training acc= 0.729165 Val acc= 0.728550\n",
            "Epoch 2374: Training loss= 0.102918 Val loss= 0.448994 Training acc= 0.729180 Val acc= 0.728550\n",
            "Epoch 2375: Training loss= 0.102908 Val loss= 0.448887 Training acc= 0.729210 Val acc= 0.728565\n",
            "Epoch 2376: Training loss= 0.102897 Val loss= 0.448779 Training acc= 0.729210 Val acc= 0.728575\n",
            "Epoch 2377: Training loss= 0.102886 Val loss= 0.448672 Training acc= 0.729235 Val acc= 0.728605\n",
            "Epoch 2378: Training loss= 0.102875 Val loss= 0.448565 Training acc= 0.729260 Val acc= 0.728630\n",
            "Epoch 2379: Training loss= 0.102865 Val loss= 0.448457 Training acc= 0.729265 Val acc= 0.728645\n",
            "Epoch 2380: Training loss= 0.102854 Val loss= 0.448350 Training acc= 0.729270 Val acc= 0.728640\n",
            "Epoch 2381: Training loss= 0.102843 Val loss= 0.448243 Training acc= 0.729290 Val acc= 0.728650\n",
            "Epoch 2382: Training loss= 0.102832 Val loss= 0.448136 Training acc= 0.729320 Val acc= 0.728690\n",
            "Epoch 2383: Training loss= 0.102822 Val loss= 0.448029 Training acc= 0.729310 Val acc= 0.728695\n",
            "Epoch 2384: Training loss= 0.102811 Val loss= 0.447922 Training acc= 0.729305 Val acc= 0.728700\n",
            "Epoch 2385: Training loss= 0.102800 Val loss= 0.447815 Training acc= 0.729295 Val acc= 0.728710\n",
            "Epoch 2386: Training loss= 0.102790 Val loss= 0.447708 Training acc= 0.729345 Val acc= 0.728745\n",
            "Epoch 2387: Training loss= 0.102779 Val loss= 0.447602 Training acc= 0.729355 Val acc= 0.728745\n",
            "Epoch 2388: Training loss= 0.102768 Val loss= 0.447495 Training acc= 0.729375 Val acc= 0.728755\n",
            "Epoch 2389: Training loss= 0.102758 Val loss= 0.447388 Training acc= 0.729380 Val acc= 0.728745\n",
            "Epoch 2390: Training loss= 0.102747 Val loss= 0.447282 Training acc= 0.729410 Val acc= 0.728775\n",
            "Epoch 2391: Training loss= 0.102736 Val loss= 0.447175 Training acc= 0.729420 Val acc= 0.728785\n",
            "Epoch 2392: Training loss= 0.102726 Val loss= 0.447069 Training acc= 0.729415 Val acc= 0.728780\n",
            "Epoch 2393: Training loss= 0.102715 Val loss= 0.446962 Training acc= 0.729445 Val acc= 0.728785\n",
            "Epoch 2394: Training loss= 0.102705 Val loss= 0.446856 Training acc= 0.729475 Val acc= 0.728790\n",
            "Epoch 2395: Training loss= 0.102694 Val loss= 0.446750 Training acc= 0.729480 Val acc= 0.728795\n",
            "Epoch 2396: Training loss= 0.102683 Val loss= 0.446644 Training acc= 0.729505 Val acc= 0.728840\n",
            "Epoch 2397: Training loss= 0.102673 Val loss= 0.446538 Training acc= 0.729525 Val acc= 0.728840\n",
            "Epoch 2398: Training loss= 0.102662 Val loss= 0.446431 Training acc= 0.729530 Val acc= 0.728835\n",
            "Epoch 2399: Training loss= 0.102652 Val loss= 0.446325 Training acc= 0.729550 Val acc= 0.728860\n",
            "Epoch 2400: Training loss= 0.102641 Val loss= 0.446220 Training acc= 0.729545 Val acc= 0.728875\n",
            "Epoch 2401: Training loss= 0.102631 Val loss= 0.446114 Training acc= 0.729540 Val acc= 0.728880\n",
            "Epoch 2402: Training loss= 0.102620 Val loss= 0.446008 Training acc= 0.729555 Val acc= 0.728885\n",
            "Epoch 2403: Training loss= 0.102609 Val loss= 0.445902 Training acc= 0.729575 Val acc= 0.728900\n",
            "Epoch 2404: Training loss= 0.102599 Val loss= 0.445796 Training acc= 0.729600 Val acc= 0.728915\n",
            "Epoch 2405: Training loss= 0.102588 Val loss= 0.445691 Training acc= 0.729600 Val acc= 0.728925\n",
            "Epoch 2406: Training loss= 0.102578 Val loss= 0.445585 Training acc= 0.729625 Val acc= 0.728950\n",
            "Epoch 2407: Training loss= 0.102567 Val loss= 0.445480 Training acc= 0.729640 Val acc= 0.728970\n",
            "Epoch 2408: Training loss= 0.102557 Val loss= 0.445374 Training acc= 0.729665 Val acc= 0.728995\n",
            "Epoch 2409: Training loss= 0.102546 Val loss= 0.445269 Training acc= 0.729670 Val acc= 0.728995\n",
            "Epoch 2410: Training loss= 0.102536 Val loss= 0.445163 Training acc= 0.729695 Val acc= 0.729010\n",
            "Epoch 2411: Training loss= 0.102525 Val loss= 0.445058 Training acc= 0.729725 Val acc= 0.729045\n",
            "Epoch 2412: Training loss= 0.102515 Val loss= 0.444953 Training acc= 0.729730 Val acc= 0.729070\n",
            "Epoch 2413: Training loss= 0.102504 Val loss= 0.444848 Training acc= 0.729760 Val acc= 0.729105\n",
            "Epoch 2414: Training loss= 0.102494 Val loss= 0.444743 Training acc= 0.729770 Val acc= 0.729115\n",
            "Epoch 2415: Training loss= 0.102484 Val loss= 0.444638 Training acc= 0.729770 Val acc= 0.729140\n",
            "Epoch 2416: Training loss= 0.102473 Val loss= 0.444533 Training acc= 0.729790 Val acc= 0.729155\n",
            "Epoch 2417: Training loss= 0.102463 Val loss= 0.444428 Training acc= 0.729815 Val acc= 0.729170\n",
            "Epoch 2418: Training loss= 0.102452 Val loss= 0.444323 Training acc= 0.729835 Val acc= 0.729185\n",
            "Epoch 2419: Training loss= 0.102442 Val loss= 0.444218 Training acc= 0.729850 Val acc= 0.729205\n",
            "Epoch 2420: Training loss= 0.102431 Val loss= 0.444113 Training acc= 0.729835 Val acc= 0.729190\n",
            "Epoch 2421: Training loss= 0.102421 Val loss= 0.444009 Training acc= 0.729875 Val acc= 0.729230\n",
            "Epoch 2422: Training loss= 0.102411 Val loss= 0.443904 Training acc= 0.729905 Val acc= 0.729265\n",
            "Epoch 2423: Training loss= 0.102400 Val loss= 0.443800 Training acc= 0.729920 Val acc= 0.729295\n",
            "Epoch 2424: Training loss= 0.102390 Val loss= 0.443695 Training acc= 0.729915 Val acc= 0.729320\n",
            "Epoch 2425: Training loss= 0.102380 Val loss= 0.443591 Training acc= 0.729940 Val acc= 0.729330\n",
            "Epoch 2426: Training loss= 0.102369 Val loss= 0.443486 Training acc= 0.729955 Val acc= 0.729335\n",
            "Epoch 2427: Training loss= 0.102359 Val loss= 0.443382 Training acc= 0.729955 Val acc= 0.729330\n",
            "Epoch 2428: Training loss= 0.102349 Val loss= 0.443278 Training acc= 0.729975 Val acc= 0.729350\n",
            "Epoch 2429: Training loss= 0.102338 Val loss= 0.443174 Training acc= 0.729970 Val acc= 0.729330\n",
            "Epoch 2430: Training loss= 0.102328 Val loss= 0.443069 Training acc= 0.729975 Val acc= 0.729350\n",
            "Epoch 2431: Training loss= 0.102318 Val loss= 0.442965 Training acc= 0.729975 Val acc= 0.729360\n",
            "Epoch 2432: Training loss= 0.102307 Val loss= 0.442861 Training acc= 0.729990 Val acc= 0.729375\n",
            "Epoch 2433: Training loss= 0.102297 Val loss= 0.442757 Training acc= 0.730010 Val acc= 0.729400\n",
            "Epoch 2434: Training loss= 0.102287 Val loss= 0.442653 Training acc= 0.730030 Val acc= 0.729445\n",
            "Epoch 2435: Training loss= 0.102276 Val loss= 0.442550 Training acc= 0.730040 Val acc= 0.729465\n",
            "Epoch 2436: Training loss= 0.102266 Val loss= 0.442446 Training acc= 0.730060 Val acc= 0.729480\n",
            "Epoch 2437: Training loss= 0.102256 Val loss= 0.442342 Training acc= 0.730070 Val acc= 0.729475\n",
            "Epoch 2438: Training loss= 0.102246 Val loss= 0.442238 Training acc= 0.730080 Val acc= 0.729485\n",
            "Epoch 2439: Training loss= 0.102235 Val loss= 0.442135 Training acc= 0.730080 Val acc= 0.729500\n",
            "Epoch 2440: Training loss= 0.102225 Val loss= 0.442031 Training acc= 0.730110 Val acc= 0.729530\n",
            "Epoch 2441: Training loss= 0.102215 Val loss= 0.441928 Training acc= 0.730105 Val acc= 0.729545\n",
            "Epoch 2442: Training loss= 0.102205 Val loss= 0.441824 Training acc= 0.730095 Val acc= 0.729535\n",
            "Epoch 2443: Training loss= 0.102194 Val loss= 0.441721 Training acc= 0.730125 Val acc= 0.729570\n",
            "Epoch 2444: Training loss= 0.102184 Val loss= 0.441618 Training acc= 0.730140 Val acc= 0.729595\n",
            "Epoch 2445: Training loss= 0.102174 Val loss= 0.441515 Training acc= 0.730160 Val acc= 0.729615\n",
            "Epoch 2446: Training loss= 0.102164 Val loss= 0.441411 Training acc= 0.730180 Val acc= 0.729630\n",
            "Epoch 2447: Training loss= 0.102153 Val loss= 0.441308 Training acc= 0.730205 Val acc= 0.729655\n",
            "Epoch 2448: Training loss= 0.102143 Val loss= 0.441205 Training acc= 0.730225 Val acc= 0.729695\n",
            "Epoch 2449: Training loss= 0.102133 Val loss= 0.441102 Training acc= 0.730245 Val acc= 0.729725\n",
            "Epoch 2450: Training loss= 0.102123 Val loss= 0.440999 Training acc= 0.730260 Val acc= 0.729740\n",
            "Epoch 2451: Training loss= 0.102113 Val loss= 0.440896 Training acc= 0.730280 Val acc= 0.729755\n",
            "Epoch 2452: Training loss= 0.102103 Val loss= 0.440794 Training acc= 0.730305 Val acc= 0.729790\n",
            "Epoch 2453: Training loss= 0.102092 Val loss= 0.440691 Training acc= 0.730305 Val acc= 0.729790\n",
            "Epoch 2454: Training loss= 0.102082 Val loss= 0.440588 Training acc= 0.730310 Val acc= 0.729800\n",
            "Epoch 2455: Training loss= 0.102072 Val loss= 0.440485 Training acc= 0.730310 Val acc= 0.729810\n",
            "Epoch 2456: Training loss= 0.102062 Val loss= 0.440383 Training acc= 0.730315 Val acc= 0.729815\n",
            "Epoch 2457: Training loss= 0.102052 Val loss= 0.440280 Training acc= 0.730335 Val acc= 0.729830\n",
            "Epoch 2458: Training loss= 0.102042 Val loss= 0.440178 Training acc= 0.730340 Val acc= 0.729855\n",
            "Epoch 2459: Training loss= 0.102032 Val loss= 0.440075 Training acc= 0.730350 Val acc= 0.729880\n",
            "Epoch 2460: Training loss= 0.102022 Val loss= 0.439973 Training acc= 0.730365 Val acc= 0.729895\n",
            "Epoch 2461: Training loss= 0.102011 Val loss= 0.439871 Training acc= 0.730385 Val acc= 0.729920\n",
            "Epoch 2462: Training loss= 0.102001 Val loss= 0.439769 Training acc= 0.730400 Val acc= 0.729945\n",
            "Epoch 2463: Training loss= 0.101991 Val loss= 0.439666 Training acc= 0.730405 Val acc= 0.729955\n",
            "Epoch 2464: Training loss= 0.101981 Val loss= 0.439564 Training acc= 0.730415 Val acc= 0.729950\n",
            "Epoch 2465: Training loss= 0.101971 Val loss= 0.439462 Training acc= 0.730425 Val acc= 0.729975\n",
            "Epoch 2466: Training loss= 0.101961 Val loss= 0.439360 Training acc= 0.730445 Val acc= 0.729980\n",
            "Epoch 2467: Training loss= 0.101951 Val loss= 0.439258 Training acc= 0.730470 Val acc= 0.730000\n",
            "Epoch 2468: Training loss= 0.101941 Val loss= 0.439156 Training acc= 0.730490 Val acc= 0.730005\n",
            "Epoch 2469: Training loss= 0.101931 Val loss= 0.439055 Training acc= 0.730490 Val acc= 0.730025\n",
            "Epoch 2470: Training loss= 0.101921 Val loss= 0.438953 Training acc= 0.730505 Val acc= 0.730045\n",
            "Epoch 2471: Training loss= 0.101911 Val loss= 0.438851 Training acc= 0.730530 Val acc= 0.730065\n",
            "Epoch 2472: Training loss= 0.101901 Val loss= 0.438749 Training acc= 0.730550 Val acc= 0.730075\n",
            "Epoch 2473: Training loss= 0.101891 Val loss= 0.438648 Training acc= 0.730585 Val acc= 0.730105\n",
            "Epoch 2474: Training loss= 0.101881 Val loss= 0.438546 Training acc= 0.730615 Val acc= 0.730125\n",
            "Epoch 2475: Training loss= 0.101871 Val loss= 0.438445 Training acc= 0.730620 Val acc= 0.730160\n",
            "Epoch 2476: Training loss= 0.101861 Val loss= 0.438343 Training acc= 0.730645 Val acc= 0.730195\n",
            "Epoch 2477: Training loss= 0.101851 Val loss= 0.438242 Training acc= 0.730665 Val acc= 0.730210\n",
            "Epoch 2478: Training loss= 0.101841 Val loss= 0.438141 Training acc= 0.730680 Val acc= 0.730220\n",
            "Epoch 2479: Training loss= 0.101831 Val loss= 0.438039 Training acc= 0.730715 Val acc= 0.730245\n",
            "Epoch 2480: Training loss= 0.101821 Val loss= 0.437938 Training acc= 0.730730 Val acc= 0.730260\n",
            "Epoch 2481: Training loss= 0.101811 Val loss= 0.437837 Training acc= 0.730745 Val acc= 0.730270\n",
            "Epoch 2482: Training loss= 0.101801 Val loss= 0.437736 Training acc= 0.730750 Val acc= 0.730280\n",
            "Epoch 2483: Training loss= 0.101791 Val loss= 0.437635 Training acc= 0.730760 Val acc= 0.730275\n",
            "Epoch 2484: Training loss= 0.101781 Val loss= 0.437534 Training acc= 0.730765 Val acc= 0.730270\n",
            "Epoch 2485: Training loss= 0.101771 Val loss= 0.437433 Training acc= 0.730785 Val acc= 0.730280\n",
            "Epoch 2486: Training loss= 0.101761 Val loss= 0.437332 Training acc= 0.730785 Val acc= 0.730265\n",
            "Epoch 2487: Training loss= 0.101752 Val loss= 0.437231 Training acc= 0.730790 Val acc= 0.730250\n",
            "Epoch 2488: Training loss= 0.101742 Val loss= 0.437131 Training acc= 0.730800 Val acc= 0.730270\n",
            "Epoch 2489: Training loss= 0.101732 Val loss= 0.437030 Training acc= 0.730805 Val acc= 0.730275\n",
            "Epoch 2490: Training loss= 0.101722 Val loss= 0.436929 Training acc= 0.730825 Val acc= 0.730280\n",
            "Epoch 2491: Training loss= 0.101712 Val loss= 0.436829 Training acc= 0.730845 Val acc= 0.730295\n",
            "Epoch 2492: Training loss= 0.101702 Val loss= 0.436728 Training acc= 0.730870 Val acc= 0.730325\n",
            "Epoch 2493: Training loss= 0.101692 Val loss= 0.436628 Training acc= 0.730890 Val acc= 0.730335\n",
            "Epoch 2494: Training loss= 0.101682 Val loss= 0.436527 Training acc= 0.730910 Val acc= 0.730355\n",
            "Epoch 2495: Training loss= 0.101673 Val loss= 0.436427 Training acc= 0.730925 Val acc= 0.730365\n",
            "Epoch 2496: Training loss= 0.101663 Val loss= 0.436327 Training acc= 0.730935 Val acc= 0.730395\n",
            "Epoch 2497: Training loss= 0.101653 Val loss= 0.436226 Training acc= 0.730935 Val acc= 0.730405\n",
            "Epoch 2498: Training loss= 0.101643 Val loss= 0.436126 Training acc= 0.730940 Val acc= 0.730425\n",
            "Epoch 2499: Training loss= 0.101633 Val loss= 0.436026 Training acc= 0.730960 Val acc= 0.730410\n",
            "Epoch 2500: Training loss= 0.101623 Val loss= 0.435926 Training acc= 0.730985 Val acc= 0.730440\n",
            "Epoch 2501: Training loss= 0.101614 Val loss= 0.435826 Training acc= 0.731015 Val acc= 0.730480\n",
            "Epoch 2502: Training loss= 0.101604 Val loss= 0.435726 Training acc= 0.731010 Val acc= 0.730480\n",
            "Epoch 2503: Training loss= 0.101594 Val loss= 0.435626 Training acc= 0.731020 Val acc= 0.730475\n",
            "Epoch 2504: Training loss= 0.101584 Val loss= 0.435526 Training acc= 0.731020 Val acc= 0.730490\n",
            "Epoch 2505: Training loss= 0.101575 Val loss= 0.435427 Training acc= 0.731025 Val acc= 0.730495\n",
            "Epoch 2506: Training loss= 0.101565 Val loss= 0.435327 Training acc= 0.731065 Val acc= 0.730535\n",
            "Epoch 2507: Training loss= 0.101555 Val loss= 0.435227 Training acc= 0.731060 Val acc= 0.730540\n",
            "Epoch 2508: Training loss= 0.101545 Val loss= 0.435128 Training acc= 0.731095 Val acc= 0.730555\n",
            "Epoch 2509: Training loss= 0.101535 Val loss= 0.435028 Training acc= 0.731105 Val acc= 0.730560\n",
            "Epoch 2510: Training loss= 0.101526 Val loss= 0.434928 Training acc= 0.731120 Val acc= 0.730570\n",
            "Epoch 2511: Training loss= 0.101516 Val loss= 0.434829 Training acc= 0.731135 Val acc= 0.730580\n",
            "Epoch 2512: Training loss= 0.101506 Val loss= 0.434730 Training acc= 0.731130 Val acc= 0.730580\n",
            "Epoch 2513: Training loss= 0.101497 Val loss= 0.434630 Training acc= 0.731140 Val acc= 0.730580\n",
            "Epoch 2514: Training loss= 0.101487 Val loss= 0.434531 Training acc= 0.731160 Val acc= 0.730610\n",
            "Epoch 2515: Training loss= 0.101477 Val loss= 0.434432 Training acc= 0.731180 Val acc= 0.730625\n",
            "Epoch 2516: Training loss= 0.101467 Val loss= 0.434333 Training acc= 0.731195 Val acc= 0.730640\n",
            "Epoch 2517: Training loss= 0.101458 Val loss= 0.434233 Training acc= 0.731210 Val acc= 0.730645\n",
            "Epoch 2518: Training loss= 0.101448 Val loss= 0.434134 Training acc= 0.731240 Val acc= 0.730655\n",
            "Epoch 2519: Training loss= 0.101438 Val loss= 0.434035 Training acc= 0.731255 Val acc= 0.730680\n",
            "Epoch 2520: Training loss= 0.101429 Val loss= 0.433936 Training acc= 0.731265 Val acc= 0.730720\n",
            "Epoch 2521: Training loss= 0.101419 Val loss= 0.433838 Training acc= 0.731250 Val acc= 0.730720\n",
            "Epoch 2522: Training loss= 0.101409 Val loss= 0.433739 Training acc= 0.731270 Val acc= 0.730740\n",
            "Epoch 2523: Training loss= 0.101400 Val loss= 0.433640 Training acc= 0.731285 Val acc= 0.730740\n",
            "Epoch 2524: Training loss= 0.101390 Val loss= 0.433541 Training acc= 0.731295 Val acc= 0.730760\n",
            "Epoch 2525: Training loss= 0.101380 Val loss= 0.433443 Training acc= 0.731305 Val acc= 0.730765\n",
            "Epoch 2526: Training loss= 0.101371 Val loss= 0.433344 Training acc= 0.731315 Val acc= 0.730780\n",
            "Epoch 2527: Training loss= 0.101361 Val loss= 0.433245 Training acc= 0.731325 Val acc= 0.730800\n",
            "Epoch 2528: Training loss= 0.101352 Val loss= 0.433147 Training acc= 0.731350 Val acc= 0.730800\n",
            "Epoch 2529: Training loss= 0.101342 Val loss= 0.433048 Training acc= 0.731365 Val acc= 0.730820\n",
            "Epoch 2530: Training loss= 0.101332 Val loss= 0.432950 Training acc= 0.731385 Val acc= 0.730835\n",
            "Epoch 2531: Training loss= 0.101323 Val loss= 0.432852 Training acc= 0.731385 Val acc= 0.730835\n",
            "Epoch 2532: Training loss= 0.101313 Val loss= 0.432753 Training acc= 0.731410 Val acc= 0.730860\n",
            "Epoch 2533: Training loss= 0.101304 Val loss= 0.432655 Training acc= 0.731405 Val acc= 0.730885\n",
            "Epoch 2534: Training loss= 0.101294 Val loss= 0.432557 Training acc= 0.731420 Val acc= 0.730890\n",
            "Epoch 2535: Training loss= 0.101284 Val loss= 0.432459 Training acc= 0.731440 Val acc= 0.730915\n",
            "Epoch 2536: Training loss= 0.101275 Val loss= 0.432361 Training acc= 0.731455 Val acc= 0.730920\n",
            "Epoch 2537: Training loss= 0.101265 Val loss= 0.432263 Training acc= 0.731475 Val acc= 0.730935\n",
            "Epoch 2538: Training loss= 0.101256 Val loss= 0.432165 Training acc= 0.731485 Val acc= 0.730940\n",
            "Epoch 2539: Training loss= 0.101246 Val loss= 0.432067 Training acc= 0.731490 Val acc= 0.730940\n",
            "Epoch 2540: Training loss= 0.101237 Val loss= 0.431969 Training acc= 0.731490 Val acc= 0.730955\n",
            "Epoch 2541: Training loss= 0.101227 Val loss= 0.431871 Training acc= 0.731495 Val acc= 0.730960\n",
            "Epoch 2542: Training loss= 0.101218 Val loss= 0.431773 Training acc= 0.731505 Val acc= 0.730975\n",
            "Epoch 2543: Training loss= 0.101208 Val loss= 0.431676 Training acc= 0.731540 Val acc= 0.731015\n",
            "Epoch 2544: Training loss= 0.101199 Val loss= 0.431578 Training acc= 0.731555 Val acc= 0.731045\n",
            "Epoch 2545: Training loss= 0.101189 Val loss= 0.431480 Training acc= 0.731595 Val acc= 0.731075\n",
            "Epoch 2546: Training loss= 0.101180 Val loss= 0.431383 Training acc= 0.731615 Val acc= 0.731090\n",
            "Epoch 2547: Training loss= 0.101170 Val loss= 0.431285 Training acc= 0.731615 Val acc= 0.731090\n",
            "Epoch 2548: Training loss= 0.101161 Val loss= 0.431188 Training acc= 0.731605 Val acc= 0.731075\n",
            "Epoch 2549: Training loss= 0.101151 Val loss= 0.431091 Training acc= 0.731630 Val acc= 0.731075\n",
            "Epoch 2550: Training loss= 0.101142 Val loss= 0.430993 Training acc= 0.731655 Val acc= 0.731090\n",
            "Epoch 2551: Training loss= 0.101132 Val loss= 0.430896 Training acc= 0.731670 Val acc= 0.731105\n",
            "Epoch 2552: Training loss= 0.101123 Val loss= 0.430799 Training acc= 0.731710 Val acc= 0.731145\n",
            "Epoch 2553: Training loss= 0.101113 Val loss= 0.430702 Training acc= 0.731735 Val acc= 0.731175\n",
            "Epoch 2554: Training loss= 0.101104 Val loss= 0.430605 Training acc= 0.731735 Val acc= 0.731185\n",
            "Epoch 2555: Training loss= 0.101094 Val loss= 0.430508 Training acc= 0.731745 Val acc= 0.731195\n",
            "Epoch 2556: Training loss= 0.101085 Val loss= 0.430411 Training acc= 0.731750 Val acc= 0.731200\n",
            "Epoch 2557: Training loss= 0.101076 Val loss= 0.430314 Training acc= 0.731775 Val acc= 0.731230\n",
            "Epoch 2558: Training loss= 0.101066 Val loss= 0.430217 Training acc= 0.731770 Val acc= 0.731235\n",
            "Epoch 2559: Training loss= 0.101057 Val loss= 0.430120 Training acc= 0.731775 Val acc= 0.731265\n",
            "Epoch 2560: Training loss= 0.101047 Val loss= 0.430023 Training acc= 0.731805 Val acc= 0.731295\n",
            "Epoch 2561: Training loss= 0.101038 Val loss= 0.429926 Training acc= 0.731810 Val acc= 0.731310\n",
            "Epoch 2562: Training loss= 0.101029 Val loss= 0.429830 Training acc= 0.731830 Val acc= 0.731340\n",
            "Epoch 2563: Training loss= 0.101019 Val loss= 0.429733 Training acc= 0.731855 Val acc= 0.731365\n",
            "Epoch 2564: Training loss= 0.101010 Val loss= 0.429637 Training acc= 0.731870 Val acc= 0.731375\n",
            "Epoch 2565: Training loss= 0.101000 Val loss= 0.429540 Training acc= 0.731880 Val acc= 0.731385\n",
            "Epoch 2566: Training loss= 0.100991 Val loss= 0.429444 Training acc= 0.731870 Val acc= 0.731385\n",
            "Epoch 2567: Training loss= 0.100982 Val loss= 0.429347 Training acc= 0.731895 Val acc= 0.731410\n",
            "Epoch 2568: Training loss= 0.100972 Val loss= 0.429251 Training acc= 0.731915 Val acc= 0.731430\n",
            "Epoch 2569: Training loss= 0.100963 Val loss= 0.429155 Training acc= 0.731930 Val acc= 0.731435\n",
            "Epoch 2570: Training loss= 0.100954 Val loss= 0.429058 Training acc= 0.731945 Val acc= 0.731445\n",
            "Epoch 2571: Training loss= 0.100944 Val loss= 0.428962 Training acc= 0.731935 Val acc= 0.731445\n",
            "Epoch 2572: Training loss= 0.100935 Val loss= 0.428866 Training acc= 0.731965 Val acc= 0.731485\n",
            "Epoch 2573: Training loss= 0.100926 Val loss= 0.428770 Training acc= 0.731970 Val acc= 0.731490\n",
            "Epoch 2574: Training loss= 0.100916 Val loss= 0.428674 Training acc= 0.731995 Val acc= 0.731520\n",
            "Epoch 2575: Training loss= 0.100907 Val loss= 0.428578 Training acc= 0.732010 Val acc= 0.731530\n",
            "Epoch 2576: Training loss= 0.100898 Val loss= 0.428482 Training acc= 0.732010 Val acc= 0.731535\n",
            "Epoch 2577: Training loss= 0.100888 Val loss= 0.428386 Training acc= 0.732045 Val acc= 0.731575\n",
            "Epoch 2578: Training loss= 0.100879 Val loss= 0.428290 Training acc= 0.732055 Val acc= 0.731590\n",
            "Epoch 2579: Training loss= 0.100870 Val loss= 0.428194 Training acc= 0.732065 Val acc= 0.731585\n",
            "Epoch 2580: Training loss= 0.100861 Val loss= 0.428099 Training acc= 0.732080 Val acc= 0.731595\n",
            "Epoch 2581: Training loss= 0.100851 Val loss= 0.428003 Training acc= 0.732085 Val acc= 0.731615\n",
            "Epoch 2582: Training loss= 0.100842 Val loss= 0.427907 Training acc= 0.732105 Val acc= 0.731630\n",
            "Epoch 2583: Training loss= 0.100833 Val loss= 0.427812 Training acc= 0.732130 Val acc= 0.731660\n",
            "Epoch 2584: Training loss= 0.100824 Val loss= 0.427716 Training acc= 0.732130 Val acc= 0.731675\n",
            "Epoch 2585: Training loss= 0.100814 Val loss= 0.427621 Training acc= 0.732155 Val acc= 0.731680\n",
            "Epoch 2586: Training loss= 0.100805 Val loss= 0.427525 Training acc= 0.732175 Val acc= 0.731705\n",
            "Epoch 2587: Training loss= 0.100796 Val loss= 0.427430 Training acc= 0.732175 Val acc= 0.731725\n",
            "Epoch 2588: Training loss= 0.100787 Val loss= 0.427335 Training acc= 0.732210 Val acc= 0.731765\n",
            "Epoch 2589: Training loss= 0.100777 Val loss= 0.427240 Training acc= 0.732240 Val acc= 0.731780\n",
            "Epoch 2590: Training loss= 0.100768 Val loss= 0.427144 Training acc= 0.732255 Val acc= 0.731800\n",
            "Epoch 2591: Training loss= 0.100759 Val loss= 0.427049 Training acc= 0.732265 Val acc= 0.731820\n",
            "Epoch 2592: Training loss= 0.100750 Val loss= 0.426954 Training acc= 0.732275 Val acc= 0.731820\n",
            "Epoch 2593: Training loss= 0.100741 Val loss= 0.426859 Training acc= 0.732310 Val acc= 0.731840\n",
            "Epoch 2594: Training loss= 0.100731 Val loss= 0.426764 Training acc= 0.732330 Val acc= 0.731855\n",
            "Epoch 2595: Training loss= 0.100722 Val loss= 0.426669 Training acc= 0.732325 Val acc= 0.731845\n",
            "Epoch 2596: Training loss= 0.100713 Val loss= 0.426574 Training acc= 0.732340 Val acc= 0.731840\n",
            "Epoch 2597: Training loss= 0.100704 Val loss= 0.426479 Training acc= 0.732340 Val acc= 0.731850\n",
            "Epoch 2598: Training loss= 0.100695 Val loss= 0.426385 Training acc= 0.732335 Val acc= 0.731850\n",
            "Epoch 2599: Training loss= 0.100686 Val loss= 0.426290 Training acc= 0.732345 Val acc= 0.731845\n",
            "Epoch 2600: Training loss= 0.100677 Val loss= 0.426195 Training acc= 0.732340 Val acc= 0.731840\n",
            "Epoch 2601: Training loss= 0.100667 Val loss= 0.426101 Training acc= 0.732355 Val acc= 0.731860\n",
            "Epoch 2602: Training loss= 0.100658 Val loss= 0.426006 Training acc= 0.732370 Val acc= 0.731880\n",
            "Epoch 2603: Training loss= 0.100649 Val loss= 0.425911 Training acc= 0.732385 Val acc= 0.731885\n",
            "Epoch 2604: Training loss= 0.100640 Val loss= 0.425817 Training acc= 0.732400 Val acc= 0.731900\n",
            "Epoch 2605: Training loss= 0.100631 Val loss= 0.425723 Training acc= 0.732425 Val acc= 0.731925\n",
            "Epoch 2606: Training loss= 0.100622 Val loss= 0.425628 Training acc= 0.732480 Val acc= 0.731950\n",
            "Epoch 2607: Training loss= 0.100613 Val loss= 0.425534 Training acc= 0.732505 Val acc= 0.731960\n",
            "Epoch 2608: Training loss= 0.100604 Val loss= 0.425440 Training acc= 0.732515 Val acc= 0.731985\n",
            "Epoch 2609: Training loss= 0.100595 Val loss= 0.425345 Training acc= 0.732505 Val acc= 0.731980\n",
            "Epoch 2610: Training loss= 0.100585 Val loss= 0.425251 Training acc= 0.732540 Val acc= 0.732005\n",
            "Epoch 2611: Training loss= 0.100576 Val loss= 0.425157 Training acc= 0.732545 Val acc= 0.732025\n",
            "Epoch 2612: Training loss= 0.100567 Val loss= 0.425063 Training acc= 0.732550 Val acc= 0.732035\n",
            "Epoch 2613: Training loss= 0.100558 Val loss= 0.424969 Training acc= 0.732570 Val acc= 0.732040\n",
            "Epoch 2614: Training loss= 0.100549 Val loss= 0.424875 Training acc= 0.732600 Val acc= 0.732065\n",
            "Epoch 2615: Training loss= 0.100540 Val loss= 0.424781 Training acc= 0.732615 Val acc= 0.732080\n",
            "Epoch 2616: Training loss= 0.100531 Val loss= 0.424687 Training acc= 0.732610 Val acc= 0.732080\n",
            "Epoch 2617: Training loss= 0.100522 Val loss= 0.424593 Training acc= 0.732625 Val acc= 0.732065\n",
            "Epoch 2618: Training loss= 0.100513 Val loss= 0.424500 Training acc= 0.732630 Val acc= 0.732075\n",
            "Epoch 2619: Training loss= 0.100504 Val loss= 0.424406 Training acc= 0.732625 Val acc= 0.732075\n",
            "Epoch 2620: Training loss= 0.100495 Val loss= 0.424312 Training acc= 0.732630 Val acc= 0.732075\n",
            "Epoch 2621: Training loss= 0.100486 Val loss= 0.424219 Training acc= 0.732650 Val acc= 0.732105\n",
            "Epoch 2622: Training loss= 0.100477 Val loss= 0.424125 Training acc= 0.732675 Val acc= 0.732130\n",
            "Epoch 2623: Training loss= 0.100468 Val loss= 0.424032 Training acc= 0.732675 Val acc= 0.732140\n",
            "Epoch 2624: Training loss= 0.100459 Val loss= 0.423938 Training acc= 0.732715 Val acc= 0.732170\n",
            "Epoch 2625: Training loss= 0.100450 Val loss= 0.423845 Training acc= 0.732740 Val acc= 0.732190\n",
            "Epoch 2626: Training loss= 0.100441 Val loss= 0.423751 Training acc= 0.732785 Val acc= 0.732230\n",
            "Epoch 2627: Training loss= 0.100432 Val loss= 0.423658 Training acc= 0.732810 Val acc= 0.732255\n",
            "Epoch 2628: Training loss= 0.100423 Val loss= 0.423565 Training acc= 0.732825 Val acc= 0.732265\n",
            "Epoch 2629: Training loss= 0.100414 Val loss= 0.423472 Training acc= 0.732850 Val acc= 0.732280\n",
            "Epoch 2630: Training loss= 0.100405 Val loss= 0.423379 Training acc= 0.732865 Val acc= 0.732295\n",
            "Epoch 2631: Training loss= 0.100396 Val loss= 0.423285 Training acc= 0.732870 Val acc= 0.732305\n",
            "Epoch 2632: Training loss= 0.100387 Val loss= 0.423192 Training acc= 0.732900 Val acc= 0.732305\n",
            "Epoch 2633: Training loss= 0.100378 Val loss= 0.423099 Training acc= 0.732930 Val acc= 0.732345\n",
            "Epoch 2634: Training loss= 0.100369 Val loss= 0.423006 Training acc= 0.732925 Val acc= 0.732345\n",
            "Epoch 2635: Training loss= 0.100360 Val loss= 0.422914 Training acc= 0.732940 Val acc= 0.732365\n",
            "Epoch 2636: Training loss= 0.100351 Val loss= 0.422821 Training acc= 0.732950 Val acc= 0.732360\n",
            "Epoch 2637: Training loss= 0.100343 Val loss= 0.422728 Training acc= 0.732950 Val acc= 0.732370\n",
            "Epoch 2638: Training loss= 0.100334 Val loss= 0.422635 Training acc= 0.732960 Val acc= 0.732375\n",
            "Epoch 2639: Training loss= 0.100325 Val loss= 0.422542 Training acc= 0.732975 Val acc= 0.732380\n",
            "Epoch 2640: Training loss= 0.100316 Val loss= 0.422450 Training acc= 0.732995 Val acc= 0.732395\n",
            "Epoch 2641: Training loss= 0.100307 Val loss= 0.422357 Training acc= 0.733015 Val acc= 0.732420\n",
            "Epoch 2642: Training loss= 0.100298 Val loss= 0.422265 Training acc= 0.733010 Val acc= 0.732430\n",
            "Epoch 2643: Training loss= 0.100289 Val loss= 0.422172 Training acc= 0.733035 Val acc= 0.732455\n",
            "Epoch 2644: Training loss= 0.100280 Val loss= 0.422080 Training acc= 0.733060 Val acc= 0.732465\n",
            "Epoch 2645: Training loss= 0.100271 Val loss= 0.421987 Training acc= 0.733075 Val acc= 0.732495\n",
            "Epoch 2646: Training loss= 0.100263 Val loss= 0.421895 Training acc= 0.733100 Val acc= 0.732510\n",
            "Epoch 2647: Training loss= 0.100254 Val loss= 0.421803 Training acc= 0.733110 Val acc= 0.732515\n",
            "Epoch 2648: Training loss= 0.100245 Val loss= 0.421710 Training acc= 0.733145 Val acc= 0.732550\n",
            "Epoch 2649: Training loss= 0.100236 Val loss= 0.421618 Training acc= 0.733150 Val acc= 0.732560\n",
            "Epoch 2650: Training loss= 0.100227 Val loss= 0.421526 Training acc= 0.733160 Val acc= 0.732560\n",
            "Epoch 2651: Training loss= 0.100218 Val loss= 0.421434 Training acc= 0.733160 Val acc= 0.732575\n",
            "Epoch 2652: Training loss= 0.100209 Val loss= 0.421342 Training acc= 0.733170 Val acc= 0.732590\n",
            "Epoch 2653: Training loss= 0.100201 Val loss= 0.421250 Training acc= 0.733175 Val acc= 0.732600\n",
            "Epoch 2654: Training loss= 0.100192 Val loss= 0.421158 Training acc= 0.733205 Val acc= 0.732630\n",
            "Epoch 2655: Training loss= 0.100183 Val loss= 0.421066 Training acc= 0.733200 Val acc= 0.732625\n",
            "Epoch 2656: Training loss= 0.100174 Val loss= 0.420974 Training acc= 0.733210 Val acc= 0.732630\n",
            "Epoch 2657: Training loss= 0.100165 Val loss= 0.420882 Training acc= 0.733230 Val acc= 0.732650\n",
            "Epoch 2658: Training loss= 0.100157 Val loss= 0.420791 Training acc= 0.733230 Val acc= 0.732665\n",
            "Epoch 2659: Training loss= 0.100148 Val loss= 0.420699 Training acc= 0.733240 Val acc= 0.732680\n",
            "Epoch 2660: Training loss= 0.100139 Val loss= 0.420607 Training acc= 0.733245 Val acc= 0.732690\n",
            "Epoch 2661: Training loss= 0.100130 Val loss= 0.420516 Training acc= 0.733255 Val acc= 0.732695\n",
            "Epoch 2662: Training loss= 0.100122 Val loss= 0.420424 Training acc= 0.733275 Val acc= 0.732730\n",
            "Epoch 2663: Training loss= 0.100113 Val loss= 0.420332 Training acc= 0.733290 Val acc= 0.732750\n",
            "Epoch 2664: Training loss= 0.100104 Val loss= 0.420241 Training acc= 0.733305 Val acc= 0.732775\n",
            "Epoch 2665: Training loss= 0.100095 Val loss= 0.420150 Training acc= 0.733325 Val acc= 0.732810\n",
            "Epoch 2666: Training loss= 0.100087 Val loss= 0.420058 Training acc= 0.733350 Val acc= 0.732830\n",
            "Epoch 2667: Training loss= 0.100078 Val loss= 0.419967 Training acc= 0.733355 Val acc= 0.732835\n",
            "Epoch 2668: Training loss= 0.100069 Val loss= 0.419876 Training acc= 0.733370 Val acc= 0.732855\n",
            "Epoch 2669: Training loss= 0.100060 Val loss= 0.419784 Training acc= 0.733395 Val acc= 0.732880\n",
            "Epoch 2670: Training loss= 0.100052 Val loss= 0.419693 Training acc= 0.733410 Val acc= 0.732890\n",
            "Epoch 2671: Training loss= 0.100043 Val loss= 0.419602 Training acc= 0.733430 Val acc= 0.732895\n",
            "Epoch 2672: Training loss= 0.100034 Val loss= 0.419511 Training acc= 0.733435 Val acc= 0.732905\n",
            "Epoch 2673: Training loss= 0.100025 Val loss= 0.419420 Training acc= 0.733445 Val acc= 0.732910\n",
            "Epoch 2674: Training loss= 0.100017 Val loss= 0.419329 Training acc= 0.733460 Val acc= 0.732915\n",
            "Epoch 2675: Training loss= 0.100008 Val loss= 0.419238 Training acc= 0.733495 Val acc= 0.732930\n",
            "Epoch 2676: Training loss= 0.099999 Val loss= 0.419147 Training acc= 0.733505 Val acc= 0.732940\n",
            "Epoch 2677: Training loss= 0.099991 Val loss= 0.419056 Training acc= 0.733515 Val acc= 0.732960\n",
            "Epoch 2678: Training loss= 0.099982 Val loss= 0.418966 Training acc= 0.733520 Val acc= 0.732970\n",
            "Epoch 2679: Training loss= 0.099973 Val loss= 0.418875 Training acc= 0.733550 Val acc= 0.733025\n",
            "Epoch 2680: Training loss= 0.099965 Val loss= 0.418784 Training acc= 0.733530 Val acc= 0.733020\n",
            "Epoch 2681: Training loss= 0.099956 Val loss= 0.418694 Training acc= 0.733540 Val acc= 0.733025\n",
            "Epoch 2682: Training loss= 0.099947 Val loss= 0.418603 Training acc= 0.733565 Val acc= 0.733050\n",
            "Epoch 2683: Training loss= 0.099939 Val loss= 0.418512 Training acc= 0.733600 Val acc= 0.733075\n",
            "Epoch 2684: Training loss= 0.099930 Val loss= 0.418422 Training acc= 0.733615 Val acc= 0.733090\n",
            "Epoch 2685: Training loss= 0.099922 Val loss= 0.418331 Training acc= 0.733630 Val acc= 0.733120\n",
            "Epoch 2686: Training loss= 0.099913 Val loss= 0.418241 Training acc= 0.733655 Val acc= 0.733150\n",
            "Epoch 2687: Training loss= 0.099904 Val loss= 0.418151 Training acc= 0.733660 Val acc= 0.733140\n",
            "Epoch 2688: Training loss= 0.099896 Val loss= 0.418060 Training acc= 0.733670 Val acc= 0.733155\n",
            "Epoch 2689: Training loss= 0.099887 Val loss= 0.417970 Training acc= 0.733680 Val acc= 0.733170\n",
            "Epoch 2690: Training loss= 0.099878 Val loss= 0.417880 Training acc= 0.733705 Val acc= 0.733170\n",
            "Epoch 2691: Training loss= 0.099870 Val loss= 0.417790 Training acc= 0.733720 Val acc= 0.733180\n",
            "Epoch 2692: Training loss= 0.099861 Val loss= 0.417700 Training acc= 0.733730 Val acc= 0.733185\n",
            "Epoch 2693: Training loss= 0.099853 Val loss= 0.417610 Training acc= 0.733730 Val acc= 0.733195\n",
            "Epoch 2694: Training loss= 0.099844 Val loss= 0.417520 Training acc= 0.733745 Val acc= 0.733195\n",
            "Epoch 2695: Training loss= 0.099835 Val loss= 0.417430 Training acc= 0.733740 Val acc= 0.733205\n",
            "Epoch 2696: Training loss= 0.099827 Val loss= 0.417340 Training acc= 0.733745 Val acc= 0.733210\n",
            "Epoch 2697: Training loss= 0.099818 Val loss= 0.417250 Training acc= 0.733755 Val acc= 0.733225\n",
            "Epoch 2698: Training loss= 0.099810 Val loss= 0.417160 Training acc= 0.733755 Val acc= 0.733210\n",
            "Epoch 2699: Training loss= 0.099801 Val loss= 0.417070 Training acc= 0.733775 Val acc= 0.733225\n",
            "Epoch 2700: Training loss= 0.099793 Val loss= 0.416980 Training acc= 0.733785 Val acc= 0.733225\n",
            "Epoch 2701: Training loss= 0.099784 Val loss= 0.416891 Training acc= 0.733815 Val acc= 0.733245\n",
            "Epoch 2702: Training loss= 0.099776 Val loss= 0.416801 Training acc= 0.733825 Val acc= 0.733250\n",
            "Epoch 2703: Training loss= 0.099767 Val loss= 0.416712 Training acc= 0.733835 Val acc= 0.733270\n",
            "Epoch 2704: Training loss= 0.099759 Val loss= 0.416622 Training acc= 0.733860 Val acc= 0.733285\n",
            "Epoch 2705: Training loss= 0.099750 Val loss= 0.416533 Training acc= 0.733860 Val acc= 0.733290\n",
            "Epoch 2706: Training loss= 0.099742 Val loss= 0.416443 Training acc= 0.733870 Val acc= 0.733295\n",
            "Epoch 2707: Training loss= 0.099733 Val loss= 0.416354 Training acc= 0.733895 Val acc= 0.733330\n",
            "Epoch 2708: Training loss= 0.099725 Val loss= 0.416264 Training acc= 0.733895 Val acc= 0.733325\n",
            "Epoch 2709: Training loss= 0.099716 Val loss= 0.416175 Training acc= 0.733930 Val acc= 0.733365\n",
            "Epoch 2710: Training loss= 0.099708 Val loss= 0.416086 Training acc= 0.733955 Val acc= 0.733390\n",
            "Epoch 2711: Training loss= 0.099699 Val loss= 0.415997 Training acc= 0.733970 Val acc= 0.733390\n",
            "Epoch 2712: Training loss= 0.099691 Val loss= 0.415907 Training acc= 0.733965 Val acc= 0.733385\n",
            "Epoch 2713: Training loss= 0.099682 Val loss= 0.415818 Training acc= 0.733980 Val acc= 0.733410\n",
            "Epoch 2714: Training loss= 0.099674 Val loss= 0.415729 Training acc= 0.733985 Val acc= 0.733430\n",
            "Epoch 2715: Training loss= 0.099665 Val loss= 0.415640 Training acc= 0.733985 Val acc= 0.733425\n",
            "Epoch 2716: Training loss= 0.099657 Val loss= 0.415551 Training acc= 0.733985 Val acc= 0.733435\n",
            "Epoch 2717: Training loss= 0.099648 Val loss= 0.415462 Training acc= 0.733985 Val acc= 0.733445\n",
            "Epoch 2718: Training loss= 0.099640 Val loss= 0.415373 Training acc= 0.733995 Val acc= 0.733450\n",
            "Epoch 2719: Training loss= 0.099631 Val loss= 0.415285 Training acc= 0.733985 Val acc= 0.733440\n",
            "Epoch 2720: Training loss= 0.099623 Val loss= 0.415196 Training acc= 0.733985 Val acc= 0.733460\n",
            "Epoch 2721: Training loss= 0.099614 Val loss= 0.415107 Training acc= 0.734000 Val acc= 0.733470\n",
            "Epoch 2722: Training loss= 0.099606 Val loss= 0.415018 Training acc= 0.734040 Val acc= 0.733500\n",
            "Epoch 2723: Training loss= 0.099598 Val loss= 0.414930 Training acc= 0.734040 Val acc= 0.733505\n",
            "Epoch 2724: Training loss= 0.099589 Val loss= 0.414841 Training acc= 0.734035 Val acc= 0.733490\n",
            "Epoch 2725: Training loss= 0.099581 Val loss= 0.414753 Training acc= 0.734060 Val acc= 0.733505\n",
            "Epoch 2726: Training loss= 0.099572 Val loss= 0.414664 Training acc= 0.734095 Val acc= 0.733545\n",
            "Epoch 2727: Training loss= 0.099564 Val loss= 0.414576 Training acc= 0.734115 Val acc= 0.733570\n",
            "Epoch 2728: Training loss= 0.099556 Val loss= 0.414487 Training acc= 0.734130 Val acc= 0.733575\n",
            "Epoch 2729: Training loss= 0.099547 Val loss= 0.414399 Training acc= 0.734135 Val acc= 0.733585\n",
            "Epoch 2730: Training loss= 0.099539 Val loss= 0.414311 Training acc= 0.734165 Val acc= 0.733610\n",
            "Epoch 2731: Training loss= 0.099530 Val loss= 0.414222 Training acc= 0.734170 Val acc= 0.733615\n",
            "Epoch 2732: Training loss= 0.099522 Val loss= 0.414134 Training acc= 0.734210 Val acc= 0.733655\n",
            "Epoch 2733: Training loss= 0.099514 Val loss= 0.414046 Training acc= 0.734225 Val acc= 0.733655\n",
            "Epoch 2734: Training loss= 0.099505 Val loss= 0.413958 Training acc= 0.734265 Val acc= 0.733715\n",
            "Epoch 2735: Training loss= 0.099497 Val loss= 0.413870 Training acc= 0.734280 Val acc= 0.733715\n",
            "Epoch 2736: Training loss= 0.099489 Val loss= 0.413782 Training acc= 0.734310 Val acc= 0.733730\n",
            "Epoch 2737: Training loss= 0.099480 Val loss= 0.413694 Training acc= 0.734325 Val acc= 0.733735\n",
            "Epoch 2738: Training loss= 0.099472 Val loss= 0.413606 Training acc= 0.734335 Val acc= 0.733750\n",
            "Epoch 2739: Training loss= 0.099464 Val loss= 0.413518 Training acc= 0.734355 Val acc= 0.733745\n",
            "Epoch 2740: Training loss= 0.099455 Val loss= 0.413430 Training acc= 0.734370 Val acc= 0.733760\n",
            "Epoch 2741: Training loss= 0.099447 Val loss= 0.413342 Training acc= 0.734375 Val acc= 0.733775\n",
            "Epoch 2742: Training loss= 0.099439 Val loss= 0.413254 Training acc= 0.734380 Val acc= 0.733785\n",
            "Epoch 2743: Training loss= 0.099430 Val loss= 0.413167 Training acc= 0.734395 Val acc= 0.733795\n",
            "Epoch 2744: Training loss= 0.099422 Val loss= 0.413079 Training acc= 0.734425 Val acc= 0.733820\n",
            "Epoch 2745: Training loss= 0.099414 Val loss= 0.412991 Training acc= 0.734465 Val acc= 0.733845\n",
            "Epoch 2746: Training loss= 0.099406 Val loss= 0.412904 Training acc= 0.734505 Val acc= 0.733870\n",
            "Epoch 2747: Training loss= 0.099397 Val loss= 0.412816 Training acc= 0.734530 Val acc= 0.733900\n",
            "Epoch 2748: Training loss= 0.099389 Val loss= 0.412729 Training acc= 0.734555 Val acc= 0.733920\n",
            "Epoch 2749: Training loss= 0.099381 Val loss= 0.412641 Training acc= 0.734585 Val acc= 0.733940\n",
            "Epoch 2750: Training loss= 0.099372 Val loss= 0.412554 Training acc= 0.734600 Val acc= 0.733955\n",
            "Epoch 2751: Training loss= 0.099364 Val loss= 0.412466 Training acc= 0.734625 Val acc= 0.734000\n",
            "Epoch 2752: Training loss= 0.099356 Val loss= 0.412379 Training acc= 0.734620 Val acc= 0.733990\n",
            "Epoch 2753: Training loss= 0.099348 Val loss= 0.412292 Training acc= 0.734645 Val acc= 0.733995\n",
            "Epoch 2754: Training loss= 0.099339 Val loss= 0.412205 Training acc= 0.734670 Val acc= 0.734005\n",
            "Epoch 2755: Training loss= 0.099331 Val loss= 0.412117 Training acc= 0.734670 Val acc= 0.734005\n",
            "Epoch 2756: Training loss= 0.099323 Val loss= 0.412030 Training acc= 0.734690 Val acc= 0.734015\n",
            "Epoch 2757: Training loss= 0.099315 Val loss= 0.411943 Training acc= 0.734700 Val acc= 0.734025\n",
            "Epoch 2758: Training loss= 0.099306 Val loss= 0.411856 Training acc= 0.734725 Val acc= 0.734035\n",
            "Epoch 2759: Training loss= 0.099298 Val loss= 0.411769 Training acc= 0.734730 Val acc= 0.734030\n",
            "Epoch 2760: Training loss= 0.099290 Val loss= 0.411682 Training acc= 0.734720 Val acc= 0.734050\n",
            "Epoch 2761: Training loss= 0.099282 Val loss= 0.411595 Training acc= 0.734750 Val acc= 0.734065\n",
            "Epoch 2762: Training loss= 0.099274 Val loss= 0.411508 Training acc= 0.734775 Val acc= 0.734085\n",
            "Epoch 2763: Training loss= 0.099265 Val loss= 0.411422 Training acc= 0.734780 Val acc= 0.734095\n",
            "Epoch 2764: Training loss= 0.099257 Val loss= 0.411335 Training acc= 0.734795 Val acc= 0.734115\n",
            "Epoch 2765: Training loss= 0.099249 Val loss= 0.411248 Training acc= 0.734805 Val acc= 0.734145\n",
            "Epoch 2766: Training loss= 0.099241 Val loss= 0.411162 Training acc= 0.734825 Val acc= 0.734165\n",
            "Epoch 2767: Training loss= 0.099233 Val loss= 0.411075 Training acc= 0.734850 Val acc= 0.734170\n",
            "Epoch 2768: Training loss= 0.099224 Val loss= 0.410988 Training acc= 0.734870 Val acc= 0.734175\n",
            "Epoch 2769: Training loss= 0.099216 Val loss= 0.410902 Training acc= 0.734885 Val acc= 0.734185\n",
            "Epoch 2770: Training loss= 0.099208 Val loss= 0.410815 Training acc= 0.734900 Val acc= 0.734210\n",
            "Epoch 2771: Training loss= 0.099200 Val loss= 0.410729 Training acc= 0.734895 Val acc= 0.734205\n",
            "Epoch 2772: Training loss= 0.099192 Val loss= 0.410642 Training acc= 0.734900 Val acc= 0.734190\n",
            "Epoch 2773: Training loss= 0.099184 Val loss= 0.410556 Training acc= 0.734890 Val acc= 0.734200\n",
            "Epoch 2774: Training loss= 0.099175 Val loss= 0.410470 Training acc= 0.734925 Val acc= 0.734230\n",
            "Epoch 2775: Training loss= 0.099167 Val loss= 0.410383 Training acc= 0.734945 Val acc= 0.734250\n",
            "Epoch 2776: Training loss= 0.099159 Val loss= 0.410297 Training acc= 0.734945 Val acc= 0.734260\n",
            "Epoch 2777: Training loss= 0.099151 Val loss= 0.410211 Training acc= 0.734960 Val acc= 0.734270\n",
            "Epoch 2778: Training loss= 0.099143 Val loss= 0.410125 Training acc= 0.734960 Val acc= 0.734260\n",
            "Epoch 2779: Training loss= 0.099135 Val loss= 0.410039 Training acc= 0.734955 Val acc= 0.734255\n",
            "Epoch 2780: Training loss= 0.099127 Val loss= 0.409953 Training acc= 0.734980 Val acc= 0.734270\n",
            "Epoch 2781: Training loss= 0.099119 Val loss= 0.409867 Training acc= 0.734985 Val acc= 0.734260\n",
            "Epoch 2782: Training loss= 0.099111 Val loss= 0.409781 Training acc= 0.735010 Val acc= 0.734280\n",
            "Epoch 2783: Training loss= 0.099102 Val loss= 0.409695 Training acc= 0.735030 Val acc= 0.734290\n",
            "Epoch 2784: Training loss= 0.099094 Val loss= 0.409609 Training acc= 0.735090 Val acc= 0.734330\n",
            "Epoch 2785: Training loss= 0.099086 Val loss= 0.409523 Training acc= 0.735115 Val acc= 0.734350\n",
            "Epoch 2786: Training loss= 0.099078 Val loss= 0.409437 Training acc= 0.735125 Val acc= 0.734365\n",
            "Epoch 2787: Training loss= 0.099070 Val loss= 0.409352 Training acc= 0.735170 Val acc= 0.734400\n",
            "Epoch 2788: Training loss= 0.099062 Val loss= 0.409266 Training acc= 0.735175 Val acc= 0.734415\n",
            "Epoch 2789: Training loss= 0.099054 Val loss= 0.409180 Training acc= 0.735195 Val acc= 0.734435\n",
            "Epoch 2790: Training loss= 0.099046 Val loss= 0.409095 Training acc= 0.735200 Val acc= 0.734445\n",
            "Epoch 2791: Training loss= 0.099038 Val loss= 0.409009 Training acc= 0.735205 Val acc= 0.734455\n",
            "Epoch 2792: Training loss= 0.099030 Val loss= 0.408924 Training acc= 0.735230 Val acc= 0.734490\n",
            "Epoch 2793: Training loss= 0.099022 Val loss= 0.408838 Training acc= 0.735260 Val acc= 0.734520\n",
            "Epoch 2794: Training loss= 0.099014 Val loss= 0.408753 Training acc= 0.735300 Val acc= 0.734550\n",
            "Epoch 2795: Training loss= 0.099006 Val loss= 0.408667 Training acc= 0.735325 Val acc= 0.734570\n",
            "Epoch 2796: Training loss= 0.098998 Val loss= 0.408582 Training acc= 0.735340 Val acc= 0.734590\n",
            "Epoch 2797: Training loss= 0.098990 Val loss= 0.408497 Training acc= 0.735350 Val acc= 0.734605\n",
            "Epoch 2798: Training loss= 0.098982 Val loss= 0.408412 Training acc= 0.735365 Val acc= 0.734620\n",
            "Epoch 2799: Training loss= 0.098974 Val loss= 0.408326 Training acc= 0.735390 Val acc= 0.734635\n",
            "Epoch 2800: Training loss= 0.098966 Val loss= 0.408241 Training acc= 0.735385 Val acc= 0.734635\n",
            "Epoch 2801: Training loss= 0.098958 Val loss= 0.408156 Training acc= 0.735395 Val acc= 0.734645\n",
            "Epoch 2802: Training loss= 0.098950 Val loss= 0.408071 Training acc= 0.735395 Val acc= 0.734650\n",
            "Epoch 2803: Training loss= 0.098942 Val loss= 0.407986 Training acc= 0.735415 Val acc= 0.734660\n",
            "Epoch 2804: Training loss= 0.098934 Val loss= 0.407901 Training acc= 0.735430 Val acc= 0.734670\n",
            "Epoch 2805: Training loss= 0.098926 Val loss= 0.407816 Training acc= 0.735425 Val acc= 0.734670\n",
            "Epoch 2806: Training loss= 0.098918 Val loss= 0.407731 Training acc= 0.735440 Val acc= 0.734690\n",
            "Epoch 2807: Training loss= 0.098910 Val loss= 0.407646 Training acc= 0.735425 Val acc= 0.734685\n",
            "Epoch 2808: Training loss= 0.098902 Val loss= 0.407561 Training acc= 0.735440 Val acc= 0.734715\n",
            "Epoch 2809: Training loss= 0.098894 Val loss= 0.407477 Training acc= 0.735460 Val acc= 0.734750\n",
            "Epoch 2810: Training loss= 0.098886 Val loss= 0.407392 Training acc= 0.735455 Val acc= 0.734730\n",
            "Epoch 2811: Training loss= 0.098878 Val loss= 0.407307 Training acc= 0.735495 Val acc= 0.734765\n",
            "Epoch 2812: Training loss= 0.098870 Val loss= 0.407223 Training acc= 0.735525 Val acc= 0.734800\n",
            "Epoch 2813: Training loss= 0.098862 Val loss= 0.407138 Training acc= 0.735540 Val acc= 0.734810\n",
            "Epoch 2814: Training loss= 0.098854 Val loss= 0.407053 Training acc= 0.735555 Val acc= 0.734825\n",
            "Epoch 2815: Training loss= 0.098846 Val loss= 0.406969 Training acc= 0.735590 Val acc= 0.734840\n",
            "Epoch 2816: Training loss= 0.098838 Val loss= 0.406884 Training acc= 0.735605 Val acc= 0.734855\n",
            "Epoch 2817: Training loss= 0.098830 Val loss= 0.406800 Training acc= 0.735620 Val acc= 0.734865\n",
            "Epoch 2818: Training loss= 0.098822 Val loss= 0.406716 Training acc= 0.735620 Val acc= 0.734860\n",
            "Epoch 2819: Training loss= 0.098814 Val loss= 0.406631 Training acc= 0.735630 Val acc= 0.734875\n",
            "Epoch 2820: Training loss= 0.098806 Val loss= 0.406547 Training acc= 0.735655 Val acc= 0.734890\n",
            "Epoch 2821: Training loss= 0.098799 Val loss= 0.406463 Training acc= 0.735695 Val acc= 0.734915\n",
            "Epoch 2822: Training loss= 0.098791 Val loss= 0.406379 Training acc= 0.735700 Val acc= 0.734925\n",
            "Epoch 2823: Training loss= 0.098783 Val loss= 0.406294 Training acc= 0.735695 Val acc= 0.734925\n",
            "Epoch 2824: Training loss= 0.098775 Val loss= 0.406210 Training acc= 0.735725 Val acc= 0.734960\n",
            "Epoch 2825: Training loss= 0.098767 Val loss= 0.406126 Training acc= 0.735735 Val acc= 0.734965\n",
            "Epoch 2826: Training loss= 0.098759 Val loss= 0.406042 Training acc= 0.735755 Val acc= 0.734975\n",
            "Epoch 2827: Training loss= 0.098751 Val loss= 0.405958 Training acc= 0.735765 Val acc= 0.734980\n",
            "Epoch 2828: Training loss= 0.098743 Val loss= 0.405874 Training acc= 0.735810 Val acc= 0.735030\n",
            "Epoch 2829: Training loss= 0.098735 Val loss= 0.405790 Training acc= 0.735840 Val acc= 0.735070\n",
            "Epoch 2830: Training loss= 0.098728 Val loss= 0.405707 Training acc= 0.735845 Val acc= 0.735065\n",
            "Epoch 2831: Training loss= 0.098720 Val loss= 0.405623 Training acc= 0.735880 Val acc= 0.735110\n",
            "Epoch 2832: Training loss= 0.098712 Val loss= 0.405539 Training acc= 0.735875 Val acc= 0.735110\n",
            "Epoch 2833: Training loss= 0.098704 Val loss= 0.405455 Training acc= 0.735910 Val acc= 0.735140\n",
            "Epoch 2834: Training loss= 0.098696 Val loss= 0.405372 Training acc= 0.735905 Val acc= 0.735130\n",
            "Epoch 2835: Training loss= 0.098688 Val loss= 0.405288 Training acc= 0.735930 Val acc= 0.735155\n",
            "Epoch 2836: Training loss= 0.098681 Val loss= 0.405204 Training acc= 0.735950 Val acc= 0.735180\n",
            "Epoch 2837: Training loss= 0.098673 Val loss= 0.405121 Training acc= 0.735965 Val acc= 0.735195\n",
            "Epoch 2838: Training loss= 0.098665 Val loss= 0.405037 Training acc= 0.735985 Val acc= 0.735235\n",
            "Epoch 2839: Training loss= 0.098657 Val loss= 0.404954 Training acc= 0.736000 Val acc= 0.735245\n",
            "Epoch 2840: Training loss= 0.098649 Val loss= 0.404870 Training acc= 0.736010 Val acc= 0.735255\n",
            "Epoch 2841: Training loss= 0.098642 Val loss= 0.404787 Training acc= 0.736020 Val acc= 0.735265\n",
            "Epoch 2842: Training loss= 0.098634 Val loss= 0.404704 Training acc= 0.736030 Val acc= 0.735270\n",
            "Epoch 2843: Training loss= 0.098626 Val loss= 0.404620 Training acc= 0.736025 Val acc= 0.735265\n",
            "Epoch 2844: Training loss= 0.098618 Val loss= 0.404537 Training acc= 0.736070 Val acc= 0.735305\n",
            "Epoch 2845: Training loss= 0.098610 Val loss= 0.404454 Training acc= 0.736090 Val acc= 0.735335\n",
            "Epoch 2846: Training loss= 0.098603 Val loss= 0.404371 Training acc= 0.736065 Val acc= 0.735310\n",
            "Epoch 2847: Training loss= 0.098595 Val loss= 0.404287 Training acc= 0.736080 Val acc= 0.735325\n",
            "Epoch 2848: Training loss= 0.098587 Val loss= 0.404204 Training acc= 0.736090 Val acc= 0.735340\n",
            "Epoch 2849: Training loss= 0.098579 Val loss= 0.404121 Training acc= 0.736125 Val acc= 0.735385\n",
            "Epoch 2850: Training loss= 0.098572 Val loss= 0.404038 Training acc= 0.736150 Val acc= 0.735410\n",
            "Epoch 2851: Training loss= 0.098564 Val loss= 0.403955 Training acc= 0.736150 Val acc= 0.735420\n",
            "Epoch 2852: Training loss= 0.098556 Val loss= 0.403872 Training acc= 0.736190 Val acc= 0.735455\n",
            "Epoch 2853: Training loss= 0.098548 Val loss= 0.403789 Training acc= 0.736200 Val acc= 0.735460\n",
            "Epoch 2854: Training loss= 0.098541 Val loss= 0.403707 Training acc= 0.736240 Val acc= 0.735490\n",
            "Epoch 2855: Training loss= 0.098533 Val loss= 0.403624 Training acc= 0.736250 Val acc= 0.735500\n",
            "Epoch 2856: Training loss= 0.098525 Val loss= 0.403541 Training acc= 0.736265 Val acc= 0.735520\n",
            "Epoch 2857: Training loss= 0.098517 Val loss= 0.403458 Training acc= 0.736275 Val acc= 0.735520\n",
            "Epoch 2858: Training loss= 0.098510 Val loss= 0.403376 Training acc= 0.736285 Val acc= 0.735515\n",
            "Epoch 2859: Training loss= 0.098502 Val loss= 0.403293 Training acc= 0.736305 Val acc= 0.735535\n",
            "Epoch 2860: Training loss= 0.098494 Val loss= 0.403210 Training acc= 0.736335 Val acc= 0.735565\n",
            "Epoch 2861: Training loss= 0.098486 Val loss= 0.403128 Training acc= 0.736330 Val acc= 0.735555\n",
            "Epoch 2862: Training loss= 0.098479 Val loss= 0.403045 Training acc= 0.736315 Val acc= 0.735540\n",
            "Epoch 2863: Training loss= 0.098471 Val loss= 0.402963 Training acc= 0.736320 Val acc= 0.735545\n",
            "Epoch 2864: Training loss= 0.098463 Val loss= 0.402881 Training acc= 0.736360 Val acc= 0.735580\n",
            "Epoch 2865: Training loss= 0.098456 Val loss= 0.402798 Training acc= 0.736360 Val acc= 0.735590\n",
            "Epoch 2866: Training loss= 0.098448 Val loss= 0.402716 Training acc= 0.736360 Val acc= 0.735580\n",
            "Epoch 2867: Training loss= 0.098440 Val loss= 0.402634 Training acc= 0.736365 Val acc= 0.735585\n",
            "Epoch 2868: Training loss= 0.098433 Val loss= 0.402551 Training acc= 0.736380 Val acc= 0.735620\n",
            "Epoch 2869: Training loss= 0.098425 Val loss= 0.402469 Training acc= 0.736400 Val acc= 0.735630\n",
            "Epoch 2870: Training loss= 0.098417 Val loss= 0.402387 Training acc= 0.736415 Val acc= 0.735640\n",
            "Epoch 2871: Training loss= 0.098410 Val loss= 0.402305 Training acc= 0.736405 Val acc= 0.735635\n",
            "Epoch 2872: Training loss= 0.098402 Val loss= 0.402223 Training acc= 0.736410 Val acc= 0.735650\n",
            "Epoch 2873: Training loss= 0.098394 Val loss= 0.402141 Training acc= 0.736435 Val acc= 0.735685\n",
            "Epoch 2874: Training loss= 0.098387 Val loss= 0.402059 Training acc= 0.736440 Val acc= 0.735690\n",
            "Epoch 2875: Training loss= 0.098379 Val loss= 0.401977 Training acc= 0.736435 Val acc= 0.735685\n",
            "Epoch 2876: Training loss= 0.098371 Val loss= 0.401895 Training acc= 0.736465 Val acc= 0.735700\n",
            "Epoch 2877: Training loss= 0.098364 Val loss= 0.401813 Training acc= 0.736495 Val acc= 0.735740\n",
            "Epoch 2878: Training loss= 0.098356 Val loss= 0.401731 Training acc= 0.736535 Val acc= 0.735760\n",
            "Epoch 2879: Training loss= 0.098349 Val loss= 0.401649 Training acc= 0.736550 Val acc= 0.735760\n",
            "Epoch 2880: Training loss= 0.098341 Val loss= 0.401567 Training acc= 0.736570 Val acc= 0.735770\n",
            "Epoch 2881: Training loss= 0.098333 Val loss= 0.401486 Training acc= 0.736580 Val acc= 0.735785\n",
            "Epoch 2882: Training loss= 0.098326 Val loss= 0.401404 Training acc= 0.736595 Val acc= 0.735800\n",
            "Epoch 2883: Training loss= 0.098318 Val loss= 0.401322 Training acc= 0.736620 Val acc= 0.735840\n",
            "Epoch 2884: Training loss= 0.098311 Val loss= 0.401241 Training acc= 0.736635 Val acc= 0.735860\n",
            "Epoch 2885: Training loss= 0.098303 Val loss= 0.401159 Training acc= 0.736695 Val acc= 0.735900\n",
            "Epoch 2886: Training loss= 0.098295 Val loss= 0.401078 Training acc= 0.736715 Val acc= 0.735925\n",
            "Epoch 2887: Training loss= 0.098288 Val loss= 0.400996 Training acc= 0.736755 Val acc= 0.735960\n",
            "Epoch 2888: Training loss= 0.098280 Val loss= 0.400915 Training acc= 0.736750 Val acc= 0.735965\n",
            "Epoch 2889: Training loss= 0.098273 Val loss= 0.400834 Training acc= 0.736745 Val acc= 0.735960\n",
            "Epoch 2890: Training loss= 0.098265 Val loss= 0.400752 Training acc= 0.736765 Val acc= 0.735975\n",
            "Epoch 2891: Training loss= 0.098257 Val loss= 0.400671 Training acc= 0.736790 Val acc= 0.735995\n",
            "Epoch 2892: Training loss= 0.098250 Val loss= 0.400590 Training acc= 0.736795 Val acc= 0.736000\n",
            "Epoch 2893: Training loss= 0.098242 Val loss= 0.400508 Training acc= 0.736805 Val acc= 0.736005\n",
            "Epoch 2894: Training loss= 0.098235 Val loss= 0.400427 Training acc= 0.736810 Val acc= 0.736010\n",
            "Epoch 2895: Training loss= 0.098227 Val loss= 0.400346 Training acc= 0.736815 Val acc= 0.736010\n",
            "Epoch 2896: Training loss= 0.098220 Val loss= 0.400265 Training acc= 0.736830 Val acc= 0.736025\n",
            "Epoch 2897: Training loss= 0.098212 Val loss= 0.400184 Training acc= 0.736795 Val acc= 0.735995\n",
            "Epoch 2898: Training loss= 0.098205 Val loss= 0.400103 Training acc= 0.736825 Val acc= 0.736010\n",
            "Epoch 2899: Training loss= 0.098197 Val loss= 0.400022 Training acc= 0.736860 Val acc= 0.736055\n",
            "Epoch 2900: Training loss= 0.098190 Val loss= 0.399941 Training acc= 0.736860 Val acc= 0.736050\n",
            "Epoch 2901: Training loss= 0.098182 Val loss= 0.399860 Training acc= 0.736885 Val acc= 0.736095\n",
            "Epoch 2902: Training loss= 0.098175 Val loss= 0.399779 Training acc= 0.736875 Val acc= 0.736085\n",
            "Epoch 2903: Training loss= 0.098167 Val loss= 0.399698 Training acc= 0.736910 Val acc= 0.736130\n",
            "Epoch 2904: Training loss= 0.098160 Val loss= 0.399618 Training acc= 0.736920 Val acc= 0.736145\n",
            "Epoch 2905: Training loss= 0.098152 Val loss= 0.399537 Training acc= 0.736940 Val acc= 0.736170\n",
            "Epoch 2906: Training loss= 0.098145 Val loss= 0.399456 Training acc= 0.736945 Val acc= 0.736175\n",
            "Epoch 2907: Training loss= 0.098137 Val loss= 0.399376 Training acc= 0.736960 Val acc= 0.736180\n",
            "Epoch 2908: Training loss= 0.098130 Val loss= 0.399295 Training acc= 0.736970 Val acc= 0.736190\n",
            "Epoch 2909: Training loss= 0.098122 Val loss= 0.399214 Training acc= 0.736995 Val acc= 0.736205\n",
            "Epoch 2910: Training loss= 0.098115 Val loss= 0.399134 Training acc= 0.737030 Val acc= 0.736235\n",
            "Epoch 2911: Training loss= 0.098107 Val loss= 0.399053 Training acc= 0.737060 Val acc= 0.736260\n",
            "Epoch 2912: Training loss= 0.098100 Val loss= 0.398973 Training acc= 0.737075 Val acc= 0.736270\n",
            "Epoch 2913: Training loss= 0.098092 Val loss= 0.398893 Training acc= 0.737085 Val acc= 0.736275\n",
            "Epoch 2914: Training loss= 0.098085 Val loss= 0.398812 Training acc= 0.737115 Val acc= 0.736305\n",
            "Epoch 2915: Training loss= 0.098077 Val loss= 0.398732 Training acc= 0.737120 Val acc= 0.736295\n",
            "Epoch 2916: Training loss= 0.098070 Val loss= 0.398652 Training acc= 0.737145 Val acc= 0.736310\n",
            "Epoch 2917: Training loss= 0.098062 Val loss= 0.398571 Training acc= 0.737180 Val acc= 0.736345\n",
            "Epoch 2918: Training loss= 0.098055 Val loss= 0.398491 Training acc= 0.737200 Val acc= 0.736355\n",
            "Epoch 2919: Training loss= 0.098048 Val loss= 0.398411 Training acc= 0.737235 Val acc= 0.736390\n",
            "Epoch 2920: Training loss= 0.098040 Val loss= 0.398331 Training acc= 0.737245 Val acc= 0.736405\n",
            "Epoch 2921: Training loss= 0.098033 Val loss= 0.398251 Training acc= 0.737250 Val acc= 0.736405\n",
            "Epoch 2922: Training loss= 0.098025 Val loss= 0.398171 Training acc= 0.737265 Val acc= 0.736420\n",
            "Epoch 2923: Training loss= 0.098018 Val loss= 0.398091 Training acc= 0.737270 Val acc= 0.736420\n",
            "Epoch 2924: Training loss= 0.098010 Val loss= 0.398011 Training acc= 0.737265 Val acc= 0.736435\n",
            "Epoch 2925: Training loss= 0.098003 Val loss= 0.397931 Training acc= 0.737270 Val acc= 0.736445\n",
            "Epoch 2926: Training loss= 0.097996 Val loss= 0.397851 Training acc= 0.737280 Val acc= 0.736445\n",
            "Epoch 2927: Training loss= 0.097988 Val loss= 0.397771 Training acc= 0.737280 Val acc= 0.736445\n",
            "Epoch 2928: Training loss= 0.097981 Val loss= 0.397691 Training acc= 0.737285 Val acc= 0.736450\n",
            "Epoch 2929: Training loss= 0.097973 Val loss= 0.397611 Training acc= 0.737310 Val acc= 0.736460\n",
            "Epoch 2930: Training loss= 0.097966 Val loss= 0.397532 Training acc= 0.737310 Val acc= 0.736460\n",
            "Epoch 2931: Training loss= 0.097959 Val loss= 0.397452 Training acc= 0.737300 Val acc= 0.736460\n",
            "Epoch 2932: Training loss= 0.097951 Val loss= 0.397372 Training acc= 0.737320 Val acc= 0.736495\n",
            "Epoch 2933: Training loss= 0.097944 Val loss= 0.397293 Training acc= 0.737310 Val acc= 0.736495\n",
            "Epoch 2934: Training loss= 0.097937 Val loss= 0.397213 Training acc= 0.737335 Val acc= 0.736525\n",
            "Epoch 2935: Training loss= 0.097929 Val loss= 0.397134 Training acc= 0.737345 Val acc= 0.736530\n",
            "Epoch 2936: Training loss= 0.097922 Val loss= 0.397054 Training acc= 0.737360 Val acc= 0.736540\n",
            "Epoch 2937: Training loss= 0.097914 Val loss= 0.396975 Training acc= 0.737355 Val acc= 0.736555\n",
            "Epoch 2938: Training loss= 0.097907 Val loss= 0.396895 Training acc= 0.737390 Val acc= 0.736590\n",
            "Epoch 2939: Training loss= 0.097900 Val loss= 0.396816 Training acc= 0.737410 Val acc= 0.736620\n",
            "Epoch 2940: Training loss= 0.097892 Val loss= 0.396737 Training acc= 0.737415 Val acc= 0.736620\n",
            "Epoch 2941: Training loss= 0.097885 Val loss= 0.396657 Training acc= 0.737430 Val acc= 0.736630\n",
            "Epoch 2942: Training loss= 0.097878 Val loss= 0.396578 Training acc= 0.737435 Val acc= 0.736645\n",
            "Epoch 2943: Training loss= 0.097870 Val loss= 0.396499 Training acc= 0.737450 Val acc= 0.736665\n",
            "Epoch 2944: Training loss= 0.097863 Val loss= 0.396420 Training acc= 0.737455 Val acc= 0.736670\n",
            "Epoch 2945: Training loss= 0.097856 Val loss= 0.396341 Training acc= 0.737435 Val acc= 0.736650\n",
            "Epoch 2946: Training loss= 0.097849 Val loss= 0.396261 Training acc= 0.737455 Val acc= 0.736675\n",
            "Epoch 2947: Training loss= 0.097841 Val loss= 0.396182 Training acc= 0.737460 Val acc= 0.736685\n",
            "Epoch 2948: Training loss= 0.097834 Val loss= 0.396103 Training acc= 0.737480 Val acc= 0.736710\n",
            "Epoch 2949: Training loss= 0.097827 Val loss= 0.396024 Training acc= 0.737485 Val acc= 0.736705\n",
            "Epoch 2950: Training loss= 0.097819 Val loss= 0.395945 Training acc= 0.737495 Val acc= 0.736730\n",
            "Epoch 2951: Training loss= 0.097812 Val loss= 0.395867 Training acc= 0.737505 Val acc= 0.736730\n",
            "Epoch 2952: Training loss= 0.097805 Val loss= 0.395788 Training acc= 0.737495 Val acc= 0.736710\n",
            "Epoch 2953: Training loss= 0.097797 Val loss= 0.395709 Training acc= 0.737480 Val acc= 0.736695\n",
            "Epoch 2954: Training loss= 0.097790 Val loss= 0.395630 Training acc= 0.737475 Val acc= 0.736695\n",
            "Epoch 2955: Training loss= 0.097783 Val loss= 0.395551 Training acc= 0.737505 Val acc= 0.736700\n",
            "Epoch 2956: Training loss= 0.097776 Val loss= 0.395473 Training acc= 0.737505 Val acc= 0.736705\n",
            "Epoch 2957: Training loss= 0.097768 Val loss= 0.395394 Training acc= 0.737500 Val acc= 0.736700\n",
            "Epoch 2958: Training loss= 0.097761 Val loss= 0.395315 Training acc= 0.737510 Val acc= 0.736725\n",
            "Epoch 2959: Training loss= 0.097754 Val loss= 0.395237 Training acc= 0.737530 Val acc= 0.736745\n",
            "Epoch 2960: Training loss= 0.097747 Val loss= 0.395158 Training acc= 0.737530 Val acc= 0.736750\n",
            "Epoch 2961: Training loss= 0.097739 Val loss= 0.395080 Training acc= 0.737540 Val acc= 0.736765\n",
            "Epoch 2962: Training loss= 0.097732 Val loss= 0.395001 Training acc= 0.737550 Val acc= 0.736775\n",
            "Epoch 2963: Training loss= 0.097725 Val loss= 0.394923 Training acc= 0.737570 Val acc= 0.736795\n",
            "Epoch 2964: Training loss= 0.097718 Val loss= 0.394844 Training acc= 0.737600 Val acc= 0.736820\n",
            "Epoch 2965: Training loss= 0.097710 Val loss= 0.394766 Training acc= 0.737645 Val acc= 0.736880\n",
            "Epoch 2966: Training loss= 0.097703 Val loss= 0.394688 Training acc= 0.737660 Val acc= 0.736890\n",
            "Epoch 2967: Training loss= 0.097696 Val loss= 0.394609 Training acc= 0.737675 Val acc= 0.736910\n",
            "Epoch 2968: Training loss= 0.097689 Val loss= 0.394531 Training acc= 0.737690 Val acc= 0.736920\n",
            "Epoch 2969: Training loss= 0.097682 Val loss= 0.394453 Training acc= 0.737705 Val acc= 0.736945\n",
            "Epoch 2970: Training loss= 0.097674 Val loss= 0.394375 Training acc= 0.737715 Val acc= 0.736955\n",
            "Epoch 2971: Training loss= 0.097667 Val loss= 0.394297 Training acc= 0.737730 Val acc= 0.736975\n",
            "Epoch 2972: Training loss= 0.097660 Val loss= 0.394219 Training acc= 0.737765 Val acc= 0.736995\n",
            "Epoch 2973: Training loss= 0.097653 Val loss= 0.394141 Training acc= 0.737770 Val acc= 0.737015\n",
            "Epoch 2974: Training loss= 0.097646 Val loss= 0.394063 Training acc= 0.737785 Val acc= 0.737030\n",
            "Epoch 2975: Training loss= 0.097638 Val loss= 0.393985 Training acc= 0.737795 Val acc= 0.737025\n",
            "Epoch 2976: Training loss= 0.097631 Val loss= 0.393907 Training acc= 0.737805 Val acc= 0.737030\n",
            "Epoch 2977: Training loss= 0.097624 Val loss= 0.393829 Training acc= 0.737820 Val acc= 0.737050\n",
            "Epoch 2978: Training loss= 0.097617 Val loss= 0.393751 Training acc= 0.737835 Val acc= 0.737065\n",
            "Epoch 2979: Training loss= 0.097610 Val loss= 0.393673 Training acc= 0.737815 Val acc= 0.737070\n",
            "Epoch 2980: Training loss= 0.097602 Val loss= 0.393595 Training acc= 0.737865 Val acc= 0.737110\n",
            "Epoch 2981: Training loss= 0.097595 Val loss= 0.393518 Training acc= 0.737885 Val acc= 0.737120\n",
            "Epoch 2982: Training loss= 0.097588 Val loss= 0.393440 Training acc= 0.737930 Val acc= 0.737170\n",
            "Epoch 2983: Training loss= 0.097581 Val loss= 0.393362 Training acc= 0.737970 Val acc= 0.737210\n",
            "Epoch 2984: Training loss= 0.097574 Val loss= 0.393285 Training acc= 0.737970 Val acc= 0.737205\n",
            "Epoch 2985: Training loss= 0.097567 Val loss= 0.393207 Training acc= 0.737980 Val acc= 0.737215\n",
            "Epoch 2986: Training loss= 0.097560 Val loss= 0.393129 Training acc= 0.737995 Val acc= 0.737235\n",
            "Epoch 2987: Training loss= 0.097552 Val loss= 0.393052 Training acc= 0.737990 Val acc= 0.737230\n",
            "Epoch 2988: Training loss= 0.097545 Val loss= 0.392974 Training acc= 0.737995 Val acc= 0.737245\n",
            "Epoch 2989: Training loss= 0.097538 Val loss= 0.392897 Training acc= 0.737995 Val acc= 0.737240\n",
            "Epoch 2990: Training loss= 0.097531 Val loss= 0.392820 Training acc= 0.737990 Val acc= 0.737220\n",
            "Epoch 2991: Training loss= 0.097524 Val loss= 0.392742 Training acc= 0.738000 Val acc= 0.737225\n",
            "Epoch 2992: Training loss= 0.097517 Val loss= 0.392665 Training acc= 0.738010 Val acc= 0.737235\n",
            "Epoch 2993: Training loss= 0.097510 Val loss= 0.392588 Training acc= 0.738030 Val acc= 0.737245\n",
            "Epoch 2994: Training loss= 0.097503 Val loss= 0.392510 Training acc= 0.738035 Val acc= 0.737255\n",
            "Epoch 2995: Training loss= 0.097495 Val loss= 0.392433 Training acc= 0.738040 Val acc= 0.737245\n",
            "Epoch 2996: Training loss= 0.097488 Val loss= 0.392356 Training acc= 0.738060 Val acc= 0.737250\n",
            "Epoch 2997: Training loss= 0.097481 Val loss= 0.392279 Training acc= 0.738050 Val acc= 0.737245\n",
            "Epoch 2998: Training loss= 0.097474 Val loss= 0.392202 Training acc= 0.738070 Val acc= 0.737270\n",
            "Epoch 2999: Training loss= 0.097467 Val loss= 0.392125 Training acc= 0.738090 Val acc= 0.737285\n",
            "Epoch 3000: Training loss= 0.097460 Val loss= 0.392048 Training acc= 0.738115 Val acc= 0.737310\n",
            "Epoch 3001: Training loss= 0.097453 Val loss= 0.391971 Training acc= 0.738145 Val acc= 0.737330\n",
            "Epoch 3002: Training loss= 0.097446 Val loss= 0.391894 Training acc= 0.738155 Val acc= 0.737335\n",
            "Epoch 3003: Training loss= 0.097439 Val loss= 0.391817 Training acc= 0.738180 Val acc= 0.737355\n",
            "Epoch 3004: Training loss= 0.097432 Val loss= 0.391740 Training acc= 0.738200 Val acc= 0.737380\n",
            "Epoch 3005: Training loss= 0.097425 Val loss= 0.391663 Training acc= 0.738225 Val acc= 0.737400\n",
            "Epoch 3006: Training loss= 0.097418 Val loss= 0.391587 Training acc= 0.738245 Val acc= 0.737420\n",
            "Epoch 3007: Training loss= 0.097411 Val loss= 0.391510 Training acc= 0.738255 Val acc= 0.737425\n",
            "Epoch 3008: Training loss= 0.097404 Val loss= 0.391433 Training acc= 0.738285 Val acc= 0.737460\n",
            "Epoch 3009: Training loss= 0.097397 Val loss= 0.391356 Training acc= 0.738295 Val acc= 0.737485\n",
            "Epoch 3010: Training loss= 0.097389 Val loss= 0.391280 Training acc= 0.738295 Val acc= 0.737505\n",
            "Epoch 3011: Training loss= 0.097382 Val loss= 0.391203 Training acc= 0.738305 Val acc= 0.737515\n",
            "Epoch 3012: Training loss= 0.097375 Val loss= 0.391127 Training acc= 0.738320 Val acc= 0.737545\n",
            "Epoch 3013: Training loss= 0.097368 Val loss= 0.391050 Training acc= 0.738325 Val acc= 0.737550\n",
            "Epoch 3014: Training loss= 0.097361 Val loss= 0.390974 Training acc= 0.738310 Val acc= 0.737540\n",
            "Epoch 3015: Training loss= 0.097354 Val loss= 0.390897 Training acc= 0.738305 Val acc= 0.737540\n",
            "Epoch 3016: Training loss= 0.097347 Val loss= 0.390821 Training acc= 0.738345 Val acc= 0.737570\n",
            "Epoch 3017: Training loss= 0.097340 Val loss= 0.390744 Training acc= 0.738350 Val acc= 0.737575\n",
            "Epoch 3018: Training loss= 0.097333 Val loss= 0.390668 Training acc= 0.738365 Val acc= 0.737585\n",
            "Epoch 3019: Training loss= 0.097326 Val loss= 0.390592 Training acc= 0.738380 Val acc= 0.737600\n",
            "Epoch 3020: Training loss= 0.097319 Val loss= 0.390515 Training acc= 0.738390 Val acc= 0.737610\n",
            "Epoch 3021: Training loss= 0.097312 Val loss= 0.390439 Training acc= 0.738410 Val acc= 0.737630\n",
            "Epoch 3022: Training loss= 0.097305 Val loss= 0.390363 Training acc= 0.738445 Val acc= 0.737675\n",
            "Epoch 3023: Training loss= 0.097298 Val loss= 0.390287 Training acc= 0.738460 Val acc= 0.737710\n",
            "Epoch 3024: Training loss= 0.097291 Val loss= 0.390211 Training acc= 0.738470 Val acc= 0.737725\n",
            "Epoch 3025: Training loss= 0.097284 Val loss= 0.390135 Training acc= 0.738495 Val acc= 0.737740\n",
            "Epoch 3026: Training loss= 0.097277 Val loss= 0.390059 Training acc= 0.738520 Val acc= 0.737755\n",
            "Epoch 3027: Training loss= 0.097270 Val loss= 0.389983 Training acc= 0.738535 Val acc= 0.737770\n",
            "Epoch 3028: Training loss= 0.097263 Val loss= 0.389907 Training acc= 0.738540 Val acc= 0.737790\n",
            "Epoch 3029: Training loss= 0.097257 Val loss= 0.389831 Training acc= 0.738545 Val acc= 0.737800\n",
            "Epoch 3030: Training loss= 0.097250 Val loss= 0.389755 Training acc= 0.738575 Val acc= 0.737830\n",
            "Epoch 3031: Training loss= 0.097243 Val loss= 0.389679 Training acc= 0.738575 Val acc= 0.737835\n",
            "Epoch 3032: Training loss= 0.097236 Val loss= 0.389603 Training acc= 0.738585 Val acc= 0.737835\n",
            "Epoch 3033: Training loss= 0.097229 Val loss= 0.389527 Training acc= 0.738590 Val acc= 0.737840\n",
            "Epoch 3034: Training loss= 0.097222 Val loss= 0.389452 Training acc= 0.738585 Val acc= 0.737850\n",
            "Epoch 3035: Training loss= 0.097215 Val loss= 0.389376 Training acc= 0.738625 Val acc= 0.737880\n",
            "Epoch 3036: Training loss= 0.097208 Val loss= 0.389300 Training acc= 0.738620 Val acc= 0.737880\n",
            "Epoch 3037: Training loss= 0.097201 Val loss= 0.389225 Training acc= 0.738615 Val acc= 0.737880\n",
            "Epoch 3038: Training loss= 0.097194 Val loss= 0.389149 Training acc= 0.738640 Val acc= 0.737895\n",
            "Epoch 3039: Training loss= 0.097187 Val loss= 0.389073 Training acc= 0.738660 Val acc= 0.737930\n",
            "Epoch 3040: Training loss= 0.097180 Val loss= 0.388998 Training acc= 0.738675 Val acc= 0.737950\n",
            "Epoch 3041: Training loss= 0.097173 Val loss= 0.388922 Training acc= 0.738700 Val acc= 0.737970\n",
            "Epoch 3042: Training loss= 0.097166 Val loss= 0.388847 Training acc= 0.738725 Val acc= 0.737985\n",
            "Epoch 3043: Training loss= 0.097160 Val loss= 0.388772 Training acc= 0.738755 Val acc= 0.738005\n",
            "Epoch 3044: Training loss= 0.097153 Val loss= 0.388696 Training acc= 0.738775 Val acc= 0.738015\n",
            "Epoch 3045: Training loss= 0.097146 Val loss= 0.388621 Training acc= 0.738795 Val acc= 0.738030\n",
            "Epoch 3046: Training loss= 0.097139 Val loss= 0.388545 Training acc= 0.738810 Val acc= 0.738040\n",
            "Epoch 3047: Training loss= 0.097132 Val loss= 0.388470 Training acc= 0.738820 Val acc= 0.738050\n",
            "Epoch 3048: Training loss= 0.097125 Val loss= 0.388395 Training acc= 0.738830 Val acc= 0.738065\n",
            "Epoch 3049: Training loss= 0.097118 Val loss= 0.388320 Training acc= 0.738830 Val acc= 0.738070\n",
            "Epoch 3050: Training loss= 0.097111 Val loss= 0.388245 Training acc= 0.738850 Val acc= 0.738090\n",
            "Epoch 3051: Training loss= 0.097104 Val loss= 0.388169 Training acc= 0.738840 Val acc= 0.738090\n",
            "Epoch 3052: Training loss= 0.097098 Val loss= 0.388094 Training acc= 0.738870 Val acc= 0.738115\n",
            "Epoch 3053: Training loss= 0.097091 Val loss= 0.388019 Training acc= 0.738870 Val acc= 0.738115\n",
            "Epoch 3054: Training loss= 0.097084 Val loss= 0.387944 Training acc= 0.738885 Val acc= 0.738140\n",
            "Epoch 3055: Training loss= 0.097077 Val loss= 0.387869 Training acc= 0.738885 Val acc= 0.738140\n",
            "Epoch 3056: Training loss= 0.097070 Val loss= 0.387794 Training acc= 0.738895 Val acc= 0.738150\n",
            "Epoch 3057: Training loss= 0.097063 Val loss= 0.387720 Training acc= 0.738910 Val acc= 0.738150\n",
            "Epoch 3058: Training loss= 0.097056 Val loss= 0.387645 Training acc= 0.738925 Val acc= 0.738160\n",
            "Epoch 3059: Training loss= 0.097050 Val loss= 0.387570 Training acc= 0.738935 Val acc= 0.738170\n",
            "Epoch 3060: Training loss= 0.097043 Val loss= 0.387495 Training acc= 0.738940 Val acc= 0.738160\n",
            "Epoch 3061: Training loss= 0.097036 Val loss= 0.387420 Training acc= 0.738960 Val acc= 0.738165\n",
            "Epoch 3062: Training loss= 0.097029 Val loss= 0.387346 Training acc= 0.738985 Val acc= 0.738185\n",
            "Epoch 3063: Training loss= 0.097022 Val loss= 0.387271 Training acc= 0.739005 Val acc= 0.738205\n",
            "Epoch 3064: Training loss= 0.097015 Val loss= 0.387196 Training acc= 0.739020 Val acc= 0.738230\n",
            "Epoch 3065: Training loss= 0.097009 Val loss= 0.387122 Training acc= 0.739055 Val acc= 0.738270\n",
            "Epoch 3066: Training loss= 0.097002 Val loss= 0.387047 Training acc= 0.739090 Val acc= 0.738300\n",
            "Epoch 3067: Training loss= 0.096995 Val loss= 0.386972 Training acc= 0.739095 Val acc= 0.738305\n",
            "Epoch 3068: Training loss= 0.096988 Val loss= 0.386898 Training acc= 0.739120 Val acc= 0.738320\n",
            "Epoch 3069: Training loss= 0.096981 Val loss= 0.386823 Training acc= 0.739130 Val acc= 0.738330\n",
            "Epoch 3070: Training loss= 0.096975 Val loss= 0.386749 Training acc= 0.739150 Val acc= 0.738345\n",
            "Epoch 3071: Training loss= 0.096968 Val loss= 0.386675 Training acc= 0.739165 Val acc= 0.738355\n",
            "Epoch 3072: Training loss= 0.096961 Val loss= 0.386600 Training acc= 0.739170 Val acc= 0.738365\n",
            "Epoch 3073: Training loss= 0.096954 Val loss= 0.386526 Training acc= 0.739180 Val acc= 0.738375\n",
            "Epoch 3074: Training loss= 0.096948 Val loss= 0.386452 Training acc= 0.739180 Val acc= 0.738375\n",
            "Epoch 3075: Training loss= 0.096941 Val loss= 0.386377 Training acc= 0.739190 Val acc= 0.738375\n",
            "Epoch 3076: Training loss= 0.096934 Val loss= 0.386303 Training acc= 0.739200 Val acc= 0.738385\n",
            "Epoch 3077: Training loss= 0.096927 Val loss= 0.386229 Training acc= 0.739210 Val acc= 0.738405\n",
            "Epoch 3078: Training loss= 0.096920 Val loss= 0.386155 Training acc= 0.739230 Val acc= 0.738425\n",
            "Epoch 3079: Training loss= 0.096914 Val loss= 0.386081 Training acc= 0.739230 Val acc= 0.738425\n",
            "Epoch 3080: Training loss= 0.096907 Val loss= 0.386007 Training acc= 0.739265 Val acc= 0.738455\n",
            "Epoch 3081: Training loss= 0.096900 Val loss= 0.385933 Training acc= 0.739265 Val acc= 0.738470\n",
            "Epoch 3082: Training loss= 0.096893 Val loss= 0.385859 Training acc= 0.739305 Val acc= 0.738505\n",
            "Epoch 3083: Training loss= 0.096887 Val loss= 0.385785 Training acc= 0.739325 Val acc= 0.738510\n",
            "Epoch 3084: Training loss= 0.096880 Val loss= 0.385711 Training acc= 0.739345 Val acc= 0.738520\n",
            "Epoch 3085: Training loss= 0.096873 Val loss= 0.385637 Training acc= 0.739360 Val acc= 0.738545\n",
            "Epoch 3086: Training loss= 0.096867 Val loss= 0.385563 Training acc= 0.739370 Val acc= 0.738540\n",
            "Epoch 3087: Training loss= 0.096860 Val loss= 0.385489 Training acc= 0.739395 Val acc= 0.738550\n",
            "Epoch 3088: Training loss= 0.096853 Val loss= 0.385415 Training acc= 0.739405 Val acc= 0.738560\n",
            "Epoch 3089: Training loss= 0.096846 Val loss= 0.385342 Training acc= 0.739405 Val acc= 0.738565\n",
            "Epoch 3090: Training loss= 0.096840 Val loss= 0.385268 Training acc= 0.739415 Val acc= 0.738580\n",
            "Epoch 3091: Training loss= 0.096833 Val loss= 0.385194 Training acc= 0.739420 Val acc= 0.738585\n",
            "Epoch 3092: Training loss= 0.096826 Val loss= 0.385120 Training acc= 0.739430 Val acc= 0.738585\n",
            "Epoch 3093: Training loss= 0.096819 Val loss= 0.385047 Training acc= 0.739430 Val acc= 0.738595\n",
            "Epoch 3094: Training loss= 0.096813 Val loss= 0.384973 Training acc= 0.739445 Val acc= 0.738600\n",
            "Epoch 3095: Training loss= 0.096806 Val loss= 0.384900 Training acc= 0.739460 Val acc= 0.738600\n",
            "Epoch 3096: Training loss= 0.096799 Val loss= 0.384826 Training acc= 0.739475 Val acc= 0.738610\n",
            "Epoch 3097: Training loss= 0.096793 Val loss= 0.384753 Training acc= 0.739490 Val acc= 0.738620\n",
            "Epoch 3098: Training loss= 0.096786 Val loss= 0.384679 Training acc= 0.739505 Val acc= 0.738620\n",
            "Epoch 3099: Training loss= 0.096779 Val loss= 0.384606 Training acc= 0.739500 Val acc= 0.738630\n",
            "Epoch 3100: Training loss= 0.096773 Val loss= 0.384533 Training acc= 0.739525 Val acc= 0.738645\n",
            "Epoch 3101: Training loss= 0.096766 Val loss= 0.384459 Training acc= 0.739540 Val acc= 0.738660\n",
            "Epoch 3102: Training loss= 0.096759 Val loss= 0.384386 Training acc= 0.739560 Val acc= 0.738695\n",
            "Epoch 3103: Training loss= 0.096753 Val loss= 0.384313 Training acc= 0.739575 Val acc= 0.738710\n",
            "Epoch 3104: Training loss= 0.096746 Val loss= 0.384239 Training acc= 0.739580 Val acc= 0.738705\n",
            "Epoch 3105: Training loss= 0.096739 Val loss= 0.384166 Training acc= 0.739615 Val acc= 0.738730\n",
            "Epoch 3106: Training loss= 0.096733 Val loss= 0.384093 Training acc= 0.739615 Val acc= 0.738735\n",
            "Epoch 3107: Training loss= 0.096726 Val loss= 0.384020 Training acc= 0.739640 Val acc= 0.738750\n",
            "Epoch 3108: Training loss= 0.096719 Val loss= 0.383947 Training acc= 0.739645 Val acc= 0.738765\n",
            "Epoch 3109: Training loss= 0.096713 Val loss= 0.383874 Training acc= 0.739655 Val acc= 0.738770\n",
            "Epoch 3110: Training loss= 0.096706 Val loss= 0.383801 Training acc= 0.739700 Val acc= 0.738810\n",
            "Epoch 3111: Training loss= 0.096699 Val loss= 0.383728 Training acc= 0.739705 Val acc= 0.738815\n",
            "Epoch 3112: Training loss= 0.096693 Val loss= 0.383655 Training acc= 0.739710 Val acc= 0.738825\n",
            "Epoch 3113: Training loss= 0.096686 Val loss= 0.383582 Training acc= 0.739760 Val acc= 0.738850\n",
            "Epoch 3114: Training loss= 0.096680 Val loss= 0.383509 Training acc= 0.739770 Val acc= 0.738865\n",
            "Epoch 3115: Training loss= 0.096673 Val loss= 0.383436 Training acc= 0.739780 Val acc= 0.738870\n",
            "Epoch 3116: Training loss= 0.096666 Val loss= 0.383363 Training acc= 0.739790 Val acc= 0.738870\n",
            "Epoch 3117: Training loss= 0.096660 Val loss= 0.383291 Training acc= 0.739795 Val acc= 0.738870\n",
            "Epoch 3118: Training loss= 0.096653 Val loss= 0.383218 Training acc= 0.739820 Val acc= 0.738890\n",
            "Epoch 3119: Training loss= 0.096647 Val loss= 0.383145 Training acc= 0.739840 Val acc= 0.738895\n",
            "Epoch 3120: Training loss= 0.096640 Val loss= 0.383072 Training acc= 0.739850 Val acc= 0.738910\n",
            "Epoch 3121: Training loss= 0.096633 Val loss= 0.383000 Training acc= 0.739850 Val acc= 0.738905\n",
            "Epoch 3122: Training loss= 0.096627 Val loss= 0.382927 Training acc= 0.739850 Val acc= 0.738910\n",
            "Epoch 3123: Training loss= 0.096620 Val loss= 0.382855 Training acc= 0.739880 Val acc= 0.738940\n",
            "Epoch 3124: Training loss= 0.096614 Val loss= 0.382782 Training acc= 0.739885 Val acc= 0.738950\n",
            "Epoch 3125: Training loss= 0.096607 Val loss= 0.382710 Training acc= 0.739880 Val acc= 0.738950\n",
            "Epoch 3126: Training loss= 0.096600 Val loss= 0.382637 Training acc= 0.739915 Val acc= 0.738960\n",
            "Epoch 3127: Training loss= 0.096594 Val loss= 0.382565 Training acc= 0.739920 Val acc= 0.738960\n",
            "Epoch 3128: Training loss= 0.096587 Val loss= 0.382492 Training acc= 0.739920 Val acc= 0.738955\n",
            "Epoch 3129: Training loss= 0.096581 Val loss= 0.382420 Training acc= 0.739920 Val acc= 0.738955\n",
            "Epoch 3130: Training loss= 0.096574 Val loss= 0.382348 Training acc= 0.739935 Val acc= 0.738965\n",
            "Epoch 3131: Training loss= 0.096568 Val loss= 0.382275 Training acc= 0.739955 Val acc= 0.738990\n",
            "Epoch 3132: Training loss= 0.096561 Val loss= 0.382203 Training acc= 0.739965 Val acc= 0.739005\n",
            "Epoch 3133: Training loss= 0.096554 Val loss= 0.382131 Training acc= 0.739990 Val acc= 0.739020\n",
            "Epoch 3134: Training loss= 0.096548 Val loss= 0.382059 Training acc= 0.740005 Val acc= 0.739040\n",
            "Epoch 3135: Training loss= 0.096541 Val loss= 0.381987 Training acc= 0.740010 Val acc= 0.739045\n",
            "Epoch 3136: Training loss= 0.096535 Val loss= 0.381914 Training acc= 0.740025 Val acc= 0.739065\n",
            "Epoch 3137: Training loss= 0.096528 Val loss= 0.381842 Training acc= 0.740030 Val acc= 0.739070\n",
            "Epoch 3138: Training loss= 0.096522 Val loss= 0.381770 Training acc= 0.740065 Val acc= 0.739100\n",
            "Epoch 3139: Training loss= 0.096515 Val loss= 0.381698 Training acc= 0.740070 Val acc= 0.739105\n",
            "Epoch 3140: Training loss= 0.096509 Val loss= 0.381626 Training acc= 0.740090 Val acc= 0.739125\n",
            "Epoch 3141: Training loss= 0.096502 Val loss= 0.381554 Training acc= 0.740095 Val acc= 0.739130\n",
            "Epoch 3142: Training loss= 0.096496 Val loss= 0.381482 Training acc= 0.740085 Val acc= 0.739130\n",
            "Epoch 3143: Training loss= 0.096489 Val loss= 0.381411 Training acc= 0.740105 Val acc= 0.739160\n",
            "Epoch 3144: Training loss= 0.096483 Val loss= 0.381339 Training acc= 0.740125 Val acc= 0.739170\n",
            "Epoch 3145: Training loss= 0.096476 Val loss= 0.381267 Training acc= 0.740135 Val acc= 0.739185\n",
            "Epoch 3146: Training loss= 0.096470 Val loss= 0.381195 Training acc= 0.740150 Val acc= 0.739190\n",
            "Epoch 3147: Training loss= 0.096463 Val loss= 0.381123 Training acc= 0.740150 Val acc= 0.739190\n",
            "Epoch 3148: Training loss= 0.096457 Val loss= 0.381052 Training acc= 0.740150 Val acc= 0.739190\n",
            "Epoch 3149: Training loss= 0.096450 Val loss= 0.380980 Training acc= 0.740170 Val acc= 0.739215\n",
            "Epoch 3150: Training loss= 0.096444 Val loss= 0.380908 Training acc= 0.740185 Val acc= 0.739215\n",
            "Epoch 3151: Training loss= 0.096437 Val loss= 0.380837 Training acc= 0.740200 Val acc= 0.739240\n",
            "Epoch 3152: Training loss= 0.096431 Val loss= 0.380765 Training acc= 0.740225 Val acc= 0.739260\n",
            "Epoch 3153: Training loss= 0.096424 Val loss= 0.380694 Training acc= 0.740230 Val acc= 0.739265\n",
            "Epoch 3154: Training loss= 0.096418 Val loss= 0.380622 Training acc= 0.740255 Val acc= 0.739315\n",
            "Epoch 3155: Training loss= 0.096411 Val loss= 0.380551 Training acc= 0.740270 Val acc= 0.739335\n",
            "Epoch 3156: Training loss= 0.096405 Val loss= 0.380479 Training acc= 0.740310 Val acc= 0.739380\n",
            "Epoch 3157: Training loss= 0.096398 Val loss= 0.380408 Training acc= 0.740305 Val acc= 0.739380\n",
            "Epoch 3158: Training loss= 0.096392 Val loss= 0.380336 Training acc= 0.740325 Val acc= 0.739420\n",
            "Epoch 3159: Training loss= 0.096385 Val loss= 0.380265 Training acc= 0.740325 Val acc= 0.739420\n",
            "Epoch 3160: Training loss= 0.096379 Val loss= 0.380194 Training acc= 0.740330 Val acc= 0.739425\n",
            "Epoch 3161: Training loss= 0.096373 Val loss= 0.380122 Training acc= 0.740325 Val acc= 0.739430\n",
            "Epoch 3162: Training loss= 0.096366 Val loss= 0.380051 Training acc= 0.740320 Val acc= 0.739425\n",
            "Epoch 3163: Training loss= 0.096360 Val loss= 0.379980 Training acc= 0.740335 Val acc= 0.739425\n",
            "Epoch 3164: Training loss= 0.096353 Val loss= 0.379909 Training acc= 0.740355 Val acc= 0.739455\n",
            "Epoch 3165: Training loss= 0.096347 Val loss= 0.379838 Training acc= 0.740375 Val acc= 0.739475\n",
            "Epoch 3166: Training loss= 0.096340 Val loss= 0.379767 Training acc= 0.740400 Val acc= 0.739510\n",
            "Epoch 3167: Training loss= 0.096334 Val loss= 0.379696 Training acc= 0.740410 Val acc= 0.739525\n",
            "Epoch 3168: Training loss= 0.096327 Val loss= 0.379624 Training acc= 0.740420 Val acc= 0.739530\n",
            "Epoch 3169: Training loss= 0.096321 Val loss= 0.379553 Training acc= 0.740430 Val acc= 0.739560\n",
            "Epoch 3170: Training loss= 0.096315 Val loss= 0.379483 Training acc= 0.740430 Val acc= 0.739555\n",
            "Epoch 3171: Training loss= 0.096308 Val loss= 0.379412 Training acc= 0.740465 Val acc= 0.739585\n",
            "Epoch 3172: Training loss= 0.096302 Val loss= 0.379341 Training acc= 0.740480 Val acc= 0.739590\n",
            "Epoch 3173: Training loss= 0.096295 Val loss= 0.379270 Training acc= 0.740505 Val acc= 0.739610\n",
            "Epoch 3174: Training loss= 0.096289 Val loss= 0.379199 Training acc= 0.740520 Val acc= 0.739610\n",
            "Epoch 3175: Training loss= 0.096283 Val loss= 0.379128 Training acc= 0.740530 Val acc= 0.739620\n",
            "Epoch 3176: Training loss= 0.096276 Val loss= 0.379057 Training acc= 0.740530 Val acc= 0.739630\n",
            "Epoch 3177: Training loss= 0.096270 Val loss= 0.378987 Training acc= 0.740545 Val acc= 0.739645\n",
            "Epoch 3178: Training loss= 0.096263 Val loss= 0.378916 Training acc= 0.740545 Val acc= 0.739650\n",
            "Epoch 3179: Training loss= 0.096257 Val loss= 0.378845 Training acc= 0.740555 Val acc= 0.739650\n",
            "Epoch 3180: Training loss= 0.096251 Val loss= 0.378775 Training acc= 0.740590 Val acc= 0.739685\n",
            "Epoch 3181: Training loss= 0.096244 Val loss= 0.378704 Training acc= 0.740595 Val acc= 0.739685\n",
            "Epoch 3182: Training loss= 0.096238 Val loss= 0.378633 Training acc= 0.740605 Val acc= 0.739690\n",
            "Epoch 3183: Training loss= 0.096232 Val loss= 0.378563 Training acc= 0.740630 Val acc= 0.739705\n",
            "Epoch 3184: Training loss= 0.096225 Val loss= 0.378492 Training acc= 0.740635 Val acc= 0.739720\n",
            "Epoch 3185: Training loss= 0.096219 Val loss= 0.378422 Training acc= 0.740670 Val acc= 0.739755\n",
            "Epoch 3186: Training loss= 0.096212 Val loss= 0.378352 Training acc= 0.740675 Val acc= 0.739765\n",
            "Epoch 3187: Training loss= 0.096206 Val loss= 0.378281 Training acc= 0.740690 Val acc= 0.739795\n",
            "Epoch 3188: Training loss= 0.096200 Val loss= 0.378211 Training acc= 0.740670 Val acc= 0.739790\n",
            "Epoch 3189: Training loss= 0.096193 Val loss= 0.378140 Training acc= 0.740670 Val acc= 0.739785\n",
            "Epoch 3190: Training loss= 0.096187 Val loss= 0.378070 Training acc= 0.740690 Val acc= 0.739800\n",
            "Epoch 3191: Training loss= 0.096181 Val loss= 0.378000 Training acc= 0.740710 Val acc= 0.739815\n",
            "Epoch 3192: Training loss= 0.096174 Val loss= 0.377930 Training acc= 0.740730 Val acc= 0.739870\n",
            "Epoch 3193: Training loss= 0.096168 Val loss= 0.377859 Training acc= 0.740735 Val acc= 0.739880\n",
            "Epoch 3194: Training loss= 0.096162 Val loss= 0.377789 Training acc= 0.740750 Val acc= 0.739890\n",
            "Epoch 3195: Training loss= 0.096155 Val loss= 0.377719 Training acc= 0.740785 Val acc= 0.739925\n",
            "Epoch 3196: Training loss= 0.096149 Val loss= 0.377649 Training acc= 0.740790 Val acc= 0.739925\n",
            "Epoch 3197: Training loss= 0.096143 Val loss= 0.377579 Training acc= 0.740795 Val acc= 0.739930\n",
            "Epoch 3198: Training loss= 0.096136 Val loss= 0.377509 Training acc= 0.740800 Val acc= 0.739935\n",
            "Epoch 3199: Training loss= 0.096130 Val loss= 0.377439 Training acc= 0.740810 Val acc= 0.739935\n",
            "Epoch 3200: Training loss= 0.096124 Val loss= 0.377369 Training acc= 0.740810 Val acc= 0.739950\n",
            "Epoch 3201: Training loss= 0.096118 Val loss= 0.377299 Training acc= 0.740815 Val acc= 0.739955\n",
            "Epoch 3202: Training loss= 0.096111 Val loss= 0.377229 Training acc= 0.740810 Val acc= 0.739950\n",
            "Epoch 3203: Training loss= 0.096105 Val loss= 0.377159 Training acc= 0.740815 Val acc= 0.739965\n",
            "Epoch 3204: Training loss= 0.096099 Val loss= 0.377089 Training acc= 0.740830 Val acc= 0.739980\n",
            "Epoch 3205: Training loss= 0.096092 Val loss= 0.377020 Training acc= 0.740840 Val acc= 0.739990\n",
            "Epoch 3206: Training loss= 0.096086 Val loss= 0.376950 Training acc= 0.740845 Val acc= 0.740000\n",
            "Epoch 3207: Training loss= 0.096080 Val loss= 0.376880 Training acc= 0.740850 Val acc= 0.740020\n",
            "Epoch 3208: Training loss= 0.096073 Val loss= 0.376810 Training acc= 0.740860 Val acc= 0.740025\n",
            "Epoch 3209: Training loss= 0.096067 Val loss= 0.376741 Training acc= 0.740865 Val acc= 0.740040\n",
            "Epoch 3210: Training loss= 0.096061 Val loss= 0.376671 Training acc= 0.740885 Val acc= 0.740065\n",
            "Epoch 3211: Training loss= 0.096055 Val loss= 0.376601 Training acc= 0.740900 Val acc= 0.740090\n",
            "Epoch 3212: Training loss= 0.096048 Val loss= 0.376532 Training acc= 0.740915 Val acc= 0.740100\n",
            "Epoch 3213: Training loss= 0.096042 Val loss= 0.376462 Training acc= 0.740935 Val acc= 0.740110\n",
            "Epoch 3214: Training loss= 0.096036 Val loss= 0.376393 Training acc= 0.740960 Val acc= 0.740135\n",
            "Epoch 3215: Training loss= 0.096030 Val loss= 0.376323 Training acc= 0.740960 Val acc= 0.740130\n",
            "Epoch 3216: Training loss= 0.096023 Val loss= 0.376254 Training acc= 0.740945 Val acc= 0.740125\n",
            "Epoch 3217: Training loss= 0.096017 Val loss= 0.376184 Training acc= 0.740960 Val acc= 0.740145\n",
            "Epoch 3218: Training loss= 0.096011 Val loss= 0.376115 Training acc= 0.740985 Val acc= 0.740170\n",
            "Epoch 3219: Training loss= 0.096005 Val loss= 0.376046 Training acc= 0.740995 Val acc= 0.740175\n",
            "Epoch 3220: Training loss= 0.095998 Val loss= 0.375976 Training acc= 0.741010 Val acc= 0.740195\n",
            "Epoch 3221: Training loss= 0.095992 Val loss= 0.375907 Training acc= 0.741015 Val acc= 0.740200\n",
            "Epoch 3222: Training loss= 0.095986 Val loss= 0.375838 Training acc= 0.741035 Val acc= 0.740215\n",
            "Epoch 3223: Training loss= 0.095980 Val loss= 0.375768 Training acc= 0.741050 Val acc= 0.740215\n",
            "Epoch 3224: Training loss= 0.095973 Val loss= 0.375699 Training acc= 0.741050 Val acc= 0.740220\n",
            "Epoch 3225: Training loss= 0.095967 Val loss= 0.375630 Training acc= 0.741055 Val acc= 0.740230\n",
            "Epoch 3226: Training loss= 0.095961 Val loss= 0.375561 Training acc= 0.741065 Val acc= 0.740240\n",
            "Epoch 3227: Training loss= 0.095955 Val loss= 0.375492 Training acc= 0.741070 Val acc= 0.740255\n",
            "Epoch 3228: Training loss= 0.095949 Val loss= 0.375423 Training acc= 0.741075 Val acc= 0.740265\n",
            "Epoch 3229: Training loss= 0.095942 Val loss= 0.375354 Training acc= 0.741095 Val acc= 0.740295\n",
            "Epoch 3230: Training loss= 0.095936 Val loss= 0.375285 Training acc= 0.741100 Val acc= 0.740295\n",
            "Epoch 3231: Training loss= 0.095930 Val loss= 0.375216 Training acc= 0.741120 Val acc= 0.740305\n",
            "Epoch 3232: Training loss= 0.095924 Val loss= 0.375147 Training acc= 0.741140 Val acc= 0.740330\n",
            "Epoch 3233: Training loss= 0.095918 Val loss= 0.375078 Training acc= 0.741155 Val acc= 0.740345\n",
            "Epoch 3234: Training loss= 0.095911 Val loss= 0.375009 Training acc= 0.741175 Val acc= 0.740365\n",
            "Epoch 3235: Training loss= 0.095905 Val loss= 0.374940 Training acc= 0.741185 Val acc= 0.740375\n",
            "Epoch 3236: Training loss= 0.095899 Val loss= 0.374871 Training acc= 0.741185 Val acc= 0.740365\n",
            "Epoch 3237: Training loss= 0.095893 Val loss= 0.374803 Training acc= 0.741190 Val acc= 0.740375\n",
            "Epoch 3238: Training loss= 0.095887 Val loss= 0.374734 Training acc= 0.741175 Val acc= 0.740370\n",
            "Epoch 3239: Training loss= 0.095881 Val loss= 0.374665 Training acc= 0.741185 Val acc= 0.740395\n",
            "Epoch 3240: Training loss= 0.095874 Val loss= 0.374596 Training acc= 0.741210 Val acc= 0.740415\n",
            "Epoch 3241: Training loss= 0.095868 Val loss= 0.374528 Training acc= 0.741220 Val acc= 0.740435\n",
            "Epoch 3242: Training loss= 0.095862 Val loss= 0.374459 Training acc= 0.741220 Val acc= 0.740435\n",
            "Epoch 3243: Training loss= 0.095856 Val loss= 0.374391 Training acc= 0.741230 Val acc= 0.740440\n",
            "Epoch 3244: Training loss= 0.095850 Val loss= 0.374322 Training acc= 0.741260 Val acc= 0.740470\n",
            "Epoch 3245: Training loss= 0.095844 Val loss= 0.374254 Training acc= 0.741280 Val acc= 0.740490\n",
            "Epoch 3246: Training loss= 0.095837 Val loss= 0.374185 Training acc= 0.741300 Val acc= 0.740495\n",
            "Epoch 3247: Training loss= 0.095831 Val loss= 0.374117 Training acc= 0.741310 Val acc= 0.740505\n",
            "Epoch 3248: Training loss= 0.095825 Val loss= 0.374048 Training acc= 0.741300 Val acc= 0.740515\n",
            "Epoch 3249: Training loss= 0.095819 Val loss= 0.373980 Training acc= 0.741320 Val acc= 0.740535\n",
            "Epoch 3250: Training loss= 0.095813 Val loss= 0.373911 Training acc= 0.741320 Val acc= 0.740520\n",
            "Epoch 3251: Training loss= 0.095807 Val loss= 0.373843 Training acc= 0.741335 Val acc= 0.740520\n",
            "Epoch 3252: Training loss= 0.095801 Val loss= 0.373775 Training acc= 0.741350 Val acc= 0.740540\n",
            "Epoch 3253: Training loss= 0.095794 Val loss= 0.373707 Training acc= 0.741370 Val acc= 0.740555\n",
            "Epoch 3254: Training loss= 0.095788 Val loss= 0.373638 Training acc= 0.741375 Val acc= 0.740565\n",
            "Epoch 3255: Training loss= 0.095782 Val loss= 0.373570 Training acc= 0.741370 Val acc= 0.740565\n",
            "Epoch 3256: Training loss= 0.095776 Val loss= 0.373502 Training acc= 0.741395 Val acc= 0.740595\n",
            "Epoch 3257: Training loss= 0.095770 Val loss= 0.373434 Training acc= 0.741410 Val acc= 0.740620\n",
            "Epoch 3258: Training loss= 0.095764 Val loss= 0.373366 Training acc= 0.741410 Val acc= 0.740610\n",
            "Epoch 3259: Training loss= 0.095758 Val loss= 0.373298 Training acc= 0.741425 Val acc= 0.740625\n",
            "Epoch 3260: Training loss= 0.095752 Val loss= 0.373229 Training acc= 0.741445 Val acc= 0.740635\n",
            "Epoch 3261: Training loss= 0.095746 Val loss= 0.373161 Training acc= 0.741445 Val acc= 0.740650\n",
            "Epoch 3262: Training loss= 0.095739 Val loss= 0.373093 Training acc= 0.741445 Val acc= 0.740645\n",
            "Epoch 3263: Training loss= 0.095733 Val loss= 0.373026 Training acc= 0.741460 Val acc= 0.740650\n",
            "Epoch 3264: Training loss= 0.095727 Val loss= 0.372958 Training acc= 0.741475 Val acc= 0.740655\n",
            "Epoch 3265: Training loss= 0.095721 Val loss= 0.372890 Training acc= 0.741485 Val acc= 0.740665\n",
            "Epoch 3266: Training loss= 0.095715 Val loss= 0.372822 Training acc= 0.741485 Val acc= 0.740660\n",
            "Epoch 3267: Training loss= 0.095709 Val loss= 0.372754 Training acc= 0.741480 Val acc= 0.740660\n",
            "Epoch 3268: Training loss= 0.095703 Val loss= 0.372686 Training acc= 0.741490 Val acc= 0.740670\n",
            "Epoch 3269: Training loss= 0.095697 Val loss= 0.372618 Training acc= 0.741495 Val acc= 0.740670\n",
            "Epoch 3270: Training loss= 0.095691 Val loss= 0.372551 Training acc= 0.741500 Val acc= 0.740660\n",
            "Epoch 3271: Training loss= 0.095685 Val loss= 0.372483 Training acc= 0.741520 Val acc= 0.740675\n",
            "Epoch 3272: Training loss= 0.095679 Val loss= 0.372415 Training acc= 0.741505 Val acc= 0.740690\n",
            "Epoch 3273: Training loss= 0.095673 Val loss= 0.372348 Training acc= 0.741510 Val acc= 0.740690\n",
            "Epoch 3274: Training loss= 0.095667 Val loss= 0.372280 Training acc= 0.741515 Val acc= 0.740705\n",
            "Epoch 3275: Training loss= 0.095661 Val loss= 0.372213 Training acc= 0.741510 Val acc= 0.740705\n",
            "Epoch 3276: Training loss= 0.095654 Val loss= 0.372145 Training acc= 0.741525 Val acc= 0.740715\n",
            "Epoch 3277: Training loss= 0.095648 Val loss= 0.372077 Training acc= 0.741520 Val acc= 0.740715\n",
            "Epoch 3278: Training loss= 0.095642 Val loss= 0.372010 Training acc= 0.741505 Val acc= 0.740720\n",
            "Epoch 3279: Training loss= 0.095636 Val loss= 0.371943 Training acc= 0.741510 Val acc= 0.740735\n",
            "Epoch 3280: Training loss= 0.095630 Val loss= 0.371875 Training acc= 0.741510 Val acc= 0.740745\n",
            "Epoch 3281: Training loss= 0.095624 Val loss= 0.371808 Training acc= 0.741525 Val acc= 0.740760\n",
            "Epoch 3282: Training loss= 0.095618 Val loss= 0.371740 Training acc= 0.741530 Val acc= 0.740770\n",
            "Epoch 3283: Training loss= 0.095612 Val loss= 0.371673 Training acc= 0.741530 Val acc= 0.740775\n",
            "Epoch 3284: Training loss= 0.095606 Val loss= 0.371606 Training acc= 0.741570 Val acc= 0.740805\n",
            "Epoch 3285: Training loss= 0.095600 Val loss= 0.371538 Training acc= 0.741580 Val acc= 0.740820\n",
            "Epoch 3286: Training loss= 0.095594 Val loss= 0.371471 Training acc= 0.741620 Val acc= 0.740860\n",
            "Epoch 3287: Training loss= 0.095588 Val loss= 0.371404 Training acc= 0.741615 Val acc= 0.740855\n",
            "Epoch 3288: Training loss= 0.095582 Val loss= 0.371337 Training acc= 0.741615 Val acc= 0.740860\n",
            "Epoch 3289: Training loss= 0.095576 Val loss= 0.371270 Training acc= 0.741630 Val acc= 0.740875\n",
            "Epoch 3290: Training loss= 0.095570 Val loss= 0.371203 Training acc= 0.741645 Val acc= 0.740885\n",
            "Epoch 3291: Training loss= 0.095564 Val loss= 0.371135 Training acc= 0.741655 Val acc= 0.740890\n",
            "Epoch 3292: Training loss= 0.095558 Val loss= 0.371068 Training acc= 0.741640 Val acc= 0.740880\n",
            "Epoch 3293: Training loss= 0.095552 Val loss= 0.371001 Training acc= 0.741645 Val acc= 0.740890\n",
            "Epoch 3294: Training loss= 0.095546 Val loss= 0.370934 Training acc= 0.741640 Val acc= 0.740880\n",
            "Epoch 3295: Training loss= 0.095540 Val loss= 0.370867 Training acc= 0.741680 Val acc= 0.740915\n",
            "Epoch 3296: Training loss= 0.095534 Val loss= 0.370800 Training acc= 0.741710 Val acc= 0.740945\n",
            "Epoch 3297: Training loss= 0.095528 Val loss= 0.370734 Training acc= 0.741755 Val acc= 0.740975\n",
            "Epoch 3298: Training loss= 0.095522 Val loss= 0.370667 Training acc= 0.741770 Val acc= 0.740980\n",
            "Epoch 3299: Training loss= 0.095516 Val loss= 0.370600 Training acc= 0.741795 Val acc= 0.741010\n",
            "Epoch 3300: Training loss= 0.095510 Val loss= 0.370533 Training acc= 0.741825 Val acc= 0.741060\n",
            "Epoch 3301: Training loss= 0.095504 Val loss= 0.370466 Training acc= 0.741825 Val acc= 0.741060\n",
            "Epoch 3302: Training loss= 0.095498 Val loss= 0.370400 Training acc= 0.741855 Val acc= 0.741090\n",
            "Epoch 3303: Training loss= 0.095492 Val loss= 0.370333 Training acc= 0.741865 Val acc= 0.741090\n",
            "Epoch 3304: Training loss= 0.095486 Val loss= 0.370266 Training acc= 0.741895 Val acc= 0.741125\n",
            "Epoch 3305: Training loss= 0.095480 Val loss= 0.370199 Training acc= 0.741920 Val acc= 0.741155\n",
            "Epoch 3306: Training loss= 0.095474 Val loss= 0.370133 Training acc= 0.741945 Val acc= 0.741180\n",
            "Epoch 3307: Training loss= 0.095469 Val loss= 0.370066 Training acc= 0.741980 Val acc= 0.741210\n",
            "Epoch 3308: Training loss= 0.095463 Val loss= 0.370000 Training acc= 0.741980 Val acc= 0.741215\n",
            "Epoch 3309: Training loss= 0.095457 Val loss= 0.369933 Training acc= 0.742000 Val acc= 0.741230\n",
            "Epoch 3310: Training loss= 0.095451 Val loss= 0.369867 Training acc= 0.742050 Val acc= 0.741285\n",
            "Epoch 3311: Training loss= 0.095445 Val loss= 0.369800 Training acc= 0.742065 Val acc= 0.741300\n",
            "Epoch 3312: Training loss= 0.095439 Val loss= 0.369734 Training acc= 0.742095 Val acc= 0.741345\n",
            "Epoch 3313: Training loss= 0.095433 Val loss= 0.369667 Training acc= 0.742115 Val acc= 0.741365\n",
            "Epoch 3314: Training loss= 0.095427 Val loss= 0.369601 Training acc= 0.742115 Val acc= 0.741355\n",
            "Epoch 3315: Training loss= 0.095421 Val loss= 0.369535 Training acc= 0.742120 Val acc= 0.741360\n",
            "Epoch 3316: Training loss= 0.095415 Val loss= 0.369468 Training acc= 0.742120 Val acc= 0.741365\n",
            "Epoch 3317: Training loss= 0.095409 Val loss= 0.369402 Training acc= 0.742150 Val acc= 0.741385\n",
            "Epoch 3318: Training loss= 0.095403 Val loss= 0.369336 Training acc= 0.742150 Val acc= 0.741385\n",
            "Epoch 3319: Training loss= 0.095397 Val loss= 0.369269 Training acc= 0.742175 Val acc= 0.741385\n",
            "Epoch 3320: Training loss= 0.095392 Val loss= 0.369203 Training acc= 0.742175 Val acc= 0.741390\n",
            "Epoch 3321: Training loss= 0.095386 Val loss= 0.369137 Training acc= 0.742200 Val acc= 0.741405\n",
            "Epoch 3322: Training loss= 0.095380 Val loss= 0.369071 Training acc= 0.742195 Val acc= 0.741410\n",
            "Epoch 3323: Training loss= 0.095374 Val loss= 0.369005 Training acc= 0.742205 Val acc= 0.741430\n",
            "Epoch 3324: Training loss= 0.095368 Val loss= 0.368939 Training acc= 0.742230 Val acc= 0.741440\n",
            "Epoch 3325: Training loss= 0.095362 Val loss= 0.368873 Training acc= 0.742260 Val acc= 0.741460\n",
            "Epoch 3326: Training loss= 0.095356 Val loss= 0.368807 Training acc= 0.742275 Val acc= 0.741460\n",
            "Epoch 3327: Training loss= 0.095350 Val loss= 0.368741 Training acc= 0.742285 Val acc= 0.741480\n",
            "Epoch 3328: Training loss= 0.095344 Val loss= 0.368675 Training acc= 0.742295 Val acc= 0.741480\n",
            "Epoch 3329: Training loss= 0.095338 Val loss= 0.368609 Training acc= 0.742320 Val acc= 0.741490\n",
            "Epoch 3330: Training loss= 0.095333 Val loss= 0.368543 Training acc= 0.742345 Val acc= 0.741505\n",
            "Epoch 3331: Training loss= 0.095327 Val loss= 0.368477 Training acc= 0.742340 Val acc= 0.741510\n",
            "Epoch 3332: Training loss= 0.095321 Val loss= 0.368411 Training acc= 0.742340 Val acc= 0.741515\n",
            "Epoch 3333: Training loss= 0.095315 Val loss= 0.368345 Training acc= 0.742365 Val acc= 0.741535\n",
            "Epoch 3334: Training loss= 0.095309 Val loss= 0.368280 Training acc= 0.742375 Val acc= 0.741560\n",
            "Epoch 3335: Training loss= 0.095303 Val loss= 0.368214 Training acc= 0.742410 Val acc= 0.741585\n",
            "Epoch 3336: Training loss= 0.095297 Val loss= 0.368148 Training acc= 0.742435 Val acc= 0.741610\n",
            "Epoch 3337: Training loss= 0.095292 Val loss= 0.368082 Training acc= 0.742435 Val acc= 0.741610\n",
            "Epoch 3338: Training loss= 0.095286 Val loss= 0.368017 Training acc= 0.742425 Val acc= 0.741610\n",
            "Epoch 3339: Training loss= 0.095280 Val loss= 0.367951 Training acc= 0.742430 Val acc= 0.741610\n",
            "Epoch 3340: Training loss= 0.095274 Val loss= 0.367886 Training acc= 0.742440 Val acc= 0.741625\n",
            "Epoch 3341: Training loss= 0.095268 Val loss= 0.367820 Training acc= 0.742470 Val acc= 0.741665\n",
            "Epoch 3342: Training loss= 0.095262 Val loss= 0.367754 Training acc= 0.742500 Val acc= 0.741700\n",
            "Epoch 3343: Training loss= 0.095257 Val loss= 0.367689 Training acc= 0.742515 Val acc= 0.741740\n",
            "Epoch 3344: Training loss= 0.095251 Val loss= 0.367623 Training acc= 0.742515 Val acc= 0.741735\n",
            "Epoch 3345: Training loss= 0.095245 Val loss= 0.367558 Training acc= 0.742530 Val acc= 0.741750\n",
            "Epoch 3346: Training loss= 0.095239 Val loss= 0.367493 Training acc= 0.742545 Val acc= 0.741755\n",
            "Epoch 3347: Training loss= 0.095233 Val loss= 0.367427 Training acc= 0.742540 Val acc= 0.741750\n",
            "Epoch 3348: Training loss= 0.095227 Val loss= 0.367362 Training acc= 0.742535 Val acc= 0.741755\n",
            "Epoch 3349: Training loss= 0.095222 Val loss= 0.367297 Training acc= 0.742540 Val acc= 0.741750\n",
            "Epoch 3350: Training loss= 0.095216 Val loss= 0.367231 Training acc= 0.742540 Val acc= 0.741750\n",
            "Epoch 3351: Training loss= 0.095210 Val loss= 0.367166 Training acc= 0.742565 Val acc= 0.741775\n",
            "Epoch 3352: Training loss= 0.095204 Val loss= 0.367101 Training acc= 0.742555 Val acc= 0.741775\n",
            "Epoch 3353: Training loss= 0.095198 Val loss= 0.367035 Training acc= 0.742555 Val acc= 0.741765\n",
            "Epoch 3354: Training loss= 0.095193 Val loss= 0.366970 Training acc= 0.742550 Val acc= 0.741760\n",
            "Epoch 3355: Training loss= 0.095187 Val loss= 0.366905 Training acc= 0.742565 Val acc= 0.741775\n",
            "Epoch 3356: Training loss= 0.095181 Val loss= 0.366840 Training acc= 0.742585 Val acc= 0.741800\n",
            "Epoch 3357: Training loss= 0.095175 Val loss= 0.366775 Training acc= 0.742615 Val acc= 0.741825\n",
            "Epoch 3358: Training loss= 0.095169 Val loss= 0.366710 Training acc= 0.742610 Val acc= 0.741820\n",
            "Epoch 3359: Training loss= 0.095164 Val loss= 0.366645 Training acc= 0.742615 Val acc= 0.741835\n",
            "Epoch 3360: Training loss= 0.095158 Val loss= 0.366580 Training acc= 0.742610 Val acc= 0.741840\n",
            "Epoch 3361: Training loss= 0.095152 Val loss= 0.366515 Training acc= 0.742630 Val acc= 0.741850\n",
            "Epoch 3362: Training loss= 0.095146 Val loss= 0.366450 Training acc= 0.742635 Val acc= 0.741870\n",
            "Epoch 3363: Training loss= 0.095141 Val loss= 0.366385 Training acc= 0.742640 Val acc= 0.741870\n",
            "Epoch 3364: Training loss= 0.095135 Val loss= 0.366320 Training acc= 0.742640 Val acc= 0.741860\n",
            "Epoch 3365: Training loss= 0.095129 Val loss= 0.366255 Training acc= 0.742660 Val acc= 0.741870\n",
            "Epoch 3366: Training loss= 0.095123 Val loss= 0.366190 Training acc= 0.742670 Val acc= 0.741885\n",
            "Epoch 3367: Training loss= 0.095117 Val loss= 0.366126 Training acc= 0.742675 Val acc= 0.741890\n",
            "Epoch 3368: Training loss= 0.095112 Val loss= 0.366061 Training acc= 0.742705 Val acc= 0.741910\n",
            "Epoch 3369: Training loss= 0.095106 Val loss= 0.365996 Training acc= 0.742730 Val acc= 0.741925\n",
            "Epoch 3370: Training loss= 0.095100 Val loss= 0.365931 Training acc= 0.742720 Val acc= 0.741915\n",
            "Epoch 3371: Training loss= 0.095094 Val loss= 0.365867 Training acc= 0.742725 Val acc= 0.741910\n",
            "Epoch 3372: Training loss= 0.095089 Val loss= 0.365802 Training acc= 0.742715 Val acc= 0.741900\n",
            "Epoch 3373: Training loss= 0.095083 Val loss= 0.365737 Training acc= 0.742730 Val acc= 0.741905\n",
            "Epoch 3374: Training loss= 0.095077 Val loss= 0.365673 Training acc= 0.742735 Val acc= 0.741910\n",
            "Epoch 3375: Training loss= 0.095071 Val loss= 0.365608 Training acc= 0.742750 Val acc= 0.741920\n",
            "Epoch 3376: Training loss= 0.095066 Val loss= 0.365544 Training acc= 0.742770 Val acc= 0.741945\n",
            "Epoch 3377: Training loss= 0.095060 Val loss= 0.365479 Training acc= 0.742795 Val acc= 0.741990\n",
            "Epoch 3378: Training loss= 0.095054 Val loss= 0.365415 Training acc= 0.742820 Val acc= 0.742005\n",
            "Epoch 3379: Training loss= 0.095049 Val loss= 0.365350 Training acc= 0.742845 Val acc= 0.742020\n",
            "Epoch 3380: Training loss= 0.095043 Val loss= 0.365286 Training acc= 0.742855 Val acc= 0.742030\n",
            "Epoch 3381: Training loss= 0.095037 Val loss= 0.365221 Training acc= 0.742875 Val acc= 0.742045\n",
            "Epoch 3382: Training loss= 0.095031 Val loss= 0.365157 Training acc= 0.742890 Val acc= 0.742060\n",
            "Epoch 3383: Training loss= 0.095026 Val loss= 0.365093 Training acc= 0.742885 Val acc= 0.742050\n",
            "Epoch 3384: Training loss= 0.095020 Val loss= 0.365028 Training acc= 0.742885 Val acc= 0.742050\n",
            "Epoch 3385: Training loss= 0.095014 Val loss= 0.364964 Training acc= 0.742890 Val acc= 0.742055\n",
            "Epoch 3386: Training loss= 0.095009 Val loss= 0.364900 Training acc= 0.742895 Val acc= 0.742065\n",
            "Epoch 3387: Training loss= 0.095003 Val loss= 0.364836 Training acc= 0.742890 Val acc= 0.742060\n",
            "Epoch 3388: Training loss= 0.094997 Val loss= 0.364771 Training acc= 0.742900 Val acc= 0.742075\n",
            "Epoch 3389: Training loss= 0.094992 Val loss= 0.364707 Training acc= 0.742880 Val acc= 0.742075\n",
            "Epoch 3390: Training loss= 0.094986 Val loss= 0.364643 Training acc= 0.742890 Val acc= 0.742090\n",
            "Epoch 3391: Training loss= 0.094980 Val loss= 0.364579 Training acc= 0.742890 Val acc= 0.742095\n",
            "Epoch 3392: Training loss= 0.094974 Val loss= 0.364515 Training acc= 0.742915 Val acc= 0.742125\n",
            "Epoch 3393: Training loss= 0.094969 Val loss= 0.364451 Training acc= 0.742910 Val acc= 0.742115\n",
            "Epoch 3394: Training loss= 0.094963 Val loss= 0.364387 Training acc= 0.742925 Val acc= 0.742130\n",
            "Epoch 3395: Training loss= 0.094957 Val loss= 0.364323 Training acc= 0.742945 Val acc= 0.742145\n",
            "Epoch 3396: Training loss= 0.094952 Val loss= 0.364259 Training acc= 0.742955 Val acc= 0.742155\n",
            "Epoch 3397: Training loss= 0.094946 Val loss= 0.364195 Training acc= 0.742955 Val acc= 0.742160\n",
            "Epoch 3398: Training loss= 0.094940 Val loss= 0.364131 Training acc= 0.742965 Val acc= 0.742170\n",
            "Epoch 3399: Training loss= 0.094935 Val loss= 0.364067 Training acc= 0.742985 Val acc= 0.742200\n",
            "Epoch 3400: Training loss= 0.094929 Val loss= 0.364003 Training acc= 0.742990 Val acc= 0.742200\n",
            "Epoch 3401: Training loss= 0.094923 Val loss= 0.363939 Training acc= 0.742995 Val acc= 0.742200\n",
            "Epoch 3402: Training loss= 0.094918 Val loss= 0.363876 Training acc= 0.742995 Val acc= 0.742185\n",
            "Epoch 3403: Training loss= 0.094912 Val loss= 0.363812 Training acc= 0.743010 Val acc= 0.742205\n",
            "Epoch 3404: Training loss= 0.094906 Val loss= 0.363748 Training acc= 0.743020 Val acc= 0.742205\n",
            "Epoch 3405: Training loss= 0.094901 Val loss= 0.363684 Training acc= 0.743055 Val acc= 0.742225\n",
            "Epoch 3406: Training loss= 0.094895 Val loss= 0.363621 Training acc= 0.743050 Val acc= 0.742225\n",
            "Epoch 3407: Training loss= 0.094890 Val loss= 0.363557 Training acc= 0.743040 Val acc= 0.742225\n",
            "Epoch 3408: Training loss= 0.094884 Val loss= 0.363494 Training acc= 0.743045 Val acc= 0.742230\n",
            "Epoch 3409: Training loss= 0.094878 Val loss= 0.363430 Training acc= 0.743060 Val acc= 0.742255\n",
            "Epoch 3410: Training loss= 0.094873 Val loss= 0.363366 Training acc= 0.743070 Val acc= 0.742250\n",
            "Epoch 3411: Training loss= 0.094867 Val loss= 0.363303 Training acc= 0.743065 Val acc= 0.742240\n",
            "Epoch 3412: Training loss= 0.094861 Val loss= 0.363239 Training acc= 0.743080 Val acc= 0.742245\n",
            "Epoch 3413: Training loss= 0.094856 Val loss= 0.363176 Training acc= 0.743100 Val acc= 0.742275\n",
            "Epoch 3414: Training loss= 0.094850 Val loss= 0.363112 Training acc= 0.743085 Val acc= 0.742260\n",
            "Epoch 3415: Training loss= 0.094845 Val loss= 0.363049 Training acc= 0.743090 Val acc= 0.742255\n",
            "Epoch 3416: Training loss= 0.094839 Val loss= 0.362986 Training acc= 0.743100 Val acc= 0.742275\n",
            "Epoch 3417: Training loss= 0.094833 Val loss= 0.362922 Training acc= 0.743120 Val acc= 0.742300\n",
            "Epoch 3418: Training loss= 0.094828 Val loss= 0.362859 Training acc= 0.743145 Val acc= 0.742320\n",
            "Epoch 3419: Training loss= 0.094822 Val loss= 0.362796 Training acc= 0.743145 Val acc= 0.742325\n",
            "Epoch 3420: Training loss= 0.094816 Val loss= 0.362732 Training acc= 0.743190 Val acc= 0.742355\n",
            "Epoch 3421: Training loss= 0.094811 Val loss= 0.362669 Training acc= 0.743190 Val acc= 0.742355\n",
            "Epoch 3422: Training loss= 0.094805 Val loss= 0.362606 Training acc= 0.743205 Val acc= 0.742375\n",
            "Epoch 3423: Training loss= 0.094800 Val loss= 0.362543 Training acc= 0.743230 Val acc= 0.742400\n",
            "Epoch 3424: Training loss= 0.094794 Val loss= 0.362479 Training acc= 0.743260 Val acc= 0.742430\n",
            "Epoch 3425: Training loss= 0.094789 Val loss= 0.362416 Training acc= 0.743260 Val acc= 0.742435\n",
            "Epoch 3426: Training loss= 0.094783 Val loss= 0.362353 Training acc= 0.743255 Val acc= 0.742440\n",
            "Epoch 3427: Training loss= 0.094777 Val loss= 0.362290 Training acc= 0.743260 Val acc= 0.742445\n",
            "Epoch 3428: Training loss= 0.094772 Val loss= 0.362227 Training acc= 0.743290 Val acc= 0.742480\n",
            "Epoch 3429: Training loss= 0.094766 Val loss= 0.362164 Training acc= 0.743285 Val acc= 0.742480\n",
            "Epoch 3430: Training loss= 0.094761 Val loss= 0.362101 Training acc= 0.743290 Val acc= 0.742480\n",
            "Epoch 3431: Training loss= 0.094755 Val loss= 0.362038 Training acc= 0.743295 Val acc= 0.742475\n",
            "Epoch 3432: Training loss= 0.094750 Val loss= 0.361975 Training acc= 0.743325 Val acc= 0.742495\n",
            "Epoch 3433: Training loss= 0.094744 Val loss= 0.361912 Training acc= 0.743310 Val acc= 0.742495\n",
            "Epoch 3434: Training loss= 0.094738 Val loss= 0.361849 Training acc= 0.743305 Val acc= 0.742490\n",
            "Epoch 3435: Training loss= 0.094733 Val loss= 0.361786 Training acc= 0.743320 Val acc= 0.742505\n",
            "Epoch 3436: Training loss= 0.094727 Val loss= 0.361724 Training acc= 0.743350 Val acc= 0.742530\n",
            "Epoch 3437: Training loss= 0.094722 Val loss= 0.361661 Training acc= 0.743355 Val acc= 0.742545\n",
            "Epoch 3438: Training loss= 0.094716 Val loss= 0.361598 Training acc= 0.743360 Val acc= 0.742540\n",
            "Epoch 3439: Training loss= 0.094711 Val loss= 0.361535 Training acc= 0.743375 Val acc= 0.742550\n",
            "Epoch 3440: Training loss= 0.094705 Val loss= 0.361473 Training acc= 0.743365 Val acc= 0.742550\n",
            "Epoch 3441: Training loss= 0.094700 Val loss= 0.361410 Training acc= 0.743385 Val acc= 0.742560\n",
            "Epoch 3442: Training loss= 0.094694 Val loss= 0.361347 Training acc= 0.743390 Val acc= 0.742570\n",
            "Epoch 3443: Training loss= 0.094688 Val loss= 0.361285 Training acc= 0.743400 Val acc= 0.742570\n",
            "Epoch 3444: Training loss= 0.094683 Val loss= 0.361222 Training acc= 0.743395 Val acc= 0.742585\n",
            "Epoch 3445: Training loss= 0.094677 Val loss= 0.361159 Training acc= 0.743425 Val acc= 0.742615\n",
            "Epoch 3446: Training loss= 0.094672 Val loss= 0.361097 Training acc= 0.743430 Val acc= 0.742615\n",
            "Epoch 3447: Training loss= 0.094666 Val loss= 0.361034 Training acc= 0.743435 Val acc= 0.742640\n",
            "Epoch 3448: Training loss= 0.094661 Val loss= 0.360972 Training acc= 0.743450 Val acc= 0.742645\n",
            "Epoch 3449: Training loss= 0.094655 Val loss= 0.360909 Training acc= 0.743475 Val acc= 0.742665\n",
            "Epoch 3450: Training loss= 0.094650 Val loss= 0.360847 Training acc= 0.743505 Val acc= 0.742690\n",
            "Epoch 3451: Training loss= 0.094644 Val loss= 0.360784 Training acc= 0.743525 Val acc= 0.742720\n",
            "Epoch 3452: Training loss= 0.094639 Val loss= 0.360722 Training acc= 0.743550 Val acc= 0.742735\n",
            "Epoch 3453: Training loss= 0.094633 Val loss= 0.360660 Training acc= 0.743565 Val acc= 0.742745\n",
            "Epoch 3454: Training loss= 0.094628 Val loss= 0.360597 Training acc= 0.743585 Val acc= 0.742755\n",
            "Epoch 3455: Training loss= 0.094622 Val loss= 0.360535 Training acc= 0.743590 Val acc= 0.742760\n",
            "Epoch 3456: Training loss= 0.094617 Val loss= 0.360473 Training acc= 0.743600 Val acc= 0.742770\n",
            "Epoch 3457: Training loss= 0.094611 Val loss= 0.360411 Training acc= 0.743625 Val acc= 0.742800\n",
            "Epoch 3458: Training loss= 0.094606 Val loss= 0.360348 Training acc= 0.743650 Val acc= 0.742825\n",
            "Epoch 3459: Training loss= 0.094600 Val loss= 0.360286 Training acc= 0.743650 Val acc= 0.742830\n",
            "Epoch 3460: Training loss= 0.094595 Val loss= 0.360224 Training acc= 0.743670 Val acc= 0.742860\n",
            "Epoch 3461: Training loss= 0.094589 Val loss= 0.360162 Training acc= 0.743705 Val acc= 0.742900\n",
            "Epoch 3462: Training loss= 0.094584 Val loss= 0.360100 Training acc= 0.743715 Val acc= 0.742925\n",
            "Epoch 3463: Training loss= 0.094578 Val loss= 0.360038 Training acc= 0.743735 Val acc= 0.742945\n",
            "Epoch 3464: Training loss= 0.094573 Val loss= 0.359976 Training acc= 0.743765 Val acc= 0.742970\n",
            "Epoch 3465: Training loss= 0.094567 Val loss= 0.359914 Training acc= 0.743770 Val acc= 0.742970\n",
            "Epoch 3466: Training loss= 0.094562 Val loss= 0.359852 Training acc= 0.743765 Val acc= 0.742970\n",
            "Epoch 3467: Training loss= 0.094557 Val loss= 0.359790 Training acc= 0.743770 Val acc= 0.742975\n",
            "Epoch 3468: Training loss= 0.094551 Val loss= 0.359728 Training acc= 0.743780 Val acc= 0.742980\n",
            "Epoch 3469: Training loss= 0.094546 Val loss= 0.359666 Training acc= 0.743770 Val acc= 0.742980\n",
            "Epoch 3470: Training loss= 0.094540 Val loss= 0.359604 Training acc= 0.743775 Val acc= 0.742995\n",
            "Epoch 3471: Training loss= 0.094535 Val loss= 0.359542 Training acc= 0.743800 Val acc= 0.743020\n",
            "Epoch 3472: Training loss= 0.094529 Val loss= 0.359480 Training acc= 0.743790 Val acc= 0.743020\n",
            "Epoch 3473: Training loss= 0.094524 Val loss= 0.359418 Training acc= 0.743805 Val acc= 0.743035\n",
            "Epoch 3474: Training loss= 0.094518 Val loss= 0.359357 Training acc= 0.743825 Val acc= 0.743040\n",
            "Epoch 3475: Training loss= 0.094513 Val loss= 0.359295 Training acc= 0.743815 Val acc= 0.743030\n",
            "Epoch 3476: Training loss= 0.094507 Val loss= 0.359233 Training acc= 0.743825 Val acc= 0.743035\n",
            "Epoch 3477: Training loss= 0.094502 Val loss= 0.359171 Training acc= 0.743830 Val acc= 0.743045\n",
            "Epoch 3478: Training loss= 0.094497 Val loss= 0.359110 Training acc= 0.743830 Val acc= 0.743040\n",
            "Epoch 3479: Training loss= 0.094491 Val loss= 0.359048 Training acc= 0.743830 Val acc= 0.743045\n",
            "Epoch 3480: Training loss= 0.094486 Val loss= 0.358986 Training acc= 0.743835 Val acc= 0.743055\n",
            "Epoch 3481: Training loss= 0.094480 Val loss= 0.358925 Training acc= 0.743850 Val acc= 0.743065\n",
            "Epoch 3482: Training loss= 0.094475 Val loss= 0.358863 Training acc= 0.743850 Val acc= 0.743070\n",
            "Epoch 3483: Training loss= 0.094469 Val loss= 0.358802 Training acc= 0.743840 Val acc= 0.743065\n",
            "Epoch 3484: Training loss= 0.094464 Val loss= 0.358740 Training acc= 0.743835 Val acc= 0.743065\n",
            "Epoch 3485: Training loss= 0.094459 Val loss= 0.358679 Training acc= 0.743855 Val acc= 0.743090\n",
            "Epoch 3486: Training loss= 0.094453 Val loss= 0.358617 Training acc= 0.743865 Val acc= 0.743100\n",
            "Epoch 3487: Training loss= 0.094448 Val loss= 0.358556 Training acc= 0.743875 Val acc= 0.743105\n",
            "Epoch 3488: Training loss= 0.094442 Val loss= 0.358494 Training acc= 0.743885 Val acc= 0.743120\n",
            "Epoch 3489: Training loss= 0.094437 Val loss= 0.358433 Training acc= 0.743910 Val acc= 0.743150\n",
            "Epoch 3490: Training loss= 0.094432 Val loss= 0.358372 Training acc= 0.743925 Val acc= 0.743165\n",
            "Epoch 3491: Training loss= 0.094426 Val loss= 0.358310 Training acc= 0.743935 Val acc= 0.743175\n",
            "Epoch 3492: Training loss= 0.094421 Val loss= 0.358249 Training acc= 0.743945 Val acc= 0.743185\n",
            "Epoch 3493: Training loss= 0.094415 Val loss= 0.358188 Training acc= 0.743950 Val acc= 0.743185\n",
            "Epoch 3494: Training loss= 0.094410 Val loss= 0.358127 Training acc= 0.743960 Val acc= 0.743210\n",
            "Epoch 3495: Training loss= 0.094405 Val loss= 0.358065 Training acc= 0.743965 Val acc= 0.743210\n",
            "Epoch 3496: Training loss= 0.094399 Val loss= 0.358004 Training acc= 0.743980 Val acc= 0.743230\n",
            "Epoch 3497: Training loss= 0.094394 Val loss= 0.357943 Training acc= 0.743990 Val acc= 0.743240\n",
            "Epoch 3498: Training loss= 0.094388 Val loss= 0.357882 Training acc= 0.744020 Val acc= 0.743260\n",
            "Epoch 3499: Training loss= 0.094383 Val loss= 0.357821 Training acc= 0.744020 Val acc= 0.743260\n",
            "Epoch 3500: Training loss= 0.094378 Val loss= 0.357760 Training acc= 0.744025 Val acc= 0.743275\n",
            "Epoch 3501: Training loss= 0.094372 Val loss= 0.357699 Training acc= 0.744040 Val acc= 0.743290\n",
            "Epoch 3502: Training loss= 0.094367 Val loss= 0.357638 Training acc= 0.744040 Val acc= 0.743295\n",
            "Epoch 3503: Training loss= 0.094362 Val loss= 0.357577 Training acc= 0.744060 Val acc= 0.743305\n",
            "Epoch 3504: Training loss= 0.094356 Val loss= 0.357516 Training acc= 0.744060 Val acc= 0.743300\n",
            "Epoch 3505: Training loss= 0.094351 Val loss= 0.357455 Training acc= 0.744060 Val acc= 0.743300\n",
            "Epoch 3506: Training loss= 0.094346 Val loss= 0.357394 Training acc= 0.744085 Val acc= 0.743320\n",
            "Epoch 3507: Training loss= 0.094340 Val loss= 0.357333 Training acc= 0.744105 Val acc= 0.743345\n",
            "Epoch 3508: Training loss= 0.094335 Val loss= 0.357272 Training acc= 0.744115 Val acc= 0.743355\n",
            "Epoch 3509: Training loss= 0.094329 Val loss= 0.357211 Training acc= 0.744105 Val acc= 0.743360\n",
            "Epoch 3510: Training loss= 0.094324 Val loss= 0.357150 Training acc= 0.744075 Val acc= 0.743340\n",
            "Epoch 3511: Training loss= 0.094319 Val loss= 0.357089 Training acc= 0.744080 Val acc= 0.743335\n",
            "Epoch 3512: Training loss= 0.094313 Val loss= 0.357029 Training acc= 0.744110 Val acc= 0.743360\n",
            "Epoch 3513: Training loss= 0.094308 Val loss= 0.356968 Training acc= 0.744125 Val acc= 0.743375\n",
            "Epoch 3514: Training loss= 0.094303 Val loss= 0.356907 Training acc= 0.744125 Val acc= 0.743380\n",
            "Epoch 3515: Training loss= 0.094297 Val loss= 0.356847 Training acc= 0.744145 Val acc= 0.743395\n",
            "Epoch 3516: Training loss= 0.094292 Val loss= 0.356786 Training acc= 0.744165 Val acc= 0.743410\n",
            "Epoch 3517: Training loss= 0.094287 Val loss= 0.356725 Training acc= 0.744185 Val acc= 0.743430\n",
            "Epoch 3518: Training loss= 0.094281 Val loss= 0.356665 Training acc= 0.744190 Val acc= 0.743440\n",
            "Epoch 3519: Training loss= 0.094276 Val loss= 0.356604 Training acc= 0.744195 Val acc= 0.743445\n",
            "Epoch 3520: Training loss= 0.094271 Val loss= 0.356544 Training acc= 0.744205 Val acc= 0.743445\n",
            "Epoch 3521: Training loss= 0.094265 Val loss= 0.356483 Training acc= 0.744245 Val acc= 0.743480\n",
            "Epoch 3522: Training loss= 0.094260 Val loss= 0.356423 Training acc= 0.744240 Val acc= 0.743490\n",
            "Epoch 3523: Training loss= 0.094255 Val loss= 0.356362 Training acc= 0.744240 Val acc= 0.743480\n",
            "Epoch 3524: Training loss= 0.094250 Val loss= 0.356302 Training acc= 0.744250 Val acc= 0.743500\n",
            "Epoch 3525: Training loss= 0.094244 Val loss= 0.356241 Training acc= 0.744245 Val acc= 0.743510\n",
            "Epoch 3526: Training loss= 0.094239 Val loss= 0.356181 Training acc= 0.744250 Val acc= 0.743515\n",
            "Epoch 3527: Training loss= 0.094234 Val loss= 0.356120 Training acc= 0.744255 Val acc= 0.743520\n",
            "Epoch 3528: Training loss= 0.094228 Val loss= 0.356060 Training acc= 0.744265 Val acc= 0.743525\n",
            "Epoch 3529: Training loss= 0.094223 Val loss= 0.356000 Training acc= 0.744285 Val acc= 0.743540\n",
            "Epoch 3530: Training loss= 0.094218 Val loss= 0.355940 Training acc= 0.744300 Val acc= 0.743540\n",
            "Epoch 3531: Training loss= 0.094212 Val loss= 0.355879 Training acc= 0.744315 Val acc= 0.743560\n",
            "Epoch 3532: Training loss= 0.094207 Val loss= 0.355819 Training acc= 0.744310 Val acc= 0.743545\n",
            "Epoch 3533: Training loss= 0.094202 Val loss= 0.355759 Training acc= 0.744290 Val acc= 0.743535\n",
            "Epoch 3534: Training loss= 0.094197 Val loss= 0.355699 Training acc= 0.744300 Val acc= 0.743550\n",
            "Epoch 3535: Training loss= 0.094191 Val loss= 0.355639 Training acc= 0.744315 Val acc= 0.743580\n",
            "Epoch 3536: Training loss= 0.094186 Val loss= 0.355578 Training acc= 0.744320 Val acc= 0.743600\n",
            "Epoch 3537: Training loss= 0.094181 Val loss= 0.355518 Training acc= 0.744340 Val acc= 0.743630\n",
            "Epoch 3538: Training loss= 0.094176 Val loss= 0.355458 Training acc= 0.744345 Val acc= 0.743640\n",
            "Epoch 3539: Training loss= 0.094170 Val loss= 0.355398 Training acc= 0.744330 Val acc= 0.743630\n",
            "Epoch 3540: Training loss= 0.094165 Val loss= 0.355338 Training acc= 0.744330 Val acc= 0.743625\n",
            "Epoch 3541: Training loss= 0.094160 Val loss= 0.355278 Training acc= 0.744345 Val acc= 0.743640\n",
            "Epoch 3542: Training loss= 0.094154 Val loss= 0.355218 Training acc= 0.744345 Val acc= 0.743635\n",
            "Epoch 3543: Training loss= 0.094149 Val loss= 0.355158 Training acc= 0.744365 Val acc= 0.743655\n",
            "Epoch 3544: Training loss= 0.094144 Val loss= 0.355098 Training acc= 0.744380 Val acc= 0.743675\n",
            "Epoch 3545: Training loss= 0.094139 Val loss= 0.355038 Training acc= 0.744390 Val acc= 0.743685\n",
            "Epoch 3546: Training loss= 0.094133 Val loss= 0.354979 Training acc= 0.744405 Val acc= 0.743695\n",
            "Epoch 3547: Training loss= 0.094128 Val loss= 0.354919 Training acc= 0.744420 Val acc= 0.743715\n",
            "Epoch 3548: Training loss= 0.094123 Val loss= 0.354859 Training acc= 0.744435 Val acc= 0.743730\n",
            "Epoch 3549: Training loss= 0.094118 Val loss= 0.354799 Training acc= 0.744450 Val acc= 0.743745\n",
            "Epoch 3550: Training loss= 0.094112 Val loss= 0.354739 Training acc= 0.744470 Val acc= 0.743750\n",
            "Epoch 3551: Training loss= 0.094107 Val loss= 0.354680 Training acc= 0.744475 Val acc= 0.743755\n",
            "Epoch 3552: Training loss= 0.094102 Val loss= 0.354620 Training acc= 0.744500 Val acc= 0.743770\n",
            "Epoch 3553: Training loss= 0.094097 Val loss= 0.354560 Training acc= 0.744500 Val acc= 0.743770\n",
            "Epoch 3554: Training loss= 0.094092 Val loss= 0.354501 Training acc= 0.744505 Val acc= 0.743770\n",
            "Epoch 3555: Training loss= 0.094086 Val loss= 0.354441 Training acc= 0.744510 Val acc= 0.743775\n",
            "Epoch 3556: Training loss= 0.094081 Val loss= 0.354381 Training acc= 0.744505 Val acc= 0.743775\n",
            "Epoch 3557: Training loss= 0.094076 Val loss= 0.354322 Training acc= 0.744520 Val acc= 0.743785\n",
            "Epoch 3558: Training loss= 0.094071 Val loss= 0.354262 Training acc= 0.744520 Val acc= 0.743790\n",
            "Epoch 3559: Training loss= 0.094065 Val loss= 0.354203 Training acc= 0.744525 Val acc= 0.743815\n",
            "Epoch 3560: Training loss= 0.094060 Val loss= 0.354143 Training acc= 0.744535 Val acc= 0.743825\n",
            "Epoch 3561: Training loss= 0.094055 Val loss= 0.354084 Training acc= 0.744545 Val acc= 0.743830\n",
            "Epoch 3562: Training loss= 0.094050 Val loss= 0.354024 Training acc= 0.744545 Val acc= 0.743840\n",
            "Epoch 3563: Training loss= 0.094045 Val loss= 0.353965 Training acc= 0.744575 Val acc= 0.743855\n",
            "Epoch 3564: Training loss= 0.094039 Val loss= 0.353905 Training acc= 0.744590 Val acc= 0.743865\n",
            "Epoch 3565: Training loss= 0.094034 Val loss= 0.353846 Training acc= 0.744595 Val acc= 0.743865\n",
            "Epoch 3566: Training loss= 0.094029 Val loss= 0.353787 Training acc= 0.744615 Val acc= 0.743870\n",
            "Epoch 3567: Training loss= 0.094024 Val loss= 0.353727 Training acc= 0.744620 Val acc= 0.743880\n",
            "Epoch 3568: Training loss= 0.094019 Val loss= 0.353668 Training acc= 0.744645 Val acc= 0.743905\n",
            "Epoch 3569: Training loss= 0.094013 Val loss= 0.353609 Training acc= 0.744645 Val acc= 0.743900\n",
            "Epoch 3570: Training loss= 0.094008 Val loss= 0.353549 Training acc= 0.744655 Val acc= 0.743920\n",
            "Epoch 3571: Training loss= 0.094003 Val loss= 0.353490 Training acc= 0.744660 Val acc= 0.743940\n",
            "Epoch 3572: Training loss= 0.093998 Val loss= 0.353431 Training acc= 0.744670 Val acc= 0.743955\n",
            "Epoch 3573: Training loss= 0.093993 Val loss= 0.353372 Training acc= 0.744690 Val acc= 0.743975\n",
            "Epoch 3574: Training loss= 0.093988 Val loss= 0.353313 Training acc= 0.744705 Val acc= 0.743990\n",
            "Epoch 3575: Training loss= 0.093982 Val loss= 0.353254 Training acc= 0.744710 Val acc= 0.744000\n",
            "Epoch 3576: Training loss= 0.093977 Val loss= 0.353194 Training acc= 0.744720 Val acc= 0.744010\n",
            "Epoch 3577: Training loss= 0.093972 Val loss= 0.353135 Training acc= 0.744730 Val acc= 0.744015\n",
            "Epoch 3578: Training loss= 0.093967 Val loss= 0.353076 Training acc= 0.744725 Val acc= 0.744010\n",
            "Epoch 3579: Training loss= 0.093962 Val loss= 0.353017 Training acc= 0.744735 Val acc= 0.744025\n",
            "Epoch 3580: Training loss= 0.093957 Val loss= 0.352958 Training acc= 0.744750 Val acc= 0.744040\n",
            "Epoch 3581: Training loss= 0.093951 Val loss= 0.352899 Training acc= 0.744745 Val acc= 0.744045\n",
            "Epoch 3582: Training loss= 0.093946 Val loss= 0.352840 Training acc= 0.744745 Val acc= 0.744045\n",
            "Epoch 3583: Training loss= 0.093941 Val loss= 0.352782 Training acc= 0.744750 Val acc= 0.744060\n",
            "Epoch 3584: Training loss= 0.093936 Val loss= 0.352723 Training acc= 0.744765 Val acc= 0.744080\n",
            "Epoch 3585: Training loss= 0.093931 Val loss= 0.352664 Training acc= 0.744775 Val acc= 0.744095\n",
            "Epoch 3586: Training loss= 0.093926 Val loss= 0.352605 Training acc= 0.744780 Val acc= 0.744105\n",
            "Epoch 3587: Training loss= 0.093920 Val loss= 0.352546 Training acc= 0.744780 Val acc= 0.744110\n",
            "Epoch 3588: Training loss= 0.093915 Val loss= 0.352487 Training acc= 0.744770 Val acc= 0.744095\n",
            "Epoch 3589: Training loss= 0.093910 Val loss= 0.352429 Training acc= 0.744780 Val acc= 0.744110\n",
            "Epoch 3590: Training loss= 0.093905 Val loss= 0.352370 Training acc= 0.744780 Val acc= 0.744105\n",
            "Epoch 3591: Training loss= 0.093900 Val loss= 0.352311 Training acc= 0.744790 Val acc= 0.744110\n",
            "Epoch 3592: Training loss= 0.093895 Val loss= 0.352252 Training acc= 0.744810 Val acc= 0.744125\n",
            "Epoch 3593: Training loss= 0.093890 Val loss= 0.352194 Training acc= 0.744830 Val acc= 0.744140\n",
            "Epoch 3594: Training loss= 0.093885 Val loss= 0.352135 Training acc= 0.744845 Val acc= 0.744160\n",
            "Epoch 3595: Training loss= 0.093879 Val loss= 0.352076 Training acc= 0.744840 Val acc= 0.744165\n",
            "Epoch 3596: Training loss= 0.093874 Val loss= 0.352018 Training acc= 0.744840 Val acc= 0.744170\n",
            "Epoch 3597: Training loss= 0.093869 Val loss= 0.351959 Training acc= 0.744850 Val acc= 0.744170\n",
            "Epoch 3598: Training loss= 0.093864 Val loss= 0.351901 Training acc= 0.744860 Val acc= 0.744170\n",
            "Epoch 3599: Training loss= 0.093859 Val loss= 0.351842 Training acc= 0.744870 Val acc= 0.744175\n",
            "Epoch 3600: Training loss= 0.093854 Val loss= 0.351784 Training acc= 0.744880 Val acc= 0.744185\n",
            "Epoch 3601: Training loss= 0.093849 Val loss= 0.351725 Training acc= 0.744910 Val acc= 0.744210\n",
            "Epoch 3602: Training loss= 0.093844 Val loss= 0.351667 Training acc= 0.744930 Val acc= 0.744215\n",
            "Epoch 3603: Training loss= 0.093839 Val loss= 0.351608 Training acc= 0.744945 Val acc= 0.744230\n",
            "Epoch 3604: Training loss= 0.093833 Val loss= 0.351550 Training acc= 0.744965 Val acc= 0.744240\n",
            "Epoch 3605: Training loss= 0.093828 Val loss= 0.351492 Training acc= 0.744990 Val acc= 0.744265\n",
            "Epoch 3606: Training loss= 0.093823 Val loss= 0.351433 Training acc= 0.745000 Val acc= 0.744275\n",
            "Epoch 3607: Training loss= 0.093818 Val loss= 0.351375 Training acc= 0.745015 Val acc= 0.744290\n",
            "Epoch 3608: Training loss= 0.093813 Val loss= 0.351317 Training acc= 0.745025 Val acc= 0.744300\n",
            "Epoch 3609: Training loss= 0.093808 Val loss= 0.351259 Training acc= 0.745040 Val acc= 0.744310\n",
            "Epoch 3610: Training loss= 0.093803 Val loss= 0.351200 Training acc= 0.745045 Val acc= 0.744320\n",
            "Epoch 3611: Training loss= 0.093798 Val loss= 0.351142 Training acc= 0.745060 Val acc= 0.744340\n",
            "Epoch 3612: Training loss= 0.093793 Val loss= 0.351084 Training acc= 0.745060 Val acc= 0.744340\n",
            "Epoch 3613: Training loss= 0.093788 Val loss= 0.351026 Training acc= 0.745050 Val acc= 0.744340\n",
            "Epoch 3614: Training loss= 0.093783 Val loss= 0.350968 Training acc= 0.745055 Val acc= 0.744350\n",
            "Epoch 3615: Training loss= 0.093778 Val loss= 0.350909 Training acc= 0.745055 Val acc= 0.744370\n",
            "Epoch 3616: Training loss= 0.093772 Val loss= 0.350851 Training acc= 0.745095 Val acc= 0.744415\n",
            "Epoch 3617: Training loss= 0.093767 Val loss= 0.350793 Training acc= 0.745105 Val acc= 0.744430\n",
            "Epoch 3618: Training loss= 0.093762 Val loss= 0.350735 Training acc= 0.745105 Val acc= 0.744445\n",
            "Epoch 3619: Training loss= 0.093757 Val loss= 0.350677 Training acc= 0.745115 Val acc= 0.744460\n",
            "Epoch 3620: Training loss= 0.093752 Val loss= 0.350619 Training acc= 0.745120 Val acc= 0.744460\n",
            "Epoch 3621: Training loss= 0.093747 Val loss= 0.350561 Training acc= 0.745120 Val acc= 0.744460\n",
            "Epoch 3622: Training loss= 0.093742 Val loss= 0.350503 Training acc= 0.745130 Val acc= 0.744465\n",
            "Epoch 3623: Training loss= 0.093737 Val loss= 0.350445 Training acc= 0.745155 Val acc= 0.744490\n",
            "Epoch 3624: Training loss= 0.093732 Val loss= 0.350388 Training acc= 0.745145 Val acc= 0.744500\n",
            "Epoch 3625: Training loss= 0.093727 Val loss= 0.350330 Training acc= 0.745170 Val acc= 0.744520\n",
            "Epoch 3626: Training loss= 0.093722 Val loss= 0.350272 Training acc= 0.745170 Val acc= 0.744530\n",
            "Epoch 3627: Training loss= 0.093717 Val loss= 0.350214 Training acc= 0.745175 Val acc= 0.744535\n",
            "Epoch 3628: Training loss= 0.093712 Val loss= 0.350156 Training acc= 0.745190 Val acc= 0.744550\n",
            "Epoch 3629: Training loss= 0.093707 Val loss= 0.350098 Training acc= 0.745200 Val acc= 0.744550\n",
            "Epoch 3630: Training loss= 0.093702 Val loss= 0.350041 Training acc= 0.745220 Val acc= 0.744560\n",
            "Epoch 3631: Training loss= 0.093697 Val loss= 0.349983 Training acc= 0.745240 Val acc= 0.744575\n",
            "Epoch 3632: Training loss= 0.093692 Val loss= 0.349925 Training acc= 0.745245 Val acc= 0.744575\n",
            "Epoch 3633: Training loss= 0.093687 Val loss= 0.349868 Training acc= 0.745255 Val acc= 0.744585\n",
            "Epoch 3634: Training loss= 0.093682 Val loss= 0.349810 Training acc= 0.745255 Val acc= 0.744575\n",
            "Epoch 3635: Training loss= 0.093677 Val loss= 0.349752 Training acc= 0.745265 Val acc= 0.744585\n",
            "Epoch 3636: Training loss= 0.093672 Val loss= 0.349695 Training acc= 0.745275 Val acc= 0.744595\n",
            "Epoch 3637: Training loss= 0.093667 Val loss= 0.349637 Training acc= 0.745265 Val acc= 0.744595\n",
            "Epoch 3638: Training loss= 0.093662 Val loss= 0.349580 Training acc= 0.745280 Val acc= 0.744605\n",
            "Epoch 3639: Training loss= 0.093657 Val loss= 0.349522 Training acc= 0.745270 Val acc= 0.744600\n",
            "Epoch 3640: Training loss= 0.093652 Val loss= 0.349465 Training acc= 0.745290 Val acc= 0.744615\n",
            "Epoch 3641: Training loss= 0.093647 Val loss= 0.349407 Training acc= 0.745305 Val acc= 0.744625\n",
            "Epoch 3642: Training loss= 0.093642 Val loss= 0.349350 Training acc= 0.745305 Val acc= 0.744635\n",
            "Epoch 3643: Training loss= 0.093637 Val loss= 0.349292 Training acc= 0.745325 Val acc= 0.744655\n",
            "Epoch 3644: Training loss= 0.093632 Val loss= 0.349235 Training acc= 0.745345 Val acc= 0.744675\n",
            "Epoch 3645: Training loss= 0.093627 Val loss= 0.349178 Training acc= 0.745355 Val acc= 0.744690\n",
            "Epoch 3646: Training loss= 0.093622 Val loss= 0.349120 Training acc= 0.745355 Val acc= 0.744695\n",
            "Epoch 3647: Training loss= 0.093617 Val loss= 0.349063 Training acc= 0.745360 Val acc= 0.744685\n",
            "Epoch 3648: Training loss= 0.093612 Val loss= 0.349006 Training acc= 0.745400 Val acc= 0.744720\n",
            "Epoch 3649: Training loss= 0.093607 Val loss= 0.348948 Training acc= 0.745395 Val acc= 0.744715\n",
            "Epoch 3650: Training loss= 0.093602 Val loss= 0.348891 Training acc= 0.745405 Val acc= 0.744715\n",
            "Epoch 3651: Training loss= 0.093597 Val loss= 0.348834 Training acc= 0.745395 Val acc= 0.744715\n",
            "Epoch 3652: Training loss= 0.093592 Val loss= 0.348777 Training acc= 0.745405 Val acc= 0.744720\n",
            "Epoch 3653: Training loss= 0.093587 Val loss= 0.348719 Training acc= 0.745430 Val acc= 0.744740\n",
            "Epoch 3654: Training loss= 0.093582 Val loss= 0.348662 Training acc= 0.745450 Val acc= 0.744755\n",
            "Epoch 3655: Training loss= 0.093577 Val loss= 0.348605 Training acc= 0.745485 Val acc= 0.744770\n",
            "Epoch 3656: Training loss= 0.093572 Val loss= 0.348548 Training acc= 0.745500 Val acc= 0.744790\n",
            "Epoch 3657: Training loss= 0.093567 Val loss= 0.348491 Training acc= 0.745520 Val acc= 0.744815\n",
            "Epoch 3658: Training loss= 0.093562 Val loss= 0.348434 Training acc= 0.745540 Val acc= 0.744830\n",
            "Epoch 3659: Training loss= 0.093557 Val loss= 0.348377 Training acc= 0.745560 Val acc= 0.744825\n",
            "Epoch 3660: Training loss= 0.093552 Val loss= 0.348320 Training acc= 0.745595 Val acc= 0.744835\n",
            "Epoch 3661: Training loss= 0.093547 Val loss= 0.348263 Training acc= 0.745610 Val acc= 0.744850\n",
            "Epoch 3662: Training loss= 0.093542 Val loss= 0.348206 Training acc= 0.745625 Val acc= 0.744865\n",
            "Epoch 3663: Training loss= 0.093537 Val loss= 0.348149 Training acc= 0.745630 Val acc= 0.744860\n",
            "Epoch 3664: Training loss= 0.093532 Val loss= 0.348092 Training acc= 0.745650 Val acc= 0.744895\n",
            "Epoch 3665: Training loss= 0.093527 Val loss= 0.348035 Training acc= 0.745655 Val acc= 0.744905\n",
            "Epoch 3666: Training loss= 0.093522 Val loss= 0.347978 Training acc= 0.745645 Val acc= 0.744895\n",
            "Epoch 3667: Training loss= 0.093517 Val loss= 0.347921 Training acc= 0.745640 Val acc= 0.744905\n",
            "Epoch 3668: Training loss= 0.093512 Val loss= 0.347865 Training acc= 0.745680 Val acc= 0.744945\n",
            "Epoch 3669: Training loss= 0.093507 Val loss= 0.347808 Training acc= 0.745695 Val acc= 0.744965\n",
            "Epoch 3670: Training loss= 0.093502 Val loss= 0.347751 Training acc= 0.745695 Val acc= 0.744975\n",
            "Epoch 3671: Training loss= 0.093497 Val loss= 0.347694 Training acc= 0.745695 Val acc= 0.744975\n",
            "Epoch 3672: Training loss= 0.093493 Val loss= 0.347638 Training acc= 0.745695 Val acc= 0.744970\n",
            "Epoch 3673: Training loss= 0.093488 Val loss= 0.347581 Training acc= 0.745690 Val acc= 0.744970\n",
            "Epoch 3674: Training loss= 0.093483 Val loss= 0.347524 Training acc= 0.745690 Val acc= 0.744985\n",
            "Epoch 3675: Training loss= 0.093478 Val loss= 0.347468 Training acc= 0.745690 Val acc= 0.744995\n",
            "Epoch 3676: Training loss= 0.093473 Val loss= 0.347411 Training acc= 0.745690 Val acc= 0.745010\n",
            "Epoch 3677: Training loss= 0.093468 Val loss= 0.347354 Training acc= 0.745700 Val acc= 0.745025\n",
            "Epoch 3678: Training loss= 0.093463 Val loss= 0.347298 Training acc= 0.745710 Val acc= 0.745045\n",
            "Epoch 3679: Training loss= 0.093458 Val loss= 0.347241 Training acc= 0.745725 Val acc= 0.745050\n",
            "Epoch 3680: Training loss= 0.093453 Val loss= 0.347185 Training acc= 0.745735 Val acc= 0.745060\n",
            "Epoch 3681: Training loss= 0.093448 Val loss= 0.347128 Training acc= 0.745745 Val acc= 0.745070\n",
            "Epoch 3682: Training loss= 0.093443 Val loss= 0.347072 Training acc= 0.745750 Val acc= 0.745080\n",
            "Epoch 3683: Training loss= 0.093438 Val loss= 0.347015 Training acc= 0.745760 Val acc= 0.745095\n",
            "Epoch 3684: Training loss= 0.093434 Val loss= 0.346959 Training acc= 0.745775 Val acc= 0.745115\n",
            "Epoch 3685: Training loss= 0.093429 Val loss= 0.346902 Training acc= 0.745795 Val acc= 0.745135\n",
            "Epoch 3686: Training loss= 0.093424 Val loss= 0.346846 Training acc= 0.745815 Val acc= 0.745150\n",
            "Epoch 3687: Training loss= 0.093419 Val loss= 0.346790 Training acc= 0.745825 Val acc= 0.745155\n",
            "Epoch 3688: Training loss= 0.093414 Val loss= 0.346733 Training acc= 0.745820 Val acc= 0.745170\n",
            "Epoch 3689: Training loss= 0.093409 Val loss= 0.346677 Training acc= 0.745845 Val acc= 0.745195\n",
            "Epoch 3690: Training loss= 0.093404 Val loss= 0.346621 Training acc= 0.745840 Val acc= 0.745190\n",
            "Epoch 3691: Training loss= 0.093399 Val loss= 0.346564 Training acc= 0.745855 Val acc= 0.745195\n",
            "Epoch 3692: Training loss= 0.093394 Val loss= 0.346508 Training acc= 0.745855 Val acc= 0.745195\n",
            "Epoch 3693: Training loss= 0.093390 Val loss= 0.346452 Training acc= 0.745865 Val acc= 0.745200\n",
            "Epoch 3694: Training loss= 0.093385 Val loss= 0.346396 Training acc= 0.745870 Val acc= 0.745200\n",
            "Epoch 3695: Training loss= 0.093380 Val loss= 0.346339 Training acc= 0.745890 Val acc= 0.745215\n",
            "Epoch 3696: Training loss= 0.093375 Val loss= 0.346283 Training acc= 0.745900 Val acc= 0.745235\n",
            "Epoch 3697: Training loss= 0.093370 Val loss= 0.346227 Training acc= 0.745905 Val acc= 0.745245\n",
            "Epoch 3698: Training loss= 0.093365 Val loss= 0.346171 Training acc= 0.745895 Val acc= 0.745240\n",
            "Epoch 3699: Training loss= 0.093360 Val loss= 0.346115 Training acc= 0.745895 Val acc= 0.745250\n",
            "Epoch 3700: Training loss= 0.093355 Val loss= 0.346059 Training acc= 0.745915 Val acc= 0.745260\n",
            "Epoch 3701: Training loss= 0.093351 Val loss= 0.346003 Training acc= 0.745910 Val acc= 0.745260\n",
            "Epoch 3702: Training loss= 0.093346 Val loss= 0.345947 Training acc= 0.745920 Val acc= 0.745260\n",
            "Epoch 3703: Training loss= 0.093341 Val loss= 0.345891 Training acc= 0.745930 Val acc= 0.745260\n",
            "Epoch 3704: Training loss= 0.093336 Val loss= 0.345835 Training acc= 0.745925 Val acc= 0.745255\n",
            "Epoch 3705: Training loss= 0.093331 Val loss= 0.345779 Training acc= 0.745935 Val acc= 0.745255\n",
            "Epoch 3706: Training loss= 0.093326 Val loss= 0.345723 Training acc= 0.745940 Val acc= 0.745265\n",
            "Epoch 3707: Training loss= 0.093321 Val loss= 0.345667 Training acc= 0.745950 Val acc= 0.745260\n",
            "Epoch 3708: Training loss= 0.093317 Val loss= 0.345611 Training acc= 0.745980 Val acc= 0.745280\n",
            "Epoch 3709: Training loss= 0.093312 Val loss= 0.345556 Training acc= 0.745995 Val acc= 0.745295\n",
            "Epoch 3710: Training loss= 0.093307 Val loss= 0.345500 Training acc= 0.745985 Val acc= 0.745300\n",
            "Epoch 3711: Training loss= 0.093302 Val loss= 0.345444 Training acc= 0.745980 Val acc= 0.745300\n",
            "Epoch 3712: Training loss= 0.093297 Val loss= 0.345388 Training acc= 0.745980 Val acc= 0.745315\n",
            "Epoch 3713: Training loss= 0.093292 Val loss= 0.345332 Training acc= 0.745975 Val acc= 0.745315\n",
            "Epoch 3714: Training loss= 0.093288 Val loss= 0.345277 Training acc= 0.745960 Val acc= 0.745305\n",
            "Epoch 3715: Training loss= 0.093283 Val loss= 0.345221 Training acc= 0.745975 Val acc= 0.745320\n",
            "Epoch 3716: Training loss= 0.093278 Val loss= 0.345165 Training acc= 0.745985 Val acc= 0.745315\n",
            "Epoch 3717: Training loss= 0.093273 Val loss= 0.345110 Training acc= 0.745995 Val acc= 0.745325\n",
            "Epoch 3718: Training loss= 0.093268 Val loss= 0.345054 Training acc= 0.746000 Val acc= 0.745310\n",
            "Epoch 3719: Training loss= 0.093263 Val loss= 0.344998 Training acc= 0.746015 Val acc= 0.745325\n",
            "Epoch 3720: Training loss= 0.093259 Val loss= 0.344943 Training acc= 0.746030 Val acc= 0.745330\n",
            "Epoch 3721: Training loss= 0.093254 Val loss= 0.344887 Training acc= 0.746035 Val acc= 0.745340\n",
            "Epoch 3722: Training loss= 0.093249 Val loss= 0.344832 Training acc= 0.746045 Val acc= 0.745345\n",
            "Epoch 3723: Training loss= 0.093244 Val loss= 0.344776 Training acc= 0.746065 Val acc= 0.745360\n",
            "Epoch 3724: Training loss= 0.093239 Val loss= 0.344721 Training acc= 0.746095 Val acc= 0.745395\n",
            "Epoch 3725: Training loss= 0.093235 Val loss= 0.344665 Training acc= 0.746095 Val acc= 0.745390\n",
            "Epoch 3726: Training loss= 0.093230 Val loss= 0.344610 Training acc= 0.746100 Val acc= 0.745395\n",
            "Epoch 3727: Training loss= 0.093225 Val loss= 0.344554 Training acc= 0.746115 Val acc= 0.745410\n",
            "Epoch 3728: Training loss= 0.093220 Val loss= 0.344499 Training acc= 0.746135 Val acc= 0.745435\n",
            "Epoch 3729: Training loss= 0.093215 Val loss= 0.344443 Training acc= 0.746135 Val acc= 0.745430\n",
            "Epoch 3730: Training loss= 0.093211 Val loss= 0.344388 Training acc= 0.746145 Val acc= 0.745435\n",
            "Epoch 3731: Training loss= 0.093206 Val loss= 0.344333 Training acc= 0.746175 Val acc= 0.745455\n",
            "Epoch 3732: Training loss= 0.093201 Val loss= 0.344277 Training acc= 0.746175 Val acc= 0.745465\n",
            "Epoch 3733: Training loss= 0.093196 Val loss= 0.344222 Training acc= 0.746200 Val acc= 0.745475\n",
            "Epoch 3734: Training loss= 0.093191 Val loss= 0.344167 Training acc= 0.746215 Val acc= 0.745500\n",
            "Epoch 3735: Training loss= 0.093187 Val loss= 0.344112 Training acc= 0.746220 Val acc= 0.745510\n",
            "Epoch 3736: Training loss= 0.093182 Val loss= 0.344056 Training acc= 0.746225 Val acc= 0.745500\n",
            "Epoch 3737: Training loss= 0.093177 Val loss= 0.344001 Training acc= 0.746220 Val acc= 0.745500\n",
            "Epoch 3738: Training loss= 0.093172 Val loss= 0.343946 Training acc= 0.746220 Val acc= 0.745510\n",
            "Epoch 3739: Training loss= 0.093168 Val loss= 0.343891 Training acc= 0.746220 Val acc= 0.745510\n",
            "Epoch 3740: Training loss= 0.093163 Val loss= 0.343836 Training acc= 0.746240 Val acc= 0.745520\n",
            "Epoch 3741: Training loss= 0.093158 Val loss= 0.343781 Training acc= 0.746255 Val acc= 0.745530\n",
            "Epoch 3742: Training loss= 0.093153 Val loss= 0.343726 Training acc= 0.746250 Val acc= 0.745540\n",
            "Epoch 3743: Training loss= 0.093148 Val loss= 0.343671 Training acc= 0.746255 Val acc= 0.745545\n",
            "Epoch 3744: Training loss= 0.093144 Val loss= 0.343616 Training acc= 0.746255 Val acc= 0.745540\n",
            "Epoch 3745: Training loss= 0.093139 Val loss= 0.343560 Training acc= 0.746240 Val acc= 0.745535\n",
            "Epoch 3746: Training loss= 0.093134 Val loss= 0.343506 Training acc= 0.746245 Val acc= 0.745550\n",
            "Epoch 3747: Training loss= 0.093129 Val loss= 0.343451 Training acc= 0.746270 Val acc= 0.745575\n",
            "Epoch 3748: Training loss= 0.093125 Val loss= 0.343396 Training acc= 0.746275 Val acc= 0.745580\n",
            "Epoch 3749: Training loss= 0.093120 Val loss= 0.343341 Training acc= 0.746270 Val acc= 0.745580\n",
            "Epoch 3750: Training loss= 0.093115 Val loss= 0.343286 Training acc= 0.746270 Val acc= 0.745590\n",
            "Epoch 3751: Training loss= 0.093110 Val loss= 0.343231 Training acc= 0.746275 Val acc= 0.745590\n",
            "Epoch 3752: Training loss= 0.093106 Val loss= 0.343176 Training acc= 0.746280 Val acc= 0.745595\n",
            "Epoch 3753: Training loss= 0.093101 Val loss= 0.343121 Training acc= 0.746305 Val acc= 0.745630\n",
            "Epoch 3754: Training loss= 0.093096 Val loss= 0.343066 Training acc= 0.746320 Val acc= 0.745665\n",
            "Epoch 3755: Training loss= 0.093091 Val loss= 0.343012 Training acc= 0.746310 Val acc= 0.745665\n",
            "Epoch 3756: Training loss= 0.093087 Val loss= 0.342957 Training acc= 0.746330 Val acc= 0.745695\n",
            "Epoch 3757: Training loss= 0.093082 Val loss= 0.342902 Training acc= 0.746330 Val acc= 0.745690\n",
            "Epoch 3758: Training loss= 0.093077 Val loss= 0.342847 Training acc= 0.746320 Val acc= 0.745690\n",
            "Epoch 3759: Training loss= 0.093073 Val loss= 0.342793 Training acc= 0.746350 Val acc= 0.745710\n",
            "Epoch 3760: Training loss= 0.093068 Val loss= 0.342738 Training acc= 0.746365 Val acc= 0.745730\n",
            "Epoch 3761: Training loss= 0.093063 Val loss= 0.342683 Training acc= 0.746385 Val acc= 0.745750\n",
            "Epoch 3762: Training loss= 0.093058 Val loss= 0.342629 Training acc= 0.746380 Val acc= 0.745745\n",
            "Epoch 3763: Training loss= 0.093054 Val loss= 0.342574 Training acc= 0.746385 Val acc= 0.745745\n",
            "Epoch 3764: Training loss= 0.093049 Val loss= 0.342520 Training acc= 0.746385 Val acc= 0.745760\n",
            "Epoch 3765: Training loss= 0.093044 Val loss= 0.342465 Training acc= 0.746410 Val acc= 0.745790\n",
            "Epoch 3766: Training loss= 0.093040 Val loss= 0.342410 Training acc= 0.746440 Val acc= 0.745815\n",
            "Epoch 3767: Training loss= 0.093035 Val loss= 0.342356 Training acc= 0.746465 Val acc= 0.745840\n",
            "Epoch 3768: Training loss= 0.093030 Val loss= 0.342301 Training acc= 0.746480 Val acc= 0.745855\n",
            "Epoch 3769: Training loss= 0.093025 Val loss= 0.342247 Training acc= 0.746495 Val acc= 0.745870\n",
            "Epoch 3770: Training loss= 0.093021 Val loss= 0.342193 Training acc= 0.746530 Val acc= 0.745900\n",
            "Epoch 3771: Training loss= 0.093016 Val loss= 0.342138 Training acc= 0.746525 Val acc= 0.745900\n",
            "Epoch 3772: Training loss= 0.093011 Val loss= 0.342084 Training acc= 0.746545 Val acc= 0.745920\n",
            "Epoch 3773: Training loss= 0.093007 Val loss= 0.342029 Training acc= 0.746555 Val acc= 0.745940\n",
            "Epoch 3774: Training loss= 0.093002 Val loss= 0.341975 Training acc= 0.746535 Val acc= 0.745940\n",
            "Epoch 3775: Training loss= 0.092997 Val loss= 0.341921 Training acc= 0.746555 Val acc= 0.745960\n",
            "Epoch 3776: Training loss= 0.092993 Val loss= 0.341866 Training acc= 0.746555 Val acc= 0.745970\n",
            "Epoch 3777: Training loss= 0.092988 Val loss= 0.341812 Training acc= 0.746575 Val acc= 0.745985\n",
            "Epoch 3778: Training loss= 0.092983 Val loss= 0.341758 Training acc= 0.746580 Val acc= 0.745985\n",
            "Epoch 3779: Training loss= 0.092978 Val loss= 0.341704 Training acc= 0.746600 Val acc= 0.746005\n",
            "Epoch 3780: Training loss= 0.092974 Val loss= 0.341649 Training acc= 0.746605 Val acc= 0.746020\n",
            "Epoch 3781: Training loss= 0.092969 Val loss= 0.341595 Training acc= 0.746620 Val acc= 0.746025\n",
            "Epoch 3782: Training loss= 0.092964 Val loss= 0.341541 Training acc= 0.746630 Val acc= 0.746030\n",
            "Epoch 3783: Training loss= 0.092960 Val loss= 0.341487 Training acc= 0.746645 Val acc= 0.746050\n",
            "Epoch 3784: Training loss= 0.092955 Val loss= 0.341433 Training acc= 0.746670 Val acc= 0.746060\n",
            "Epoch 3785: Training loss= 0.092950 Val loss= 0.341379 Training acc= 0.746675 Val acc= 0.746070\n",
            "Epoch 3786: Training loss= 0.092946 Val loss= 0.341324 Training acc= 0.746685 Val acc= 0.746090\n",
            "Epoch 3787: Training loss= 0.092941 Val loss= 0.341270 Training acc= 0.746690 Val acc= 0.746100\n",
            "Epoch 3788: Training loss= 0.092936 Val loss= 0.341216 Training acc= 0.746685 Val acc= 0.746095\n",
            "Epoch 3789: Training loss= 0.092932 Val loss= 0.341162 Training acc= 0.746700 Val acc= 0.746110\n",
            "Epoch 3790: Training loss= 0.092927 Val loss= 0.341108 Training acc= 0.746705 Val acc= 0.746135\n",
            "Epoch 3791: Training loss= 0.092922 Val loss= 0.341054 Training acc= 0.746710 Val acc= 0.746145\n",
            "Epoch 3792: Training loss= 0.092918 Val loss= 0.341000 Training acc= 0.746730 Val acc= 0.746160\n",
            "Epoch 3793: Training loss= 0.092913 Val loss= 0.340947 Training acc= 0.746725 Val acc= 0.746160\n",
            "Epoch 3794: Training loss= 0.092908 Val loss= 0.340893 Training acc= 0.746725 Val acc= 0.746165\n",
            "Epoch 3795: Training loss= 0.092904 Val loss= 0.340839 Training acc= 0.746740 Val acc= 0.746180\n",
            "Epoch 3796: Training loss= 0.092899 Val loss= 0.340785 Training acc= 0.746770 Val acc= 0.746210\n",
            "Epoch 3797: Training loss= 0.092895 Val loss= 0.340731 Training acc= 0.746785 Val acc= 0.746240\n",
            "Epoch 3798: Training loss= 0.092890 Val loss= 0.340677 Training acc= 0.746780 Val acc= 0.746250\n",
            "Epoch 3799: Training loss= 0.092885 Val loss= 0.340623 Training acc= 0.746775 Val acc= 0.746245\n",
            "Epoch 3800: Training loss= 0.092881 Val loss= 0.340570 Training acc= 0.746780 Val acc= 0.746245\n",
            "Epoch 3801: Training loss= 0.092876 Val loss= 0.340516 Training acc= 0.746785 Val acc= 0.746250\n",
            "Epoch 3802: Training loss= 0.092871 Val loss= 0.340462 Training acc= 0.746800 Val acc= 0.746270\n",
            "Epoch 3803: Training loss= 0.092867 Val loss= 0.340408 Training acc= 0.746820 Val acc= 0.746285\n",
            "Epoch 3804: Training loss= 0.092862 Val loss= 0.340355 Training acc= 0.746825 Val acc= 0.746300\n",
            "Epoch 3805: Training loss= 0.092857 Val loss= 0.340301 Training acc= 0.746830 Val acc= 0.746300\n",
            "Epoch 3806: Training loss= 0.092853 Val loss= 0.340247 Training acc= 0.746840 Val acc= 0.746300\n",
            "Epoch 3807: Training loss= 0.092848 Val loss= 0.340194 Training acc= 0.746845 Val acc= 0.746305\n",
            "Epoch 3808: Training loss= 0.092844 Val loss= 0.340140 Training acc= 0.746850 Val acc= 0.746310\n",
            "Epoch 3809: Training loss= 0.092839 Val loss= 0.340087 Training acc= 0.746855 Val acc= 0.746320\n",
            "Epoch 3810: Training loss= 0.092834 Val loss= 0.340033 Training acc= 0.746855 Val acc= 0.746320\n",
            "Epoch 3811: Training loss= 0.092830 Val loss= 0.339980 Training acc= 0.746850 Val acc= 0.746315\n",
            "Epoch 3812: Training loss= 0.092825 Val loss= 0.339926 Training acc= 0.746850 Val acc= 0.746310\n",
            "Epoch 3813: Training loss= 0.092821 Val loss= 0.339873 Training acc= 0.746860 Val acc= 0.746330\n",
            "Epoch 3814: Training loss= 0.092816 Val loss= 0.339819 Training acc= 0.746870 Val acc= 0.746340\n",
            "Epoch 3815: Training loss= 0.092811 Val loss= 0.339766 Training acc= 0.746890 Val acc= 0.746355\n",
            "Epoch 3816: Training loss= 0.092807 Val loss= 0.339712 Training acc= 0.746885 Val acc= 0.746360\n",
            "Epoch 3817: Training loss= 0.092802 Val loss= 0.339659 Training acc= 0.746890 Val acc= 0.746370\n",
            "Epoch 3818: Training loss= 0.092798 Val loss= 0.339605 Training acc= 0.746875 Val acc= 0.746365\n",
            "Epoch 3819: Training loss= 0.092793 Val loss= 0.339552 Training acc= 0.746900 Val acc= 0.746380\n",
            "Epoch 3820: Training loss= 0.092788 Val loss= 0.339499 Training acc= 0.746905 Val acc= 0.746380\n",
            "Epoch 3821: Training loss= 0.092784 Val loss= 0.339445 Training acc= 0.746920 Val acc= 0.746390\n",
            "Epoch 3822: Training loss= 0.092779 Val loss= 0.339392 Training acc= 0.746945 Val acc= 0.746415\n",
            "Epoch 3823: Training loss= 0.092775 Val loss= 0.339339 Training acc= 0.746945 Val acc= 0.746425\n",
            "Epoch 3824: Training loss= 0.092770 Val loss= 0.339286 Training acc= 0.746970 Val acc= 0.746455\n",
            "Epoch 3825: Training loss= 0.092765 Val loss= 0.339232 Training acc= 0.746985 Val acc= 0.746475\n",
            "Epoch 3826: Training loss= 0.092761 Val loss= 0.339179 Training acc= 0.746995 Val acc= 0.746490\n",
            "Epoch 3827: Training loss= 0.092756 Val loss= 0.339126 Training acc= 0.747020 Val acc= 0.746520\n",
            "Epoch 3828: Training loss= 0.092752 Val loss= 0.339073 Training acc= 0.747035 Val acc= 0.746535\n",
            "Epoch 3829: Training loss= 0.092747 Val loss= 0.339020 Training acc= 0.747040 Val acc= 0.746550\n",
            "Epoch 3830: Training loss= 0.092742 Val loss= 0.338967 Training acc= 0.747055 Val acc= 0.746565\n",
            "Epoch 3831: Training loss= 0.092738 Val loss= 0.338913 Training acc= 0.747050 Val acc= 0.746545\n",
            "Epoch 3832: Training loss= 0.092733 Val loss= 0.338860 Training acc= 0.747050 Val acc= 0.746550\n",
            "Epoch 3833: Training loss= 0.092729 Val loss= 0.338807 Training acc= 0.747065 Val acc= 0.746555\n",
            "Epoch 3834: Training loss= 0.092724 Val loss= 0.338754 Training acc= 0.747060 Val acc= 0.746555\n",
            "Epoch 3835: Training loss= 0.092720 Val loss= 0.338701 Training acc= 0.747085 Val acc= 0.746570\n",
            "Epoch 3836: Training loss= 0.092715 Val loss= 0.338648 Training acc= 0.747075 Val acc= 0.746580\n",
            "Epoch 3837: Training loss= 0.092711 Val loss= 0.338595 Training acc= 0.747090 Val acc= 0.746590\n",
            "Epoch 3838: Training loss= 0.092706 Val loss= 0.338542 Training acc= 0.747100 Val acc= 0.746595\n",
            "Epoch 3839: Training loss= 0.092701 Val loss= 0.338489 Training acc= 0.747105 Val acc= 0.746595\n",
            "Epoch 3840: Training loss= 0.092697 Val loss= 0.338437 Training acc= 0.747115 Val acc= 0.746600\n",
            "Epoch 3841: Training loss= 0.092692 Val loss= 0.338384 Training acc= 0.747125 Val acc= 0.746620\n",
            "Epoch 3842: Training loss= 0.092688 Val loss= 0.338331 Training acc= 0.747135 Val acc= 0.746630\n",
            "Epoch 3843: Training loss= 0.092683 Val loss= 0.338278 Training acc= 0.747140 Val acc= 0.746630\n",
            "Epoch 3844: Training loss= 0.092679 Val loss= 0.338225 Training acc= 0.747145 Val acc= 0.746635\n",
            "Epoch 3845: Training loss= 0.092674 Val loss= 0.338172 Training acc= 0.747165 Val acc= 0.746640\n",
            "Epoch 3846: Training loss= 0.092670 Val loss= 0.338120 Training acc= 0.747185 Val acc= 0.746660\n",
            "Epoch 3847: Training loss= 0.092665 Val loss= 0.338067 Training acc= 0.747180 Val acc= 0.746655\n",
            "Epoch 3848: Training loss= 0.092661 Val loss= 0.338014 Training acc= 0.747185 Val acc= 0.746660\n",
            "Epoch 3849: Training loss= 0.092656 Val loss= 0.337961 Training acc= 0.747200 Val acc= 0.746675\n",
            "Epoch 3850: Training loss= 0.092651 Val loss= 0.337909 Training acc= 0.747230 Val acc= 0.746700\n",
            "Epoch 3851: Training loss= 0.092647 Val loss= 0.337856 Training acc= 0.747230 Val acc= 0.746710\n",
            "Epoch 3852: Training loss= 0.092642 Val loss= 0.337803 Training acc= 0.747240 Val acc= 0.746715\n",
            "Epoch 3853: Training loss= 0.092638 Val loss= 0.337751 Training acc= 0.747230 Val acc= 0.746710\n",
            "Epoch 3854: Training loss= 0.092633 Val loss= 0.337698 Training acc= 0.747240 Val acc= 0.746720\n",
            "Epoch 3855: Training loss= 0.092629 Val loss= 0.337646 Training acc= 0.747245 Val acc= 0.746725\n",
            "Epoch 3856: Training loss= 0.092624 Val loss= 0.337593 Training acc= 0.747250 Val acc= 0.746735\n",
            "Epoch 3857: Training loss= 0.092620 Val loss= 0.337540 Training acc= 0.747255 Val acc= 0.746745\n",
            "Epoch 3858: Training loss= 0.092615 Val loss= 0.337488 Training acc= 0.747250 Val acc= 0.746740\n",
            "Epoch 3859: Training loss= 0.092611 Val loss= 0.337435 Training acc= 0.747275 Val acc= 0.746770\n",
            "Epoch 3860: Training loss= 0.092606 Val loss= 0.337383 Training acc= 0.747285 Val acc= 0.746770\n",
            "Epoch 3861: Training loss= 0.092602 Val loss= 0.337331 Training acc= 0.747310 Val acc= 0.746785\n",
            "Epoch 3862: Training loss= 0.092597 Val loss= 0.337278 Training acc= 0.747335 Val acc= 0.746810\n",
            "Epoch 3863: Training loss= 0.092593 Val loss= 0.337226 Training acc= 0.747360 Val acc= 0.746835\n",
            "Epoch 3864: Training loss= 0.092588 Val loss= 0.337173 Training acc= 0.747365 Val acc= 0.746850\n",
            "Epoch 3865: Training loss= 0.092584 Val loss= 0.337121 Training acc= 0.747375 Val acc= 0.746870\n",
            "Epoch 3866: Training loss= 0.092579 Val loss= 0.337069 Training acc= 0.747380 Val acc= 0.746885\n",
            "Epoch 3867: Training loss= 0.092575 Val loss= 0.337016 Training acc= 0.747410 Val acc= 0.746905\n",
            "Epoch 3868: Training loss= 0.092570 Val loss= 0.336964 Training acc= 0.747425 Val acc= 0.746920\n",
            "Epoch 3869: Training loss= 0.092566 Val loss= 0.336912 Training acc= 0.747445 Val acc= 0.746935\n",
            "Epoch 3870: Training loss= 0.092561 Val loss= 0.336859 Training acc= 0.747445 Val acc= 0.746945\n",
            "Epoch 3871: Training loss= 0.092557 Val loss= 0.336807 Training acc= 0.747480 Val acc= 0.746975\n",
            "Epoch 3872: Training loss= 0.092552 Val loss= 0.336755 Training acc= 0.747485 Val acc= 0.746980\n",
            "Epoch 3873: Training loss= 0.092548 Val loss= 0.336703 Training acc= 0.747480 Val acc= 0.746965\n",
            "Epoch 3874: Training loss= 0.092543 Val loss= 0.336651 Training acc= 0.747490 Val acc= 0.746975\n",
            "Epoch 3875: Training loss= 0.092539 Val loss= 0.336598 Training acc= 0.747510 Val acc= 0.746995\n",
            "Epoch 3876: Training loss= 0.092534 Val loss= 0.336546 Training acc= 0.747520 Val acc= 0.747010\n",
            "Epoch 3877: Training loss= 0.092530 Val loss= 0.336494 Training acc= 0.747530 Val acc= 0.747015\n",
            "Epoch 3878: Training loss= 0.092526 Val loss= 0.336442 Training acc= 0.747535 Val acc= 0.747025\n",
            "Epoch 3879: Training loss= 0.092521 Val loss= 0.336390 Training acc= 0.747555 Val acc= 0.747030\n",
            "Epoch 3880: Training loss= 0.092517 Val loss= 0.336338 Training acc= 0.747585 Val acc= 0.747045\n",
            "Epoch 3881: Training loss= 0.092512 Val loss= 0.336286 Training acc= 0.747600 Val acc= 0.747050\n",
            "Epoch 3882: Training loss= 0.092508 Val loss= 0.336234 Training acc= 0.747595 Val acc= 0.747045\n",
            "Epoch 3883: Training loss= 0.092503 Val loss= 0.336182 Training acc= 0.747600 Val acc= 0.747055\n",
            "Epoch 3884: Training loss= 0.092499 Val loss= 0.336130 Training acc= 0.747635 Val acc= 0.747080\n",
            "Epoch 3885: Training loss= 0.092494 Val loss= 0.336078 Training acc= 0.747660 Val acc= 0.747090\n",
            "Epoch 3886: Training loss= 0.092490 Val loss= 0.336026 Training acc= 0.747675 Val acc= 0.747100\n",
            "Epoch 3887: Training loss= 0.092485 Val loss= 0.335974 Training acc= 0.747665 Val acc= 0.747090\n",
            "Epoch 3888: Training loss= 0.092481 Val loss= 0.335922 Training acc= 0.747665 Val acc= 0.747095\n",
            "Epoch 3889: Training loss= 0.092476 Val loss= 0.335870 Training acc= 0.747650 Val acc= 0.747085\n",
            "Epoch 3890: Training loss= 0.092472 Val loss= 0.335819 Training acc= 0.747635 Val acc= 0.747090\n",
            "Epoch 3891: Training loss= 0.092468 Val loss= 0.335767 Training acc= 0.747650 Val acc= 0.747090\n",
            "Epoch 3892: Training loss= 0.092463 Val loss= 0.335715 Training acc= 0.747670 Val acc= 0.747115\n",
            "Epoch 3893: Training loss= 0.092459 Val loss= 0.335663 Training acc= 0.747685 Val acc= 0.747140\n",
            "Epoch 3894: Training loss= 0.092454 Val loss= 0.335611 Training acc= 0.747690 Val acc= 0.747135\n",
            "Epoch 3895: Training loss= 0.092450 Val loss= 0.335560 Training acc= 0.747700 Val acc= 0.747145\n",
            "Epoch 3896: Training loss= 0.092445 Val loss= 0.335508 Training acc= 0.747720 Val acc= 0.747180\n",
            "Epoch 3897: Training loss= 0.092441 Val loss= 0.335456 Training acc= 0.747755 Val acc= 0.747210\n",
            "Epoch 3898: Training loss= 0.092437 Val loss= 0.335405 Training acc= 0.747770 Val acc= 0.747225\n",
            "Epoch 3899: Training loss= 0.092432 Val loss= 0.335353 Training acc= 0.747785 Val acc= 0.747235\n",
            "Epoch 3900: Training loss= 0.092428 Val loss= 0.335301 Training acc= 0.747805 Val acc= 0.747250\n",
            "Epoch 3901: Training loss= 0.092423 Val loss= 0.335250 Training acc= 0.747795 Val acc= 0.747250\n",
            "Epoch 3902: Training loss= 0.092419 Val loss= 0.335198 Training acc= 0.747800 Val acc= 0.747270\n",
            "Epoch 3903: Training loss= 0.092414 Val loss= 0.335147 Training acc= 0.747810 Val acc= 0.747280\n",
            "Epoch 3904: Training loss= 0.092410 Val loss= 0.335095 Training acc= 0.747830 Val acc= 0.747310\n",
            "Epoch 3905: Training loss= 0.092406 Val loss= 0.335044 Training acc= 0.747850 Val acc= 0.747315\n",
            "Epoch 3906: Training loss= 0.092401 Val loss= 0.334992 Training acc= 0.747860 Val acc= 0.747330\n",
            "Epoch 3907: Training loss= 0.092397 Val loss= 0.334941 Training acc= 0.747880 Val acc= 0.747345\n",
            "Epoch 3908: Training loss= 0.092392 Val loss= 0.334889 Training acc= 0.747905 Val acc= 0.747360\n",
            "Epoch 3909: Training loss= 0.092388 Val loss= 0.334838 Training acc= 0.747890 Val acc= 0.747335\n",
            "Epoch 3910: Training loss= 0.092384 Val loss= 0.334786 Training acc= 0.747895 Val acc= 0.747335\n",
            "Epoch 3911: Training loss= 0.092379 Val loss= 0.334735 Training acc= 0.747895 Val acc= 0.747340\n",
            "Epoch 3912: Training loss= 0.092375 Val loss= 0.334683 Training acc= 0.747925 Val acc= 0.747375\n",
            "Epoch 3913: Training loss= 0.092370 Val loss= 0.334632 Training acc= 0.747935 Val acc= 0.747385\n",
            "Epoch 3914: Training loss= 0.092366 Val loss= 0.334581 Training acc= 0.747940 Val acc= 0.747395\n",
            "Epoch 3915: Training loss= 0.092362 Val loss= 0.334529 Training acc= 0.747975 Val acc= 0.747420\n",
            "Epoch 3916: Training loss= 0.092357 Val loss= 0.334478 Training acc= 0.747990 Val acc= 0.747435\n",
            "Epoch 3917: Training loss= 0.092353 Val loss= 0.334427 Training acc= 0.748025 Val acc= 0.747455\n",
            "Epoch 3918: Training loss= 0.092348 Val loss= 0.334376 Training acc= 0.748030 Val acc= 0.747465\n",
            "Epoch 3919: Training loss= 0.092344 Val loss= 0.334324 Training acc= 0.748035 Val acc= 0.747470\n",
            "Epoch 3920: Training loss= 0.092340 Val loss= 0.334273 Training acc= 0.748030 Val acc= 0.747465\n",
            "Epoch 3921: Training loss= 0.092335 Val loss= 0.334222 Training acc= 0.748030 Val acc= 0.747460\n",
            "Epoch 3922: Training loss= 0.092331 Val loss= 0.334171 Training acc= 0.748030 Val acc= 0.747470\n",
            "Epoch 3923: Training loss= 0.092326 Val loss= 0.334120 Training acc= 0.748045 Val acc= 0.747495\n",
            "Epoch 3924: Training loss= 0.092322 Val loss= 0.334068 Training acc= 0.748045 Val acc= 0.747495\n",
            "Epoch 3925: Training loss= 0.092318 Val loss= 0.334017 Training acc= 0.748050 Val acc= 0.747500\n",
            "Epoch 3926: Training loss= 0.092313 Val loss= 0.333966 Training acc= 0.748055 Val acc= 0.747500\n",
            "Epoch 3927: Training loss= 0.092309 Val loss= 0.333915 Training acc= 0.748050 Val acc= 0.747510\n",
            "Epoch 3928: Training loss= 0.092305 Val loss= 0.333864 Training acc= 0.748055 Val acc= 0.747515\n",
            "Epoch 3929: Training loss= 0.092300 Val loss= 0.333813 Training acc= 0.748070 Val acc= 0.747525\n",
            "Epoch 3930: Training loss= 0.092296 Val loss= 0.333762 Training acc= 0.748085 Val acc= 0.747545\n",
            "Epoch 3931: Training loss= 0.092291 Val loss= 0.333711 Training acc= 0.748105 Val acc= 0.747560\n",
            "Epoch 3932: Training loss= 0.092287 Val loss= 0.333660 Training acc= 0.748125 Val acc= 0.747575\n",
            "Epoch 3933: Training loss= 0.092283 Val loss= 0.333609 Training acc= 0.748120 Val acc= 0.747575\n",
            "Epoch 3934: Training loss= 0.092278 Val loss= 0.333558 Training acc= 0.748135 Val acc= 0.747585\n",
            "Epoch 3935: Training loss= 0.092274 Val loss= 0.333507 Training acc= 0.748135 Val acc= 0.747585\n",
            "Epoch 3936: Training loss= 0.092270 Val loss= 0.333456 Training acc= 0.748165 Val acc= 0.747600\n",
            "Epoch 3937: Training loss= 0.092265 Val loss= 0.333405 Training acc= 0.748175 Val acc= 0.747605\n",
            "Epoch 3938: Training loss= 0.092261 Val loss= 0.333355 Training acc= 0.748180 Val acc= 0.747605\n",
            "Epoch 3939: Training loss= 0.092257 Val loss= 0.333304 Training acc= 0.748170 Val acc= 0.747595\n",
            "Epoch 3940: Training loss= 0.092252 Val loss= 0.333253 Training acc= 0.748160 Val acc= 0.747590\n",
            "Epoch 3941: Training loss= 0.092248 Val loss= 0.333202 Training acc= 0.748165 Val acc= 0.747600\n",
            "Epoch 3942: Training loss= 0.092244 Val loss= 0.333151 Training acc= 0.748175 Val acc= 0.747620\n",
            "Epoch 3943: Training loss= 0.092239 Val loss= 0.333101 Training acc= 0.748175 Val acc= 0.747620\n",
            "Epoch 3944: Training loss= 0.092235 Val loss= 0.333050 Training acc= 0.748185 Val acc= 0.747630\n",
            "Epoch 3945: Training loss= 0.092231 Val loss= 0.332999 Training acc= 0.748185 Val acc= 0.747635\n",
            "Epoch 3946: Training loss= 0.092226 Val loss= 0.332949 Training acc= 0.748205 Val acc= 0.747650\n",
            "Epoch 3947: Training loss= 0.092222 Val loss= 0.332898 Training acc= 0.748195 Val acc= 0.747645\n",
            "Epoch 3948: Training loss= 0.092218 Val loss= 0.332847 Training acc= 0.748190 Val acc= 0.747640\n",
            "Epoch 3949: Training loss= 0.092213 Val loss= 0.332797 Training acc= 0.748190 Val acc= 0.747640\n",
            "Epoch 3950: Training loss= 0.092209 Val loss= 0.332746 Training acc= 0.748195 Val acc= 0.747645\n",
            "Epoch 3951: Training loss= 0.092205 Val loss= 0.332695 Training acc= 0.748200 Val acc= 0.747660\n",
            "Epoch 3952: Training loss= 0.092200 Val loss= 0.332645 Training acc= 0.748225 Val acc= 0.747690\n",
            "Epoch 3953: Training loss= 0.092196 Val loss= 0.332594 Training acc= 0.748240 Val acc= 0.747700\n",
            "Epoch 3954: Training loss= 0.092192 Val loss= 0.332544 Training acc= 0.748235 Val acc= 0.747695\n",
            "Epoch 3955: Training loss= 0.092187 Val loss= 0.332493 Training acc= 0.748255 Val acc= 0.747710\n",
            "Epoch 3956: Training loss= 0.092183 Val loss= 0.332443 Training acc= 0.748275 Val acc= 0.747725\n",
            "Epoch 3957: Training loss= 0.092179 Val loss= 0.332392 Training acc= 0.748270 Val acc= 0.747720\n",
            "Epoch 3958: Training loss= 0.092174 Val loss= 0.332342 Training acc= 0.748280 Val acc= 0.747735\n",
            "Epoch 3959: Training loss= 0.092170 Val loss= 0.332291 Training acc= 0.748285 Val acc= 0.747735\n",
            "Epoch 3960: Training loss= 0.092166 Val loss= 0.332241 Training acc= 0.748280 Val acc= 0.747725\n",
            "Epoch 3961: Training loss= 0.092161 Val loss= 0.332191 Training acc= 0.748285 Val acc= 0.747730\n",
            "Epoch 3962: Training loss= 0.092157 Val loss= 0.332140 Training acc= 0.748305 Val acc= 0.747750\n",
            "Epoch 3963: Training loss= 0.092153 Val loss= 0.332090 Training acc= 0.748310 Val acc= 0.747750\n",
            "Epoch 3964: Training loss= 0.092149 Val loss= 0.332040 Training acc= 0.748315 Val acc= 0.747755\n",
            "Epoch 3965: Training loss= 0.092144 Val loss= 0.331989 Training acc= 0.748330 Val acc= 0.747775\n",
            "Epoch 3966: Training loss= 0.092140 Val loss= 0.331939 Training acc= 0.748345 Val acc= 0.747790\n",
            "Epoch 3967: Training loss= 0.092136 Val loss= 0.331889 Training acc= 0.748350 Val acc= 0.747785\n",
            "Epoch 3968: Training loss= 0.092131 Val loss= 0.331838 Training acc= 0.748365 Val acc= 0.747795\n",
            "Epoch 3969: Training loss= 0.092127 Val loss= 0.331788 Training acc= 0.748380 Val acc= 0.747815\n",
            "Epoch 3970: Training loss= 0.092123 Val loss= 0.331738 Training acc= 0.748400 Val acc= 0.747825\n",
            "Epoch 3971: Training loss= 0.092119 Val loss= 0.331688 Training acc= 0.748420 Val acc= 0.747835\n",
            "Epoch 3972: Training loss= 0.092114 Val loss= 0.331638 Training acc= 0.748435 Val acc= 0.747865\n",
            "Epoch 3973: Training loss= 0.092110 Val loss= 0.331588 Training acc= 0.748435 Val acc= 0.747855\n",
            "Epoch 3974: Training loss= 0.092106 Val loss= 0.331537 Training acc= 0.748435 Val acc= 0.747855\n",
            "Epoch 3975: Training loss= 0.092101 Val loss= 0.331487 Training acc= 0.748435 Val acc= 0.747885\n",
            "Epoch 3976: Training loss= 0.092097 Val loss= 0.331437 Training acc= 0.748430 Val acc= 0.747885\n",
            "Epoch 3977: Training loss= 0.092093 Val loss= 0.331387 Training acc= 0.748445 Val acc= 0.747910\n",
            "Epoch 3978: Training loss= 0.092089 Val loss= 0.331337 Training acc= 0.748450 Val acc= 0.747905\n",
            "Epoch 3979: Training loss= 0.092084 Val loss= 0.331287 Training acc= 0.748465 Val acc= 0.747920\n",
            "Epoch 3980: Training loss= 0.092080 Val loss= 0.331237 Training acc= 0.748475 Val acc= 0.747920\n",
            "Epoch 3981: Training loss= 0.092076 Val loss= 0.331187 Training acc= 0.748485 Val acc= 0.747930\n",
            "Epoch 3982: Training loss= 0.092072 Val loss= 0.331137 Training acc= 0.748480 Val acc= 0.747935\n",
            "Epoch 3983: Training loss= 0.092067 Val loss= 0.331087 Training acc= 0.748490 Val acc= 0.747945\n",
            "Epoch 3984: Training loss= 0.092063 Val loss= 0.331037 Training acc= 0.748505 Val acc= 0.747955\n",
            "Epoch 3985: Training loss= 0.092059 Val loss= 0.330987 Training acc= 0.748505 Val acc= 0.747955\n",
            "Epoch 3986: Training loss= 0.092054 Val loss= 0.330937 Training acc= 0.748505 Val acc= 0.747960\n",
            "Epoch 3987: Training loss= 0.092050 Val loss= 0.330888 Training acc= 0.748525 Val acc= 0.747965\n",
            "Epoch 3988: Training loss= 0.092046 Val loss= 0.330838 Training acc= 0.748510 Val acc= 0.747950\n",
            "Epoch 3989: Training loss= 0.092042 Val loss= 0.330788 Training acc= 0.748525 Val acc= 0.747965\n",
            "Epoch 3990: Training loss= 0.092037 Val loss= 0.330738 Training acc= 0.748545 Val acc= 0.747990\n",
            "Epoch 3991: Training loss= 0.092033 Val loss= 0.330688 Training acc= 0.748540 Val acc= 0.747990\n",
            "Epoch 3992: Training loss= 0.092029 Val loss= 0.330638 Training acc= 0.748530 Val acc= 0.747980\n",
            "Epoch 3993: Training loss= 0.092025 Val loss= 0.330589 Training acc= 0.748540 Val acc= 0.748010\n",
            "Epoch 3994: Training loss= 0.092020 Val loss= 0.330539 Training acc= 0.748555 Val acc= 0.748025\n",
            "Epoch 3995: Training loss= 0.092016 Val loss= 0.330489 Training acc= 0.748575 Val acc= 0.748040\n",
            "Epoch 3996: Training loss= 0.092012 Val loss= 0.330440 Training acc= 0.748600 Val acc= 0.748050\n",
            "Epoch 3997: Training loss= 0.092008 Val loss= 0.330390 Training acc= 0.748615 Val acc= 0.748070\n",
            "Epoch 3998: Training loss= 0.092004 Val loss= 0.330340 Training acc= 0.748620 Val acc= 0.748075\n",
            "Epoch 3999: Training loss= 0.091999 Val loss= 0.330291 Training acc= 0.748635 Val acc= 0.748090\n",
            "Epoch 4000: Training loss= 0.091995 Val loss= 0.330241 Training acc= 0.748655 Val acc= 0.748085\n",
            "Epoch 4001: Training loss= 0.091991 Val loss= 0.330191 Training acc= 0.748650 Val acc= 0.748080\n",
            "Epoch 4002: Training loss= 0.091987 Val loss= 0.330142 Training acc= 0.748665 Val acc= 0.748085\n",
            "Epoch 4003: Training loss= 0.091982 Val loss= 0.330092 Training acc= 0.748700 Val acc= 0.748115\n",
            "Epoch 4004: Training loss= 0.091978 Val loss= 0.330043 Training acc= 0.748710 Val acc= 0.748130\n",
            "Epoch 4005: Training loss= 0.091974 Val loss= 0.329993 Training acc= 0.748725 Val acc= 0.748140\n",
            "Epoch 4006: Training loss= 0.091970 Val loss= 0.329944 Training acc= 0.748750 Val acc= 0.748165\n",
            "Epoch 4007: Training loss= 0.091966 Val loss= 0.329894 Training acc= 0.748765 Val acc= 0.748180\n",
            "Epoch 4008: Training loss= 0.091961 Val loss= 0.329845 Training acc= 0.748775 Val acc= 0.748190\n",
            "Epoch 4009: Training loss= 0.091957 Val loss= 0.329795 Training acc= 0.748775 Val acc= 0.748195\n",
            "Epoch 4010: Training loss= 0.091953 Val loss= 0.329746 Training acc= 0.748800 Val acc= 0.748220\n",
            "Epoch 4011: Training loss= 0.091949 Val loss= 0.329697 Training acc= 0.748815 Val acc= 0.748235\n",
            "Epoch 4012: Training loss= 0.091944 Val loss= 0.329647 Training acc= 0.748820 Val acc= 0.748240\n",
            "Epoch 4013: Training loss= 0.091940 Val loss= 0.329598 Training acc= 0.748825 Val acc= 0.748240\n",
            "Epoch 4014: Training loss= 0.091936 Val loss= 0.329548 Training acc= 0.748825 Val acc= 0.748240\n",
            "Epoch 4015: Training loss= 0.091932 Val loss= 0.329499 Training acc= 0.748825 Val acc= 0.748245\n",
            "Epoch 4016: Training loss= 0.091928 Val loss= 0.329450 Training acc= 0.748835 Val acc= 0.748250\n",
            "Epoch 4017: Training loss= 0.091923 Val loss= 0.329401 Training acc= 0.748875 Val acc= 0.748275\n",
            "Epoch 4018: Training loss= 0.091919 Val loss= 0.329351 Training acc= 0.748890 Val acc= 0.748295\n",
            "Epoch 4019: Training loss= 0.091915 Val loss= 0.329302 Training acc= 0.748895 Val acc= 0.748295\n",
            "Epoch 4020: Training loss= 0.091911 Val loss= 0.329253 Training acc= 0.748890 Val acc= 0.748295\n",
            "Epoch 4021: Training loss= 0.091907 Val loss= 0.329204 Training acc= 0.748895 Val acc= 0.748300\n",
            "Epoch 4022: Training loss= 0.091903 Val loss= 0.329154 Training acc= 0.748900 Val acc= 0.748305\n",
            "Epoch 4023: Training loss= 0.091898 Val loss= 0.329105 Training acc= 0.748900 Val acc= 0.748320\n",
            "Epoch 4024: Training loss= 0.091894 Val loss= 0.329056 Training acc= 0.748915 Val acc= 0.748335\n",
            "Epoch 4025: Training loss= 0.091890 Val loss= 0.329007 Training acc= 0.748910 Val acc= 0.748340\n",
            "Epoch 4026: Training loss= 0.091886 Val loss= 0.328958 Training acc= 0.748935 Val acc= 0.748360\n",
            "Epoch 4027: Training loss= 0.091882 Val loss= 0.328909 Training acc= 0.748955 Val acc= 0.748395\n",
            "Epoch 4028: Training loss= 0.091877 Val loss= 0.328860 Training acc= 0.748980 Val acc= 0.748440\n",
            "Epoch 4029: Training loss= 0.091873 Val loss= 0.328811 Training acc= 0.748985 Val acc= 0.748445\n",
            "Epoch 4030: Training loss= 0.091869 Val loss= 0.328762 Training acc= 0.748995 Val acc= 0.748460\n",
            "Epoch 4031: Training loss= 0.091865 Val loss= 0.328713 Training acc= 0.749020 Val acc= 0.748475\n",
            "Epoch 4032: Training loss= 0.091861 Val loss= 0.328664 Training acc= 0.749030 Val acc= 0.748480\n",
            "Epoch 4033: Training loss= 0.091857 Val loss= 0.328615 Training acc= 0.749055 Val acc= 0.748490\n",
            "Epoch 4034: Training loss= 0.091852 Val loss= 0.328566 Training acc= 0.749055 Val acc= 0.748490\n",
            "Epoch 4035: Training loss= 0.091848 Val loss= 0.328517 Training acc= 0.749060 Val acc= 0.748495\n",
            "Epoch 4036: Training loss= 0.091844 Val loss= 0.328468 Training acc= 0.749075 Val acc= 0.748515\n",
            "Epoch 4037: Training loss= 0.091840 Val loss= 0.328419 Training acc= 0.749080 Val acc= 0.748505\n",
            "Epoch 4038: Training loss= 0.091836 Val loss= 0.328370 Training acc= 0.749080 Val acc= 0.748510\n",
            "Epoch 4039: Training loss= 0.091832 Val loss= 0.328321 Training acc= 0.749100 Val acc= 0.748545\n",
            "Epoch 4040: Training loss= 0.091827 Val loss= 0.328272 Training acc= 0.749110 Val acc= 0.748550\n",
            "Epoch 4041: Training loss= 0.091823 Val loss= 0.328223 Training acc= 0.749110 Val acc= 0.748560\n",
            "Epoch 4042: Training loss= 0.091819 Val loss= 0.328175 Training acc= 0.749120 Val acc= 0.748565\n",
            "Epoch 4043: Training loss= 0.091815 Val loss= 0.328126 Training acc= 0.749130 Val acc= 0.748570\n",
            "Epoch 4044: Training loss= 0.091811 Val loss= 0.328077 Training acc= 0.749120 Val acc= 0.748550\n",
            "Epoch 4045: Training loss= 0.091807 Val loss= 0.328028 Training acc= 0.749135 Val acc= 0.748565\n",
            "Epoch 4046: Training loss= 0.091803 Val loss= 0.327980 Training acc= 0.749160 Val acc= 0.748595\n",
            "Epoch 4047: Training loss= 0.091798 Val loss= 0.327931 Training acc= 0.749180 Val acc= 0.748610\n",
            "Epoch 4048: Training loss= 0.091794 Val loss= 0.327882 Training acc= 0.749185 Val acc= 0.748615\n",
            "Epoch 4049: Training loss= 0.091790 Val loss= 0.327834 Training acc= 0.749215 Val acc= 0.748640\n",
            "Epoch 4050: Training loss= 0.091786 Val loss= 0.327785 Training acc= 0.749220 Val acc= 0.748640\n",
            "Epoch 4051: Training loss= 0.091782 Val loss= 0.327736 Training acc= 0.749230 Val acc= 0.748640\n",
            "Epoch 4052: Training loss= 0.091778 Val loss= 0.327688 Training acc= 0.749235 Val acc= 0.748645\n",
            "Epoch 4053: Training loss= 0.091774 Val loss= 0.327639 Training acc= 0.749250 Val acc= 0.748660\n",
            "Epoch 4054: Training loss= 0.091769 Val loss= 0.327590 Training acc= 0.749255 Val acc= 0.748670\n",
            "Epoch 4055: Training loss= 0.091765 Val loss= 0.327542 Training acc= 0.749250 Val acc= 0.748660\n",
            "Epoch 4056: Training loss= 0.091761 Val loss= 0.327493 Training acc= 0.749265 Val acc= 0.748675\n",
            "Epoch 4057: Training loss= 0.091757 Val loss= 0.327445 Training acc= 0.749270 Val acc= 0.748695\n",
            "Epoch 4058: Training loss= 0.091753 Val loss= 0.327396 Training acc= 0.749255 Val acc= 0.748690\n",
            "Epoch 4059: Training loss= 0.091749 Val loss= 0.327348 Training acc= 0.749270 Val acc= 0.748705\n",
            "Epoch 4060: Training loss= 0.091745 Val loss= 0.327299 Training acc= 0.749290 Val acc= 0.748730\n",
            "Epoch 4061: Training loss= 0.091741 Val loss= 0.327251 Training acc= 0.749285 Val acc= 0.748725\n",
            "Epoch 4062: Training loss= 0.091736 Val loss= 0.327203 Training acc= 0.749280 Val acc= 0.748735\n",
            "Epoch 4063: Training loss= 0.091732 Val loss= 0.327154 Training acc= 0.749290 Val acc= 0.748750\n",
            "Epoch 4064: Training loss= 0.091728 Val loss= 0.327106 Training acc= 0.749300 Val acc= 0.748760\n",
            "Epoch 4065: Training loss= 0.091724 Val loss= 0.327057 Training acc= 0.749320 Val acc= 0.748755\n",
            "Epoch 4066: Training loss= 0.091720 Val loss= 0.327009 Training acc= 0.749335 Val acc= 0.748770\n",
            "Epoch 4067: Training loss= 0.091716 Val loss= 0.326961 Training acc= 0.749335 Val acc= 0.748760\n",
            "Epoch 4068: Training loss= 0.091712 Val loss= 0.326912 Training acc= 0.749330 Val acc= 0.748760\n",
            "Epoch 4069: Training loss= 0.091708 Val loss= 0.326864 Training acc= 0.749315 Val acc= 0.748750\n",
            "Epoch 4070: Training loss= 0.091704 Val loss= 0.326816 Training acc= 0.749320 Val acc= 0.748750\n",
            "Epoch 4071: Training loss= 0.091700 Val loss= 0.326768 Training acc= 0.749325 Val acc= 0.748750\n",
            "Epoch 4072: Training loss= 0.091695 Val loss= 0.326719 Training acc= 0.749355 Val acc= 0.748790\n",
            "Epoch 4073: Training loss= 0.091691 Val loss= 0.326671 Training acc= 0.749355 Val acc= 0.748795\n",
            "Epoch 4074: Training loss= 0.091687 Val loss= 0.326623 Training acc= 0.749375 Val acc= 0.748810\n",
            "Epoch 4075: Training loss= 0.091683 Val loss= 0.326575 Training acc= 0.749390 Val acc= 0.748835\n",
            "Epoch 4076: Training loss= 0.091679 Val loss= 0.326527 Training acc= 0.749390 Val acc= 0.748845\n",
            "Epoch 4077: Training loss= 0.091675 Val loss= 0.326478 Training acc= 0.749405 Val acc= 0.748860\n",
            "Epoch 4078: Training loss= 0.091671 Val loss= 0.326430 Training acc= 0.749410 Val acc= 0.748860\n",
            "Epoch 4079: Training loss= 0.091667 Val loss= 0.326382 Training acc= 0.749425 Val acc= 0.748880\n",
            "Epoch 4080: Training loss= 0.091663 Val loss= 0.326334 Training acc= 0.749450 Val acc= 0.748900\n",
            "Epoch 4081: Training loss= 0.091659 Val loss= 0.326286 Training acc= 0.749460 Val acc= 0.748915\n",
            "Epoch 4082: Training loss= 0.091655 Val loss= 0.326238 Training acc= 0.749480 Val acc= 0.748920\n",
            "Epoch 4083: Training loss= 0.091651 Val loss= 0.326190 Training acc= 0.749480 Val acc= 0.748925\n",
            "Epoch 4084: Training loss= 0.091646 Val loss= 0.326142 Training acc= 0.749480 Val acc= 0.748930\n",
            "Epoch 4085: Training loss= 0.091642 Val loss= 0.326094 Training acc= 0.749485 Val acc= 0.748940\n",
            "Epoch 4086: Training loss= 0.091638 Val loss= 0.326046 Training acc= 0.749510 Val acc= 0.748955\n",
            "Epoch 4087: Training loss= 0.091634 Val loss= 0.325998 Training acc= 0.749515 Val acc= 0.748955\n",
            "Epoch 4088: Training loss= 0.091630 Val loss= 0.325950 Training acc= 0.749520 Val acc= 0.748960\n",
            "Epoch 4089: Training loss= 0.091626 Val loss= 0.325902 Training acc= 0.749530 Val acc= 0.748965\n",
            "Epoch 4090: Training loss= 0.091622 Val loss= 0.325854 Training acc= 0.749535 Val acc= 0.748975\n",
            "Epoch 4091: Training loss= 0.091618 Val loss= 0.325806 Training acc= 0.749535 Val acc= 0.748970\n",
            "Epoch 4092: Training loss= 0.091614 Val loss= 0.325758 Training acc= 0.749540 Val acc= 0.748975\n",
            "Epoch 4093: Training loss= 0.091610 Val loss= 0.325711 Training acc= 0.749550 Val acc= 0.748980\n",
            "Epoch 4094: Training loss= 0.091606 Val loss= 0.325663 Training acc= 0.749555 Val acc= 0.748970\n",
            "Epoch 4095: Training loss= 0.091602 Val loss= 0.325615 Training acc= 0.749550 Val acc= 0.748975\n",
            "Epoch 4096: Training loss= 0.091598 Val loss= 0.325567 Training acc= 0.749560 Val acc= 0.748975\n",
            "Epoch 4097: Training loss= 0.091594 Val loss= 0.325519 Training acc= 0.749555 Val acc= 0.748970\n",
            "Epoch 4098: Training loss= 0.091590 Val loss= 0.325472 Training acc= 0.749570 Val acc= 0.748980\n",
            "Epoch 4099: Training loss= 0.091586 Val loss= 0.325424 Training acc= 0.749575 Val acc= 0.748990\n",
            "Epoch 4100: Training loss= 0.091581 Val loss= 0.325376 Training acc= 0.749575 Val acc= 0.748995\n",
            "Epoch 4101: Training loss= 0.091577 Val loss= 0.325329 Training acc= 0.749580 Val acc= 0.749005\n",
            "Epoch 4102: Training loss= 0.091573 Val loss= 0.325281 Training acc= 0.749570 Val acc= 0.749005\n",
            "Epoch 4103: Training loss= 0.091569 Val loss= 0.325233 Training acc= 0.749570 Val acc= 0.748990\n",
            "Epoch 4104: Training loss= 0.091565 Val loss= 0.325186 Training acc= 0.749575 Val acc= 0.748995\n",
            "Epoch 4105: Training loss= 0.091561 Val loss= 0.325138 Training acc= 0.749585 Val acc= 0.749005\n",
            "Epoch 4106: Training loss= 0.091557 Val loss= 0.325090 Training acc= 0.749585 Val acc= 0.749005\n",
            "Epoch 4107: Training loss= 0.091553 Val loss= 0.325043 Training acc= 0.749590 Val acc= 0.749015\n",
            "Epoch 4108: Training loss= 0.091549 Val loss= 0.324995 Training acc= 0.749595 Val acc= 0.749010\n",
            "Epoch 4109: Training loss= 0.091545 Val loss= 0.324948 Training acc= 0.749610 Val acc= 0.749025\n",
            "Epoch 4110: Training loss= 0.091541 Val loss= 0.324900 Training acc= 0.749625 Val acc= 0.749045\n",
            "Epoch 4111: Training loss= 0.091537 Val loss= 0.324853 Training acc= 0.749645 Val acc= 0.749065\n",
            "Epoch 4112: Training loss= 0.091533 Val loss= 0.324805 Training acc= 0.749655 Val acc= 0.749090\n",
            "Epoch 4113: Training loss= 0.091529 Val loss= 0.324758 Training acc= 0.749665 Val acc= 0.749100\n",
            "Epoch 4114: Training loss= 0.091525 Val loss= 0.324710 Training acc= 0.749645 Val acc= 0.749095\n",
            "Epoch 4115: Training loss= 0.091521 Val loss= 0.324663 Training acc= 0.749640 Val acc= 0.749100\n",
            "Epoch 4116: Training loss= 0.091517 Val loss= 0.324615 Training acc= 0.749650 Val acc= 0.749110\n",
            "Epoch 4117: Training loss= 0.091513 Val loss= 0.324568 Training acc= 0.749660 Val acc= 0.749125\n",
            "Epoch 4118: Training loss= 0.091509 Val loss= 0.324520 Training acc= 0.749685 Val acc= 0.749140\n",
            "Epoch 4119: Training loss= 0.091505 Val loss= 0.324473 Training acc= 0.749685 Val acc= 0.749150\n",
            "Epoch 4120: Training loss= 0.091501 Val loss= 0.324426 Training acc= 0.749700 Val acc= 0.749170\n",
            "Epoch 4121: Training loss= 0.091497 Val loss= 0.324378 Training acc= 0.749725 Val acc= 0.749185\n",
            "Epoch 4122: Training loss= 0.091493 Val loss= 0.324331 Training acc= 0.749740 Val acc= 0.749205\n",
            "Epoch 4123: Training loss= 0.091489 Val loss= 0.324284 Training acc= 0.749750 Val acc= 0.749220\n",
            "Epoch 4124: Training loss= 0.091485 Val loss= 0.324236 Training acc= 0.749770 Val acc= 0.749250\n",
            "Epoch 4125: Training loss= 0.091481 Val loss= 0.324189 Training acc= 0.749780 Val acc= 0.749255\n",
            "Epoch 4126: Training loss= 0.091477 Val loss= 0.324142 Training acc= 0.749785 Val acc= 0.749255\n",
            "Epoch 4127: Training loss= 0.091473 Val loss= 0.324095 Training acc= 0.749785 Val acc= 0.749270\n",
            "Epoch 4128: Training loss= 0.091469 Val loss= 0.324048 Training acc= 0.749805 Val acc= 0.749285\n",
            "Epoch 4129: Training loss= 0.091465 Val loss= 0.324000 Training acc= 0.749825 Val acc= 0.749295\n",
            "Epoch 4130: Training loss= 0.091461 Val loss= 0.323953 Training acc= 0.749835 Val acc= 0.749315\n",
            "Epoch 4131: Training loss= 0.091457 Val loss= 0.323906 Training acc= 0.749845 Val acc= 0.749340\n",
            "Epoch 4132: Training loss= 0.091453 Val loss= 0.323859 Training acc= 0.749865 Val acc= 0.749355\n",
            "Epoch 4133: Training loss= 0.091449 Val loss= 0.323812 Training acc= 0.749860 Val acc= 0.749360\n",
            "Epoch 4134: Training loss= 0.091445 Val loss= 0.323765 Training acc= 0.749835 Val acc= 0.749335\n",
            "Epoch 4135: Training loss= 0.091441 Val loss= 0.323718 Training acc= 0.749830 Val acc= 0.749330\n",
            "Epoch 4136: Training loss= 0.091437 Val loss= 0.323671 Training acc= 0.749835 Val acc= 0.749330\n",
            "Epoch 4137: Training loss= 0.091433 Val loss= 0.323623 Training acc= 0.749860 Val acc= 0.749345\n",
            "Epoch 4138: Training loss= 0.091429 Val loss= 0.323576 Training acc= 0.749870 Val acc= 0.749350\n",
            "Epoch 4139: Training loss= 0.091425 Val loss= 0.323529 Training acc= 0.749865 Val acc= 0.749355\n",
            "Epoch 4140: Training loss= 0.091421 Val loss= 0.323482 Training acc= 0.749865 Val acc= 0.749370\n",
            "Epoch 4141: Training loss= 0.091417 Val loss= 0.323436 Training acc= 0.749875 Val acc= 0.749380\n",
            "Epoch 4142: Training loss= 0.091413 Val loss= 0.323389 Training acc= 0.749900 Val acc= 0.749400\n",
            "Epoch 4143: Training loss= 0.091409 Val loss= 0.323342 Training acc= 0.749895 Val acc= 0.749395\n",
            "Epoch 4144: Training loss= 0.091405 Val loss= 0.323295 Training acc= 0.749915 Val acc= 0.749410\n",
            "Epoch 4145: Training loss= 0.091401 Val loss= 0.323248 Training acc= 0.749925 Val acc= 0.749415\n",
            "Epoch 4146: Training loss= 0.091397 Val loss= 0.323201 Training acc= 0.749945 Val acc= 0.749440\n",
            "Epoch 4147: Training loss= 0.091393 Val loss= 0.323154 Training acc= 0.749945 Val acc= 0.749445\n",
            "Epoch 4148: Training loss= 0.091389 Val loss= 0.323107 Training acc= 0.749985 Val acc= 0.749480\n",
            "Epoch 4149: Training loss= 0.091385 Val loss= 0.323060 Training acc= 0.749990 Val acc= 0.749490\n",
            "Epoch 4150: Training loss= 0.091381 Val loss= 0.323014 Training acc= 0.749990 Val acc= 0.749495\n",
            "Epoch 4151: Training loss= 0.091377 Val loss= 0.322967 Training acc= 0.750010 Val acc= 0.749500\n",
            "Epoch 4152: Training loss= 0.091373 Val loss= 0.322920 Training acc= 0.750010 Val acc= 0.749510\n",
            "Epoch 4153: Training loss= 0.091370 Val loss= 0.322873 Training acc= 0.750040 Val acc= 0.749555\n",
            "Epoch 4154: Training loss= 0.091366 Val loss= 0.322826 Training acc= 0.750040 Val acc= 0.749555\n",
            "Epoch 4155: Training loss= 0.091362 Val loss= 0.322780 Training acc= 0.750035 Val acc= 0.749550\n",
            "Epoch 4156: Training loss= 0.091358 Val loss= 0.322733 Training acc= 0.750050 Val acc= 0.749560\n",
            "Epoch 4157: Training loss= 0.091354 Val loss= 0.322686 Training acc= 0.750060 Val acc= 0.749560\n",
            "Epoch 4158: Training loss= 0.091350 Val loss= 0.322640 Training acc= 0.750080 Val acc= 0.749570\n",
            "Epoch 4159: Training loss= 0.091346 Val loss= 0.322593 Training acc= 0.750095 Val acc= 0.749575\n",
            "Epoch 4160: Training loss= 0.091342 Val loss= 0.322546 Training acc= 0.750105 Val acc= 0.749595\n",
            "Epoch 4161: Training loss= 0.091338 Val loss= 0.322500 Training acc= 0.750110 Val acc= 0.749590\n",
            "Epoch 4162: Training loss= 0.091334 Val loss= 0.322453 Training acc= 0.750115 Val acc= 0.749595\n",
            "Epoch 4163: Training loss= 0.091330 Val loss= 0.322407 Training acc= 0.750130 Val acc= 0.749610\n",
            "Epoch 4164: Training loss= 0.091326 Val loss= 0.322360 Training acc= 0.750155 Val acc= 0.749630\n",
            "Epoch 4165: Training loss= 0.091322 Val loss= 0.322314 Training acc= 0.750155 Val acc= 0.749625\n",
            "Epoch 4166: Training loss= 0.091318 Val loss= 0.322267 Training acc= 0.750160 Val acc= 0.749625\n",
            "Epoch 4167: Training loss= 0.091314 Val loss= 0.322220 Training acc= 0.750145 Val acc= 0.749625\n",
            "Epoch 4168: Training loss= 0.091310 Val loss= 0.322174 Training acc= 0.750160 Val acc= 0.749640\n",
            "Epoch 4169: Training loss= 0.091306 Val loss= 0.322128 Training acc= 0.750195 Val acc= 0.749660\n",
            "Epoch 4170: Training loss= 0.091303 Val loss= 0.322081 Training acc= 0.750210 Val acc= 0.749665\n",
            "Epoch 4171: Training loss= 0.091299 Val loss= 0.322035 Training acc= 0.750210 Val acc= 0.749665\n",
            "Epoch 4172: Training loss= 0.091295 Val loss= 0.321988 Training acc= 0.750220 Val acc= 0.749675\n",
            "Epoch 4173: Training loss= 0.091291 Val loss= 0.321942 Training acc= 0.750230 Val acc= 0.749695\n",
            "Epoch 4174: Training loss= 0.091287 Val loss= 0.321895 Training acc= 0.750245 Val acc= 0.749700\n",
            "Epoch 4175: Training loss= 0.091283 Val loss= 0.321849 Training acc= 0.750260 Val acc= 0.749705\n",
            "Epoch 4176: Training loss= 0.091279 Val loss= 0.321803 Training acc= 0.750280 Val acc= 0.749730\n",
            "Epoch 4177: Training loss= 0.091275 Val loss= 0.321756 Training acc= 0.750290 Val acc= 0.749745\n",
            "Epoch 4178: Training loss= 0.091271 Val loss= 0.321710 Training acc= 0.750280 Val acc= 0.749750\n",
            "Epoch 4179: Training loss= 0.091267 Val loss= 0.321664 Training acc= 0.750270 Val acc= 0.749740\n",
            "Epoch 4180: Training loss= 0.091263 Val loss= 0.321617 Training acc= 0.750280 Val acc= 0.749745\n",
            "Epoch 4181: Training loss= 0.091260 Val loss= 0.321571 Training acc= 0.750285 Val acc= 0.749745\n",
            "Epoch 4182: Training loss= 0.091256 Val loss= 0.321525 Training acc= 0.750305 Val acc= 0.749775\n",
            "Epoch 4183: Training loss= 0.091252 Val loss= 0.321479 Training acc= 0.750310 Val acc= 0.749780\n",
            "Epoch 4184: Training loss= 0.091248 Val loss= 0.321433 Training acc= 0.750340 Val acc= 0.749810\n",
            "Epoch 4185: Training loss= 0.091244 Val loss= 0.321386 Training acc= 0.750330 Val acc= 0.749795\n",
            "Epoch 4186: Training loss= 0.091240 Val loss= 0.321340 Training acc= 0.750340 Val acc= 0.749815\n",
            "Epoch 4187: Training loss= 0.091236 Val loss= 0.321294 Training acc= 0.750340 Val acc= 0.749810\n",
            "Epoch 4188: Training loss= 0.091232 Val loss= 0.321248 Training acc= 0.750350 Val acc= 0.749820\n",
            "Epoch 4189: Training loss= 0.091228 Val loss= 0.321202 Training acc= 0.750365 Val acc= 0.749830\n",
            "Epoch 4190: Training loss= 0.091224 Val loss= 0.321156 Training acc= 0.750385 Val acc= 0.749860\n",
            "Epoch 4191: Training loss= 0.091221 Val loss= 0.321110 Training acc= 0.750390 Val acc= 0.749855\n",
            "Epoch 4192: Training loss= 0.091217 Val loss= 0.321064 Training acc= 0.750380 Val acc= 0.749855\n",
            "Epoch 4193: Training loss= 0.091213 Val loss= 0.321017 Training acc= 0.750400 Val acc= 0.749875\n",
            "Epoch 4194: Training loss= 0.091209 Val loss= 0.320971 Training acc= 0.750415 Val acc= 0.749900\n",
            "Epoch 4195: Training loss= 0.091205 Val loss= 0.320925 Training acc= 0.750415 Val acc= 0.749905\n",
            "Epoch 4196: Training loss= 0.091201 Val loss= 0.320879 Training acc= 0.750415 Val acc= 0.749915\n",
            "Epoch 4197: Training loss= 0.091197 Val loss= 0.320833 Training acc= 0.750420 Val acc= 0.749910\n",
            "Epoch 4198: Training loss= 0.091193 Val loss= 0.320787 Training acc= 0.750435 Val acc= 0.749920\n",
            "Epoch 4199: Training loss= 0.091189 Val loss= 0.320742 Training acc= 0.750430 Val acc= 0.749925\n",
            "Epoch 4200: Training loss= 0.091186 Val loss= 0.320696 Training acc= 0.750435 Val acc= 0.749930\n",
            "Epoch 4201: Training loss= 0.091182 Val loss= 0.320650 Training acc= 0.750435 Val acc= 0.749935\n",
            "Epoch 4202: Training loss= 0.091178 Val loss= 0.320604 Training acc= 0.750435 Val acc= 0.749935\n",
            "Epoch 4203: Training loss= 0.091174 Val loss= 0.320558 Training acc= 0.750435 Val acc= 0.749935\n",
            "Epoch 4204: Training loss= 0.091170 Val loss= 0.320512 Training acc= 0.750440 Val acc= 0.749930\n",
            "Epoch 4205: Training loss= 0.091166 Val loss= 0.320466 Training acc= 0.750435 Val acc= 0.749925\n",
            "Epoch 4206: Training loss= 0.091162 Val loss= 0.320420 Training acc= 0.750450 Val acc= 0.749930\n",
            "Epoch 4207: Training loss= 0.091159 Val loss= 0.320375 Training acc= 0.750450 Val acc= 0.749930\n",
            "Epoch 4208: Training loss= 0.091155 Val loss= 0.320329 Training acc= 0.750455 Val acc= 0.749930\n",
            "Epoch 4209: Training loss= 0.091151 Val loss= 0.320283 Training acc= 0.750455 Val acc= 0.749930\n",
            "Epoch 4210: Training loss= 0.091147 Val loss= 0.320237 Training acc= 0.750450 Val acc= 0.749930\n",
            "Epoch 4211: Training loss= 0.091143 Val loss= 0.320191 Training acc= 0.750455 Val acc= 0.749935\n",
            "Epoch 4212: Training loss= 0.091139 Val loss= 0.320146 Training acc= 0.750475 Val acc= 0.749945\n",
            "Epoch 4213: Training loss= 0.091135 Val loss= 0.320100 Training acc= 0.750480 Val acc= 0.749945\n",
            "Epoch 4214: Training loss= 0.091132 Val loss= 0.320054 Training acc= 0.750490 Val acc= 0.749965\n",
            "Epoch 4215: Training loss= 0.091128 Val loss= 0.320009 Training acc= 0.750495 Val acc= 0.749975\n",
            "Epoch 4216: Training loss= 0.091124 Val loss= 0.319963 Training acc= 0.750515 Val acc= 0.749995\n",
            "Epoch 4217: Training loss= 0.091120 Val loss= 0.319917 Training acc= 0.750540 Val acc= 0.750010\n",
            "Epoch 4218: Training loss= 0.091116 Val loss= 0.319872 Training acc= 0.750535 Val acc= 0.749995\n",
            "Epoch 4219: Training loss= 0.091112 Val loss= 0.319826 Training acc= 0.750540 Val acc= 0.750000\n",
            "Epoch 4220: Training loss= 0.091108 Val loss= 0.319781 Training acc= 0.750550 Val acc= 0.750015\n",
            "Epoch 4221: Training loss= 0.091105 Val loss= 0.319735 Training acc= 0.750560 Val acc= 0.750030\n",
            "Epoch 4222: Training loss= 0.091101 Val loss= 0.319689 Training acc= 0.750560 Val acc= 0.750025\n",
            "Epoch 4223: Training loss= 0.091097 Val loss= 0.319644 Training acc= 0.750560 Val acc= 0.750030\n",
            "Epoch 4224: Training loss= 0.091093 Val loss= 0.319598 Training acc= 0.750565 Val acc= 0.750040\n",
            "Epoch 4225: Training loss= 0.091089 Val loss= 0.319553 Training acc= 0.750580 Val acc= 0.750045\n",
            "Epoch 4226: Training loss= 0.091085 Val loss= 0.319507 Training acc= 0.750595 Val acc= 0.750060\n",
            "Epoch 4227: Training loss= 0.091082 Val loss= 0.319462 Training acc= 0.750595 Val acc= 0.750060\n",
            "Epoch 4228: Training loss= 0.091078 Val loss= 0.319417 Training acc= 0.750615 Val acc= 0.750075\n",
            "Epoch 4229: Training loss= 0.091074 Val loss= 0.319371 Training acc= 0.750610 Val acc= 0.750060\n",
            "Epoch 4230: Training loss= 0.091070 Val loss= 0.319326 Training acc= 0.750620 Val acc= 0.750060\n",
            "Epoch 4231: Training loss= 0.091066 Val loss= 0.319280 Training acc= 0.750610 Val acc= 0.750060\n",
            "Epoch 4232: Training loss= 0.091062 Val loss= 0.319235 Training acc= 0.750625 Val acc= 0.750065\n",
            "Epoch 4233: Training loss= 0.091059 Val loss= 0.319190 Training acc= 0.750640 Val acc= 0.750070\n",
            "Epoch 4234: Training loss= 0.091055 Val loss= 0.319144 Training acc= 0.750645 Val acc= 0.750075\n",
            "Epoch 4235: Training loss= 0.091051 Val loss= 0.319099 Training acc= 0.750660 Val acc= 0.750085\n",
            "Epoch 4236: Training loss= 0.091047 Val loss= 0.319054 Training acc= 0.750665 Val acc= 0.750085\n",
            "Epoch 4237: Training loss= 0.091043 Val loss= 0.319008 Training acc= 0.750675 Val acc= 0.750085\n",
            "Epoch 4238: Training loss= 0.091040 Val loss= 0.318963 Training acc= 0.750700 Val acc= 0.750100\n",
            "Epoch 4239: Training loss= 0.091036 Val loss= 0.318918 Training acc= 0.750710 Val acc= 0.750110\n",
            "Epoch 4240: Training loss= 0.091032 Val loss= 0.318872 Training acc= 0.750720 Val acc= 0.750125\n",
            "Epoch 4241: Training loss= 0.091028 Val loss= 0.318827 Training acc= 0.750715 Val acc= 0.750130\n",
            "Epoch 4242: Training loss= 0.091024 Val loss= 0.318782 Training acc= 0.750750 Val acc= 0.750170\n",
            "Epoch 4243: Training loss= 0.091021 Val loss= 0.318737 Training acc= 0.750750 Val acc= 0.750170\n",
            "Epoch 4244: Training loss= 0.091017 Val loss= 0.318692 Training acc= 0.750755 Val acc= 0.750170\n",
            "Epoch 4245: Training loss= 0.091013 Val loss= 0.318647 Training acc= 0.750755 Val acc= 0.750190\n",
            "Epoch 4246: Training loss= 0.091009 Val loss= 0.318601 Training acc= 0.750760 Val acc= 0.750195\n",
            "Epoch 4247: Training loss= 0.091005 Val loss= 0.318556 Training acc= 0.750760 Val acc= 0.750215\n",
            "Epoch 4248: Training loss= 0.091002 Val loss= 0.318511 Training acc= 0.750760 Val acc= 0.750220\n",
            "Epoch 4249: Training loss= 0.090998 Val loss= 0.318466 Training acc= 0.750785 Val acc= 0.750235\n",
            "Epoch 4250: Training loss= 0.090994 Val loss= 0.318421 Training acc= 0.750790 Val acc= 0.750240\n",
            "Epoch 4251: Training loss= 0.090990 Val loss= 0.318376 Training acc= 0.750800 Val acc= 0.750250\n",
            "Epoch 4252: Training loss= 0.090986 Val loss= 0.318331 Training acc= 0.750815 Val acc= 0.750255\n",
            "Epoch 4253: Training loss= 0.090983 Val loss= 0.318286 Training acc= 0.750830 Val acc= 0.750265\n",
            "Epoch 4254: Training loss= 0.090979 Val loss= 0.318241 Training acc= 0.750830 Val acc= 0.750285\n",
            "Epoch 4255: Training loss= 0.090975 Val loss= 0.318196 Training acc= 0.750835 Val acc= 0.750300\n",
            "Epoch 4256: Training loss= 0.090971 Val loss= 0.318151 Training acc= 0.750835 Val acc= 0.750305\n",
            "Epoch 4257: Training loss= 0.090967 Val loss= 0.318106 Training acc= 0.750855 Val acc= 0.750335\n",
            "Epoch 4258: Training loss= 0.090964 Val loss= 0.318061 Training acc= 0.750865 Val acc= 0.750345\n",
            "Epoch 4259: Training loss= 0.090960 Val loss= 0.318016 Training acc= 0.750870 Val acc= 0.750345\n",
            "Epoch 4260: Training loss= 0.090956 Val loss= 0.317971 Training acc= 0.750880 Val acc= 0.750360\n",
            "Epoch 4261: Training loss= 0.090952 Val loss= 0.317926 Training acc= 0.750885 Val acc= 0.750365\n",
            "Epoch 4262: Training loss= 0.090949 Val loss= 0.317881 Training acc= 0.750880 Val acc= 0.750360\n",
            "Epoch 4263: Training loss= 0.090945 Val loss= 0.317837 Training acc= 0.750900 Val acc= 0.750380\n",
            "Epoch 4264: Training loss= 0.090941 Val loss= 0.317792 Training acc= 0.750920 Val acc= 0.750400\n",
            "Epoch 4265: Training loss= 0.090937 Val loss= 0.317747 Training acc= 0.750930 Val acc= 0.750400\n",
            "Epoch 4266: Training loss= 0.090933 Val loss= 0.317702 Training acc= 0.750940 Val acc= 0.750415\n",
            "Epoch 4267: Training loss= 0.090930 Val loss= 0.317657 Training acc= 0.750955 Val acc= 0.750445\n",
            "Epoch 4268: Training loss= 0.090926 Val loss= 0.317613 Training acc= 0.750970 Val acc= 0.750455\n",
            "Epoch 4269: Training loss= 0.090922 Val loss= 0.317568 Training acc= 0.750975 Val acc= 0.750465\n",
            "Epoch 4270: Training loss= 0.090918 Val loss= 0.317523 Training acc= 0.750980 Val acc= 0.750460\n",
            "Epoch 4271: Training loss= 0.090915 Val loss= 0.317478 Training acc= 0.750975 Val acc= 0.750455\n",
            "Epoch 4272: Training loss= 0.090911 Val loss= 0.317434 Training acc= 0.750970 Val acc= 0.750450\n",
            "Epoch 4273: Training loss= 0.090907 Val loss= 0.317389 Training acc= 0.750975 Val acc= 0.750465\n",
            "Epoch 4274: Training loss= 0.090903 Val loss= 0.317344 Training acc= 0.750985 Val acc= 0.750470\n",
            "Epoch 4275: Training loss= 0.090900 Val loss= 0.317300 Training acc= 0.750995 Val acc= 0.750480\n",
            "Epoch 4276: Training loss= 0.090896 Val loss= 0.317255 Training acc= 0.751015 Val acc= 0.750490\n",
            "Epoch 4277: Training loss= 0.090892 Val loss= 0.317210 Training acc= 0.751030 Val acc= 0.750505\n",
            "Epoch 4278: Training loss= 0.090888 Val loss= 0.317166 Training acc= 0.751050 Val acc= 0.750525\n",
            "Epoch 4279: Training loss= 0.090885 Val loss= 0.317121 Training acc= 0.751065 Val acc= 0.750535\n",
            "Epoch 4280: Training loss= 0.090881 Val loss= 0.317077 Training acc= 0.751080 Val acc= 0.750545\n",
            "Epoch 4281: Training loss= 0.090877 Val loss= 0.317032 Training acc= 0.751095 Val acc= 0.750555\n",
            "Epoch 4282: Training loss= 0.090873 Val loss= 0.316987 Training acc= 0.751110 Val acc= 0.750565\n",
            "Epoch 4283: Training loss= 0.090870 Val loss= 0.316943 Training acc= 0.751120 Val acc= 0.750575\n",
            "Epoch 4284: Training loss= 0.090866 Val loss= 0.316898 Training acc= 0.751110 Val acc= 0.750575\n",
            "Epoch 4285: Training loss= 0.090862 Val loss= 0.316854 Training acc= 0.751125 Val acc= 0.750580\n",
            "Epoch 4286: Training loss= 0.090858 Val loss= 0.316809 Training acc= 0.751145 Val acc= 0.750600\n",
            "Epoch 4287: Training loss= 0.090855 Val loss= 0.316765 Training acc= 0.751165 Val acc= 0.750620\n",
            "Epoch 4288: Training loss= 0.090851 Val loss= 0.316721 Training acc= 0.751160 Val acc= 0.750620\n",
            "Epoch 4289: Training loss= 0.090847 Val loss= 0.316676 Training acc= 0.751150 Val acc= 0.750615\n",
            "Epoch 4290: Training loss= 0.090844 Val loss= 0.316632 Training acc= 0.751175 Val acc= 0.750630\n",
            "Epoch 4291: Training loss= 0.090840 Val loss= 0.316587 Training acc= 0.751170 Val acc= 0.750635\n",
            "Epoch 4292: Training loss= 0.090836 Val loss= 0.316543 Training acc= 0.751175 Val acc= 0.750645\n",
            "Epoch 4293: Training loss= 0.090832 Val loss= 0.316499 Training acc= 0.751185 Val acc= 0.750660\n",
            "Epoch 4294: Training loss= 0.090829 Val loss= 0.316454 Training acc= 0.751200 Val acc= 0.750665\n",
            "Epoch 4295: Training loss= 0.090825 Val loss= 0.316410 Training acc= 0.751195 Val acc= 0.750675\n",
            "Epoch 4296: Training loss= 0.090821 Val loss= 0.316366 Training acc= 0.751205 Val acc= 0.750695\n",
            "Epoch 4297: Training loss= 0.090817 Val loss= 0.316321 Training acc= 0.751220 Val acc= 0.750710\n",
            "Epoch 4298: Training loss= 0.090814 Val loss= 0.316277 Training acc= 0.751230 Val acc= 0.750725\n",
            "Epoch 4299: Training loss= 0.090810 Val loss= 0.316233 Training acc= 0.751245 Val acc= 0.750735\n",
            "Epoch 4300: Training loss= 0.090806 Val loss= 0.316189 Training acc= 0.751255 Val acc= 0.750765\n",
            "Epoch 4301: Training loss= 0.090803 Val loss= 0.316144 Training acc= 0.751255 Val acc= 0.750775\n",
            "Epoch 4302: Training loss= 0.090799 Val loss= 0.316100 Training acc= 0.751255 Val acc= 0.750775\n",
            "Epoch 4303: Training loss= 0.090795 Val loss= 0.316056 Training acc= 0.751260 Val acc= 0.750775\n",
            "Epoch 4304: Training loss= 0.090791 Val loss= 0.316012 Training acc= 0.751270 Val acc= 0.750785\n",
            "Epoch 4305: Training loss= 0.090788 Val loss= 0.315968 Training acc= 0.751275 Val acc= 0.750790\n",
            "Epoch 4306: Training loss= 0.090784 Val loss= 0.315923 Training acc= 0.751280 Val acc= 0.750795\n",
            "Epoch 4307: Training loss= 0.090780 Val loss= 0.315879 Training acc= 0.751275 Val acc= 0.750795\n",
            "Epoch 4308: Training loss= 0.090777 Val loss= 0.315835 Training acc= 0.751295 Val acc= 0.750810\n",
            "Epoch 4309: Training loss= 0.090773 Val loss= 0.315791 Training acc= 0.751300 Val acc= 0.750810\n",
            "Epoch 4310: Training loss= 0.090769 Val loss= 0.315747 Training acc= 0.751300 Val acc= 0.750820\n",
            "Epoch 4311: Training loss= 0.090766 Val loss= 0.315703 Training acc= 0.751310 Val acc= 0.750825\n",
            "Epoch 4312: Training loss= 0.090762 Val loss= 0.315659 Training acc= 0.751330 Val acc= 0.750840\n",
            "Epoch 4313: Training loss= 0.090758 Val loss= 0.315615 Training acc= 0.751330 Val acc= 0.750850\n",
            "Epoch 4314: Training loss= 0.090754 Val loss= 0.315571 Training acc= 0.751330 Val acc= 0.750855\n",
            "Epoch 4315: Training loss= 0.090751 Val loss= 0.315527 Training acc= 0.751330 Val acc= 0.750855\n",
            "Epoch 4316: Training loss= 0.090747 Val loss= 0.315483 Training acc= 0.751340 Val acc= 0.750865\n",
            "Epoch 4317: Training loss= 0.090743 Val loss= 0.315439 Training acc= 0.751335 Val acc= 0.750865\n",
            "Epoch 4318: Training loss= 0.090740 Val loss= 0.315395 Training acc= 0.751345 Val acc= 0.750880\n",
            "Epoch 4319: Training loss= 0.090736 Val loss= 0.315351 Training acc= 0.751360 Val acc= 0.750900\n",
            "Epoch 4320: Training loss= 0.090732 Val loss= 0.315307 Training acc= 0.751360 Val acc= 0.750915\n",
            "Epoch 4321: Training loss= 0.090729 Val loss= 0.315263 Training acc= 0.751350 Val acc= 0.750910\n",
            "Epoch 4322: Training loss= 0.090725 Val loss= 0.315219 Training acc= 0.751360 Val acc= 0.750920\n",
            "Epoch 4323: Training loss= 0.090721 Val loss= 0.315175 Training acc= 0.751380 Val acc= 0.750935\n",
            "Epoch 4324: Training loss= 0.090718 Val loss= 0.315132 Training acc= 0.751385 Val acc= 0.750935\n",
            "Epoch 4325: Training loss= 0.090714 Val loss= 0.315088 Training acc= 0.751390 Val acc= 0.750945\n",
            "Epoch 4326: Training loss= 0.090710 Val loss= 0.315044 Training acc= 0.751390 Val acc= 0.750945\n",
            "Epoch 4327: Training loss= 0.090707 Val loss= 0.315000 Training acc= 0.751405 Val acc= 0.750960\n",
            "Epoch 4328: Training loss= 0.090703 Val loss= 0.314956 Training acc= 0.751390 Val acc= 0.750960\n",
            "Epoch 4329: Training loss= 0.090699 Val loss= 0.314913 Training acc= 0.751385 Val acc= 0.750965\n",
            "Epoch 4330: Training loss= 0.090696 Val loss= 0.314869 Training acc= 0.751395 Val acc= 0.750970\n",
            "Epoch 4331: Training loss= 0.090692 Val loss= 0.314825 Training acc= 0.751395 Val acc= 0.750965\n",
            "Epoch 4332: Training loss= 0.090688 Val loss= 0.314781 Training acc= 0.751410 Val acc= 0.750970\n",
            "Epoch 4333: Training loss= 0.090685 Val loss= 0.314738 Training acc= 0.751410 Val acc= 0.750970\n",
            "Epoch 4334: Training loss= 0.090681 Val loss= 0.314694 Training acc= 0.751410 Val acc= 0.750970\n",
            "Epoch 4335: Training loss= 0.090677 Val loss= 0.314650 Training acc= 0.751425 Val acc= 0.750985\n",
            "Epoch 4336: Training loss= 0.090674 Val loss= 0.314607 Training acc= 0.751425 Val acc= 0.750990\n",
            "Epoch 4337: Training loss= 0.090670 Val loss= 0.314563 Training acc= 0.751430 Val acc= 0.751000\n",
            "Epoch 4338: Training loss= 0.090666 Val loss= 0.314519 Training acc= 0.751460 Val acc= 0.751020\n",
            "Epoch 4339: Training loss= 0.090663 Val loss= 0.314476 Training acc= 0.751470 Val acc= 0.751040\n",
            "Epoch 4340: Training loss= 0.090659 Val loss= 0.314432 Training acc= 0.751470 Val acc= 0.751040\n",
            "Epoch 4341: Training loss= 0.090655 Val loss= 0.314388 Training acc= 0.751485 Val acc= 0.751050\n",
            "Epoch 4342: Training loss= 0.090652 Val loss= 0.314345 Training acc= 0.751490 Val acc= 0.751060\n",
            "Epoch 4343: Training loss= 0.090648 Val loss= 0.314301 Training acc= 0.751485 Val acc= 0.751050\n",
            "Epoch 4344: Training loss= 0.090644 Val loss= 0.314258 Training acc= 0.751500 Val acc= 0.751065\n",
            "Epoch 4345: Training loss= 0.090641 Val loss= 0.314214 Training acc= 0.751510 Val acc= 0.751065\n",
            "Epoch 4346: Training loss= 0.090637 Val loss= 0.314171 Training acc= 0.751500 Val acc= 0.751065\n",
            "Epoch 4347: Training loss= 0.090633 Val loss= 0.314127 Training acc= 0.751515 Val acc= 0.751075\n",
            "Epoch 4348: Training loss= 0.090630 Val loss= 0.314084 Training acc= 0.751515 Val acc= 0.751075\n",
            "Epoch 4349: Training loss= 0.090626 Val loss= 0.314040 Training acc= 0.751520 Val acc= 0.751085\n",
            "Epoch 4350: Training loss= 0.090623 Val loss= 0.313997 Training acc= 0.751525 Val acc= 0.751090\n",
            "Epoch 4351: Training loss= 0.090619 Val loss= 0.313954 Training acc= 0.751530 Val acc= 0.751090\n",
            "Epoch 4352: Training loss= 0.090615 Val loss= 0.313910 Training acc= 0.751525 Val acc= 0.751085\n",
            "Epoch 4353: Training loss= 0.090612 Val loss= 0.313867 Training acc= 0.751530 Val acc= 0.751095\n",
            "Epoch 4354: Training loss= 0.090608 Val loss= 0.313823 Training acc= 0.751530 Val acc= 0.751090\n",
            "Epoch 4355: Training loss= 0.090604 Val loss= 0.313780 Training acc= 0.751550 Val acc= 0.751110\n",
            "Epoch 4356: Training loss= 0.090601 Val loss= 0.313737 Training acc= 0.751550 Val acc= 0.751120\n",
            "Epoch 4357: Training loss= 0.090597 Val loss= 0.313693 Training acc= 0.751545 Val acc= 0.751115\n",
            "Epoch 4358: Training loss= 0.090593 Val loss= 0.313650 Training acc= 0.751540 Val acc= 0.751115\n",
            "Epoch 4359: Training loss= 0.090590 Val loss= 0.313607 Training acc= 0.751545 Val acc= 0.751125\n",
            "Epoch 4360: Training loss= 0.090586 Val loss= 0.313563 Training acc= 0.751550 Val acc= 0.751130\n",
            "Epoch 4361: Training loss= 0.090583 Val loss= 0.313520 Training acc= 0.751555 Val acc= 0.751140\n",
            "Epoch 4362: Training loss= 0.090579 Val loss= 0.313477 Training acc= 0.751570 Val acc= 0.751145\n",
            "Epoch 4363: Training loss= 0.090575 Val loss= 0.313434 Training acc= 0.751570 Val acc= 0.751150\n",
            "Epoch 4364: Training loss= 0.090572 Val loss= 0.313391 Training acc= 0.751585 Val acc= 0.751165\n",
            "Epoch 4365: Training loss= 0.090568 Val loss= 0.313347 Training acc= 0.751600 Val acc= 0.751185\n",
            "Epoch 4366: Training loss= 0.090565 Val loss= 0.313304 Training acc= 0.751585 Val acc= 0.751165\n",
            "Epoch 4367: Training loss= 0.090561 Val loss= 0.313261 Training acc= 0.751595 Val acc= 0.751175\n",
            "Epoch 4368: Training loss= 0.090557 Val loss= 0.313218 Training acc= 0.751615 Val acc= 0.751190\n",
            "Epoch 4369: Training loss= 0.090554 Val loss= 0.313175 Training acc= 0.751615 Val acc= 0.751185\n",
            "Epoch 4370: Training loss= 0.090550 Val loss= 0.313132 Training acc= 0.751615 Val acc= 0.751195\n",
            "Epoch 4371: Training loss= 0.090546 Val loss= 0.313088 Training acc= 0.751625 Val acc= 0.751210\n",
            "Epoch 4372: Training loss= 0.090543 Val loss= 0.313045 Training acc= 0.751635 Val acc= 0.751220\n",
            "Epoch 4373: Training loss= 0.090539 Val loss= 0.313002 Training acc= 0.751645 Val acc= 0.751230\n",
            "Epoch 4374: Training loss= 0.090536 Val loss= 0.312959 Training acc= 0.751650 Val acc= 0.751230\n",
            "Epoch 4375: Training loss= 0.090532 Val loss= 0.312916 Training acc= 0.751660 Val acc= 0.751235\n",
            "Epoch 4376: Training loss= 0.090528 Val loss= 0.312873 Training acc= 0.751660 Val acc= 0.751245\n",
            "Epoch 4377: Training loss= 0.090525 Val loss= 0.312830 Training acc= 0.751665 Val acc= 0.751245\n",
            "Epoch 4378: Training loss= 0.090521 Val loss= 0.312787 Training acc= 0.751675 Val acc= 0.751255\n",
            "Epoch 4379: Training loss= 0.090518 Val loss= 0.312744 Training acc= 0.751685 Val acc= 0.751265\n",
            "Epoch 4380: Training loss= 0.090514 Val loss= 0.312701 Training acc= 0.751680 Val acc= 0.751265\n",
            "Epoch 4381: Training loss= 0.090510 Val loss= 0.312658 Training acc= 0.751695 Val acc= 0.751285\n",
            "Epoch 4382: Training loss= 0.090507 Val loss= 0.312615 Training acc= 0.751705 Val acc= 0.751290\n",
            "Epoch 4383: Training loss= 0.090503 Val loss= 0.312572 Training acc= 0.751720 Val acc= 0.751305\n",
            "Epoch 4384: Training loss= 0.090500 Val loss= 0.312530 Training acc= 0.751730 Val acc= 0.751315\n",
            "Epoch 4385: Training loss= 0.090496 Val loss= 0.312487 Training acc= 0.751745 Val acc= 0.751330\n",
            "Epoch 4386: Training loss= 0.090493 Val loss= 0.312444 Training acc= 0.751735 Val acc= 0.751325\n",
            "Epoch 4387: Training loss= 0.090489 Val loss= 0.312401 Training acc= 0.751740 Val acc= 0.751315\n",
            "Epoch 4388: Training loss= 0.090485 Val loss= 0.312358 Training acc= 0.751740 Val acc= 0.751310\n",
            "Epoch 4389: Training loss= 0.090482 Val loss= 0.312315 Training acc= 0.751750 Val acc= 0.751315\n",
            "Epoch 4390: Training loss= 0.090478 Val loss= 0.312272 Training acc= 0.751755 Val acc= 0.751300\n",
            "Epoch 4391: Training loss= 0.090475 Val loss= 0.312230 Training acc= 0.751750 Val acc= 0.751295\n",
            "Epoch 4392: Training loss= 0.090471 Val loss= 0.312187 Training acc= 0.751775 Val acc= 0.751315\n",
            "Epoch 4393: Training loss= 0.090467 Val loss= 0.312144 Training acc= 0.751800 Val acc= 0.751340\n",
            "Epoch 4394: Training loss= 0.090464 Val loss= 0.312101 Training acc= 0.751805 Val acc= 0.751345\n",
            "Epoch 4395: Training loss= 0.090460 Val loss= 0.312059 Training acc= 0.751810 Val acc= 0.751355\n",
            "Epoch 4396: Training loss= 0.090457 Val loss= 0.312016 Training acc= 0.751805 Val acc= 0.751355\n",
            "Epoch 4397: Training loss= 0.090453 Val loss= 0.311973 Training acc= 0.751795 Val acc= 0.751350\n",
            "Epoch 4398: Training loss= 0.090450 Val loss= 0.311931 Training acc= 0.751805 Val acc= 0.751340\n",
            "Epoch 4399: Training loss= 0.090446 Val loss= 0.311888 Training acc= 0.751820 Val acc= 0.751350\n",
            "Epoch 4400: Training loss= 0.090442 Val loss= 0.311845 Training acc= 0.751815 Val acc= 0.751340\n",
            "Epoch 4401: Training loss= 0.090439 Val loss= 0.311803 Training acc= 0.751820 Val acc= 0.751345\n",
            "Epoch 4402: Training loss= 0.090435 Val loss= 0.311760 Training acc= 0.751825 Val acc= 0.751340\n",
            "Epoch 4403: Training loss= 0.090432 Val loss= 0.311717 Training acc= 0.751830 Val acc= 0.751360\n",
            "Epoch 4404: Training loss= 0.090428 Val loss= 0.311675 Training acc= 0.751830 Val acc= 0.751370\n",
            "Epoch 4405: Training loss= 0.090425 Val loss= 0.311632 Training acc= 0.751835 Val acc= 0.751370\n",
            "Epoch 4406: Training loss= 0.090421 Val loss= 0.311590 Training acc= 0.751855 Val acc= 0.751385\n",
            "Epoch 4407: Training loss= 0.090418 Val loss= 0.311547 Training acc= 0.751860 Val acc= 0.751395\n",
            "Epoch 4408: Training loss= 0.090414 Val loss= 0.311505 Training acc= 0.751855 Val acc= 0.751390\n",
            "Epoch 4409: Training loss= 0.090410 Val loss= 0.311462 Training acc= 0.751850 Val acc= 0.751390\n",
            "Epoch 4410: Training loss= 0.090407 Val loss= 0.311419 Training acc= 0.751855 Val acc= 0.751415\n",
            "Epoch 4411: Training loss= 0.090403 Val loss= 0.311377 Training acc= 0.751865 Val acc= 0.751440\n",
            "Epoch 4412: Training loss= 0.090400 Val loss= 0.311335 Training acc= 0.751880 Val acc= 0.751455\n",
            "Epoch 4413: Training loss= 0.090396 Val loss= 0.311292 Training acc= 0.751905 Val acc= 0.751480\n",
            "Epoch 4414: Training loss= 0.090393 Val loss= 0.311250 Training acc= 0.751905 Val acc= 0.751485\n",
            "Epoch 4415: Training loss= 0.090389 Val loss= 0.311207 Training acc= 0.751925 Val acc= 0.751505\n",
            "Epoch 4416: Training loss= 0.090386 Val loss= 0.311165 Training acc= 0.751945 Val acc= 0.751530\n",
            "Epoch 4417: Training loss= 0.090382 Val loss= 0.311122 Training acc= 0.751955 Val acc= 0.751545\n",
            "Epoch 4418: Training loss= 0.090379 Val loss= 0.311080 Training acc= 0.751965 Val acc= 0.751560\n",
            "Epoch 4419: Training loss= 0.090375 Val loss= 0.311038 Training acc= 0.751970 Val acc= 0.751555\n",
            "Epoch 4420: Training loss= 0.090372 Val loss= 0.310995 Training acc= 0.751980 Val acc= 0.751570\n",
            "Epoch 4421: Training loss= 0.090368 Val loss= 0.310953 Training acc= 0.751985 Val acc= 0.751575\n",
            "Epoch 4422: Training loss= 0.090364 Val loss= 0.310911 Training acc= 0.751985 Val acc= 0.751575\n",
            "Epoch 4423: Training loss= 0.090361 Val loss= 0.310868 Training acc= 0.751990 Val acc= 0.751570\n",
            "Epoch 4424: Training loss= 0.090357 Val loss= 0.310826 Training acc= 0.751990 Val acc= 0.751565\n",
            "Epoch 4425: Training loss= 0.090354 Val loss= 0.310784 Training acc= 0.752000 Val acc= 0.751570\n",
            "Epoch 4426: Training loss= 0.090350 Val loss= 0.310742 Training acc= 0.752010 Val acc= 0.751560\n",
            "Epoch 4427: Training loss= 0.090347 Val loss= 0.310699 Training acc= 0.752020 Val acc= 0.751560\n",
            "Epoch 4428: Training loss= 0.090343 Val loss= 0.310657 Training acc= 0.752030 Val acc= 0.751565\n",
            "Epoch 4429: Training loss= 0.090340 Val loss= 0.310615 Training acc= 0.752030 Val acc= 0.751575\n",
            "Epoch 4430: Training loss= 0.090336 Val loss= 0.310573 Training acc= 0.752060 Val acc= 0.751580\n",
            "Epoch 4431: Training loss= 0.090333 Val loss= 0.310531 Training acc= 0.752070 Val acc= 0.751585\n",
            "Epoch 4432: Training loss= 0.090329 Val loss= 0.310488 Training acc= 0.752080 Val acc= 0.751595\n",
            "Epoch 4433: Training loss= 0.090326 Val loss= 0.310446 Training acc= 0.752065 Val acc= 0.751585\n",
            "Epoch 4434: Training loss= 0.090322 Val loss= 0.310404 Training acc= 0.752060 Val acc= 0.751580\n",
            "Epoch 4435: Training loss= 0.090319 Val loss= 0.310362 Training acc= 0.752070 Val acc= 0.751595\n",
            "Epoch 4436: Training loss= 0.090315 Val loss= 0.310320 Training acc= 0.752085 Val acc= 0.751615\n",
            "Epoch 4437: Training loss= 0.090312 Val loss= 0.310278 Training acc= 0.752085 Val acc= 0.751615\n",
            "Epoch 4438: Training loss= 0.090308 Val loss= 0.310236 Training acc= 0.752100 Val acc= 0.751635\n",
            "Epoch 4439: Training loss= 0.090305 Val loss= 0.310194 Training acc= 0.752110 Val acc= 0.751655\n",
            "Epoch 4440: Training loss= 0.090301 Val loss= 0.310152 Training acc= 0.752105 Val acc= 0.751660\n",
            "Epoch 4441: Training loss= 0.090298 Val loss= 0.310110 Training acc= 0.752115 Val acc= 0.751670\n",
            "Epoch 4442: Training loss= 0.090294 Val loss= 0.310068 Training acc= 0.752120 Val acc= 0.751680\n",
            "Epoch 4443: Training loss= 0.090291 Val loss= 0.310026 Training acc= 0.752115 Val acc= 0.751670\n",
            "Epoch 4444: Training loss= 0.090287 Val loss= 0.309984 Training acc= 0.752120 Val acc= 0.751675\n",
            "Epoch 4445: Training loss= 0.090284 Val loss= 0.309942 Training acc= 0.752120 Val acc= 0.751685\n",
            "Epoch 4446: Training loss= 0.090280 Val loss= 0.309900 Training acc= 0.752130 Val acc= 0.751695\n",
            "Epoch 4447: Training loss= 0.090277 Val loss= 0.309858 Training acc= 0.752135 Val acc= 0.751700\n",
            "Epoch 4448: Training loss= 0.090273 Val loss= 0.309816 Training acc= 0.752145 Val acc= 0.751710\n",
            "Epoch 4449: Training loss= 0.090270 Val loss= 0.309774 Training acc= 0.752155 Val acc= 0.751730\n",
            "Epoch 4450: Training loss= 0.090266 Val loss= 0.309732 Training acc= 0.752165 Val acc= 0.751740\n",
            "Epoch 4451: Training loss= 0.090263 Val loss= 0.309690 Training acc= 0.752180 Val acc= 0.751755\n",
            "Epoch 4452: Training loss= 0.090259 Val loss= 0.309648 Training acc= 0.752175 Val acc= 0.751755\n",
            "Epoch 4453: Training loss= 0.090256 Val loss= 0.309606 Training acc= 0.752200 Val acc= 0.751770\n",
            "Epoch 4454: Training loss= 0.090252 Val loss= 0.309565 Training acc= 0.752195 Val acc= 0.751765\n",
            "Epoch 4455: Training loss= 0.090249 Val loss= 0.309523 Training acc= 0.752190 Val acc= 0.751765\n",
            "Epoch 4456: Training loss= 0.090245 Val loss= 0.309481 Training acc= 0.752200 Val acc= 0.751780\n",
            "Epoch 4457: Training loss= 0.090242 Val loss= 0.309439 Training acc= 0.752210 Val acc= 0.751800\n",
            "Epoch 4458: Training loss= 0.090238 Val loss= 0.309397 Training acc= 0.752200 Val acc= 0.751800\n",
            "Epoch 4459: Training loss= 0.090235 Val loss= 0.309356 Training acc= 0.752185 Val acc= 0.751785\n",
            "Epoch 4460: Training loss= 0.090231 Val loss= 0.309314 Training acc= 0.752175 Val acc= 0.751770\n",
            "Epoch 4461: Training loss= 0.090228 Val loss= 0.309272 Training acc= 0.752175 Val acc= 0.751770\n",
            "Epoch 4462: Training loss= 0.090224 Val loss= 0.309230 Training acc= 0.752175 Val acc= 0.751765\n",
            "Epoch 4463: Training loss= 0.090221 Val loss= 0.309189 Training acc= 0.752170 Val acc= 0.751765\n",
            "Epoch 4464: Training loss= 0.090217 Val loss= 0.309147 Training acc= 0.752180 Val acc= 0.751785\n",
            "Epoch 4465: Training loss= 0.090214 Val loss= 0.309105 Training acc= 0.752180 Val acc= 0.751785\n",
            "Epoch 4466: Training loss= 0.090210 Val loss= 0.309064 Training acc= 0.752200 Val acc= 0.751795\n",
            "Epoch 4467: Training loss= 0.090207 Val loss= 0.309022 Training acc= 0.752195 Val acc= 0.751795\n",
            "Epoch 4468: Training loss= 0.090203 Val loss= 0.308981 Training acc= 0.752220 Val acc= 0.751820\n",
            "Epoch 4469: Training loss= 0.090200 Val loss= 0.308939 Training acc= 0.752210 Val acc= 0.751815\n",
            "Epoch 4470: Training loss= 0.090197 Val loss= 0.308897 Training acc= 0.752225 Val acc= 0.751825\n",
            "Epoch 4471: Training loss= 0.090193 Val loss= 0.308856 Training acc= 0.752230 Val acc= 0.751830\n",
            "Epoch 4472: Training loss= 0.090190 Val loss= 0.308814 Training acc= 0.752230 Val acc= 0.751830\n",
            "Epoch 4473: Training loss= 0.090186 Val loss= 0.308773 Training acc= 0.752230 Val acc= 0.751825\n",
            "Epoch 4474: Training loss= 0.090183 Val loss= 0.308731 Training acc= 0.752230 Val acc= 0.751820\n",
            "Epoch 4475: Training loss= 0.090179 Val loss= 0.308690 Training acc= 0.752250 Val acc= 0.751820\n",
            "Epoch 4476: Training loss= 0.090176 Val loss= 0.308648 Training acc= 0.752270 Val acc= 0.751830\n",
            "Epoch 4477: Training loss= 0.090172 Val loss= 0.308607 Training acc= 0.752290 Val acc= 0.751850\n",
            "Epoch 4478: Training loss= 0.090169 Val loss= 0.308565 Training acc= 0.752310 Val acc= 0.751870\n",
            "Epoch 4479: Training loss= 0.090165 Val loss= 0.308524 Training acc= 0.752300 Val acc= 0.751865\n",
            "Epoch 4480: Training loss= 0.090162 Val loss= 0.308482 Training acc= 0.752305 Val acc= 0.751865\n",
            "Epoch 4481: Training loss= 0.090159 Val loss= 0.308441 Training acc= 0.752325 Val acc= 0.751885\n",
            "Epoch 4482: Training loss= 0.090155 Val loss= 0.308399 Training acc= 0.752340 Val acc= 0.751900\n",
            "Epoch 4483: Training loss= 0.090152 Val loss= 0.308358 Training acc= 0.752345 Val acc= 0.751900\n",
            "Epoch 4484: Training loss= 0.090148 Val loss= 0.308317 Training acc= 0.752355 Val acc= 0.751910\n",
            "Epoch 4485: Training loss= 0.090145 Val loss= 0.308275 Training acc= 0.752360 Val acc= 0.751910\n",
            "Epoch 4486: Training loss= 0.090141 Val loss= 0.308234 Training acc= 0.752375 Val acc= 0.751930\n",
            "Epoch 4487: Training loss= 0.090138 Val loss= 0.308193 Training acc= 0.752380 Val acc= 0.751940\n",
            "Epoch 4488: Training loss= 0.090134 Val loss= 0.308151 Training acc= 0.752375 Val acc= 0.751935\n",
            "Epoch 4489: Training loss= 0.090131 Val loss= 0.308110 Training acc= 0.752390 Val acc= 0.751950\n",
            "Epoch 4490: Training loss= 0.090128 Val loss= 0.308069 Training acc= 0.752395 Val acc= 0.751960\n",
            "Epoch 4491: Training loss= 0.090124 Val loss= 0.308027 Training acc= 0.752395 Val acc= 0.751965\n",
            "Epoch 4492: Training loss= 0.090121 Val loss= 0.307986 Training acc= 0.752410 Val acc= 0.751975\n",
            "Epoch 4493: Training loss= 0.090117 Val loss= 0.307945 Training acc= 0.752405 Val acc= 0.751980\n",
            "Epoch 4494: Training loss= 0.090114 Val loss= 0.307904 Training acc= 0.752425 Val acc= 0.751970\n",
            "Epoch 4495: Training loss= 0.090110 Val loss= 0.307862 Training acc= 0.752460 Val acc= 0.752000\n",
            "Epoch 4496: Training loss= 0.090107 Val loss= 0.307821 Training acc= 0.752475 Val acc= 0.752025\n",
            "Epoch 4497: Training loss= 0.090104 Val loss= 0.307780 Training acc= 0.752485 Val acc= 0.752030\n",
            "Epoch 4498: Training loss= 0.090100 Val loss= 0.307739 Training acc= 0.752495 Val acc= 0.752040\n",
            "Epoch 4499: Training loss= 0.090097 Val loss= 0.307698 Training acc= 0.752500 Val acc= 0.752055\n",
            "Epoch 4500: Training loss= 0.090093 Val loss= 0.307656 Training acc= 0.752495 Val acc= 0.752050\n",
            "Epoch 4501: Training loss= 0.090090 Val loss= 0.307615 Training acc= 0.752480 Val acc= 0.752040\n",
            "Epoch 4502: Training loss= 0.090086 Val loss= 0.307574 Training acc= 0.752490 Val acc= 0.752045\n",
            "Epoch 4503: Training loss= 0.090083 Val loss= 0.307533 Training acc= 0.752495 Val acc= 0.752055\n",
            "Epoch 4504: Training loss= 0.090080 Val loss= 0.307492 Training acc= 0.752525 Val acc= 0.752080\n",
            "Epoch 4505: Training loss= 0.090076 Val loss= 0.307451 Training acc= 0.752530 Val acc= 0.752080\n",
            "Epoch 4506: Training loss= 0.090073 Val loss= 0.307410 Training acc= 0.752535 Val acc= 0.752085\n",
            "Epoch 4507: Training loss= 0.090069 Val loss= 0.307369 Training acc= 0.752565 Val acc= 0.752105\n",
            "Epoch 4508: Training loss= 0.090066 Val loss= 0.307328 Training acc= 0.752565 Val acc= 0.752105\n",
            "Epoch 4509: Training loss= 0.090062 Val loss= 0.307287 Training acc= 0.752580 Val acc= 0.752110\n",
            "Epoch 4510: Training loss= 0.090059 Val loss= 0.307246 Training acc= 0.752590 Val acc= 0.752120\n",
            "Epoch 4511: Training loss= 0.090056 Val loss= 0.307205 Training acc= 0.752590 Val acc= 0.752120\n",
            "Epoch 4512: Training loss= 0.090052 Val loss= 0.307164 Training acc= 0.752590 Val acc= 0.752125\n",
            "Epoch 4513: Training loss= 0.090049 Val loss= 0.307123 Training acc= 0.752585 Val acc= 0.752120\n",
            "Epoch 4514: Training loss= 0.090045 Val loss= 0.307082 Training acc= 0.752590 Val acc= 0.752120\n",
            "Epoch 4515: Training loss= 0.090042 Val loss= 0.307041 Training acc= 0.752610 Val acc= 0.752125\n",
            "Epoch 4516: Training loss= 0.090039 Val loss= 0.307000 Training acc= 0.752625 Val acc= 0.752140\n",
            "Epoch 4517: Training loss= 0.090035 Val loss= 0.306959 Training acc= 0.752635 Val acc= 0.752145\n",
            "Epoch 4518: Training loss= 0.090032 Val loss= 0.306918 Training acc= 0.752650 Val acc= 0.752160\n",
            "Epoch 4519: Training loss= 0.090028 Val loss= 0.306877 Training acc= 0.752670 Val acc= 0.752180\n",
            "Epoch 4520: Training loss= 0.090025 Val loss= 0.306836 Training acc= 0.752685 Val acc= 0.752190\n",
            "Epoch 4521: Training loss= 0.090022 Val loss= 0.306796 Training acc= 0.752680 Val acc= 0.752185\n",
            "Epoch 4522: Training loss= 0.090018 Val loss= 0.306755 Training acc= 0.752690 Val acc= 0.752205\n",
            "Epoch 4523: Training loss= 0.090015 Val loss= 0.306714 Training acc= 0.752675 Val acc= 0.752215\n",
            "Epoch 4524: Training loss= 0.090011 Val loss= 0.306673 Training acc= 0.752675 Val acc= 0.752215\n",
            "Epoch 4525: Training loss= 0.090008 Val loss= 0.306632 Training acc= 0.752680 Val acc= 0.752230\n",
            "Epoch 4526: Training loss= 0.090005 Val loss= 0.306592 Training acc= 0.752685 Val acc= 0.752235\n",
            "Epoch 4527: Training loss= 0.090001 Val loss= 0.306551 Training acc= 0.752695 Val acc= 0.752235\n",
            "Epoch 4528: Training loss= 0.089998 Val loss= 0.306510 Training acc= 0.752710 Val acc= 0.752250\n",
            "Epoch 4529: Training loss= 0.089995 Val loss= 0.306469 Training acc= 0.752700 Val acc= 0.752245\n",
            "Epoch 4530: Training loss= 0.089991 Val loss= 0.306429 Training acc= 0.752720 Val acc= 0.752265\n",
            "Epoch 4531: Training loss= 0.089988 Val loss= 0.306388 Training acc= 0.752730 Val acc= 0.752270\n",
            "Epoch 4532: Training loss= 0.089984 Val loss= 0.306347 Training acc= 0.752710 Val acc= 0.752260\n",
            "Epoch 4533: Training loss= 0.089981 Val loss= 0.306307 Training acc= 0.752720 Val acc= 0.752280\n",
            "Epoch 4534: Training loss= 0.089978 Val loss= 0.306266 Training acc= 0.752730 Val acc= 0.752290\n",
            "Epoch 4535: Training loss= 0.089974 Val loss= 0.306225 Training acc= 0.752720 Val acc= 0.752280\n",
            "Epoch 4536: Training loss= 0.089971 Val loss= 0.306185 Training acc= 0.752730 Val acc= 0.752300\n",
            "Epoch 4537: Training loss= 0.089968 Val loss= 0.306144 Training acc= 0.752760 Val acc= 0.752320\n",
            "Epoch 4538: Training loss= 0.089964 Val loss= 0.306103 Training acc= 0.752775 Val acc= 0.752325\n",
            "Epoch 4539: Training loss= 0.089961 Val loss= 0.306063 Training acc= 0.752790 Val acc= 0.752335\n",
            "Epoch 4540: Training loss= 0.089957 Val loss= 0.306022 Training acc= 0.752815 Val acc= 0.752355\n",
            "Epoch 4541: Training loss= 0.089954 Val loss= 0.305982 Training acc= 0.752830 Val acc= 0.752380\n",
            "Epoch 4542: Training loss= 0.089951 Val loss= 0.305941 Training acc= 0.752850 Val acc= 0.752395\n",
            "Epoch 4543: Training loss= 0.089947 Val loss= 0.305901 Training acc= 0.752860 Val acc= 0.752400\n",
            "Epoch 4544: Training loss= 0.089944 Val loss= 0.305860 Training acc= 0.752865 Val acc= 0.752405\n",
            "Epoch 4545: Training loss= 0.089941 Val loss= 0.305820 Training acc= 0.752865 Val acc= 0.752410\n",
            "Epoch 4546: Training loss= 0.089937 Val loss= 0.305779 Training acc= 0.752855 Val acc= 0.752405\n",
            "Epoch 4547: Training loss= 0.089934 Val loss= 0.305739 Training acc= 0.752870 Val acc= 0.752405\n",
            "Epoch 4548: Training loss= 0.089931 Val loss= 0.305698 Training acc= 0.752870 Val acc= 0.752400\n",
            "Epoch 4549: Training loss= 0.089927 Val loss= 0.305658 Training acc= 0.752875 Val acc= 0.752400\n",
            "Epoch 4550: Training loss= 0.089924 Val loss= 0.305617 Training acc= 0.752885 Val acc= 0.752425\n",
            "Epoch 4551: Training loss= 0.089920 Val loss= 0.305577 Training acc= 0.752875 Val acc= 0.752415\n",
            "Epoch 4552: Training loss= 0.089917 Val loss= 0.305536 Training acc= 0.752880 Val acc= 0.752420\n",
            "Epoch 4553: Training loss= 0.089914 Val loss= 0.305496 Training acc= 0.752910 Val acc= 0.752445\n",
            "Epoch 4554: Training loss= 0.089910 Val loss= 0.305456 Training acc= 0.752920 Val acc= 0.752475\n",
            "Epoch 4555: Training loss= 0.089907 Val loss= 0.305415 Training acc= 0.752935 Val acc= 0.752495\n",
            "Epoch 4556: Training loss= 0.089904 Val loss= 0.305375 Training acc= 0.752945 Val acc= 0.752500\n",
            "Epoch 4557: Training loss= 0.089900 Val loss= 0.305335 Training acc= 0.752950 Val acc= 0.752500\n",
            "Epoch 4558: Training loss= 0.089897 Val loss= 0.305294 Training acc= 0.752950 Val acc= 0.752495\n",
            "Epoch 4559: Training loss= 0.089894 Val loss= 0.305254 Training acc= 0.752970 Val acc= 0.752510\n",
            "Epoch 4560: Training loss= 0.089890 Val loss= 0.305214 Training acc= 0.752995 Val acc= 0.752530\n",
            "Epoch 4561: Training loss= 0.089887 Val loss= 0.305174 Training acc= 0.753010 Val acc= 0.752545\n",
            "Epoch 4562: Training loss= 0.089884 Val loss= 0.305133 Training acc= 0.753020 Val acc= 0.752545\n",
            "Epoch 4563: Training loss= 0.089880 Val loss= 0.305093 Training acc= 0.753025 Val acc= 0.752550\n",
            "Epoch 4564: Training loss= 0.089877 Val loss= 0.305053 Training acc= 0.753040 Val acc= 0.752560\n",
            "Epoch 4565: Training loss= 0.089874 Val loss= 0.305013 Training acc= 0.753030 Val acc= 0.752560\n",
            "Epoch 4566: Training loss= 0.089870 Val loss= 0.304972 Training acc= 0.753040 Val acc= 0.752580\n",
            "Epoch 4567: Training loss= 0.089867 Val loss= 0.304932 Training acc= 0.753050 Val acc= 0.752585\n",
            "Epoch 4568: Training loss= 0.089864 Val loss= 0.304892 Training acc= 0.753070 Val acc= 0.752590\n",
            "Epoch 4569: Training loss= 0.089860 Val loss= 0.304852 Training acc= 0.753090 Val acc= 0.752620\n",
            "Epoch 4570: Training loss= 0.089857 Val loss= 0.304812 Training acc= 0.753085 Val acc= 0.752625\n",
            "Epoch 4571: Training loss= 0.089854 Val loss= 0.304772 Training acc= 0.753095 Val acc= 0.752635\n",
            "Epoch 4572: Training loss= 0.089850 Val loss= 0.304731 Training acc= 0.753105 Val acc= 0.752640\n",
            "Epoch 4573: Training loss= 0.089847 Val loss= 0.304691 Training acc= 0.753110 Val acc= 0.752640\n",
            "Epoch 4574: Training loss= 0.089844 Val loss= 0.304651 Training acc= 0.753115 Val acc= 0.752645\n",
            "Epoch 4575: Training loss= 0.089840 Val loss= 0.304611 Training acc= 0.753135 Val acc= 0.752645\n",
            "Epoch 4576: Training loss= 0.089837 Val loss= 0.304571 Training acc= 0.753145 Val acc= 0.752650\n",
            "Epoch 4577: Training loss= 0.089834 Val loss= 0.304531 Training acc= 0.753140 Val acc= 0.752630\n",
            "Epoch 4578: Training loss= 0.089830 Val loss= 0.304491 Training acc= 0.753145 Val acc= 0.752630\n",
            "Epoch 4579: Training loss= 0.089827 Val loss= 0.304451 Training acc= 0.753145 Val acc= 0.752630\n",
            "Epoch 4580: Training loss= 0.089824 Val loss= 0.304411 Training acc= 0.753155 Val acc= 0.752630\n",
            "Epoch 4581: Training loss= 0.089820 Val loss= 0.304371 Training acc= 0.753160 Val acc= 0.752640\n",
            "Epoch 4582: Training loss= 0.089817 Val loss= 0.304331 Training acc= 0.753190 Val acc= 0.752670\n",
            "Epoch 4583: Training loss= 0.089814 Val loss= 0.304291 Training acc= 0.753185 Val acc= 0.752665\n",
            "Epoch 4584: Training loss= 0.089810 Val loss= 0.304251 Training acc= 0.753195 Val acc= 0.752670\n",
            "Epoch 4585: Training loss= 0.089807 Val loss= 0.304211 Training acc= 0.753180 Val acc= 0.752665\n",
            "Epoch 4586: Training loss= 0.089804 Val loss= 0.304171 Training acc= 0.753195 Val acc= 0.752685\n",
            "Epoch 4587: Training loss= 0.089801 Val loss= 0.304131 Training acc= 0.753175 Val acc= 0.752670\n",
            "Epoch 4588: Training loss= 0.089797 Val loss= 0.304091 Training acc= 0.753195 Val acc= 0.752680\n",
            "Epoch 4589: Training loss= 0.089794 Val loss= 0.304051 Training acc= 0.753185 Val acc= 0.752675\n",
            "Epoch 4590: Training loss= 0.089791 Val loss= 0.304012 Training acc= 0.753185 Val acc= 0.752685\n",
            "Epoch 4591: Training loss= 0.089787 Val loss= 0.303972 Training acc= 0.753200 Val acc= 0.752695\n",
            "Epoch 4592: Training loss= 0.089784 Val loss= 0.303932 Training acc= 0.753205 Val acc= 0.752700\n",
            "Epoch 4593: Training loss= 0.089781 Val loss= 0.303892 Training acc= 0.753230 Val acc= 0.752715\n",
            "Epoch 4594: Training loss= 0.089777 Val loss= 0.303852 Training acc= 0.753235 Val acc= 0.752720\n",
            "Epoch 4595: Training loss= 0.089774 Val loss= 0.303812 Training acc= 0.753245 Val acc= 0.752725\n",
            "Epoch 4596: Training loss= 0.089771 Val loss= 0.303773 Training acc= 0.753250 Val acc= 0.752745\n",
            "Epoch 4597: Training loss= 0.089768 Val loss= 0.303733 Training acc= 0.753250 Val acc= 0.752745\n",
            "Epoch 4598: Training loss= 0.089764 Val loss= 0.303693 Training acc= 0.753250 Val acc= 0.752750\n",
            "Epoch 4599: Training loss= 0.089761 Val loss= 0.303653 Training acc= 0.753250 Val acc= 0.752750\n",
            "Epoch 4600: Training loss= 0.089758 Val loss= 0.303614 Training acc= 0.753250 Val acc= 0.752755\n",
            "Epoch 4601: Training loss= 0.089754 Val loss= 0.303574 Training acc= 0.753255 Val acc= 0.752765\n",
            "Epoch 4602: Training loss= 0.089751 Val loss= 0.303534 Training acc= 0.753265 Val acc= 0.752770\n",
            "Epoch 4603: Training loss= 0.089748 Val loss= 0.303495 Training acc= 0.753275 Val acc= 0.752780\n",
            "Epoch 4604: Training loss= 0.089745 Val loss= 0.303455 Training acc= 0.753295 Val acc= 0.752800\n",
            "Epoch 4605: Training loss= 0.089741 Val loss= 0.303415 Training acc= 0.753295 Val acc= 0.752805\n",
            "Epoch 4606: Training loss= 0.089738 Val loss= 0.303376 Training acc= 0.753300 Val acc= 0.752815\n",
            "Epoch 4607: Training loss= 0.089735 Val loss= 0.303336 Training acc= 0.753320 Val acc= 0.752840\n",
            "Epoch 4608: Training loss= 0.089731 Val loss= 0.303296 Training acc= 0.753335 Val acc= 0.752845\n",
            "Epoch 4609: Training loss= 0.089728 Val loss= 0.303257 Training acc= 0.753335 Val acc= 0.752845\n",
            "Epoch 4610: Training loss= 0.089725 Val loss= 0.303217 Training acc= 0.753325 Val acc= 0.752835\n",
            "Epoch 4611: Training loss= 0.089722 Val loss= 0.303178 Training acc= 0.753345 Val acc= 0.752865\n",
            "Epoch 4612: Training loss= 0.089718 Val loss= 0.303138 Training acc= 0.753355 Val acc= 0.752880\n",
            "Epoch 4613: Training loss= 0.089715 Val loss= 0.303098 Training acc= 0.753370 Val acc= 0.752890\n",
            "Epoch 4614: Training loss= 0.089712 Val loss= 0.303059 Training acc= 0.753380 Val acc= 0.752910\n",
            "Epoch 4615: Training loss= 0.089708 Val loss= 0.303019 Training acc= 0.753385 Val acc= 0.752905\n",
            "Epoch 4616: Training loss= 0.089705 Val loss= 0.302980 Training acc= 0.753405 Val acc= 0.752925\n",
            "Epoch 4617: Training loss= 0.089702 Val loss= 0.302940 Training acc= 0.753400 Val acc= 0.752925\n",
            "Epoch 4618: Training loss= 0.089699 Val loss= 0.302901 Training acc= 0.753395 Val acc= 0.752925\n",
            "Epoch 4619: Training loss= 0.089695 Val loss= 0.302861 Training acc= 0.753385 Val acc= 0.752925\n",
            "Epoch 4620: Training loss= 0.089692 Val loss= 0.302822 Training acc= 0.753390 Val acc= 0.752925\n",
            "Epoch 4621: Training loss= 0.089689 Val loss= 0.302783 Training acc= 0.753385 Val acc= 0.752925\n",
            "Epoch 4622: Training loss= 0.089686 Val loss= 0.302743 Training acc= 0.753390 Val acc= 0.752935\n",
            "Epoch 4623: Training loss= 0.089682 Val loss= 0.302704 Training acc= 0.753395 Val acc= 0.752950\n",
            "Epoch 4624: Training loss= 0.089679 Val loss= 0.302664 Training acc= 0.753405 Val acc= 0.752950\n",
            "Epoch 4625: Training loss= 0.089676 Val loss= 0.302625 Training acc= 0.753425 Val acc= 0.752955\n",
            "Epoch 4626: Training loss= 0.089673 Val loss= 0.302586 Training acc= 0.753450 Val acc= 0.752975\n",
            "Epoch 4627: Training loss= 0.089669 Val loss= 0.302546 Training acc= 0.753455 Val acc= 0.752980\n",
            "Epoch 4628: Training loss= 0.089666 Val loss= 0.302507 Training acc= 0.753460 Val acc= 0.752995\n",
            "Epoch 4629: Training loss= 0.089663 Val loss= 0.302467 Training acc= 0.753470 Val acc= 0.753000\n",
            "Epoch 4630: Training loss= 0.089660 Val loss= 0.302428 Training acc= 0.753485 Val acc= 0.753015\n",
            "Epoch 4631: Training loss= 0.089656 Val loss= 0.302389 Training acc= 0.753490 Val acc= 0.753010\n",
            "Epoch 4632: Training loss= 0.089653 Val loss= 0.302350 Training acc= 0.753500 Val acc= 0.753025\n",
            "Epoch 4633: Training loss= 0.089650 Val loss= 0.302310 Training acc= 0.753505 Val acc= 0.753030\n",
            "Epoch 4634: Training loss= 0.089647 Val loss= 0.302271 Training acc= 0.753525 Val acc= 0.753035\n",
            "Epoch 4635: Training loss= 0.089643 Val loss= 0.302232 Training acc= 0.753530 Val acc= 0.753030\n",
            "Epoch 4636: Training loss= 0.089640 Val loss= 0.302193 Training acc= 0.753535 Val acc= 0.753035\n",
            "Epoch 4637: Training loss= 0.089637 Val loss= 0.302153 Training acc= 0.753535 Val acc= 0.753040\n",
            "Epoch 4638: Training loss= 0.089634 Val loss= 0.302114 Training acc= 0.753550 Val acc= 0.753050\n",
            "Epoch 4639: Training loss= 0.089630 Val loss= 0.302075 Training acc= 0.753555 Val acc= 0.753050\n",
            "Epoch 4640: Training loss= 0.089627 Val loss= 0.302036 Training acc= 0.753570 Val acc= 0.753065\n",
            "Epoch 4641: Training loss= 0.089624 Val loss= 0.301997 Training acc= 0.753570 Val acc= 0.753070\n",
            "Epoch 4642: Training loss= 0.089621 Val loss= 0.301957 Training acc= 0.753585 Val acc= 0.753075\n",
            "Epoch 4643: Training loss= 0.089617 Val loss= 0.301918 Training acc= 0.753600 Val acc= 0.753085\n",
            "Epoch 4644: Training loss= 0.089614 Val loss= 0.301879 Training acc= 0.753605 Val acc= 0.753090\n",
            "Epoch 4645: Training loss= 0.089611 Val loss= 0.301840 Training acc= 0.753635 Val acc= 0.753120\n",
            "Epoch 4646: Training loss= 0.089608 Val loss= 0.301801 Training acc= 0.753635 Val acc= 0.753125\n",
            "Epoch 4647: Training loss= 0.089604 Val loss= 0.301762 Training acc= 0.753645 Val acc= 0.753130\n",
            "Epoch 4648: Training loss= 0.089601 Val loss= 0.301723 Training acc= 0.753670 Val acc= 0.753145\n",
            "Epoch 4649: Training loss= 0.089598 Val loss= 0.301684 Training acc= 0.753680 Val acc= 0.753160\n",
            "Epoch 4650: Training loss= 0.089595 Val loss= 0.301645 Training acc= 0.753685 Val acc= 0.753165\n",
            "Epoch 4651: Training loss= 0.089592 Val loss= 0.301606 Training acc= 0.753685 Val acc= 0.753170\n",
            "Epoch 4652: Training loss= 0.089588 Val loss= 0.301567 Training acc= 0.753690 Val acc= 0.753175\n",
            "Epoch 4653: Training loss= 0.089585 Val loss= 0.301528 Training acc= 0.753715 Val acc= 0.753200\n",
            "Epoch 4654: Training loss= 0.089582 Val loss= 0.301489 Training acc= 0.753735 Val acc= 0.753215\n",
            "Epoch 4655: Training loss= 0.089579 Val loss= 0.301450 Training acc= 0.753735 Val acc= 0.753220\n",
            "Epoch 4656: Training loss= 0.089575 Val loss= 0.301411 Training acc= 0.753750 Val acc= 0.753235\n",
            "Epoch 4657: Training loss= 0.089572 Val loss= 0.301372 Training acc= 0.753750 Val acc= 0.753235\n",
            "Epoch 4658: Training loss= 0.089569 Val loss= 0.301333 Training acc= 0.753760 Val acc= 0.753245\n",
            "Epoch 4659: Training loss= 0.089566 Val loss= 0.301294 Training acc= 0.753775 Val acc= 0.753260\n",
            "Epoch 4660: Training loss= 0.089563 Val loss= 0.301255 Training acc= 0.753780 Val acc= 0.753280\n",
            "Epoch 4661: Training loss= 0.089559 Val loss= 0.301216 Training acc= 0.753785 Val acc= 0.753285\n",
            "Epoch 4662: Training loss= 0.089556 Val loss= 0.301177 Training acc= 0.753785 Val acc= 0.753295\n",
            "Epoch 4663: Training loss= 0.089553 Val loss= 0.301138 Training acc= 0.753805 Val acc= 0.753315\n",
            "Epoch 4664: Training loss= 0.089550 Val loss= 0.301099 Training acc= 0.753785 Val acc= 0.753315\n",
            "Epoch 4665: Training loss= 0.089546 Val loss= 0.301060 Training acc= 0.753785 Val acc= 0.753320\n",
            "Epoch 4666: Training loss= 0.089543 Val loss= 0.301022 Training acc= 0.753790 Val acc= 0.753325\n",
            "Epoch 4667: Training loss= 0.089540 Val loss= 0.300983 Training acc= 0.753805 Val acc= 0.753330\n",
            "Epoch 4668: Training loss= 0.089537 Val loss= 0.300944 Training acc= 0.753820 Val acc= 0.753350\n",
            "Epoch 4669: Training loss= 0.089534 Val loss= 0.300905 Training acc= 0.753835 Val acc= 0.753365\n",
            "Epoch 4670: Training loss= 0.089530 Val loss= 0.300866 Training acc= 0.753830 Val acc= 0.753370\n",
            "Epoch 4671: Training loss= 0.089527 Val loss= 0.300828 Training acc= 0.753845 Val acc= 0.753385\n",
            "Epoch 4672: Training loss= 0.089524 Val loss= 0.300789 Training acc= 0.753855 Val acc= 0.753390\n",
            "Epoch 4673: Training loss= 0.089521 Val loss= 0.300750 Training acc= 0.753860 Val acc= 0.753390\n",
            "Epoch 4674: Training loss= 0.089518 Val loss= 0.300711 Training acc= 0.753860 Val acc= 0.753380\n",
            "Epoch 4675: Training loss= 0.089514 Val loss= 0.300673 Training acc= 0.753860 Val acc= 0.753380\n",
            "Epoch 4676: Training loss= 0.089511 Val loss= 0.300634 Training acc= 0.753855 Val acc= 0.753375\n",
            "Epoch 4677: Training loss= 0.089508 Val loss= 0.300595 Training acc= 0.753860 Val acc= 0.753380\n",
            "Epoch 4678: Training loss= 0.089505 Val loss= 0.300557 Training acc= 0.753855 Val acc= 0.753380\n",
            "Epoch 4679: Training loss= 0.089502 Val loss= 0.300518 Training acc= 0.753860 Val acc= 0.753395\n",
            "Epoch 4680: Training loss= 0.089499 Val loss= 0.300479 Training acc= 0.753850 Val acc= 0.753380\n",
            "Epoch 4681: Training loss= 0.089495 Val loss= 0.300441 Training acc= 0.753865 Val acc= 0.753395\n",
            "Epoch 4682: Training loss= 0.089492 Val loss= 0.300402 Training acc= 0.753865 Val acc= 0.753390\n",
            "Epoch 4683: Training loss= 0.089489 Val loss= 0.300363 Training acc= 0.753870 Val acc= 0.753390\n",
            "Epoch 4684: Training loss= 0.089486 Val loss= 0.300325 Training acc= 0.753860 Val acc= 0.753380\n",
            "Epoch 4685: Training loss= 0.089483 Val loss= 0.300286 Training acc= 0.753865 Val acc= 0.753380\n",
            "Epoch 4686: Training loss= 0.089479 Val loss= 0.300248 Training acc= 0.753855 Val acc= 0.753375\n",
            "Epoch 4687: Training loss= 0.089476 Val loss= 0.300209 Training acc= 0.753865 Val acc= 0.753380\n",
            "Epoch 4688: Training loss= 0.089473 Val loss= 0.300171 Training acc= 0.753910 Val acc= 0.753405\n",
            "Epoch 4689: Training loss= 0.089470 Val loss= 0.300132 Training acc= 0.753905 Val acc= 0.753405\n",
            "Epoch 4690: Training loss= 0.089467 Val loss= 0.300094 Training acc= 0.753920 Val acc= 0.753420\n",
            "Epoch 4691: Training loss= 0.089463 Val loss= 0.300055 Training acc= 0.753910 Val acc= 0.753420\n",
            "Epoch 4692: Training loss= 0.089460 Val loss= 0.300017 Training acc= 0.753920 Val acc= 0.753435\n",
            "Epoch 4693: Training loss= 0.089457 Val loss= 0.299978 Training acc= 0.753915 Val acc= 0.753440\n",
            "Epoch 4694: Training loss= 0.089454 Val loss= 0.299940 Training acc= 0.753925 Val acc= 0.753445\n",
            "Epoch 4695: Training loss= 0.089451 Val loss= 0.299901 Training acc= 0.753940 Val acc= 0.753455\n",
            "Epoch 4696: Training loss= 0.089448 Val loss= 0.299863 Training acc= 0.753930 Val acc= 0.753450\n",
            "Epoch 4697: Training loss= 0.089444 Val loss= 0.299824 Training acc= 0.753930 Val acc= 0.753445\n",
            "Epoch 4698: Training loss= 0.089441 Val loss= 0.299786 Training acc= 0.753950 Val acc= 0.753460\n",
            "Epoch 4699: Training loss= 0.089438 Val loss= 0.299747 Training acc= 0.753960 Val acc= 0.753465\n",
            "Epoch 4700: Training loss= 0.089435 Val loss= 0.299709 Training acc= 0.753960 Val acc= 0.753465\n",
            "Epoch 4701: Training loss= 0.089432 Val loss= 0.299671 Training acc= 0.753965 Val acc= 0.753480\n",
            "Epoch 4702: Training loss= 0.089429 Val loss= 0.299632 Training acc= 0.753975 Val acc= 0.753495\n",
            "Epoch 4703: Training loss= 0.089425 Val loss= 0.299594 Training acc= 0.753985 Val acc= 0.753505\n",
            "Epoch 4704: Training loss= 0.089422 Val loss= 0.299556 Training acc= 0.753995 Val acc= 0.753510\n",
            "Epoch 4705: Training loss= 0.089419 Val loss= 0.299517 Training acc= 0.754000 Val acc= 0.753515\n",
            "Epoch 4706: Training loss= 0.089416 Val loss= 0.299479 Training acc= 0.754000 Val acc= 0.753510\n",
            "Epoch 4707: Training loss= 0.089413 Val loss= 0.299441 Training acc= 0.754005 Val acc= 0.753510\n",
            "Epoch 4708: Training loss= 0.089410 Val loss= 0.299402 Training acc= 0.754000 Val acc= 0.753510\n",
            "Epoch 4709: Training loss= 0.089407 Val loss= 0.299364 Training acc= 0.754005 Val acc= 0.753510\n",
            "Epoch 4710: Training loss= 0.089403 Val loss= 0.299326 Training acc= 0.754025 Val acc= 0.753530\n",
            "Epoch 4711: Training loss= 0.089400 Val loss= 0.299288 Training acc= 0.754030 Val acc= 0.753540\n",
            "Epoch 4712: Training loss= 0.089397 Val loss= 0.299249 Training acc= 0.754020 Val acc= 0.753535\n",
            "Epoch 4713: Training loss= 0.089394 Val loss= 0.299211 Training acc= 0.754030 Val acc= 0.753545\n",
            "Epoch 4714: Training loss= 0.089391 Val loss= 0.299173 Training acc= 0.754025 Val acc= 0.753550\n",
            "Epoch 4715: Training loss= 0.089388 Val loss= 0.299135 Training acc= 0.754040 Val acc= 0.753560\n",
            "Epoch 4716: Training loss= 0.089384 Val loss= 0.299097 Training acc= 0.754025 Val acc= 0.753555\n",
            "Epoch 4717: Training loss= 0.089381 Val loss= 0.299058 Training acc= 0.754045 Val acc= 0.753575\n",
            "Epoch 4718: Training loss= 0.089378 Val loss= 0.299020 Training acc= 0.754045 Val acc= 0.753575\n",
            "Epoch 4719: Training loss= 0.089375 Val loss= 0.298982 Training acc= 0.754040 Val acc= 0.753565\n",
            "Epoch 4720: Training loss= 0.089372 Val loss= 0.298944 Training acc= 0.754045 Val acc= 0.753570\n",
            "Epoch 4721: Training loss= 0.089369 Val loss= 0.298906 Training acc= 0.754040 Val acc= 0.753580\n",
            "Epoch 4722: Training loss= 0.089366 Val loss= 0.298868 Training acc= 0.754030 Val acc= 0.753580\n",
            "Epoch 4723: Training loss= 0.089362 Val loss= 0.298830 Training acc= 0.754035 Val acc= 0.753590\n",
            "Epoch 4724: Training loss= 0.089359 Val loss= 0.298792 Training acc= 0.754045 Val acc= 0.753605\n",
            "Epoch 4725: Training loss= 0.089356 Val loss= 0.298754 Training acc= 0.754050 Val acc= 0.753600\n",
            "Epoch 4726: Training loss= 0.089353 Val loss= 0.298716 Training acc= 0.754060 Val acc= 0.753605\n",
            "Epoch 4727: Training loss= 0.089350 Val loss= 0.298678 Training acc= 0.754085 Val acc= 0.753615\n",
            "Epoch 4728: Training loss= 0.089347 Val loss= 0.298639 Training acc= 0.754100 Val acc= 0.753630\n",
            "Epoch 4729: Training loss= 0.089344 Val loss= 0.298601 Training acc= 0.754110 Val acc= 0.753645\n",
            "Epoch 4730: Training loss= 0.089341 Val loss= 0.298563 Training acc= 0.754115 Val acc= 0.753665\n",
            "Epoch 4731: Training loss= 0.089337 Val loss= 0.298525 Training acc= 0.754135 Val acc= 0.753675\n",
            "Epoch 4732: Training loss= 0.089334 Val loss= 0.298488 Training acc= 0.754145 Val acc= 0.753690\n",
            "Epoch 4733: Training loss= 0.089331 Val loss= 0.298450 Training acc= 0.754155 Val acc= 0.753685\n",
            "Epoch 4734: Training loss= 0.089328 Val loss= 0.298412 Training acc= 0.754160 Val acc= 0.753685\n",
            "Epoch 4735: Training loss= 0.089325 Val loss= 0.298374 Training acc= 0.754175 Val acc= 0.753690\n",
            "Epoch 4736: Training loss= 0.089322 Val loss= 0.298336 Training acc= 0.754170 Val acc= 0.753685\n",
            "Epoch 4737: Training loss= 0.089319 Val loss= 0.298298 Training acc= 0.754190 Val acc= 0.753700\n",
            "Epoch 4738: Training loss= 0.089316 Val loss= 0.298260 Training acc= 0.754195 Val acc= 0.753705\n",
            "Epoch 4739: Training loss= 0.089312 Val loss= 0.298222 Training acc= 0.754190 Val acc= 0.753700\n",
            "Epoch 4740: Training loss= 0.089309 Val loss= 0.298184 Training acc= 0.754190 Val acc= 0.753700\n",
            "Epoch 4741: Training loss= 0.089306 Val loss= 0.298146 Training acc= 0.754190 Val acc= 0.753705\n",
            "Epoch 4742: Training loss= 0.089303 Val loss= 0.298108 Training acc= 0.754190 Val acc= 0.753715\n",
            "Epoch 4743: Training loss= 0.089300 Val loss= 0.298071 Training acc= 0.754205 Val acc= 0.753735\n",
            "Epoch 4744: Training loss= 0.089297 Val loss= 0.298033 Training acc= 0.754220 Val acc= 0.753745\n",
            "Epoch 4745: Training loss= 0.089294 Val loss= 0.297995 Training acc= 0.754235 Val acc= 0.753760\n",
            "Epoch 4746: Training loss= 0.089291 Val loss= 0.297957 Training acc= 0.754235 Val acc= 0.753755\n",
            "Epoch 4747: Training loss= 0.089288 Val loss= 0.297919 Training acc= 0.754235 Val acc= 0.753755\n",
            "Epoch 4748: Training loss= 0.089284 Val loss= 0.297882 Training acc= 0.754235 Val acc= 0.753755\n",
            "Epoch 4749: Training loss= 0.089281 Val loss= 0.297844 Training acc= 0.754220 Val acc= 0.753745\n",
            "Epoch 4750: Training loss= 0.089278 Val loss= 0.297806 Training acc= 0.754225 Val acc= 0.753745\n",
            "Epoch 4751: Training loss= 0.089275 Val loss= 0.297768 Training acc= 0.754240 Val acc= 0.753750\n",
            "Epoch 4752: Training loss= 0.089272 Val loss= 0.297731 Training acc= 0.754255 Val acc= 0.753755\n",
            "Epoch 4753: Training loss= 0.089269 Val loss= 0.297693 Training acc= 0.754275 Val acc= 0.753770\n",
            "Epoch 4754: Training loss= 0.089266 Val loss= 0.297655 Training acc= 0.754290 Val acc= 0.753780\n",
            "Epoch 4755: Training loss= 0.089263 Val loss= 0.297618 Training acc= 0.754310 Val acc= 0.753800\n",
            "Epoch 4756: Training loss= 0.089260 Val loss= 0.297580 Training acc= 0.754305 Val acc= 0.753800\n",
            "Epoch 4757: Training loss= 0.089256 Val loss= 0.297542 Training acc= 0.754315 Val acc= 0.753810\n",
            "Epoch 4758: Training loss= 0.089253 Val loss= 0.297505 Training acc= 0.754320 Val acc= 0.753825\n",
            "Epoch 4759: Training loss= 0.089250 Val loss= 0.297467 Training acc= 0.754320 Val acc= 0.753825\n",
            "Epoch 4760: Training loss= 0.089247 Val loss= 0.297429 Training acc= 0.754340 Val acc= 0.753840\n",
            "Epoch 4761: Training loss= 0.089244 Val loss= 0.297392 Training acc= 0.754365 Val acc= 0.753845\n",
            "Epoch 4762: Training loss= 0.089241 Val loss= 0.297354 Training acc= 0.754365 Val acc= 0.753860\n",
            "Epoch 4763: Training loss= 0.089238 Val loss= 0.297317 Training acc= 0.754375 Val acc= 0.753865\n",
            "Epoch 4764: Training loss= 0.089235 Val loss= 0.297279 Training acc= 0.754380 Val acc= 0.753870\n",
            "Epoch 4765: Training loss= 0.089232 Val loss= 0.297242 Training acc= 0.754395 Val acc= 0.753890\n",
            "Epoch 4766: Training loss= 0.089229 Val loss= 0.297204 Training acc= 0.754400 Val acc= 0.753890\n",
            "Epoch 4767: Training loss= 0.089226 Val loss= 0.297166 Training acc= 0.754410 Val acc= 0.753910\n",
            "Epoch 4768: Training loss= 0.089222 Val loss= 0.297129 Training acc= 0.754410 Val acc= 0.753905\n",
            "Epoch 4769: Training loss= 0.089219 Val loss= 0.297091 Training acc= 0.754405 Val acc= 0.753905\n",
            "Epoch 4770: Training loss= 0.089216 Val loss= 0.297054 Training acc= 0.754410 Val acc= 0.753915\n",
            "Epoch 4771: Training loss= 0.089213 Val loss= 0.297017 Training acc= 0.754420 Val acc= 0.753920\n",
            "Epoch 4772: Training loss= 0.089210 Val loss= 0.296979 Training acc= 0.754405 Val acc= 0.753925\n",
            "Epoch 4773: Training loss= 0.089207 Val loss= 0.296942 Training acc= 0.754415 Val acc= 0.753940\n",
            "Epoch 4774: Training loss= 0.089204 Val loss= 0.296904 Training acc= 0.754405 Val acc= 0.753925\n",
            "Epoch 4775: Training loss= 0.089201 Val loss= 0.296867 Training acc= 0.754415 Val acc= 0.753920\n",
            "Epoch 4776: Training loss= 0.089198 Val loss= 0.296829 Training acc= 0.754415 Val acc= 0.753915\n",
            "Epoch 4777: Training loss= 0.089195 Val loss= 0.296792 Training acc= 0.754415 Val acc= 0.753915\n",
            "Epoch 4778: Training loss= 0.089192 Val loss= 0.296755 Training acc= 0.754435 Val acc= 0.753940\n",
            "Epoch 4779: Training loss= 0.089189 Val loss= 0.296717 Training acc= 0.754465 Val acc= 0.753970\n",
            "Epoch 4780: Training loss= 0.089186 Val loss= 0.296680 Training acc= 0.754480 Val acc= 0.753980\n",
            "Epoch 4781: Training loss= 0.089182 Val loss= 0.296642 Training acc= 0.754480 Val acc= 0.753990\n",
            "Epoch 4782: Training loss= 0.089179 Val loss= 0.296605 Training acc= 0.754480 Val acc= 0.753990\n",
            "Epoch 4783: Training loss= 0.089176 Val loss= 0.296568 Training acc= 0.754485 Val acc= 0.753995\n",
            "Epoch 4784: Training loss= 0.089173 Val loss= 0.296530 Training acc= 0.754475 Val acc= 0.753995\n",
            "Epoch 4785: Training loss= 0.089170 Val loss= 0.296493 Training acc= 0.754470 Val acc= 0.753995\n",
            "Epoch 4786: Training loss= 0.089167 Val loss= 0.296456 Training acc= 0.754470 Val acc= 0.753995\n",
            "Epoch 4787: Training loss= 0.089164 Val loss= 0.296419 Training acc= 0.754470 Val acc= 0.753995\n",
            "Epoch 4788: Training loss= 0.089161 Val loss= 0.296381 Training acc= 0.754475 Val acc= 0.754005\n",
            "Epoch 4789: Training loss= 0.089158 Val loss= 0.296344 Training acc= 0.754485 Val acc= 0.754020\n",
            "Epoch 4790: Training loss= 0.089155 Val loss= 0.296307 Training acc= 0.754485 Val acc= 0.754015\n",
            "Epoch 4791: Training loss= 0.089152 Val loss= 0.296270 Training acc= 0.754500 Val acc= 0.754030\n",
            "Epoch 4792: Training loss= 0.089149 Val loss= 0.296232 Training acc= 0.754505 Val acc= 0.754030\n",
            "Epoch 4793: Training loss= 0.089146 Val loss= 0.296195 Training acc= 0.754500 Val acc= 0.754035\n",
            "Epoch 4794: Training loss= 0.089143 Val loss= 0.296158 Training acc= 0.754505 Val acc= 0.754050\n",
            "Epoch 4795: Training loss= 0.089140 Val loss= 0.296121 Training acc= 0.754520 Val acc= 0.754075\n",
            "Epoch 4796: Training loss= 0.089137 Val loss= 0.296084 Training acc= 0.754525 Val acc= 0.754075\n",
            "Epoch 4797: Training loss= 0.089134 Val loss= 0.296046 Training acc= 0.754530 Val acc= 0.754085\n",
            "Epoch 4798: Training loss= 0.089130 Val loss= 0.296009 Training acc= 0.754525 Val acc= 0.754080\n",
            "Epoch 4799: Training loss= 0.089127 Val loss= 0.295972 Training acc= 0.754520 Val acc= 0.754075\n",
            "Epoch 4800: Training loss= 0.089124 Val loss= 0.295935 Training acc= 0.754520 Val acc= 0.754075\n",
            "Epoch 4801: Training loss= 0.089121 Val loss= 0.295898 Training acc= 0.754540 Val acc= 0.754095\n",
            "Epoch 4802: Training loss= 0.089118 Val loss= 0.295861 Training acc= 0.754545 Val acc= 0.754085\n",
            "Epoch 4803: Training loss= 0.089115 Val loss= 0.295824 Training acc= 0.754545 Val acc= 0.754085\n",
            "Epoch 4804: Training loss= 0.089112 Val loss= 0.295787 Training acc= 0.754550 Val acc= 0.754090\n",
            "Epoch 4805: Training loss= 0.089109 Val loss= 0.295750 Training acc= 0.754545 Val acc= 0.754080\n",
            "Epoch 4806: Training loss= 0.089106 Val loss= 0.295713 Training acc= 0.754565 Val acc= 0.754090\n",
            "Epoch 4807: Training loss= 0.089103 Val loss= 0.295676 Training acc= 0.754570 Val acc= 0.754090\n",
            "Epoch 4808: Training loss= 0.089100 Val loss= 0.295639 Training acc= 0.754570 Val acc= 0.754090\n",
            "Epoch 4809: Training loss= 0.089097 Val loss= 0.295602 Training acc= 0.754575 Val acc= 0.754100\n",
            "Epoch 4810: Training loss= 0.089094 Val loss= 0.295565 Training acc= 0.754590 Val acc= 0.754115\n",
            "Epoch 4811: Training loss= 0.089091 Val loss= 0.295528 Training acc= 0.754585 Val acc= 0.754110\n",
            "Epoch 4812: Training loss= 0.089088 Val loss= 0.295491 Training acc= 0.754580 Val acc= 0.754120\n",
            "Epoch 4813: Training loss= 0.089085 Val loss= 0.295454 Training acc= 0.754595 Val acc= 0.754130\n",
            "Epoch 4814: Training loss= 0.089082 Val loss= 0.295417 Training acc= 0.754600 Val acc= 0.754145\n",
            "Epoch 4815: Training loss= 0.089079 Val loss= 0.295380 Training acc= 0.754615 Val acc= 0.754160\n",
            "Epoch 4816: Training loss= 0.089076 Val loss= 0.295343 Training acc= 0.754620 Val acc= 0.754165\n",
            "Epoch 4817: Training loss= 0.089073 Val loss= 0.295306 Training acc= 0.754625 Val acc= 0.754175\n",
            "Epoch 4818: Training loss= 0.089070 Val loss= 0.295269 Training acc= 0.754630 Val acc= 0.754185\n",
            "Epoch 4819: Training loss= 0.089067 Val loss= 0.295232 Training acc= 0.754630 Val acc= 0.754185\n",
            "Epoch 4820: Training loss= 0.089064 Val loss= 0.295195 Training acc= 0.754630 Val acc= 0.754185\n",
            "Epoch 4821: Training loss= 0.089061 Val loss= 0.295159 Training acc= 0.754625 Val acc= 0.754195\n",
            "Epoch 4822: Training loss= 0.089058 Val loss= 0.295122 Training acc= 0.754630 Val acc= 0.754200\n",
            "Epoch 4823: Training loss= 0.089055 Val loss= 0.295085 Training acc= 0.754640 Val acc= 0.754200\n",
            "Epoch 4824: Training loss= 0.089052 Val loss= 0.295048 Training acc= 0.754640 Val acc= 0.754200\n",
            "Epoch 4825: Training loss= 0.089049 Val loss= 0.295011 Training acc= 0.754645 Val acc= 0.754200\n",
            "Epoch 4826: Training loss= 0.089045 Val loss= 0.294974 Training acc= 0.754645 Val acc= 0.754215\n",
            "Epoch 4827: Training loss= 0.089042 Val loss= 0.294938 Training acc= 0.754675 Val acc= 0.754240\n",
            "Epoch 4828: Training loss= 0.089039 Val loss= 0.294901 Training acc= 0.754655 Val acc= 0.754210\n",
            "Epoch 4829: Training loss= 0.089036 Val loss= 0.294864 Training acc= 0.754680 Val acc= 0.754225\n",
            "Epoch 4830: Training loss= 0.089033 Val loss= 0.294827 Training acc= 0.754695 Val acc= 0.754240\n",
            "Epoch 4831: Training loss= 0.089030 Val loss= 0.294791 Training acc= 0.754705 Val acc= 0.754255\n",
            "Epoch 4832: Training loss= 0.089027 Val loss= 0.294754 Training acc= 0.754700 Val acc= 0.754255\n",
            "Epoch 4833: Training loss= 0.089024 Val loss= 0.294717 Training acc= 0.754690 Val acc= 0.754240\n",
            "Epoch 4834: Training loss= 0.089021 Val loss= 0.294680 Training acc= 0.754705 Val acc= 0.754255\n",
            "Epoch 4835: Training loss= 0.089018 Val loss= 0.294644 Training acc= 0.754710 Val acc= 0.754255\n",
            "Epoch 4836: Training loss= 0.089015 Val loss= 0.294607 Training acc= 0.754715 Val acc= 0.754265\n",
            "Epoch 4837: Training loss= 0.089012 Val loss= 0.294570 Training acc= 0.754715 Val acc= 0.754275\n",
            "Epoch 4838: Training loss= 0.089009 Val loss= 0.294534 Training acc= 0.754710 Val acc= 0.754270\n",
            "Epoch 4839: Training loss= 0.089006 Val loss= 0.294497 Training acc= 0.754710 Val acc= 0.754270\n",
            "Epoch 4840: Training loss= 0.089003 Val loss= 0.294461 Training acc= 0.754710 Val acc= 0.754270\n",
            "Epoch 4841: Training loss= 0.089000 Val loss= 0.294424 Training acc= 0.754705 Val acc= 0.754270\n",
            "Epoch 4842: Training loss= 0.088997 Val loss= 0.294387 Training acc= 0.754695 Val acc= 0.754260\n",
            "Epoch 4843: Training loss= 0.088994 Val loss= 0.294351 Training acc= 0.754700 Val acc= 0.754260\n",
            "Epoch 4844: Training loss= 0.088991 Val loss= 0.294314 Training acc= 0.754725 Val acc= 0.754285\n",
            "Epoch 4845: Training loss= 0.088988 Val loss= 0.294278 Training acc= 0.754730 Val acc= 0.754290\n",
            "Epoch 4846: Training loss= 0.088985 Val loss= 0.294241 Training acc= 0.754725 Val acc= 0.754290\n",
            "Epoch 4847: Training loss= 0.088982 Val loss= 0.294204 Training acc= 0.754720 Val acc= 0.754290\n",
            "Epoch 4848: Training loss= 0.088979 Val loss= 0.294168 Training acc= 0.754725 Val acc= 0.754300\n",
            "Epoch 4849: Training loss= 0.088976 Val loss= 0.294131 Training acc= 0.754700 Val acc= 0.754280\n",
            "Epoch 4850: Training loss= 0.088973 Val loss= 0.294095 Training acc= 0.754705 Val acc= 0.754285\n",
            "Epoch 4851: Training loss= 0.088970 Val loss= 0.294058 Training acc= 0.754725 Val acc= 0.754295\n",
            "Epoch 4852: Training loss= 0.088967 Val loss= 0.294022 Training acc= 0.754745 Val acc= 0.754320\n",
            "Epoch 4853: Training loss= 0.088964 Val loss= 0.293986 Training acc= 0.754755 Val acc= 0.754330\n",
            "Epoch 4854: Training loss= 0.088961 Val loss= 0.293949 Training acc= 0.754750 Val acc= 0.754330\n",
            "Epoch 4855: Training loss= 0.088958 Val loss= 0.293913 Training acc= 0.754755 Val acc= 0.754340\n",
            "Epoch 4856: Training loss= 0.088955 Val loss= 0.293876 Training acc= 0.754765 Val acc= 0.754335\n",
            "Epoch 4857: Training loss= 0.088952 Val loss= 0.293840 Training acc= 0.754785 Val acc= 0.754350\n",
            "Epoch 4858: Training loss= 0.088949 Val loss= 0.293803 Training acc= 0.754795 Val acc= 0.754365\n",
            "Epoch 4859: Training loss= 0.088946 Val loss= 0.293767 Training acc= 0.754795 Val acc= 0.754370\n",
            "Epoch 4860: Training loss= 0.088944 Val loss= 0.293731 Training acc= 0.754800 Val acc= 0.754380\n",
            "Epoch 4861: Training loss= 0.088941 Val loss= 0.293694 Training acc= 0.754800 Val acc= 0.754385\n",
            "Epoch 4862: Training loss= 0.088938 Val loss= 0.293658 Training acc= 0.754810 Val acc= 0.754390\n",
            "Epoch 4863: Training loss= 0.088935 Val loss= 0.293621 Training acc= 0.754825 Val acc= 0.754405\n",
            "Epoch 4864: Training loss= 0.088932 Val loss= 0.293585 Training acc= 0.754835 Val acc= 0.754410\n",
            "Epoch 4865: Training loss= 0.088929 Val loss= 0.293549 Training acc= 0.754835 Val acc= 0.754415\n",
            "Epoch 4866: Training loss= 0.088926 Val loss= 0.293512 Training acc= 0.754830 Val acc= 0.754410\n",
            "Epoch 4867: Training loss= 0.088923 Val loss= 0.293476 Training acc= 0.754840 Val acc= 0.754415\n",
            "Epoch 4868: Training loss= 0.088920 Val loss= 0.293440 Training acc= 0.754840 Val acc= 0.754420\n",
            "Epoch 4869: Training loss= 0.088917 Val loss= 0.293404 Training acc= 0.754850 Val acc= 0.754420\n",
            "Epoch 4870: Training loss= 0.088914 Val loss= 0.293367 Training acc= 0.754855 Val acc= 0.754430\n",
            "Epoch 4871: Training loss= 0.088911 Val loss= 0.293331 Training acc= 0.754855 Val acc= 0.754430\n",
            "Epoch 4872: Training loss= 0.088908 Val loss= 0.293295 Training acc= 0.754865 Val acc= 0.754440\n",
            "Epoch 4873: Training loss= 0.088905 Val loss= 0.293259 Training acc= 0.754860 Val acc= 0.754440\n",
            "Epoch 4874: Training loss= 0.088902 Val loss= 0.293222 Training acc= 0.754855 Val acc= 0.754430\n",
            "Epoch 4875: Training loss= 0.088899 Val loss= 0.293186 Training acc= 0.754860 Val acc= 0.754435\n",
            "Epoch 4876: Training loss= 0.088896 Val loss= 0.293150 Training acc= 0.754855 Val acc= 0.754425\n",
            "Epoch 4877: Training loss= 0.088893 Val loss= 0.293114 Training acc= 0.754855 Val acc= 0.754420\n",
            "Epoch 4878: Training loss= 0.088890 Val loss= 0.293078 Training acc= 0.754850 Val acc= 0.754425\n",
            "Epoch 4879: Training loss= 0.088887 Val loss= 0.293042 Training acc= 0.754865 Val acc= 0.754440\n",
            "Epoch 4880: Training loss= 0.088884 Val loss= 0.293005 Training acc= 0.754870 Val acc= 0.754440\n",
            "Epoch 4881: Training loss= 0.088881 Val loss= 0.292969 Training acc= 0.754875 Val acc= 0.754440\n",
            "Epoch 4882: Training loss= 0.088878 Val loss= 0.292933 Training acc= 0.754885 Val acc= 0.754455\n",
            "Epoch 4883: Training loss= 0.088875 Val loss= 0.292897 Training acc= 0.754890 Val acc= 0.754455\n",
            "Epoch 4884: Training loss= 0.088872 Val loss= 0.292861 Training acc= 0.754900 Val acc= 0.754460\n",
            "Epoch 4885: Training loss= 0.088869 Val loss= 0.292825 Training acc= 0.754910 Val acc= 0.754475\n",
            "Epoch 4886: Training loss= 0.088866 Val loss= 0.292789 Training acc= 0.754915 Val acc= 0.754490\n",
            "Epoch 4887: Training loss= 0.088863 Val loss= 0.292753 Training acc= 0.754925 Val acc= 0.754495\n",
            "Epoch 4888: Training loss= 0.088860 Val loss= 0.292717 Training acc= 0.754930 Val acc= 0.754490\n",
            "Epoch 4889: Training loss= 0.088858 Val loss= 0.292681 Training acc= 0.754925 Val acc= 0.754485\n",
            "Epoch 4890: Training loss= 0.088855 Val loss= 0.292645 Training acc= 0.754925 Val acc= 0.754480\n",
            "Epoch 4891: Training loss= 0.088852 Val loss= 0.292609 Training acc= 0.754930 Val acc= 0.754490\n",
            "Epoch 4892: Training loss= 0.088849 Val loss= 0.292573 Training acc= 0.754920 Val acc= 0.754485\n",
            "Epoch 4893: Training loss= 0.088846 Val loss= 0.292537 Training acc= 0.754905 Val acc= 0.754480\n",
            "Epoch 4894: Training loss= 0.088843 Val loss= 0.292501 Training acc= 0.754900 Val acc= 0.754485\n",
            "Epoch 4895: Training loss= 0.088840 Val loss= 0.292465 Training acc= 0.754905 Val acc= 0.754475\n",
            "Epoch 4896: Training loss= 0.088837 Val loss= 0.292429 Training acc= 0.754910 Val acc= 0.754490\n",
            "Epoch 4897: Training loss= 0.088834 Val loss= 0.292393 Training acc= 0.754915 Val acc= 0.754505\n",
            "Epoch 4898: Training loss= 0.088831 Val loss= 0.292357 Training acc= 0.754905 Val acc= 0.754495\n",
            "Epoch 4899: Training loss= 0.088828 Val loss= 0.292321 Training acc= 0.754910 Val acc= 0.754500\n",
            "Epoch 4900: Training loss= 0.088825 Val loss= 0.292285 Training acc= 0.754920 Val acc= 0.754510\n",
            "Epoch 4901: Training loss= 0.088822 Val loss= 0.292249 Training acc= 0.754925 Val acc= 0.754515\n",
            "Epoch 4902: Training loss= 0.088819 Val loss= 0.292213 Training acc= 0.754925 Val acc= 0.754515\n",
            "Epoch 4903: Training loss= 0.088816 Val loss= 0.292177 Training acc= 0.754935 Val acc= 0.754525\n",
            "Epoch 4904: Training loss= 0.088813 Val loss= 0.292141 Training acc= 0.754930 Val acc= 0.754520\n",
            "Epoch 4905: Training loss= 0.088811 Val loss= 0.292106 Training acc= 0.754960 Val acc= 0.754535\n",
            "Epoch 4906: Training loss= 0.088808 Val loss= 0.292070 Training acc= 0.754960 Val acc= 0.754540\n",
            "Epoch 4907: Training loss= 0.088805 Val loss= 0.292034 Training acc= 0.754980 Val acc= 0.754555\n",
            "Epoch 4908: Training loss= 0.088802 Val loss= 0.291998 Training acc= 0.754995 Val acc= 0.754570\n",
            "Epoch 4909: Training loss= 0.088799 Val loss= 0.291962 Training acc= 0.755020 Val acc= 0.754585\n",
            "Epoch 4910: Training loss= 0.088796 Val loss= 0.291926 Training acc= 0.755030 Val acc= 0.754595\n",
            "Epoch 4911: Training loss= 0.088793 Val loss= 0.291891 Training acc= 0.755035 Val acc= 0.754600\n",
            "Epoch 4912: Training loss= 0.088790 Val loss= 0.291855 Training acc= 0.755070 Val acc= 0.754645\n",
            "Epoch 4913: Training loss= 0.088787 Val loss= 0.291819 Training acc= 0.755070 Val acc= 0.754645\n",
            "Epoch 4914: Training loss= 0.088784 Val loss= 0.291783 Training acc= 0.755080 Val acc= 0.754660\n",
            "Epoch 4915: Training loss= 0.088781 Val loss= 0.291748 Training acc= 0.755080 Val acc= 0.754660\n",
            "Epoch 4916: Training loss= 0.088778 Val loss= 0.291712 Training acc= 0.755080 Val acc= 0.754670\n",
            "Epoch 4917: Training loss= 0.088775 Val loss= 0.291676 Training acc= 0.755095 Val acc= 0.754690\n",
            "Epoch 4918: Training loss= 0.088772 Val loss= 0.291641 Training acc= 0.755105 Val acc= 0.754695\n",
            "Epoch 4919: Training loss= 0.088770 Val loss= 0.291605 Training acc= 0.755105 Val acc= 0.754710\n",
            "Epoch 4920: Training loss= 0.088767 Val loss= 0.291569 Training acc= 0.755110 Val acc= 0.754705\n",
            "Epoch 4921: Training loss= 0.088764 Val loss= 0.291533 Training acc= 0.755100 Val acc= 0.754700\n",
            "Epoch 4922: Training loss= 0.088761 Val loss= 0.291498 Training acc= 0.755105 Val acc= 0.754705\n",
            "Epoch 4923: Training loss= 0.088758 Val loss= 0.291462 Training acc= 0.755115 Val acc= 0.754710\n",
            "Epoch 4924: Training loss= 0.088755 Val loss= 0.291427 Training acc= 0.755115 Val acc= 0.754715\n",
            "Epoch 4925: Training loss= 0.088752 Val loss= 0.291391 Training acc= 0.755130 Val acc= 0.754730\n",
            "Epoch 4926: Training loss= 0.088749 Val loss= 0.291355 Training acc= 0.755150 Val acc= 0.754745\n",
            "Epoch 4927: Training loss= 0.088746 Val loss= 0.291320 Training acc= 0.755155 Val acc= 0.754750\n",
            "Epoch 4928: Training loss= 0.088743 Val loss= 0.291284 Training acc= 0.755145 Val acc= 0.754755\n",
            "Epoch 4929: Training loss= 0.088740 Val loss= 0.291249 Training acc= 0.755175 Val acc= 0.754785\n",
            "Epoch 4930: Training loss= 0.088738 Val loss= 0.291213 Training acc= 0.755170 Val acc= 0.754785\n",
            "Epoch 4931: Training loss= 0.088735 Val loss= 0.291177 Training acc= 0.755175 Val acc= 0.754790\n",
            "Epoch 4932: Training loss= 0.088732 Val loss= 0.291142 Training acc= 0.755180 Val acc= 0.754795\n",
            "Epoch 4933: Training loss= 0.088729 Val loss= 0.291106 Training acc= 0.755185 Val acc= 0.754810\n",
            "Epoch 4934: Training loss= 0.088726 Val loss= 0.291071 Training acc= 0.755190 Val acc= 0.754815\n",
            "Epoch 4935: Training loss= 0.088723 Val loss= 0.291035 Training acc= 0.755205 Val acc= 0.754830\n",
            "Epoch 4936: Training loss= 0.088720 Val loss= 0.291000 Training acc= 0.755190 Val acc= 0.754830\n",
            "Epoch 4937: Training loss= 0.088717 Val loss= 0.290964 Training acc= 0.755195 Val acc= 0.754840\n",
            "Epoch 4938: Training loss= 0.088714 Val loss= 0.290929 Training acc= 0.755210 Val acc= 0.754855\n",
            "Epoch 4939: Training loss= 0.088711 Val loss= 0.290893 Training acc= 0.755195 Val acc= 0.754840\n",
            "Epoch 4940: Training loss= 0.088709 Val loss= 0.290858 Training acc= 0.755185 Val acc= 0.754840\n",
            "Epoch 4941: Training loss= 0.088706 Val loss= 0.290823 Training acc= 0.755195 Val acc= 0.754845\n",
            "Epoch 4942: Training loss= 0.088703 Val loss= 0.290787 Training acc= 0.755195 Val acc= 0.754840\n",
            "Epoch 4943: Training loss= 0.088700 Val loss= 0.290752 Training acc= 0.755220 Val acc= 0.754865\n",
            "Epoch 4944: Training loss= 0.088697 Val loss= 0.290716 Training acc= 0.755245 Val acc= 0.754885\n",
            "Epoch 4945: Training loss= 0.088694 Val loss= 0.290681 Training acc= 0.755270 Val acc= 0.754905\n",
            "Epoch 4946: Training loss= 0.088691 Val loss= 0.290646 Training acc= 0.755270 Val acc= 0.754910\n",
            "Epoch 4947: Training loss= 0.088688 Val loss= 0.290610 Training acc= 0.755290 Val acc= 0.754925\n",
            "Epoch 4948: Training loss= 0.088685 Val loss= 0.290575 Training acc= 0.755290 Val acc= 0.754920\n",
            "Epoch 4949: Training loss= 0.088683 Val loss= 0.290540 Training acc= 0.755300 Val acc= 0.754920\n",
            "Epoch 4950: Training loss= 0.088680 Val loss= 0.290504 Training acc= 0.755300 Val acc= 0.754925\n",
            "Epoch 4951: Training loss= 0.088677 Val loss= 0.290469 Training acc= 0.755310 Val acc= 0.754930\n",
            "Epoch 4952: Training loss= 0.088674 Val loss= 0.290434 Training acc= 0.755315 Val acc= 0.754935\n",
            "Epoch 4953: Training loss= 0.088671 Val loss= 0.290398 Training acc= 0.755330 Val acc= 0.754955\n",
            "Epoch 4954: Training loss= 0.088668 Val loss= 0.290363 Training acc= 0.755330 Val acc= 0.754955\n",
            "Epoch 4955: Training loss= 0.088665 Val loss= 0.290328 Training acc= 0.755325 Val acc= 0.754955\n",
            "Epoch 4956: Training loss= 0.088662 Val loss= 0.290292 Training acc= 0.755330 Val acc= 0.754960\n",
            "Epoch 4957: Training loss= 0.088660 Val loss= 0.290257 Training acc= 0.755340 Val acc= 0.754970\n",
            "Epoch 4958: Training loss= 0.088657 Val loss= 0.290222 Training acc= 0.755340 Val acc= 0.754980\n",
            "Epoch 4959: Training loss= 0.088654 Val loss= 0.290187 Training acc= 0.755360 Val acc= 0.754990\n",
            "Epoch 4960: Training loss= 0.088651 Val loss= 0.290151 Training acc= 0.755375 Val acc= 0.755000\n",
            "Epoch 4961: Training loss= 0.088648 Val loss= 0.290116 Training acc= 0.755385 Val acc= 0.755015\n",
            "Epoch 4962: Training loss= 0.088645 Val loss= 0.290081 Training acc= 0.755390 Val acc= 0.755025\n",
            "Epoch 4963: Training loss= 0.088642 Val loss= 0.290046 Training acc= 0.755395 Val acc= 0.755040\n",
            "Epoch 4964: Training loss= 0.088639 Val loss= 0.290011 Training acc= 0.755410 Val acc= 0.755055\n",
            "Epoch 4965: Training loss= 0.088637 Val loss= 0.289976 Training acc= 0.755415 Val acc= 0.755050\n",
            "Epoch 4966: Training loss= 0.088634 Val loss= 0.289940 Training acc= 0.755440 Val acc= 0.755075\n",
            "Epoch 4967: Training loss= 0.088631 Val loss= 0.289905 Training acc= 0.755440 Val acc= 0.755075\n",
            "Epoch 4968: Training loss= 0.088628 Val loss= 0.289870 Training acc= 0.755440 Val acc= 0.755075\n",
            "Epoch 4969: Training loss= 0.088625 Val loss= 0.289835 Training acc= 0.755445 Val acc= 0.755070\n",
            "Epoch 4970: Training loss= 0.088622 Val loss= 0.289800 Training acc= 0.755465 Val acc= 0.755090\n",
            "Epoch 4971: Training loss= 0.088619 Val loss= 0.289765 Training acc= 0.755465 Val acc= 0.755100\n",
            "Epoch 4972: Training loss= 0.088616 Val loss= 0.289730 Training acc= 0.755470 Val acc= 0.755110\n",
            "Epoch 4973: Training loss= 0.088614 Val loss= 0.289695 Training acc= 0.755470 Val acc= 0.755115\n",
            "Epoch 4974: Training loss= 0.088611 Val loss= 0.289660 Training acc= 0.755470 Val acc= 0.755120\n",
            "Epoch 4975: Training loss= 0.088608 Val loss= 0.289625 Training acc= 0.755465 Val acc= 0.755115\n",
            "Epoch 4976: Training loss= 0.088605 Val loss= 0.289590 Training acc= 0.755485 Val acc= 0.755135\n",
            "Epoch 4977: Training loss= 0.088602 Val loss= 0.289555 Training acc= 0.755490 Val acc= 0.755140\n",
            "Epoch 4978: Training loss= 0.088599 Val loss= 0.289520 Training acc= 0.755490 Val acc= 0.755145\n",
            "Epoch 4979: Training loss= 0.088596 Val loss= 0.289485 Training acc= 0.755500 Val acc= 0.755160\n",
            "Epoch 4980: Training loss= 0.088594 Val loss= 0.289450 Training acc= 0.755505 Val acc= 0.755160\n",
            "Epoch 4981: Training loss= 0.088591 Val loss= 0.289415 Training acc= 0.755520 Val acc= 0.755165\n",
            "Epoch 4982: Training loss= 0.088588 Val loss= 0.289380 Training acc= 0.755520 Val acc= 0.755165\n",
            "Epoch 4983: Training loss= 0.088585 Val loss= 0.289345 Training acc= 0.755520 Val acc= 0.755170\n",
            "Epoch 4984: Training loss= 0.088582 Val loss= 0.289310 Training acc= 0.755535 Val acc= 0.755180\n",
            "Epoch 4985: Training loss= 0.088579 Val loss= 0.289275 Training acc= 0.755540 Val acc= 0.755180\n",
            "Epoch 4986: Training loss= 0.088577 Val loss= 0.289240 Training acc= 0.755560 Val acc= 0.755190\n",
            "Epoch 4987: Training loss= 0.088574 Val loss= 0.289205 Training acc= 0.755565 Val acc= 0.755195\n",
            "Epoch 4988: Training loss= 0.088571 Val loss= 0.289170 Training acc= 0.755580 Val acc= 0.755215\n",
            "Epoch 4989: Training loss= 0.088568 Val loss= 0.289135 Training acc= 0.755600 Val acc= 0.755230\n",
            "Epoch 4990: Training loss= 0.088565 Val loss= 0.289100 Training acc= 0.755620 Val acc= 0.755250\n",
            "Epoch 4991: Training loss= 0.088562 Val loss= 0.289065 Training acc= 0.755645 Val acc= 0.755275\n",
            "Epoch 4992: Training loss= 0.088559 Val loss= 0.289030 Training acc= 0.755660 Val acc= 0.755285\n",
            "Epoch 4993: Training loss= 0.088557 Val loss= 0.288996 Training acc= 0.755660 Val acc= 0.755290\n",
            "Epoch 4994: Training loss= 0.088554 Val loss= 0.288961 Training acc= 0.755665 Val acc= 0.755290\n",
            "Epoch 4995: Training loss= 0.088551 Val loss= 0.288926 Training acc= 0.755685 Val acc= 0.755300\n",
            "Epoch 4996: Training loss= 0.088548 Val loss= 0.288891 Training acc= 0.755680 Val acc= 0.755295\n",
            "Epoch 4997: Training loss= 0.088545 Val loss= 0.288856 Training acc= 0.755695 Val acc= 0.755310\n",
            "Epoch 4998: Training loss= 0.088542 Val loss= 0.288822 Training acc= 0.755700 Val acc= 0.755330\n",
            "Epoch 4999: Training loss= 0.088540 Val loss= 0.288787 Training acc= 0.755700 Val acc= 0.755330\n",
            "Best model info *** :\n",
            "Epoch 4999: Training loss= 0.088540 Val loss= 0.288787 Training acc= 0.755700 Val acc= 0.755330\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXgc1Z32/e9Prd3yIkuyJVmyJe/7hvASAzEQiIEAYd8DzIAnBELIPDMT8yRhS+Z5yfvmZQgzkLCEhBAMOA6Lk7DECWYx2MbyvuNVtiQvsiTv1tLd5/mjy05jZNOy1SpLuj/X1Ze6TlW1fkeX1LeqTvUpc84hIiJyrAS/CxARkdOTAkJERJqkgBARkSYpIEREpEkKCBERaVKi3wW0lOzsbFdUVOR3GSIibcqiRYt2O+dymlrXbgKiqKiI0tJSv8sQEWlTzKzseOt0iklERJqkgBARkSYpIEREpEntZgxCRNqXxsZGysvLqaur87uUdiE1NZWCggKSkpJi3kcBISKnpfLycjp37kxRURFm5nc5bZpzjurqasrLyykuLo55P51iEpHTUl1dHVlZWQqHFmBmZGVlNftoTAEhIqcthUPLOZmfpU4xiYi0Ec45QsEgoWAD4VCQcKgRF2wASyCje26Lfz8FhIhIE/bs2cP06dP5zne+06z9Lr74YqZPn063bt2Ou80DDzzAOeecw/nnn084HCLY2ECosQEXbMCFQ+CCEA5h4SAJLkiCC5FAiEQXItG++MZ9mFRAASEi0ir27NnDU0899YWACAaDJCYe/63zrbfewjlHY0M9ocYGwsEGwqEGCDVioQYC4UZ++O1rCRCGyqUEDAJNvE7IJRCyACEChBKSCFoa9QmJkJCIBZJICCSRkJhIIDGZ1MTYr0xqjrgGhJlNAX5BpP/POecePWb9fwHneovpQA/nXDdvXQhY4a3b6py7LJ61iohEmzZtGhs3bmT06NEkJSWRmppKZmYma9euZdWK5Vx59dWUbyunrr6Ou+68nX++6Ros3MiQceex8K3fc+jQIS66+R7OGjeGT0qX0Su3BzOff4KE9M7ccd8DTLngfL55+aUMO2MSN95wHW+/O5tgMMQrL09n2LDh1FRXc+ONN1JZWcnEiROZPXs2ixYtIjsru9V+BnELCDMLAE8CFwDlwEIzm+WcW31kG+fc96O2/y4wJuolDjvnRserPhFpOx7+0ypWV+5r0dccmt+FBy8ddnTZOUewsYFgYz3hhjp+/B/fY/nSJXz8zkzmfvwJV97ybZa+N5MBvfOgeg0vPPpvdM/syuHDdZx5yS1cd+FEunbPBoxDiV05mNKJ9Zu38dvf/Z6nSs7kpptuZta8ddx8880kpnUhtVtPMnJ6YwkB8gv6sHTpMp566ike/8UTPPfcczz88MOcd9553H///bzzzjv8+te/btH+xyKeRxDjgA3OuU0AZvYKcDmw+jjb3wA8GMd6RKSDcy6MC4fBhWk8tJ+DO9aTEA6SSJCAC5JkcORkTafGGhIIkRQ+DDjOGDOSvL5DOJCQhAWS+P//+xX+9Oe3wGDb9io2H0hmwvChWCCRjJzecOAAxcXFjJ84CYAzzjiDLVu2NFnXlVdeeXSb1157DYC5c+fy+uuvAzBlyhQyMzPj+aNpUjwDohewLWq5HBjf1IZm1gcoBt6Lak41s1IgCDzqnHujif2mAlMBevfu3UJli8jpJvo//RMJBhtprD9MuKEOF6zDQg0khBtJpJFEFyL6Ss+wMxrD9YQtkYaEdFxCEgSSSEhMIZCcSriuKySmkpw/gpSsarpkZpPRI/Ihs/fff58PPvqY+QsWkJ6ezuTJk5v8jEFKSsrR54FAgMOHDzdZ95HtAoEAwWAw1h9L3J0ug9TXAzOdc6Gotj7OuQoz6wu8Z2YrnHMbo3dyzj0DPANQUlLiWq9cEfHDkdNAjfWHCDccgmA9CeEgCa6RRIIkEj76phZ2ELQkQpZIQ0IG9QlJEEgkITGFxJR0kpJTSDnBZwO6du3K/v37m1y3d+9eMjMzSU9PZ+3atcyfP7/F+zpp0iRmzJjBD37wA/76179SW1vb4t/jy8QzICqAwqjlAq+tKdcDd0c3OOcqvK+bzOx9IuMTG7+4q4i0Jy4cZt+eahrrD3OgZgeEGiJHAq6RJNdAEuGjp4GCBAgSIGxJ1CWkQyCZhOQ0EpNTSUxOJTnh5D8LnJWVxaRJkxg+fDhpaWn07Nnz6LopU6bwq1/9iiFDhjBo0CAmTJhwir3+ogcffJAbbriBF198kYkTJ5Kbm0vnzp1b/PuciDkXn3+8zSwR+Aw4n0gwLARudM6tOma7wcA7QLHzijGzTOCQc67ezLKBecDl0QPcxyopKXG6YZBI23D44H52lK1l92cLCNaUEdhfQdqh7XRp3EV2aDedrI41X5/BkD49cA4aLZGQJRFKSIbEVAIp6SSldCKxGRPPtTX19fUEAgESExOZN28ed911F0uXLj2l11yzZg1Dhgz5XJuZLXLOlTS1fdyOIJxzQTO7B3iXyGWuzzvnVpnZI0Cpc26Wt+n1wCvu80k1BHjazMJEpgN59EThICKnn8aGenaUraVm2zoO71yPVW8k7cBWsuvLyA1XUWyOI9PG7aYbNYk9qE7ry/ZOX4Eu+aSlZtGYNYTE5BSSO+CUG1u3buXaa68lHA6TnJzMs88+2+o1xO0IorXpCEKk9TXU17Fz6zpqtq3h8I4NWE0kBLLqt9EzXEWihY9ue8ClsSMxnz3pRTRm9iep5wCyikZSMGA0SckpX3jtpv7blVNz2hxBiEj70VBfx4bFc9i3uRSr2UTagTKy68vpGd5Fobmjg437XRo7EnuxI2MoW7sUkZjTn855A8kpGkr3nHz6n8KYgLQ+BYSIHHX44H4qNixnz9aVNO5cS0rtBrIObyYvVMlQi1xkeCQEtmcMo6zrJSRm96dz/kB6FA0lMzuPAQqBdkMBIdIBuXCYyi1r2LFmHg0Vy0ivXUtO3RZyw1X0t8hp56BLYHtCLrvTiqjsdi6pRePpPWoy3XPyFQIdhAJCpAPYvWMr5Ss/5vCWT+m0ezm969bSiwP0AhpcgPJAIZUZIyjrPoCU3MF0LxpBft/hFKakfu5adelYFBAi7YgLh9lbs4utK+ZycNN80ncvJ+/wenpQQzYQckZZoA+fZU7G5Y8le9BECgaOpm9qOn39Lr6Ny8jI4MCBA1RWVnLvvfcyc+bML2wzefJkfv7zn1NS0uSYMACPP/44U6dOJT09HYht+vB4UUCItFEuHGZn+Ua2LvwLrnIJubWl9Ajtops10I3IVBJbAwVs7TKWTT1H0bX/ePoMm0DfjK4KgzjKz89vMhxi9fjjj3PzzTcfDYi33nqrpUprNgWESBtRX3eIzcs/pnbN+2RUfkxx3Vpy7TC5RC4h3Zg+gu1dzoauvejUaxh9x55HUeduFPldeBs1bdo0CgsLufvuyCQPDz30EImJicyZM4fa2loaGxv56U9/yuWXX/65/bZs2cI3vvENVq5cyeHDh7n99ttZtmwZgwcP/txcTHfddRcLFy7k8OHDXH311Tz88MM88cQTVFZWcu6555Kdnc2cOXMoKiqitLSU7OxsHnvsMZ5//nkA7rjjDu677z62bNnCRRddxFlnncUnn3xCr169ePPNN0lLSzvln4ECQuQ0dXD/HtZ/+g51n71Ppz1r6Vu3hsEWmRBuc0IRq7K/Dj2G0mP4ZIqGnMmo9jxw/PY02LHiy7drjtwRcNGjx1193XXXcd999x0NiBkzZvDuu+9y77330qVLF3bv3s2ECRO47LLLjnu/51/+8pekp6ezZs0ali9fztixY4+u+8///E+6d+9OKBTi/PPPZ/ny5dx777089thjzJkzh+zsz9/3YdGiRfzmN79hwYIFOOcYP348X/3qV8nMzGT9+vW8/PLLPPvss1x77bX88Y9/5Oabbz7lH5ECQuQ00FBfR9mahdR8Nh+rXEzOvlX0Dm1ltDnqXBLbkopYmT2FpIFfo/eor1Kc2/vop5AlPsaMGcOuXbuorKykqqqKzMxMcnNz+f73v8+HH35IQkICFRUV7Ny5k9zcpm/3+eGHH3LvvfcCMHLkSEaOHHl03YwZM3jmmWcIBoNs376d1atXf279sebOncsVV1xBp06dgMgU4R999BGXXXYZxcXFjB4duX3OiaYVby4FhEgrC4dClG9cwa618whtK6Vb7QqKGjcxwBoBqKULW1MH8WnOhWT0/woDx09hQGq6z1X77AT/6cfTNddcw8yZM9mxYwfXXXcdL730ElVVVSxatIikpCSKioqanOb7y2zevJmf//znLFy4kMzMTG677baTep0jYp1WvLkUECJxtnvHNspXfUzd5k9J372MorrV9OYQvYFDLoUtKQNZkns1SX3OJG/IJPL6DCSzPZ8uakOuu+467rzzTnbv3s0HH3zAjBkz6NGjB0lJScyZM4eysrIT7n/OOecwffp0zjvvPFauXMny5csB2LdvH506daJr167s3LmTt99+m8mTJwPQuXNn9u/f/4VTTGeffTa33XYb06ZNwznH66+/zosvvhiXfh+hgBBpQfv31lC28mMObPyU5J1LyT+4hlyqjl5iujXQhzXdv0ZCQQnZg79C74FjGJqoP8PT1bBhw9i/fz+9evUiLy+Pm266iUsvvZQRI0ZQUlLC4MGDT7j/XXfdxe23386QIUMYMmQIZ5xxBgCjRo1izJgxDB48mMLCQiZNmnR0n6lTpzJlyhTy8/OZM2fO0faxY8dy2223MW7cOCAySD1mzJgWO53UFE3WJ3KSQsEgm1ctoHrNhwQqS8k5sJbCUAUJ3ieRK6wnOzKG0Zg7mi79xlM0fCLpGV19rrrt0GR9LU+T9YnE0e7KMjYtmEVg03v02/8p/TlAf2AX3alMH0Rl9iV0Kh5H4fBJ9MrJo5ffBYucAgWEyAns2Lqe7WsXUFdWSuauBQxuXE02kfsXrO86Cet3Hr1GnUtu4QB6aNxA2hkFhEiUXRWb2bpkNqHNc8mvWUihqySXyMR1m5L6M6/Pt+lRcgV9h40jW4EQd865437GQJrnZIYTFBDSoQUbG1g1903qV7xJfu1CCtwOeuB9MjltOBW9byJz4FfoPeRMBnZq3fsBd3SpqalUV1eTlZWlkDhFzjmqq6tJTU1t1n4KCOlw/nGU8DF9qucyit0ccGms7zSW8l43kTXsXIqHjWdUUrLfpXZoBQUFlJeXU1VV5Xcp7UJqaioFBQXN2kcBIe3egX21rJ//FxrWzyF/9ycUukp6AAddKhvThlM55iGGffUqxnT0D6OdZpKSkigu1ufF/aSAkHapZlcFGz76Aykb/sKQQ4sZY0EOu2TWp42iouBaskdcQNHQcYzUUYLIcSkgpN3YW7ubtbOfp/OGWQyqX8k4c2wnh8U9r6Lz6G/Sf+xkRuooQSRmCghp044cKaR99iZD6pYy3sJsSShkYeE/kX3mVfQbMZE8XW0kclIUENLm1B06wPK3nyP9s9cZWLeCcRai0nqwsNctZJVcxcCxX9U9EERagAJC2oyNK+ZT9dGvGbLrL4zjIGUJBSzOu56sCTfQf+Qk8nWkINKiFBByWmuor2PZ27+m86rfM7hxNYUukZWdJ5Ey8V8YOvEi+igUROJGASGnpfINK9n23tMMqJzFmexhm+Uzv/99DLn4HsZ2z/G7PJEOQQEhp426wwdZ/tazdF77KkMaV5PnjBWdJlB55h2M+OqVFOpoQaRVKSDEdzW7Klj3p8cYsG0m49hDWUIh84rvod/X7mB0L31QSsQvCgjxTdnaxWyf+3sGlc9gvDvAirQSdpz9PYZNvERjCyKnAQWEtKq6QwdY+bff03XZswwIbaDAGavSzmDv5T9j1JAm71kiIj5RQEirqKrcwoZ3nmLQ1pcpYV9k0Hngv9P/vG8xMre33+WJSBMUEBJX65d+xP7ZP2PkgY+ZaGGWpZ5JxVe+y7BJ36AwEPC7PBE5AQWExEX5hpXsfOOHjNn/AfusEwvzb6Tw/LsY1X+436WJSIwUENKiKjatoXLWw4ypfZcsEllQcCvDr32QiV27+12aiDSTAkJaROWWdZS/+TBjat4hiwRKc6+l/xU/YmJuod+lichJUkDIKdmxdT1lb/6Esbv/TBYJLOpxJf2v+DET8vv4XZqInKK4BoSZTQF+AQSA55xzjx6z/r+Ac73FdKCHc66bt+5W4Efeup86516IZ63SPDvLN7LljZ8ypmoW3XEszrmcom/+iAkF/fwuTURaSNwCwswCwJPABUA5sNDMZjnnVh/Zxjn3/ajtvwuM8Z53Bx4ESgAHLPL2rY1XvRKbQwf2svz39zNm+wzGEmZx9jfoc/mPGd97gN+liUgLi+cRxDhgg3NuE4CZvQJcDqw+zvY3EAkFgK8Ds51zNd6+s4EpwMtxrFe+xIoP3yRrzr8zwe3k08yLKfjmQ4wvGuR3WSISJ/EMiF7AtqjlcmB8UxuaWR+gGHjvBPv2ikONEoO9NVWs+929jNvzFtssn9Vff4VxEy/yuywRibPTZZD6emCmcy7UnJ3MbCowFaB3b30aNx6WvPsChfMeYKzbx7xe32LMzf8PhekZfpclIq0gngFRAURf41jgtTXleuDuY/adfMy+7x+7k3PuGeAZgJKSEnfypcqx9uzewabf3MnYgx+yMdCXPZdNZ+KoSX6XJSKtKJ5TZi4EBphZsZklEwmBWcduZGaDgUxgXlTzu8CFZpZpZpnAhV6btIL1Sz7k4JPnMPzAx8wrvpveP5hPf4WDSIcTtyMI51zQzO4h8sYeAJ53zq0ys0eAUufckbC4HnjFOeei9q0xs58QCRmAR44MWEv8hIJBFr7yE85Y/9/UWlc2XfoHJpac73dZIuITi3pfbtNKSkpcaWmp32W0WXtrd1P29LWMrFvEkk5n0feff0tX3dpTpN0zs0XOuSbn2j9dBqnFR9s2rMBNv47BoR0sGP4A4676PqYb9oh0eAqIDm7l3Fn0/tu3CZHAhikvMV6Xr4qIRwHRgS18438YveQBKgK9SP7WTIbqQ28iEkUB0QG5cJgFz/8bE8p/zYrUMfS564906Zbld1kicppRQHQw9XWHWPHULUzY9zc+7XYxY77zW5KSU/wuS0ROQwqIDmRvTRUVv7qCkoYVzC+6m/Hf+qkGo0XkuBQQHUT1znJqn7mM/sEySs/8/5jwjal+lyQipzkFRAewe8dWDj0zhV6hKtZOfpqSc6/2uyQRaQMUEO3cZ4vfJ+NPU8kO72HzlN8xUpexikiMdAK6HVs9/x0K37yGRNdI+eUzGKpwEJFm0BFEO7V+yYf0fvs2dgV6kPEv7zKwZ4HfJYlIG6MjiHZobenfyX7zRvYldCb1n2aRpXAQkZOggGhnytYsIu/Pt3DQOuFueYOeBf38LklE2iidYmpHytYuptOrV9JIEgnfepP84sF+lyQibZiOINqJHVvXk/7KlQQIc/C61xQOInLKFBDtwN7a3dT99kpSXR21V8+kz5Az/C5JRNoBBUQbV193iPJfXkl+qIKyC56h7/DxfpckIu2EAqINC4dCrHzyJoY1LGPZ2J8y/KzL/C5JRNoRBUQbtuCFaZyx/z3mFd/DmZd/x+9yRKSdUUC0UYvf/g0Ttz7Dwq5fZ8ItP/G7HBFphxQQbVDZ2sUMmj+NdYmDGfWd32nKbhGJC72ztDEH9tXCjFuosxS63Tad5JRUv0sSkXZKAdGGuHCYz565lV6hSnZc8Et9SlpE4iqmgDCz18zsEjNToPho0Z+fZuyBD1jY9y6GTbrE73JEpJ2L9Q3/KeBGYL2ZPWpmg+JYkzShYtMqBi96mNVJwxl30yN+lyMiHUBMAeGc+5tz7iZgLLAF+JuZfWJmt5tZUjwLFGhsqOfA9NsJm9H9lt8SSNQUWiISfzGfMjKzLOA24A5gCfALIoExOy6VyVGlL/6QQcF1rB/3U3J7D/C7HBHpIGL6V9TMXgcGAS8ClzrntnurXjWz0ngVJ7B51QJKtj5PadevUXLxP/tdjoh0ILGeq3jCOTenqRXOuZIWrEeihIJBgq/fzX7rRL9b/sfvckSkg4n1FNNQM+t2ZMHMMs1MczvEWelrjzEguJ5NJT8mMyfP73JEpIOJNSDudM7tObLgnKsF7oxPSQKR+zsMW/UYK1NGc8bFd/hdjoh0QLEGRMDM7MiCmQWA5PiUJC4cZtf0fyGBMN2vf1pTaYiIL2J953mHyID0+WZ2PvCy1yZxsPD1JxhZt4gVQ/+X7gwnIr6JdZD6B8C/AHd5y7OB5+JSUQdXVbmFwSt+xqrkEZx59b/5XY6IdGAxBYRzLgz80ntIHG176bsMdY10vfZXJAQCfpcjIh1YrHMxDTCzmWa22sw2HXnEu7iOZvW8txl78EOWFk+loP9wv8sRkQ4u1jGI3xA5eggC5wK/A34fr6I6IhcO4+b8H6rIZPS1/9vvckREYg6INOfc3wFzzpU55x4CvnQ6UTObYmbrzGyDmU07zjbXekcmq8xselR7yMyWeo9ZMdbZZi37+ysMa1jOxkF3kpqe4Xc5IiIxD1LXe1N9rzeze4AK4ITvYt6lsE8CFwDlwEIzm+WcWx21zQDgfmCSc67WzHpEvcRh59zoZvSlzao7fJDsTx5mS0IhZ1ylgWkROT3EegTxPSAduBc4A7gZuPVL9hkHbHDObXLONQCvAJcfs82dwJPeB+9wzu2KtfD2ZMmrP6HA7WD/5P8kKTnF73JERIAYAsI7ErjOOXfAOVfunLvdOXeVc27+l+zaC9gWtVzutUUbCAw0s4/NbL6ZTYlal2pmpV77N49T21Rvm9Kqqqov68ppaXdlGaM2P8/iTmcz4pxj81NExD9fGhDOuRBwVpy+fyIwAJgM3AA8GzXnUx9vIsAbgcfN7Av313TOPeOcK3HOleTk5MSpxPgqe/k+EgnS86qf+V2KiMjnxDoGscQbKP4DcPBIo3PutRPsUwEURi0XeG3RyoEFzrlGYLOZfUYkMBY65yq877HJzN4HxgAbY6y3Tfhs8Qecsf895vW+g4l9h/ldjojI58Q6BpEKVAPnAZd6j298yT4LgQFmVmxmycD1wLFXI71B5OgBM8smcsppkzdbbEpU+yRgNe1M/bsPUksXRlzzI79LERH5glg/SX17c1/YORf0rnh6FwgAzzvnVpnZI0Cpc26Wt+5CM1sNhIB/d85Vm9lXgKfNLEwkxB6NvvqpPVjx4euMqF/C/IH/xoQumX6XIyLyBeac+/KNzH4DfGFD59w/xaOok1FSUuJKS9vGze0aG+qpfHQsia6RrP9YQmpaJ79LEpEOyswWHe/Gb7GOQfw56nkqcAVQeaqFdVSL3/gF48PlLPnKk/RSOIjIaSrWU0x/jF42s5eBuXGpqJ1rbKinz+qnWZM0jNFfu9HvckREjutk70QzAOjxpVvJFyyb/Tty2U39+O/qRkAiclqL6QjCzPbz+TGIHUTuESHN4MJhuix5hm2Wz8hzr/W7HBGRE4r1FFPneBfSEawr/TuDg5+xYMj/plD3ehCR01ys94O4wsy6Ri13O970F3J8hz54gr10YsQl3/a7FBGRLxXrSfAHnXN7jyw45/YAD8anpPapcvNaRh34iNX5V5Ge0fXLdxAR8VmsAdHUdrFeIivA1rcfI0wC/S75V79LERGJSawBUWpmj5lZP+/xGLAonoW1J/v2VDN85yyWdT2XHr2K/S5HRCQmsQbEd4EG4FUi93WoA+6OV1Htzeq//A8Zdpiu593ndykiIjGL9Sqmg0CTtwyVEws2NtBn/YusTh7B0NFn+12OiEjMYr2KaXbUfRrwZlt9N35ltR/LZr9EHlXUl+jKJRFpW2I9xZTtXbkEgHeLUH2SOgadFj9NueUy8rzr/S5FRKRZYg2IsJn1PrJgZkU0MburfN76JR8yOLiG8oHfIpCoi75EpG2J9V3rh8BcM/sAMOBsYGrcqmon9s75BQddKkMv0uklEWl7YjqCcM69A5QA64CXgf8FHI5jXW1e9c5yRu2dw4oel9KlW5bf5YiINFusk/XdAXyPyH2llwITgHlEbkEqTdjwwXTGW4iek+/0uxQRkZMS6xjE94AzgTLn3LnAGGDPiXfp2DI2zKIsoZCiIWf6XYqIyEmJNSDqnHN1AGaW4pxbCwyKX1ltW1XlFobUr6Sy4CLd80FE2qxYB6nLvc9BvAHMNrNaoCx+ZbVtGz+YTo458r9yg9+liIictFg/SX2F9/QhM5sDdAXeiVtVbVzXTX9ic0IRxYPH+l2KiMhJa/b5D+fcB865Wc65hngU1Nbt2LaBIY2r2dH7Ir9LERE5JTpB3sK2fDgdgIKzbvK5EhGRU6OAaGGZm//MhkA/CvuP8LsUEZFTooBoQZVb1jEouI6qPpf4XYqIyClTQLSgrR+9BECfs3V6SUTaPgVEC8ra8hc+SxxIfvFgv0sRETllCogWsr1sHQNCG6jpo6uXRKR9UEC0kLJP/ghAr4nX+FyJiEjLUEC0kIwt77IloVBXL4lIu6GAaAE1uyoYXLec7bma3FZE2g8FRAvY+MnrJFqYnPHX+V2KiEiLUUC0AFc2j710ou/wCX6XIiLSYhQQLSB37xI2p40gIRDwuxQRkRajgDhF1TvL6R2u4HDeOL9LERFpUQqIU7Rl0bsAdB96rs+ViIi0rLgGhJlNMbN1ZrbBzKYdZ5trzWy1ma0ys+lR7bea2XrvcWs86zwVwY0fctCl0m/UWX6XIiLSomK9o1yzmVkAeBK4ACgHFprZLOfc6qhtBgD3A5Occ7Vm1sNr7w48CJQADljk7Vsbr3pPVs/aRWxMG8HIpGS/SxERaVHxPIIYB2xwzm3ybi70CnD5MdvcCTx55I3fObfLa/86MNs5V+Otmw1MiWOtJ6VmVwVF4W0czBvvdykiIi0ungHRC9gWtVzutUUbCAw0s4/NbL6ZTWnGvpjZVDMrNbPSqqqqFiw9NlsWzwYgU+MPItIO+T1InQgMACYDNwDPmlm3WHd2zj3jnCtxzpXk5OTEqcTja9z4EYdcCv1Gnd3q31tEJN7iGRAVQGHUcoHXFq0cmOWca3TObQY+IxIYsezru5zqUjamDvQA6MwAAA0HSURBVCUpOcXvUkREWlw8A2IhMMDMis0sGbgemHXMNm8QOXrAzLKJnHLaBLwLXGhmmWaWCVzotZ029lbvpChUxoFcjT+ISPsUt6uYnHNBM7uHyBt7AHjeObfKzB4BSp1zs/hHEKwGQsC/O+eqAczsJ0RCBuAR51xNvGo9GZuXvMdoc3QdPNnvUkRE4iJuAQHgnHsLeOuYtgeinjvgX73Hsfs+Dzwfz/pOxeGNc2lwifQdfY7fpYiIxIXfg9RtVubuxWxKGkBqWie/SxERiQsFxEloqK+juGE9e7JG+12KiEjcKCBOQtnqT0mxRpL6aIBaRNovBcRJqFn3MQC9hmv+JRFpvxQQJyFQWUoVmfQs6Od3KSIicaOAOAm5+1dRnj4US9CPT0TaL73DNdP+vTUUuO3U5YzwuxQRkbhSQDRT+drIZ/fSeo/xuRIRkfhSQDTT3k2LAMgfrCuYRKR9U0A0U8LOFdTQhZy8Pn6XIiISVwqIZuq+fx3lqQM0QC0i7Z7e5ZqhsaGe3sEyDmYO8bsUEZG4U0A0Q/mG5SRbkKT8kX6XIiISdwqIZqjeuBiArH5jfa5ERCT+FBDN0Fi5kgYXoKC/jiBEpP1TQDRDeu0atiX21i1GRaRDUEA0Q17dRmoyBvhdhohIq1BAxGjfnmp6UEMwa7DfpYiItIoOHxDVO8upfqg3C1/7xQm327FpBQCpuYNaoywREd91+IBITEohi72E6vadcLu921YD0L3P8NYoS0TEdx0+IFJS0wBwjXUn3C646zOCLoG8Ip1iEpGOocMHRHJKJCAINZxwu5Q9G9mekEtySmorVCUi4r8OHxAJgQANLgDBEx9BZB4uozq1dytVJSLivw4fEAANJGPB+uOuD4dC5IUqqetS3IpViYj4SwEBNFgSFjp+QOyq2ESqNWJZuge1iHQcCgigkSTsBGMQVVsiVzB1ytclriLScSgggEZLJuEERxAHK1YBkNt3VGuVJCLiOwUEkYAIhI8fEFa9nn2kk5Vb2IpViYj4SwEBBBNOfASRsW8j2xMLdRc5EelQ9I4HNCSkkxw6eNz1PRvK2JfRtxUrEhHxnwICqE/uSnpof5Pr9tbuJps9BLtrFlcR6VgUEEBjcjcywk3PxbR94zIA0vJ0H2oR6VgUEEC4Uw+y2MvaBX/9wrp93iR9WcUjWrssERFfKSCA5LyhAAx++xpcOPy5daFda2lwieT10WcgRKRjUUAAwyZfRw1dANhbs+tz61L3bqIykE9iUrIfpYmI+EYBAaSmZ7B53EMA1O4s+9y67MNbqEkvav2iRER8FteAMLMpZrbOzDaY2bQm1t9mZlVmttR73BG1LhTVPiuedQJ0yop8CG7/rm1H2+rrDpEf3k59t/7x/vYiIqedxHi9sJkFgCeBC4ByYKGZzXLOrT5m01edc/c08RKHnXOj41Xfsbr0iEzlXVdTfrRt++bVFJkjqaduEiQiHU88jyDGARucc5uccw3AK8Dlcfx+pyQrLxIQoX3bj7bVbInch7pb72G+1CQi4qd4BkQvYFvUcrnXdqyrzGy5mc00s+jJjlLNrNTM5pvZN5v6BmY21dumtKqq6pSKTUlNp5YuJBz4R0DU71gLQH4/XeIqIh2P34PUfwKKnHMjgdnAC1Hr+jjnSoAbgcfN7As3Y3DOPeOcK3HOleTk5JxyMTWBLFIO7Ty6nFS7ge3kkJ7R9ZRfW0SkrYlnQFQA0UcEBV7bUc65aufckVnyngPOiFpX4X3dBLwPjIljrQAcSMomo+EfRyLdDm6mKrVPvL+tiMhpKZ4BsRAYYGbFZpYMXA987mokM8uLWrwMWOO1Z5pZivc8G5gEHDu43eLq03rSLVQNRG4zmh8s51AX3UVORDqmuF3F5JwLmtk9wLtAAHjeObfKzB4BSp1zs4B7zewyIAjUALd5uw8BnjazMJEQe7SJq59aXCgjj+41e2mor6N6Rxl5Vo/lDIz3txUROS3FLSAAnHNvAW8d0/ZA1PP7gfub2O8ToNVHhgPdCkjY5thduYXdZavIAzoX6AomEemY/B6kPq2k9ygGoLZyI4cqIwcsuf1G+lmSiIhvFBBRuuVFxhsO7tqEVa9nDxlkZud9yV4iIu2TAiJKTkFfQs4IVW+i876NbE/qrduMikiHpXe/KCmp6VQm5JFevYq+DevY122o3yWJiPgmroPUbdHu9L6MOTgXDFIGfc3vckREfKMjiGPU9fjH/IADJ1zsYyUiIv5SQBxj9NXTKEsoYMMVb2mKDRHp0HSK6RhpnTrT54FVfpchIuI7HUGIiEiTFBAiItIkBYSIiDRJASEiIk1SQIiISJMUECIi0iQFhIiINEkBISIiTTLnnN81tAgzqwLKTuElsoHdLVROW9DR+gvqc0ehPjdPH+dcTlMr2k1AnCozK3XOlfhdR2vpaP0F9bmjUJ9bjk4xiYhIkxQQIiLSJAXEPzzjdwGtrKP1F9TnjkJ9biEagxARkSbpCEJERJqkgBARkSZ1+IAwsylmts7MNpjZNL/rORVm9ryZ7TKzlVFt3c1stpmt975meu1mZk94/V5uZmOj9rnV2369md3qR19iZWaFZjbHzFab2Soz+57X3i77bWapZvapmS3z+vuw115sZgu8fr1qZslee4q3vMFbXxT1Wvd77evM7Ov+9Ch2ZhYwsyVm9mdvuV332cy2mNkKM1tqZqVeW+v+XjvnOuwDCAAbgb5AMrAMGOp3XafQn3OAscDKqLb/F5jmPZ8G/Mx7fjHwNmDABGCB194d2OR9zfSeZ/rdtxP0OQ8Y6z3vDHwGDG2v/fbqzvCeJwELvH7MAK732n8F3OU9/w7wK+/59cCr3vOh3u97ClDs/R0E/O7fl/T9X4HpwJ+95XbdZ2ALkH1MW6v+Xnf0I4hxwAbn3CbnXAPwCnC5zzWdNOfch0DNMc2XAy94z18AvhnV/jsXMR/oZmZ5wNeB2c65GudcLTAbmBL/6k+Oc267c26x93w/sAboRTvtt1f3AW8xyXs44Dxgptd+bH+P/BxmAuebmXntrzjn6p1zm4ENRP4eTktmVgBcAjznLRvtvM/H0aq/1x09IHoB26KWy7229qSnc26793wH0NN7fry+t9mfiXcqYQyR/6rbbb+9Uy1LgV1E/uA3Anucc0Fvk+jaj/bLW78XyKIN9dfzOPAfQNhbzqL999kBfzWzRWY21Wtr1d/rxJOpWtom55wzs3Z5XbOZZQB/BO5zzu2L/MMY0d767ZwLAaPNrBvwOjDY55Liysy+Aexyzi0ys8l+19OKznLOVZhZD2C2ma2NXtkav9cd/QiiAiiMWi7w2tqTnd6hJt7XXV778fre5n4mZpZEJBxecs695jW3+3475/YAc4CJRE4pHPmHL7r2o/3y1ncFqmlb/Z0EXGZmW4icBj4P+AXtu8845yq8r7uI/CMwjlb+ve7oAbEQGOBdDZFMZEBrls81tbRZwJErF24F3oxq/5Z39cMEYK936PoucKGZZXpXSFzotZ2WvHPLvwbWOOcei1rVLvttZjnekQNmlgZcQGTcZQ5wtbfZsf098nO4GnjPRUYvZwHXe1f8FAMDgE9bpxfN45y73zlX4JwrIvI3+p5z7ibacZ/NrJOZdT7ynMjv40pa+/fa75F6vx9ERv8/I3Ie94d+13OKfXkZ2A40EjnX+M9Ezr3+HVgP/A3o7m1rwJNev1cAJVGv809EBvA2ALf73a8v6fNZRM7VLgeWeo+L22u/gZHAEq+/K4EHvPa+RN7sNgB/AFK89lRveYO3vm/Ua/3Q+zmsAy7yu28x9n8y/7iKqd322evbMu+x6sh7U2v/XmuqDRERaVJHP8UkIiLHoYAQEZEmKSBERKRJCggREWmSAkJERJqkgBA5DZjZ5COzlIqcLhQQIiLSJAWESDOY2c0WuR/DUjN72ps474CZ/ZdF7s/wdzPL8bYdbWbzvfn5X4+au7+/mf3NIvd0WGxm/byXzzCzmWa21sxesugJpUR8oIAQiZGZDQGuAyY550YDIeAmoBNQ6pwbBnwAPOjt8jvgB865kUQ+3Xqk/SXgSefcKOArRD79DpGZaO8jct+CvkTmIBLxjWZzFYnd+cAZwELvn/s0IpOlhYFXvW1+D7xmZl2Bbs65D7z2F4A/ePPr9HLOvQ7gnKsD8F7vU+dcube8FCgC5sa/WyJNU0CIxM6AF5xz93+u0ezHx2x3svPX1Ec9D6G/T/GZTjGJxO7vwNXe/PxH7g/ch8jf0ZFZRW8E5jrn9gK1Zna2134L8IGL3PWu3My+6b1Gipmlt2ovRGKk/1BEYuScW21mPyJyl68EIrPm3g0cBMZ563YRGaeAyHTMv/ICYBNwu9d+C/C0mT3ivcY1rdgNkZhpNleRU2RmB5xzGX7XIdLSdIpJRESapCMIERFpko4gRESkSQoIERFpkgJCRESapIAQEZEmKSBERKRJ/xfLgS3it6/olwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 3.43889247e-01, -1.14245699e-01,  3.56423052e-02,  1.85728454e-01,\n",
              "         1.90561304e-01,  4.38652959e-01, -9.24441726e-03, -9.53890386e-02,\n",
              "        -3.27539025e-03, -9.37055324e-02, -2.92375898e-02, -2.19150900e-01,\n",
              "        -2.17715583e-01,  4.39070779e-01,  5.81205919e-01, -9.25216490e-02,\n",
              "         5.49916667e-02,  6.04858914e-01,  3.10305176e-01, -3.69760451e-01,\n",
              "         3.57773462e-01,  2.05332695e-01,  1.73015227e-03, -8.70024757e-04,\n",
              "        -2.20153855e-01,  5.09824055e-02, -9.73169857e-02, -2.31033696e-02,\n",
              "        -3.13502770e-01,  1.72288886e-01,  1.76042487e-01, -1.43283600e-01,\n",
              "        -1.76339127e-01, -9.23858944e-02, -1.91101021e-01,  3.38459873e-01,\n",
              "         2.96030629e-01, -7.60328954e-02, -3.06458077e-01,  1.45910883e-02,\n",
              "        -3.39995680e-01,  1.85948784e-01,  1.77122612e-01, -4.30427575e-01,\n",
              "        -6.13761958e-02,  1.70763337e-02, -1.23702779e-01, -1.39434632e-01,\n",
              "         2.93914902e-01,  9.53274567e-02,  7.97404124e-02,  1.69875549e-01,\n",
              "         1.91693501e-01, -5.37826991e-02, -2.15600217e-01, -1.13908237e-01,\n",
              "        -2.33284168e-01, -1.40296996e-01, -1.58382841e-01,  7.68539160e-02,\n",
              "        -2.83043880e-02,  1.68828695e-01,  1.92845082e-01, -3.16499893e-01,\n",
              "        -4.78943111e-01,  9.10590824e-02, -7.18488333e-02,  1.71381264e-01,\n",
              "         1.60617159e-01,  2.48539281e-01,  1.60079336e-01,  4.11009248e-02,\n",
              "        -9.64510125e-02, -2.48757954e-01, -6.87691442e-03,  2.76607797e-01,\n",
              "         1.24050437e-01, -9.35996139e-02, -3.31306045e-01,  4.29540400e-01,\n",
              "        -2.22361831e-01, -1.60429419e-01, -3.18683465e-01,  2.28199521e-01,\n",
              "         2.83842285e-01,  6.64742959e-02,  6.31881962e-02,  5.02610240e-01,\n",
              "         3.16612606e-01, -3.79801844e-01, -4.58493030e-02,  6.85635994e-02,\n",
              "        -1.89931535e-01,  4.28615790e-01,  4.58825830e-01,  1.41434757e-01,\n",
              "        -4.74983570e-01, -1.05316188e-01,  4.63183804e-01, -4.44514777e-01,\n",
              "         1.41940802e-01,  1.52492535e-01, -2.77920088e-01,  1.56052118e-01,\n",
              "         2.18895258e-01, -2.17404914e-03, -3.21527831e-02,  1.02521334e-01,\n",
              "        -2.47763318e-01, -1.39858785e-01, -2.28359774e-01, -5.67627819e-02,\n",
              "         3.31000555e-01, -2.85689000e-01,  1.30423903e-01, -3.82426727e-02,\n",
              "         8.02298015e-02, -3.24865119e-01,  2.82240157e-02, -3.44349197e-02,\n",
              "        -3.67360854e-01,  1.28093216e-01,  1.64293074e-01, -3.24174660e-01,\n",
              "         2.93690055e-01,  1.76543160e-03, -1.06329309e-02,  1.03764717e-01,\n",
              "        -2.29169683e-02, -4.38020714e-02,  3.02815752e-01, -2.06987826e-01,\n",
              "         3.80226849e-01, -2.90132158e-01, -5.21526793e-01, -2.22818155e-01,\n",
              "        -3.87413780e-01, -2.74131558e-01, -1.45106066e-01,  1.43198180e-01,\n",
              "        -2.68868330e-02, -1.24990603e-01, -5.42757664e-02, -3.20619396e-01,\n",
              "         2.60518273e-01, -2.16490806e-01,  5.22174834e-02,  1.02955244e-01,\n",
              "         1.51182589e-01, -4.30741354e-02, -1.18286730e-01, -2.22437037e-01,\n",
              "        -1.19807758e-01,  1.11034478e-01,  1.44572210e-01,  1.90980731e-01,\n",
              "         4.59968987e-01, -9.73008034e-02, -2.19525485e-01,  9.22356654e-02,\n",
              "        -2.12569937e-01,  6.95489129e-02,  7.30708683e-02,  3.19938627e-01,\n",
              "        -1.57865311e-02, -2.54134036e-02,  2.96432674e-01, -2.90513456e-01,\n",
              "        -1.76459741e-01,  2.51010812e-02,  3.66421592e-01, -2.64767414e-01,\n",
              "         6.45784397e-02,  5.92830846e-01, -3.31671822e-01,  1.96575779e-01,\n",
              "         3.22705329e-01,  1.70564190e-01, -6.33294832e-02, -1.52935257e-01,\n",
              "         1.54713215e-01,  2.70182958e-01,  1.58776894e-01,  9.36279843e-04,\n",
              "         1.11195763e-02,  6.62965010e-01, -1.18515368e-01,  5.37740620e-01,\n",
              "        -1.52529926e-01, -3.92133522e-01, -1.31614787e-01, -2.78647889e-02,\n",
              "         8.41157582e-02,  3.69878866e-01,  1.89260713e-01,  2.39284060e-02,\n",
              "         2.63355406e-01,  4.71230911e-01,  2.13135025e-01, -2.63681204e-01,\n",
              "        -1.48774514e-01,  7.81730643e-02, -2.69958609e-01, -1.75217955e-01,\n",
              "        -1.78729716e-02,  1.19812219e-01,  2.58068876e-03, -1.02845029e-01,\n",
              "        -2.01301308e-01,  4.16534012e-01,  2.81335221e-01, -4.22261957e-01,\n",
              "        -7.70393787e-02,  8.55662751e-02, -2.81799048e-02, -1.15391720e-01,\n",
              "        -9.39560392e-02, -6.02585258e-01, -1.72943682e-01, -2.80159520e-02,\n",
              "        -1.67088946e-01,  1.91543305e-02,  3.48794370e-02, -2.43467287e-01,\n",
              "        -1.37099084e-01, -8.47144262e-03, -1.49048300e-01, -1.48787047e-01,\n",
              "         1.17215503e-01,  2.67570172e-02,  5.59342614e-02,  1.66201374e-01,\n",
              "         1.95800212e-01, -3.67382387e-02,  7.73772248e-02, -5.38654437e-02,\n",
              "        -1.74768283e-01, -3.06221709e-01, -7.37990317e-03,  1.20771466e-01,\n",
              "        -1.30062149e-02,  2.59707209e-01, -8.64601277e-02, -2.47285167e-01,\n",
              "         7.92850952e-02,  2.33564720e-01,  2.38543785e-03,  4.32091714e-01,\n",
              "         4.47810063e-01,  5.45421003e-04, -9.08028487e-02, -5.34206597e-02,\n",
              "        -1.32105269e-01, -4.18437967e-02,  2.48586167e-01,  1.91781895e-02,\n",
              "        -5.53668260e-02,  1.40766833e-01, -4.37143798e-02,  5.65160373e-02,\n",
              "        -6.57287858e-03,  9.37489358e-03, -7.79195300e-02,  5.34237083e-02,\n",
              "         4.40757831e-02, -1.23288642e-02, -2.56655135e-02,  2.72087601e-01,\n",
              "         3.75083499e-02, -1.85129869e-01,  1.39925691e-01]),\n",
              " 0.08853961055495715)"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlkH52AW0Yb3"
      },
      "source": [
        "\n",
        "def least_squares_SGD(y, X, theta, num_iters, gamma, show=False):\n",
        "    m = len(y);\n",
        "    train_loss= np.zeros(num_iters);\n",
        "    val_loss = np.zeros(num_iters);\n",
        "    train_acc= np.zeros(num_iters);\n",
        "    val_acc = np.zeros(num_iters);\n",
        "    models=[]\n",
        "    for iter in range (num_iters):\n",
        "      random_idx=np.random.randint(m)\n",
        "      # update weights\n",
        "      theta = theta - gamma * np.transpose(X[random_idx])*(np.matmul(X[random_idx],theta)-y[random_idx])\n",
        "      train_loss[iter] = computeCost(X, y, theta)\n",
        "      val_loss[iter] = computeCost(val_X, val_y, theta)\n",
        "      train_acc[iter] = find_acc(y, np.matmul(X,theta))\n",
        "      val_acc[iter] = find_acc(val_y, np.matmul(val_X,theta))\n",
        "      models.append(np.copy(theta))\n",
        "      print('Epoch {:d}: Training loss= {:.6f} Val loss= {:.6f} Training acc= {:.6f} Val acc= {:.6f}'.format(iter, train_loss[iter], val_loss[iter],\n",
        "                                                                                                              train_acc[iter], val_acc[iter]))\n",
        "    best_model_idx=np.argmin(val_loss)\n",
        "    print(\"Best model info *** :\")\n",
        "    print('Epoch {:d}: Training loss= {:.6f} Val loss= {:.6f} Training acc= {:.6f} Val acc= {:.6f}'.format(iter, train_loss[best_model_idx],val_loss[best_model_idx],\n",
        "                                                                                                         train_acc[best_model_idx],val_acc[best_model_idx],))\n",
        "  \n",
        "    if show:\n",
        "      plt.plot(range(1,num_iters+1), train_loss)\n",
        "      plt.plot(range(1,num_iters+1), val_loss)\n",
        "      plt.xlabel('epoch')\n",
        "      plt.ylabel('loss')\n",
        "      plt.legend(['training', 'validation'], loc='upper right')\n",
        "      plt.show()\n",
        "    return models[best_model_idx], train_loss[best_model_idx]\n",
        "least_squares_SGD(train_y,train_X,np.random.rand(train_X.shape[1]),10000,0.001,show=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWlIDfG2lukI"
      },
      "source": [
        "train_loss1=train_loss\n",
        "val_loss1 =val_loss\n",
        "train_acc1=train_acc\n",
        "val_acc1 = val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww7YbBKrDn0H"
      },
      "source": [
        "def computeCost_ridge(X, y, theta, lambda_):\n",
        "  m = len(y);\n",
        "  h = np.matmul(X,theta);\n",
        "  return 1/(2*m)*np.linalg.norm(h-y,ord=2)**2+ lambda_*np.linalg.norm(theta,ord=2)**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a3MN7zI0LUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79319b47-9bf0-4d88-f3f7-165806810294"
      },
      "source": [
        "def ridge_regression(y, X, lambda_):\n",
        "  X_T=np.transpose(X)\n",
        "  n=len(X_T)\n",
        "  m = len(y)\n",
        "  I=np.identity(n)\n",
        "  lambda_prime=lambda_*(2*m);\n",
        "  # find the final weights\n",
        "  theta = np.matmul(np.matmul(np.linalg.inv(np.matmul(X_T,X)+lambda_prime*I),X_T),y)\n",
        "  train_loss=computeCost_ridge(X, y, theta, lambda_)\n",
        "  val_loss=computeCost_ridge(val_X, val_y, theta, lambda_)\n",
        "  train_acc = find_acc(y, np.matmul(X,theta))\n",
        "  val_acc = find_acc(val_y, np.matmul(val_X,theta))\n",
        "  print('Training loss= {:.6f} Val loss= {:.6f} Training acc= {:.6f} Val acc= {:.6f}'.format(train_loss, \n",
        "                                                                                               val_loss,\n",
        "                                                                                               train_acc, val_acc))\n",
        "  return theta\n",
        "ridge_regression(train_y, train_X, 0);\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss= 0.069448 Val loss= 2.862265 Training acc= 0.818190 Val acc= 0.817195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qsxl9s4ff0V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "678b832f-0318-43bd-f6f7-f7f953e88bff"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "def sigmoid(z):\n",
        "  return 1/(1+np.exp(-z))\n",
        "def logistic_regression(y, X, theta, num_iters, gamma, show=False):\n",
        "  y=y.astype(dtype=np.float128)\n",
        "  X=X.astype(dtype=np.float128)\n",
        "  theta=theta.astype(dtype=np.float128)\n",
        "\n",
        "  m = len(y);\n",
        "  train_loss= np.zeros(num_iters)\n",
        "  val_loss = np.zeros(num_iters)\n",
        "  train_acc= np.zeros(num_iters)\n",
        "  val_acc = np.zeros(num_iters)\n",
        "  models=[]\n",
        "\n",
        "  for iter in range (num_iters):\n",
        "    h = sigmoid(np.matmul(X,theta))\n",
        "    train_loss[iter] =  1/m*np.sum(np.log(1+np.exp(np.matmul(X,theta)))-y*np.matmul(X,theta))\n",
        "    # update weights\n",
        "    theta = theta - gamma * 1/m *np.matmul(np.transpose(X),(h-y))\n",
        "    val_h = sigmoid(np.matmul(val_X,theta))\n",
        "    val_loss[iter] =  1/m*np.sum(np.log(1+np.exp(np.matmul(val_X,theta)))-val_y*np.matmul(val_X,theta))\n",
        "    train_acc[iter] = find_acc(y, h)\n",
        "    val_acc[iter] = find_acc(val_y, val_h)\n",
        "    models.append(np.copy(theta))\n",
        "    print('Epoch {:d}: Training loss= {:.6f} Val loss= {:.6f} Training acc= {:.6f} Val acc= {:.6f}'.format(iter, train_loss[iter], val_loss[iter], train_acc[iter], val_acc[iter]))\n",
        "\n",
        "  best_model_idx=np.argmin(val_loss)\n",
        "  print(\"Best model info *** :\")\n",
        "  print('Epoch {:d}: Training loss= {:.6f} Val loss= {:.6f} Training acc= {:.6f} Val acc= {:.6f}'.format(iter, train_loss[best_model_idx],val_loss[best_model_idx],\n",
        "                                                                                                         train_acc[best_model_idx],val_acc[best_model_idx],))\n",
        "  if show:\n",
        "    plt.plot(range(1,num_iters+1), train_acc)\n",
        "    plt.plot(range(1,num_iters+1), val_acc)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('acc')\n",
        "    plt.legend(['training', 'validation'], loc='upper right')\n",
        "    plt.show()\n",
        "  return models[best_model_idx], train_loss[best_model_idx]\n",
        "logistic_regression(train_y,train_X,np.random.rand(train_X.shape[1]),1000,0.1,show=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Training loss= 5.647390 Val loss= 5.582713 Training acc= 0.570545 Val acc= 0.570065\n",
            "Epoch 1: Training loss= 5.538080 Val loss= 5.474394 Training acc= 0.571180 Val acc= 0.570510\n",
            "Epoch 2: Training loss= 5.429677 Val loss= 5.367019 Training acc= 0.571600 Val acc= 0.571015\n",
            "Epoch 3: Training loss= 5.322211 Val loss= 5.260616 Training acc= 0.572175 Val acc= 0.571870\n",
            "Epoch 4: Training loss= 5.215709 Val loss= 5.155215 Training acc= 0.573000 Val acc= 0.572665\n",
            "Epoch 5: Training loss= 5.110197 Val loss= 5.050843 Training acc= 0.573825 Val acc= 0.573510\n",
            "Epoch 6: Training loss= 5.005704 Val loss= 4.947531 Training acc= 0.574525 Val acc= 0.574240\n",
            "Epoch 7: Training loss= 4.902260 Val loss= 4.845309 Training acc= 0.575250 Val acc= 0.575175\n",
            "Epoch 8: Training loss= 4.799893 Val loss= 4.744208 Training acc= 0.576100 Val acc= 0.576125\n",
            "Epoch 9: Training loss= 4.698634 Val loss= 4.644255 Training acc= 0.576960 Val acc= 0.577135\n",
            "Epoch 10: Training loss= 4.598511 Val loss= 4.545479 Training acc= 0.577975 Val acc= 0.578050\n",
            "Epoch 11: Training loss= 4.499552 Val loss= 4.447906 Training acc= 0.578740 Val acc= 0.578995\n",
            "Epoch 12: Training loss= 4.401787 Val loss= 4.351564 Training acc= 0.579780 Val acc= 0.580000\n",
            "Epoch 13: Training loss= 4.305241 Val loss= 4.256475 Training acc= 0.580690 Val acc= 0.580880\n",
            "Epoch 14: Training loss= 4.209940 Val loss= 4.162666 Training acc= 0.581600 Val acc= 0.582055\n",
            "Epoch 15: Training loss= 4.115909 Val loss= 4.070160 Training acc= 0.582635 Val acc= 0.583335\n",
            "Epoch 16: Training loss= 4.023173 Val loss= 3.978980 Training acc= 0.583905 Val acc= 0.584660\n",
            "Epoch 17: Training loss= 3.931755 Val loss= 3.889148 Training acc= 0.585215 Val acc= 0.585965\n",
            "Epoch 18: Training loss= 3.841675 Val loss= 3.800682 Training acc= 0.586590 Val acc= 0.587300\n",
            "Epoch 19: Training loss= 3.752955 Val loss= 3.713601 Training acc= 0.588040 Val acc= 0.588790\n",
            "Epoch 20: Training loss= 3.665610 Val loss= 3.627919 Training acc= 0.589450 Val acc= 0.590330\n",
            "Epoch 21: Training loss= 3.579659 Val loss= 3.543652 Training acc= 0.591080 Val acc= 0.591835\n",
            "Epoch 22: Training loss= 3.495118 Val loss= 3.460816 Training acc= 0.592610 Val acc= 0.593190\n",
            "Epoch 23: Training loss= 3.412004 Val loss= 3.379424 Training acc= 0.593895 Val acc= 0.594535\n",
            "Epoch 24: Training loss= 3.330334 Val loss= 3.299494 Training acc= 0.595260 Val acc= 0.595965\n",
            "Epoch 25: Training loss= 3.250125 Val loss= 3.221037 Training acc= 0.596535 Val acc= 0.597415\n",
            "Epoch 26: Training loss= 3.171392 Val loss= 3.144069 Training acc= 0.598015 Val acc= 0.598885\n",
            "Epoch 27: Training loss= 3.094150 Val loss= 3.068602 Training acc= 0.599455 Val acc= 0.600360\n",
            "Epoch 28: Training loss= 3.018414 Val loss= 2.994651 Training acc= 0.600995 Val acc= 0.602080\n",
            "Epoch 29: Training loss= 2.944198 Val loss= 2.922230 Training acc= 0.602695 Val acc= 0.603430\n",
            "Epoch 30: Training loss= 2.871518 Val loss= 2.851355 Training acc= 0.604000 Val acc= 0.604800\n",
            "Epoch 31: Training loss= 2.800390 Val loss= 2.782040 Training acc= 0.605575 Val acc= 0.606635\n",
            "Epoch 32: Training loss= 2.730828 Val loss= 2.714297 Training acc= 0.607335 Val acc= 0.608585\n",
            "Epoch 33: Training loss= 2.662847 Val loss= 2.648137 Training acc= 0.609365 Val acc= 0.610680\n",
            "Epoch 34: Training loss= 2.596456 Val loss= 2.583569 Training acc= 0.611390 Val acc= 0.612240\n",
            "Epoch 35: Training loss= 2.531668 Val loss= 2.520600 Training acc= 0.613095 Val acc= 0.614070\n",
            "Epoch 36: Training loss= 2.468493 Val loss= 2.459243 Training acc= 0.614775 Val acc= 0.615835\n",
            "Epoch 37: Training loss= 2.406944 Val loss= 2.399512 Training acc= 0.616770 Val acc= 0.617645\n",
            "Epoch 38: Training loss= 2.347036 Val loss= 2.341422 Training acc= 0.618500 Val acc= 0.619605\n",
            "Epoch 39: Training loss= 2.288785 Val loss= 2.284992 Training acc= 0.620435 Val acc= 0.621505\n",
            "Epoch 40: Training loss= 2.232210 Val loss= 2.230240 Training acc= 0.622570 Val acc= 0.623550\n",
            "Epoch 41: Training loss= 2.177328 Val loss= 2.177186 Training acc= 0.624585 Val acc= 0.625680\n",
            "Epoch 42: Training loss= 2.124161 Val loss= 2.125850 Training acc= 0.626865 Val acc= 0.627805\n",
            "Epoch 43: Training loss= 2.072727 Val loss= 2.076249 Training acc= 0.628890 Val acc= 0.629770\n",
            "Epoch 44: Training loss= 2.023046 Val loss= 2.028401 Training acc= 0.630830 Val acc= 0.632210\n",
            "Epoch 45: Training loss= 1.975136 Val loss= 1.982319 Training acc= 0.633250 Val acc= 0.634170\n",
            "Epoch 46: Training loss= 1.929013 Val loss= 1.938009 Training acc= 0.635375 Val acc= 0.636305\n",
            "Epoch 47: Training loss= 1.884688 Val loss= 1.895476 Training acc= 0.637520 Val acc= 0.638465\n",
            "Epoch 48: Training loss= 1.842168 Val loss= 1.854728 Training acc= 0.639800 Val acc= 0.640855\n",
            "Epoch 49: Training loss= 1.801462 Val loss= 1.815760 Training acc= 0.642245 Val acc= 0.643350\n",
            "Epoch 50: Training loss= 1.762560 Val loss= 1.778554 Training acc= 0.644750 Val acc= 0.645775\n",
            "Epoch 51: Training loss= 1.725441 Val loss= 1.743077 Training acc= 0.647205 Val acc= 0.648140\n",
            "Epoch 52: Training loss= 1.690069 Val loss= 1.709279 Training acc= 0.649640 Val acc= 0.650045\n",
            "Epoch 53: Training loss= 1.656389 Val loss= 1.677100 Training acc= 0.651485 Val acc= 0.652315\n",
            "Epoch 54: Training loss= 1.624335 Val loss= 1.646476 Training acc= 0.653705 Val acc= 0.654570\n",
            "Epoch 55: Training loss= 1.593835 Val loss= 1.617326 Training acc= 0.655890 Val acc= 0.656720\n",
            "Epoch 56: Training loss= 1.564807 Val loss= 1.589566 Training acc= 0.658000 Val acc= 0.658625\n",
            "Epoch 57: Training loss= 1.537169 Val loss= 1.563108 Training acc= 0.659815 Val acc= 0.660475\n",
            "Epoch 58: Training loss= 1.510836 Val loss= 1.537865 Training acc= 0.661770 Val acc= 0.662445\n",
            "Epoch 59: Training loss= 1.485726 Val loss= 1.513759 Training acc= 0.663580 Val acc= 0.664070\n",
            "Epoch 60: Training loss= 1.461759 Val loss= 1.490713 Training acc= 0.665130 Val acc= 0.665915\n",
            "Epoch 61: Training loss= 1.438857 Val loss= 1.468657 Training acc= 0.666820 Val acc= 0.667320\n",
            "Epoch 62: Training loss= 1.416950 Val loss= 1.447529 Training acc= 0.668410 Val acc= 0.669165\n",
            "Epoch 63: Training loss= 1.395974 Val loss= 1.427274 Training acc= 0.670195 Val acc= 0.670870\n",
            "Epoch 64: Training loss= 1.375872 Val loss= 1.407841 Training acc= 0.671960 Val acc= 0.672530\n",
            "Epoch 65: Training loss= 1.356591 Val loss= 1.389182 Training acc= 0.673680 Val acc= 0.674340\n",
            "Epoch 66: Training loss= 1.338085 Val loss= 1.371252 Training acc= 0.675575 Val acc= 0.676215\n",
            "Epoch 67: Training loss= 1.320306 Val loss= 1.354010 Training acc= 0.677350 Val acc= 0.677750\n",
            "Epoch 68: Training loss= 1.303212 Val loss= 1.337415 Training acc= 0.678995 Val acc= 0.679630\n",
            "Epoch 69: Training loss= 1.286763 Val loss= 1.321429 Training acc= 0.680850 Val acc= 0.681400\n",
            "Epoch 70: Training loss= 1.270922 Val loss= 1.306021 Training acc= 0.682735 Val acc= 0.683200\n",
            "Epoch 71: Training loss= 1.255655 Val loss= 1.291158 Training acc= 0.684360 Val acc= 0.684825\n",
            "Epoch 72: Training loss= 1.240933 Val loss= 1.276812 Training acc= 0.685980 Val acc= 0.686420\n",
            "Epoch 73: Training loss= 1.226726 Val loss= 1.262956 Training acc= 0.687660 Val acc= 0.687885\n",
            "Epoch 74: Training loss= 1.213009 Val loss= 1.249563 Training acc= 0.689105 Val acc= 0.689280\n",
            "Epoch 75: Training loss= 1.199754 Val loss= 1.236611 Training acc= 0.690435 Val acc= 0.690870\n",
            "Epoch 76: Training loss= 1.186939 Val loss= 1.224075 Training acc= 0.691930 Val acc= 0.692365\n",
            "Epoch 77: Training loss= 1.174540 Val loss= 1.211936 Training acc= 0.693335 Val acc= 0.693965\n",
            "Epoch 78: Training loss= 1.162537 Val loss= 1.200174 Training acc= 0.694720 Val acc= 0.695110\n",
            "Epoch 79: Training loss= 1.150910 Val loss= 1.188772 Training acc= 0.695870 Val acc= 0.696525\n",
            "Epoch 80: Training loss= 1.139643 Val loss= 1.177713 Training acc= 0.697300 Val acc= 0.697740\n",
            "Epoch 81: Training loss= 1.128717 Val loss= 1.166980 Training acc= 0.698650 Val acc= 0.699040\n",
            "Epoch 82: Training loss= 1.118118 Val loss= 1.156558 Training acc= 0.699810 Val acc= 0.700430\n",
            "Epoch 83: Training loss= 1.107830 Val loss= 1.146432 Training acc= 0.701065 Val acc= 0.701490\n",
            "Epoch 84: Training loss= 1.097837 Val loss= 1.136588 Training acc= 0.702150 Val acc= 0.702730\n",
            "Epoch 85: Training loss= 1.088126 Val loss= 1.127013 Training acc= 0.703390 Val acc= 0.703675\n",
            "Epoch 86: Training loss= 1.078683 Val loss= 1.117694 Training acc= 0.704345 Val acc= 0.704620\n",
            "Epoch 87: Training loss= 1.069495 Val loss= 1.108619 Training acc= 0.705330 Val acc= 0.705765\n",
            "Epoch 88: Training loss= 1.060551 Val loss= 1.099777 Training acc= 0.706500 Val acc= 0.706790\n",
            "Epoch 89: Training loss= 1.051838 Val loss= 1.091157 Training acc= 0.707585 Val acc= 0.707620\n",
            "Epoch 90: Training loss= 1.043347 Val loss= 1.082751 Training acc= 0.708485 Val acc= 0.708640\n",
            "Epoch 91: Training loss= 1.035067 Val loss= 1.074547 Training acc= 0.709415 Val acc= 0.709410\n",
            "Epoch 92: Training loss= 1.026990 Val loss= 1.066538 Training acc= 0.710190 Val acc= 0.710350\n",
            "Epoch 93: Training loss= 1.019106 Val loss= 1.058715 Training acc= 0.711135 Val acc= 0.711195\n",
            "Epoch 94: Training loss= 1.011406 Val loss= 1.051071 Training acc= 0.711975 Val acc= 0.712040\n",
            "Epoch 95: Training loss= 1.003884 Val loss= 1.043598 Training acc= 0.712830 Val acc= 0.712840\n",
            "Epoch 96: Training loss= 0.996532 Val loss= 1.036289 Training acc= 0.713690 Val acc= 0.713420\n",
            "Epoch 97: Training loss= 0.989343 Val loss= 1.029138 Training acc= 0.714250 Val acc= 0.714270\n",
            "Epoch 98: Training loss= 0.982311 Val loss= 1.022139 Training acc= 0.715105 Val acc= 0.714995\n",
            "Epoch 99: Training loss= 0.975430 Val loss= 1.015286 Training acc= 0.715870 Val acc= 0.715665\n",
            "Epoch 100: Training loss= 0.968693 Val loss= 1.008573 Training acc= 0.716370 Val acc= 0.716245\n",
            "Epoch 101: Training loss= 0.962095 Val loss= 1.001995 Training acc= 0.716950 Val acc= 0.717030\n",
            "Epoch 102: Training loss= 0.955631 Val loss= 0.995547 Training acc= 0.717680 Val acc= 0.717610\n",
            "Epoch 103: Training loss= 0.949296 Val loss= 0.989224 Training acc= 0.718180 Val acc= 0.718300\n",
            "Epoch 104: Training loss= 0.943084 Val loss= 0.983022 Training acc= 0.718880 Val acc= 0.719015\n",
            "Epoch 105: Training loss= 0.936992 Val loss= 0.976936 Training acc= 0.719555 Val acc= 0.719840\n",
            "Epoch 106: Training loss= 0.931016 Val loss= 0.970962 Training acc= 0.720325 Val acc= 0.720490\n",
            "Epoch 107: Training loss= 0.925150 Val loss= 0.965097 Training acc= 0.720910 Val acc= 0.721045\n",
            "Epoch 108: Training loss= 0.919392 Val loss= 0.959337 Training acc= 0.721430 Val acc= 0.721400\n",
            "Epoch 109: Training loss= 0.913738 Val loss= 0.953679 Training acc= 0.721855 Val acc= 0.721700\n",
            "Epoch 110: Training loss= 0.908185 Val loss= 0.948119 Training acc= 0.722215 Val acc= 0.722135\n",
            "Epoch 111: Training loss= 0.902729 Val loss= 0.942655 Training acc= 0.722630 Val acc= 0.722625\n",
            "Epoch 112: Training loss= 0.897367 Val loss= 0.937284 Training acc= 0.723100 Val acc= 0.723160\n",
            "Epoch 113: Training loss= 0.892098 Val loss= 0.932003 Training acc= 0.723635 Val acc= 0.723475\n",
            "Epoch 114: Training loss= 0.886918 Val loss= 0.926810 Training acc= 0.724090 Val acc= 0.723820\n",
            "Epoch 115: Training loss= 0.881824 Val loss= 0.921702 Training acc= 0.724455 Val acc= 0.724165\n",
            "Epoch 116: Training loss= 0.876815 Val loss= 0.916678 Training acc= 0.724800 Val acc= 0.724565\n",
            "Epoch 117: Training loss= 0.871888 Val loss= 0.911735 Training acc= 0.725240 Val acc= 0.724870\n",
            "Epoch 118: Training loss= 0.867042 Val loss= 0.906871 Training acc= 0.725605 Val acc= 0.725285\n",
            "Epoch 119: Training loss= 0.862274 Val loss= 0.902085 Training acc= 0.726035 Val acc= 0.725725\n",
            "Epoch 120: Training loss= 0.857583 Val loss= 0.897375 Training acc= 0.726550 Val acc= 0.725990\n",
            "Epoch 121: Training loss= 0.852966 Val loss= 0.892739 Training acc= 0.726735 Val acc= 0.726430\n",
            "Epoch 122: Training loss= 0.848423 Val loss= 0.888175 Training acc= 0.727220 Val acc= 0.726670\n",
            "Epoch 123: Training loss= 0.843952 Val loss= 0.883683 Training acc= 0.727545 Val acc= 0.726980\n",
            "Epoch 124: Training loss= 0.839551 Val loss= 0.879261 Training acc= 0.727930 Val acc= 0.727260\n",
            "Epoch 125: Training loss= 0.835219 Val loss= 0.874907 Training acc= 0.728190 Val acc= 0.727610\n",
            "Epoch 126: Training loss= 0.830954 Val loss= 0.870619 Training acc= 0.728435 Val acc= 0.727985\n",
            "Epoch 127: Training loss= 0.826756 Val loss= 0.866398 Training acc= 0.728770 Val acc= 0.728370\n",
            "Epoch 128: Training loss= 0.822622 Val loss= 0.862241 Training acc= 0.729255 Val acc= 0.728620\n",
            "Epoch 129: Training loss= 0.818553 Val loss= 0.858147 Training acc= 0.729425 Val acc= 0.729085\n",
            "Epoch 130: Training loss= 0.814546 Val loss= 0.854116 Training acc= 0.729900 Val acc= 0.729450\n",
            "Epoch 131: Training loss= 0.810600 Val loss= 0.850145 Training acc= 0.730150 Val acc= 0.729610\n",
            "Epoch 132: Training loss= 0.806715 Val loss= 0.846235 Training acc= 0.730375 Val acc= 0.729995\n",
            "Epoch 133: Training loss= 0.802889 Val loss= 0.842383 Training acc= 0.730675 Val acc= 0.730290\n",
            "Epoch 134: Training loss= 0.799121 Val loss= 0.838590 Training acc= 0.730965 Val acc= 0.730570\n",
            "Epoch 135: Training loss= 0.795411 Val loss= 0.834853 Training acc= 0.731215 Val acc= 0.730815\n",
            "Epoch 136: Training loss= 0.791758 Val loss= 0.831173 Training acc= 0.731525 Val acc= 0.731175\n",
            "Epoch 137: Training loss= 0.788159 Val loss= 0.827547 Training acc= 0.731945 Val acc= 0.731580\n",
            "Epoch 138: Training loss= 0.784616 Val loss= 0.823976 Training acc= 0.732345 Val acc= 0.731885\n",
            "Epoch 139: Training loss= 0.781126 Val loss= 0.820459 Training acc= 0.732605 Val acc= 0.732130\n",
            "Epoch 140: Training loss= 0.777689 Val loss= 0.816994 Training acc= 0.732915 Val acc= 0.732450\n",
            "Epoch 141: Training loss= 0.774303 Val loss= 0.813580 Training acc= 0.733225 Val acc= 0.732660\n",
            "Epoch 142: Training loss= 0.770969 Val loss= 0.810218 Training acc= 0.733510 Val acc= 0.732905\n",
            "Epoch 143: Training loss= 0.767686 Val loss= 0.806905 Training acc= 0.733740 Val acc= 0.733065\n",
            "Epoch 144: Training loss= 0.764452 Val loss= 0.803643 Training acc= 0.733975 Val acc= 0.733225\n",
            "Epoch 145: Training loss= 0.761267 Val loss= 0.800429 Training acc= 0.734135 Val acc= 0.733395\n",
            "Epoch 146: Training loss= 0.758130 Val loss= 0.797262 Training acc= 0.734420 Val acc= 0.733665\n",
            "Epoch 147: Training loss= 0.755040 Val loss= 0.794144 Training acc= 0.734805 Val acc= 0.733935\n",
            "Epoch 148: Training loss= 0.751998 Val loss= 0.791071 Training acc= 0.735015 Val acc= 0.734210\n",
            "Epoch 149: Training loss= 0.749001 Val loss= 0.788045 Training acc= 0.735205 Val acc= 0.734535\n",
            "Epoch 150: Training loss= 0.746051 Val loss= 0.785065 Training acc= 0.735530 Val acc= 0.734805\n",
            "Epoch 151: Training loss= 0.743145 Val loss= 0.782129 Training acc= 0.735810 Val acc= 0.734955\n",
            "Epoch 152: Training loss= 0.740283 Val loss= 0.779237 Training acc= 0.736005 Val acc= 0.735070\n",
            "Epoch 153: Training loss= 0.737465 Val loss= 0.776389 Training acc= 0.736185 Val acc= 0.735295\n",
            "Epoch 154: Training loss= 0.734691 Val loss= 0.773585 Training acc= 0.736410 Val acc= 0.735550\n",
            "Epoch 155: Training loss= 0.731959 Val loss= 0.770822 Training acc= 0.736790 Val acc= 0.735820\n",
            "Epoch 156: Training loss= 0.729270 Val loss= 0.768102 Training acc= 0.737075 Val acc= 0.736030\n",
            "Epoch 157: Training loss= 0.726622 Val loss= 0.765423 Training acc= 0.737330 Val acc= 0.736270\n",
            "Epoch 158: Training loss= 0.724015 Val loss= 0.762784 Training acc= 0.737525 Val acc= 0.736405\n",
            "Epoch 159: Training loss= 0.721448 Val loss= 0.760186 Training acc= 0.737785 Val acc= 0.736450\n",
            "Epoch 160: Training loss= 0.718922 Val loss= 0.757627 Training acc= 0.737850 Val acc= 0.736520\n",
            "Epoch 161: Training loss= 0.716435 Val loss= 0.755108 Training acc= 0.738030 Val acc= 0.736675\n",
            "Epoch 162: Training loss= 0.713986 Val loss= 0.752626 Training acc= 0.738155 Val acc= 0.736815\n",
            "Epoch 163: Training loss= 0.711576 Val loss= 0.750183 Training acc= 0.738305 Val acc= 0.737085\n",
            "Epoch 164: Training loss= 0.709204 Val loss= 0.747777 Training acc= 0.738495 Val acc= 0.737360\n",
            "Epoch 165: Training loss= 0.706868 Val loss= 0.745407 Training acc= 0.738690 Val acc= 0.737560\n",
            "Epoch 166: Training loss= 0.704570 Val loss= 0.743074 Training acc= 0.738915 Val acc= 0.737800\n",
            "Epoch 167: Training loss= 0.702307 Val loss= 0.740777 Training acc= 0.739180 Val acc= 0.738000\n",
            "Epoch 168: Training loss= 0.700080 Val loss= 0.738514 Training acc= 0.739280 Val acc= 0.738230\n",
            "Epoch 169: Training loss= 0.697887 Val loss= 0.736287 Training acc= 0.739530 Val acc= 0.738395\n",
            "Epoch 170: Training loss= 0.695729 Val loss= 0.734093 Training acc= 0.739715 Val acc= 0.738505\n",
            "Epoch 171: Training loss= 0.693606 Val loss= 0.731933 Training acc= 0.739960 Val acc= 0.738645\n",
            "Epoch 172: Training loss= 0.691515 Val loss= 0.729806 Training acc= 0.740065 Val acc= 0.738810\n",
            "Epoch 173: Training loss= 0.689458 Val loss= 0.727712 Training acc= 0.740280 Val acc= 0.738960\n",
            "Epoch 174: Training loss= 0.687433 Val loss= 0.725650 Training acc= 0.740410 Val acc= 0.739095\n",
            "Epoch 175: Training loss= 0.685439 Val loss= 0.723620 Training acc= 0.740560 Val acc= 0.739360\n",
            "Epoch 176: Training loss= 0.683478 Val loss= 0.721621 Training acc= 0.740780 Val acc= 0.739710\n",
            "Epoch 177: Training loss= 0.681547 Val loss= 0.719652 Training acc= 0.741115 Val acc= 0.739870\n",
            "Epoch 178: Training loss= 0.679646 Val loss= 0.717713 Training acc= 0.741310 Val acc= 0.740240\n",
            "Epoch 179: Training loss= 0.677775 Val loss= 0.715804 Training acc= 0.741620 Val acc= 0.740400\n",
            "Epoch 180: Training loss= 0.675933 Val loss= 0.713923 Training acc= 0.741790 Val acc= 0.740635\n",
            "Epoch 181: Training loss= 0.674119 Val loss= 0.712071 Training acc= 0.742040 Val acc= 0.740870\n",
            "Epoch 182: Training loss= 0.672333 Val loss= 0.710246 Training acc= 0.742285 Val acc= 0.741030\n",
            "Epoch 183: Training loss= 0.670575 Val loss= 0.708449 Training acc= 0.742395 Val acc= 0.741215\n",
            "Epoch 184: Training loss= 0.668845 Val loss= 0.706678 Training acc= 0.742605 Val acc= 0.741355\n",
            "Epoch 185: Training loss= 0.667140 Val loss= 0.704933 Training acc= 0.742760 Val acc= 0.741615\n",
            "Epoch 186: Training loss= 0.665462 Val loss= 0.703215 Training acc= 0.743025 Val acc= 0.741810\n",
            "Epoch 187: Training loss= 0.663809 Val loss= 0.701522 Training acc= 0.743190 Val acc= 0.742100\n",
            "Epoch 188: Training loss= 0.662182 Val loss= 0.699854 Training acc= 0.743385 Val acc= 0.742345\n",
            "Epoch 189: Training loss= 0.660579 Val loss= 0.698210 Training acc= 0.743620 Val acc= 0.742480\n",
            "Epoch 190: Training loss= 0.659001 Val loss= 0.696591 Training acc= 0.743745 Val acc= 0.742610\n",
            "Epoch 191: Training loss= 0.657448 Val loss= 0.694996 Training acc= 0.743925 Val acc= 0.742840\n",
            "Epoch 192: Training loss= 0.655918 Val loss= 0.693424 Training acc= 0.744160 Val acc= 0.742980\n",
            "Epoch 193: Training loss= 0.654411 Val loss= 0.691876 Training acc= 0.744285 Val acc= 0.743140\n",
            "Epoch 194: Training loss= 0.652928 Val loss= 0.690350 Training acc= 0.744520 Val acc= 0.743435\n",
            "Epoch 195: Training loss= 0.651467 Val loss= 0.688846 Training acc= 0.744845 Val acc= 0.743620\n",
            "Epoch 196: Training loss= 0.650029 Val loss= 0.687365 Training acc= 0.745040 Val acc= 0.743835\n",
            "Epoch 197: Training loss= 0.648613 Val loss= 0.685906 Training acc= 0.745205 Val acc= 0.744140\n",
            "Epoch 198: Training loss= 0.647219 Val loss= 0.684468 Training acc= 0.745485 Val acc= 0.744175\n",
            "Epoch 199: Training loss= 0.645846 Val loss= 0.683051 Training acc= 0.745580 Val acc= 0.744450\n",
            "Epoch 200: Training loss= 0.644494 Val loss= 0.681655 Training acc= 0.745900 Val acc= 0.744605\n",
            "Epoch 201: Training loss= 0.643163 Val loss= 0.680279 Training acc= 0.746030 Val acc= 0.744790\n",
            "Epoch 202: Training loss= 0.641853 Val loss= 0.678924 Training acc= 0.746210 Val acc= 0.745040\n",
            "Epoch 203: Training loss= 0.640562 Val loss= 0.677588 Training acc= 0.746395 Val acc= 0.745165\n",
            "Epoch 204: Training loss= 0.639291 Val loss= 0.676272 Training acc= 0.746540 Val acc= 0.745355\n",
            "Epoch 205: Training loss= 0.638039 Val loss= 0.674974 Training acc= 0.746790 Val acc= 0.745490\n",
            "Epoch 206: Training loss= 0.636806 Val loss= 0.673696 Training acc= 0.747000 Val acc= 0.745690\n",
            "Epoch 207: Training loss= 0.635592 Val loss= 0.672435 Training acc= 0.747240 Val acc= 0.745735\n",
            "Epoch 208: Training loss= 0.634396 Val loss= 0.671193 Training acc= 0.747275 Val acc= 0.745915\n",
            "Epoch 209: Training loss= 0.633218 Val loss= 0.669968 Training acc= 0.747450 Val acc= 0.746095\n",
            "Epoch 210: Training loss= 0.632057 Val loss= 0.668761 Training acc= 0.747695 Val acc= 0.746260\n",
            "Epoch 211: Training loss= 0.630913 Val loss= 0.667570 Training acc= 0.747920 Val acc= 0.746505\n",
            "Epoch 212: Training loss= 0.629786 Val loss= 0.666396 Training acc= 0.748180 Val acc= 0.746635\n",
            "Epoch 213: Training loss= 0.628675 Val loss= 0.665239 Training acc= 0.748335 Val acc= 0.746830\n",
            "Epoch 214: Training loss= 0.627581 Val loss= 0.664097 Training acc= 0.748545 Val acc= 0.747210\n",
            "Epoch 215: Training loss= 0.626502 Val loss= 0.662971 Training acc= 0.748850 Val acc= 0.747430\n",
            "Epoch 216: Training loss= 0.625439 Val loss= 0.661860 Training acc= 0.749140 Val acc= 0.747480\n",
            "Epoch 217: Training loss= 0.624391 Val loss= 0.660764 Training acc= 0.749165 Val acc= 0.747705\n",
            "Epoch 218: Training loss= 0.623358 Val loss= 0.659683 Training acc= 0.749315 Val acc= 0.747840\n",
            "Epoch 219: Training loss= 0.622339 Val loss= 0.658616 Training acc= 0.749480 Val acc= 0.748020\n",
            "Epoch 220: Training loss= 0.621334 Val loss= 0.657563 Training acc= 0.749655 Val acc= 0.748235\n",
            "Epoch 221: Training loss= 0.620344 Val loss= 0.656524 Training acc= 0.749855 Val acc= 0.748445\n",
            "Epoch 222: Training loss= 0.619367 Val loss= 0.655498 Training acc= 0.749995 Val acc= 0.748625\n",
            "Epoch 223: Training loss= 0.618403 Val loss= 0.654486 Training acc= 0.750140 Val acc= 0.749000\n",
            "Epoch 224: Training loss= 0.617452 Val loss= 0.653486 Training acc= 0.750540 Val acc= 0.749150\n",
            "Epoch 225: Training loss= 0.616514 Val loss= 0.652499 Training acc= 0.750605 Val acc= 0.749325\n",
            "Epoch 226: Training loss= 0.615588 Val loss= 0.651524 Training acc= 0.750720 Val acc= 0.749450\n",
            "Epoch 227: Training loss= 0.614675 Val loss= 0.650561 Training acc= 0.750865 Val acc= 0.749540\n",
            "Epoch 228: Training loss= 0.613774 Val loss= 0.649611 Training acc= 0.750895 Val acc= 0.749730\n",
            "Epoch 229: Training loss= 0.612884 Val loss= 0.648671 Training acc= 0.751135 Val acc= 0.749950\n",
            "Epoch 230: Training loss= 0.612006 Val loss= 0.647744 Training acc= 0.751330 Val acc= 0.750190\n",
            "Epoch 231: Training loss= 0.611138 Val loss= 0.646827 Training acc= 0.751465 Val acc= 0.750400\n",
            "Epoch 232: Training loss= 0.610282 Val loss= 0.645922 Training acc= 0.751635 Val acc= 0.750635\n",
            "Epoch 233: Training loss= 0.609437 Val loss= 0.645027 Training acc= 0.751780 Val acc= 0.750870\n",
            "Epoch 234: Training loss= 0.608602 Val loss= 0.644142 Training acc= 0.752020 Val acc= 0.751040\n",
            "Epoch 235: Training loss= 0.607778 Val loss= 0.643268 Training acc= 0.752105 Val acc= 0.751125\n",
            "Epoch 236: Training loss= 0.606964 Val loss= 0.642405 Training acc= 0.752180 Val acc= 0.751420\n",
            "Epoch 237: Training loss= 0.606159 Val loss= 0.641551 Training acc= 0.752450 Val acc= 0.751590\n",
            "Epoch 238: Training loss= 0.605365 Val loss= 0.640707 Training acc= 0.752630 Val acc= 0.751735\n",
            "Epoch 239: Training loss= 0.604580 Val loss= 0.639872 Training acc= 0.752710 Val acc= 0.751830\n",
            "Epoch 240: Training loss= 0.603805 Val loss= 0.639047 Training acc= 0.752770 Val acc= 0.751900\n",
            "Epoch 241: Training loss= 0.603038 Val loss= 0.638232 Training acc= 0.752860 Val acc= 0.752060\n",
            "Epoch 242: Training loss= 0.602281 Val loss= 0.637425 Training acc= 0.752995 Val acc= 0.752140\n",
            "Epoch 243: Training loss= 0.601532 Val loss= 0.636627 Training acc= 0.753090 Val acc= 0.752295\n",
            "Epoch 244: Training loss= 0.600793 Val loss= 0.635838 Training acc= 0.753230 Val acc= 0.752490\n",
            "Epoch 245: Training loss= 0.600061 Val loss= 0.635057 Training acc= 0.753430 Val acc= 0.752610\n",
            "Epoch 246: Training loss= 0.599338 Val loss= 0.634285 Training acc= 0.753600 Val acc= 0.752805\n",
            "Epoch 247: Training loss= 0.598624 Val loss= 0.633521 Training acc= 0.753830 Val acc= 0.752935\n",
            "Epoch 248: Training loss= 0.597917 Val loss= 0.632765 Training acc= 0.753975 Val acc= 0.753105\n",
            "Epoch 249: Training loss= 0.597218 Val loss= 0.632017 Training acc= 0.754135 Val acc= 0.753280\n",
            "Epoch 250: Training loss= 0.596526 Val loss= 0.631276 Training acc= 0.754300 Val acc= 0.753415\n",
            "Epoch 251: Training loss= 0.595843 Val loss= 0.630544 Training acc= 0.754460 Val acc= 0.753570\n",
            "Epoch 252: Training loss= 0.595167 Val loss= 0.629819 Training acc= 0.754605 Val acc= 0.753725\n",
            "Epoch 253: Training loss= 0.594498 Val loss= 0.629101 Training acc= 0.754815 Val acc= 0.753840\n",
            "Epoch 254: Training loss= 0.593836 Val loss= 0.628390 Training acc= 0.755010 Val acc= 0.753885\n",
            "Epoch 255: Training loss= 0.593181 Val loss= 0.627687 Training acc= 0.755055 Val acc= 0.754070\n",
            "Epoch 256: Training loss= 0.592533 Val loss= 0.626991 Training acc= 0.755175 Val acc= 0.754190\n",
            "Epoch 257: Training loss= 0.591893 Val loss= 0.626301 Training acc= 0.755300 Val acc= 0.754260\n",
            "Epoch 258: Training loss= 0.591258 Val loss= 0.625619 Training acc= 0.755350 Val acc= 0.754375\n",
            "Epoch 259: Training loss= 0.590631 Val loss= 0.624943 Training acc= 0.755490 Val acc= 0.754560\n",
            "Epoch 260: Training loss= 0.590010 Val loss= 0.624274 Training acc= 0.755625 Val acc= 0.754740\n",
            "Epoch 261: Training loss= 0.589395 Val loss= 0.623611 Training acc= 0.755760 Val acc= 0.754875\n",
            "Epoch 262: Training loss= 0.588787 Val loss= 0.622955 Training acc= 0.755795 Val acc= 0.755050\n",
            "Epoch 263: Training loss= 0.588185 Val loss= 0.622305 Training acc= 0.755975 Val acc= 0.755235\n",
            "Epoch 264: Training loss= 0.587589 Val loss= 0.621661 Training acc= 0.756090 Val acc= 0.755285\n",
            "Epoch 265: Training loss= 0.586999 Val loss= 0.621024 Training acc= 0.756185 Val acc= 0.755420\n",
            "Epoch 266: Training loss= 0.586415 Val loss= 0.620392 Training acc= 0.756370 Val acc= 0.755475\n",
            "Epoch 267: Training loss= 0.585837 Val loss= 0.619767 Training acc= 0.756455 Val acc= 0.755595\n",
            "Epoch 268: Training loss= 0.585265 Val loss= 0.619147 Training acc= 0.756550 Val acc= 0.755625\n",
            "Epoch 269: Training loss= 0.584698 Val loss= 0.618533 Training acc= 0.756580 Val acc= 0.755685\n",
            "Epoch 270: Training loss= 0.584137 Val loss= 0.617925 Training acc= 0.756635 Val acc= 0.755825\n",
            "Epoch 271: Training loss= 0.583582 Val loss= 0.617323 Training acc= 0.756785 Val acc= 0.755980\n",
            "Epoch 272: Training loss= 0.583032 Val loss= 0.616726 Training acc= 0.756885 Val acc= 0.756105\n",
            "Epoch 273: Training loss= 0.582487 Val loss= 0.616134 Training acc= 0.757035 Val acc= 0.756165\n",
            "Epoch 274: Training loss= 0.581948 Val loss= 0.615548 Training acc= 0.757130 Val acc= 0.756380\n",
            "Epoch 275: Training loss= 0.581413 Val loss= 0.614967 Training acc= 0.757320 Val acc= 0.756500\n",
            "Epoch 276: Training loss= 0.580884 Val loss= 0.614391 Training acc= 0.757465 Val acc= 0.756650\n",
            "Epoch 277: Training loss= 0.580359 Val loss= 0.613820 Training acc= 0.757655 Val acc= 0.756715\n",
            "Epoch 278: Training loss= 0.579840 Val loss= 0.613254 Training acc= 0.757745 Val acc= 0.756830\n",
            "Epoch 279: Training loss= 0.579325 Val loss= 0.612693 Training acc= 0.757875 Val acc= 0.756925\n",
            "Epoch 280: Training loss= 0.578815 Val loss= 0.612137 Training acc= 0.757980 Val acc= 0.757000\n",
            "Epoch 281: Training loss= 0.578309 Val loss= 0.611586 Training acc= 0.758070 Val acc= 0.757065\n",
            "Epoch 282: Training loss= 0.577808 Val loss= 0.611040 Training acc= 0.758140 Val acc= 0.757100\n",
            "Epoch 283: Training loss= 0.577312 Val loss= 0.610498 Training acc= 0.758175 Val acc= 0.757070\n",
            "Epoch 284: Training loss= 0.576820 Val loss= 0.609960 Training acc= 0.758160 Val acc= 0.757135\n",
            "Epoch 285: Training loss= 0.576332 Val loss= 0.609427 Training acc= 0.758255 Val acc= 0.757185\n",
            "Epoch 286: Training loss= 0.575849 Val loss= 0.608899 Training acc= 0.758360 Val acc= 0.757255\n",
            "Epoch 287: Training loss= 0.575370 Val loss= 0.608375 Training acc= 0.758470 Val acc= 0.757400\n",
            "Epoch 288: Training loss= 0.574895 Val loss= 0.607856 Training acc= 0.758655 Val acc= 0.757545\n",
            "Epoch 289: Training loss= 0.574424 Val loss= 0.607340 Training acc= 0.758720 Val acc= 0.757680\n",
            "Epoch 290: Training loss= 0.573957 Val loss= 0.606829 Training acc= 0.758865 Val acc= 0.757790\n",
            "Epoch 291: Training loss= 0.573495 Val loss= 0.606322 Training acc= 0.758910 Val acc= 0.757880\n",
            "Epoch 292: Training loss= 0.573036 Val loss= 0.605819 Training acc= 0.759000 Val acc= 0.758030\n",
            "Epoch 293: Training loss= 0.572581 Val loss= 0.605321 Training acc= 0.759115 Val acc= 0.758160\n",
            "Epoch 294: Training loss= 0.572130 Val loss= 0.604826 Training acc= 0.759220 Val acc= 0.758350\n",
            "Epoch 295: Training loss= 0.571683 Val loss= 0.604335 Training acc= 0.759360 Val acc= 0.758385\n",
            "Epoch 296: Training loss= 0.571239 Val loss= 0.603848 Training acc= 0.759400 Val acc= 0.758490\n",
            "Epoch 297: Training loss= 0.570799 Val loss= 0.603365 Training acc= 0.759450 Val acc= 0.758640\n",
            "Epoch 298: Training loss= 0.570363 Val loss= 0.602886 Training acc= 0.759595 Val acc= 0.758745\n",
            "Epoch 299: Training loss= 0.569930 Val loss= 0.602410 Training acc= 0.759650 Val acc= 0.758815\n",
            "Epoch 300: Training loss= 0.569501 Val loss= 0.601938 Training acc= 0.759675 Val acc= 0.758850\n",
            "Epoch 301: Training loss= 0.569075 Val loss= 0.601469 Training acc= 0.759695 Val acc= 0.758960\n",
            "Epoch 302: Training loss= 0.568653 Val loss= 0.601004 Training acc= 0.759765 Val acc= 0.759025\n",
            "Epoch 303: Training loss= 0.568234 Val loss= 0.600543 Training acc= 0.759855 Val acc= 0.759110\n",
            "Epoch 304: Training loss= 0.567818 Val loss= 0.600085 Training acc= 0.759960 Val acc= 0.759260\n",
            "Epoch 305: Training loss= 0.567406 Val loss= 0.599630 Training acc= 0.760115 Val acc= 0.759430\n",
            "Epoch 306: Training loss= 0.566997 Val loss= 0.599179 Training acc= 0.760275 Val acc= 0.759540\n",
            "Epoch 307: Training loss= 0.566591 Val loss= 0.598731 Training acc= 0.760425 Val acc= 0.759585\n",
            "Epoch 308: Training loss= 0.566188 Val loss= 0.598286 Training acc= 0.760490 Val acc= 0.759705\n",
            "Epoch 309: Training loss= 0.565789 Val loss= 0.597844 Training acc= 0.760675 Val acc= 0.759725\n",
            "Epoch 310: Training loss= 0.565392 Val loss= 0.597406 Training acc= 0.760735 Val acc= 0.759765\n",
            "Epoch 311: Training loss= 0.564999 Val loss= 0.596970 Training acc= 0.760760 Val acc= 0.759905\n",
            "Epoch 312: Training loss= 0.564609 Val loss= 0.596538 Training acc= 0.760850 Val acc= 0.760025\n",
            "Epoch 313: Training loss= 0.564221 Val loss= 0.596109 Training acc= 0.760940 Val acc= 0.760000\n",
            "Epoch 314: Training loss= 0.563837 Val loss= 0.595683 Training acc= 0.760965 Val acc= 0.760130\n",
            "Epoch 315: Training loss= 0.563455 Val loss= 0.595260 Training acc= 0.761055 Val acc= 0.760215\n",
            "Epoch 316: Training loss= 0.563077 Val loss= 0.594840 Training acc= 0.761185 Val acc= 0.760275\n",
            "Epoch 317: Training loss= 0.562701 Val loss= 0.594422 Training acc= 0.761290 Val acc= 0.760345\n",
            "Epoch 318: Training loss= 0.562328 Val loss= 0.594008 Training acc= 0.761350 Val acc= 0.760520\n",
            "Epoch 319: Training loss= 0.561959 Val loss= 0.593597 Training acc= 0.761530 Val acc= 0.760525\n",
            "Epoch 320: Training loss= 0.561592 Val loss= 0.593188 Training acc= 0.761590 Val acc= 0.760575\n",
            "Epoch 321: Training loss= 0.561227 Val loss= 0.592783 Training acc= 0.761560 Val acc= 0.760700\n",
            "Epoch 322: Training loss= 0.560866 Val loss= 0.592380 Training acc= 0.761680 Val acc= 0.760800\n",
            "Epoch 323: Training loss= 0.560507 Val loss= 0.591980 Training acc= 0.761735 Val acc= 0.760930\n",
            "Epoch 324: Training loss= 0.560151 Val loss= 0.591583 Training acc= 0.761800 Val acc= 0.761005\n",
            "Epoch 325: Training loss= 0.559798 Val loss= 0.591189 Training acc= 0.761900 Val acc= 0.761125\n",
            "Epoch 326: Training loss= 0.559448 Val loss= 0.590798 Training acc= 0.762030 Val acc= 0.761230\n",
            "Epoch 327: Training loss= 0.559100 Val loss= 0.590409 Training acc= 0.762125 Val acc= 0.761325\n",
            "Epoch 328: Training loss= 0.558755 Val loss= 0.590023 Training acc= 0.762245 Val acc= 0.761440\n",
            "Epoch 329: Training loss= 0.558412 Val loss= 0.589639 Training acc= 0.762340 Val acc= 0.761480\n",
            "Epoch 330: Training loss= 0.558072 Val loss= 0.589259 Training acc= 0.762395 Val acc= 0.761530\n",
            "Epoch 331: Training loss= 0.557734 Val loss= 0.588880 Training acc= 0.762370 Val acc= 0.761610\n",
            "Epoch 332: Training loss= 0.557399 Val loss= 0.588505 Training acc= 0.762440 Val acc= 0.761675\n",
            "Epoch 333: Training loss= 0.557067 Val loss= 0.588132 Training acc= 0.762480 Val acc= 0.761785\n",
            "Epoch 334: Training loss= 0.556737 Val loss= 0.587761 Training acc= 0.762580 Val acc= 0.761835\n",
            "Epoch 335: Training loss= 0.556409 Val loss= 0.587393 Training acc= 0.762655 Val acc= 0.761880\n",
            "Epoch 336: Training loss= 0.556083 Val loss= 0.587027 Training acc= 0.762700 Val acc= 0.761955\n",
            "Epoch 337: Training loss= 0.555760 Val loss= 0.586664 Training acc= 0.762800 Val acc= 0.762040\n",
            "Epoch 338: Training loss= 0.555439 Val loss= 0.586303 Training acc= 0.762915 Val acc= 0.762120\n",
            "Epoch 339: Training loss= 0.555121 Val loss= 0.585944 Training acc= 0.763030 Val acc= 0.762200\n",
            "Epoch 340: Training loss= 0.554804 Val loss= 0.585588 Training acc= 0.763140 Val acc= 0.762250\n",
            "Epoch 341: Training loss= 0.554490 Val loss= 0.585234 Training acc= 0.763225 Val acc= 0.762370\n",
            "Epoch 342: Training loss= 0.554178 Val loss= 0.584882 Training acc= 0.763315 Val acc= 0.762430\n",
            "Epoch 343: Training loss= 0.553868 Val loss= 0.584533 Training acc= 0.763405 Val acc= 0.762475\n",
            "Epoch 344: Training loss= 0.553560 Val loss= 0.584186 Training acc= 0.763435 Val acc= 0.762530\n",
            "Epoch 345: Training loss= 0.553254 Val loss= 0.583841 Training acc= 0.763480 Val acc= 0.762650\n",
            "Epoch 346: Training loss= 0.552950 Val loss= 0.583498 Training acc= 0.763560 Val acc= 0.762740\n",
            "Epoch 347: Training loss= 0.552649 Val loss= 0.583157 Training acc= 0.763635 Val acc= 0.762760\n",
            "Epoch 348: Training loss= 0.552349 Val loss= 0.582818 Training acc= 0.763675 Val acc= 0.762795\n",
            "Epoch 349: Training loss= 0.552051 Val loss= 0.582482 Training acc= 0.763680 Val acc= 0.762930\n",
            "Epoch 350: Training loss= 0.551756 Val loss= 0.582148 Training acc= 0.763815 Val acc= 0.763025\n",
            "Epoch 351: Training loss= 0.551462 Val loss= 0.581815 Training acc= 0.763910 Val acc= 0.763160\n",
            "Epoch 352: Training loss= 0.551170 Val loss= 0.581485 Training acc= 0.764020 Val acc= 0.763270\n",
            "Epoch 353: Training loss= 0.550880 Val loss= 0.581157 Training acc= 0.764100 Val acc= 0.763275\n",
            "Epoch 354: Training loss= 0.550593 Val loss= 0.580831 Training acc= 0.764065 Val acc= 0.763415\n",
            "Epoch 355: Training loss= 0.550306 Val loss= 0.580507 Training acc= 0.764175 Val acc= 0.763460\n",
            "Epoch 356: Training loss= 0.550022 Val loss= 0.580184 Training acc= 0.764245 Val acc= 0.763510\n",
            "Epoch 357: Training loss= 0.549740 Val loss= 0.579864 Training acc= 0.764360 Val acc= 0.763575\n",
            "Epoch 358: Training loss= 0.549459 Val loss= 0.579545 Training acc= 0.764420 Val acc= 0.763630\n",
            "Epoch 359: Training loss= 0.549180 Val loss= 0.579229 Training acc= 0.764510 Val acc= 0.763675\n",
            "Epoch 360: Training loss= 0.548903 Val loss= 0.578914 Training acc= 0.764545 Val acc= 0.763710\n",
            "Epoch 361: Training loss= 0.548628 Val loss= 0.578601 Training acc= 0.764605 Val acc= 0.763730\n",
            "Epoch 362: Training loss= 0.548354 Val loss= 0.578290 Training acc= 0.764615 Val acc= 0.763790\n",
            "Epoch 363: Training loss= 0.548082 Val loss= 0.577980 Training acc= 0.764680 Val acc= 0.763910\n",
            "Epoch 364: Training loss= 0.547812 Val loss= 0.577673 Training acc= 0.764795 Val acc= 0.763920\n",
            "Epoch 365: Training loss= 0.547543 Val loss= 0.577367 Training acc= 0.764805 Val acc= 0.763975\n",
            "Epoch 366: Training loss= 0.547276 Val loss= 0.577062 Training acc= 0.764850 Val acc= 0.764000\n",
            "Epoch 367: Training loss= 0.547010 Val loss= 0.576760 Training acc= 0.764890 Val acc= 0.764085\n",
            "Epoch 368: Training loss= 0.546746 Val loss= 0.576459 Training acc= 0.765005 Val acc= 0.764150\n",
            "Epoch 369: Training loss= 0.546483 Val loss= 0.576159 Training acc= 0.765040 Val acc= 0.764195\n",
            "Epoch 370: Training loss= 0.546222 Val loss= 0.575861 Training acc= 0.765080 Val acc= 0.764270\n",
            "Epoch 371: Training loss= 0.545963 Val loss= 0.575565 Training acc= 0.765130 Val acc= 0.764370\n",
            "Epoch 372: Training loss= 0.545705 Val loss= 0.575270 Training acc= 0.765230 Val acc= 0.764430\n",
            "Epoch 373: Training loss= 0.545448 Val loss= 0.574977 Training acc= 0.765305 Val acc= 0.764460\n",
            "Epoch 374: Training loss= 0.545193 Val loss= 0.574686 Training acc= 0.765345 Val acc= 0.764545\n",
            "Epoch 375: Training loss= 0.544939 Val loss= 0.574396 Training acc= 0.765440 Val acc= 0.764675\n",
            "Epoch 376: Training loss= 0.544687 Val loss= 0.574107 Training acc= 0.765525 Val acc= 0.764710\n",
            "Epoch 377: Training loss= 0.544436 Val loss= 0.573820 Training acc= 0.765580 Val acc= 0.764745\n",
            "Epoch 378: Training loss= 0.544187 Val loss= 0.573534 Training acc= 0.765625 Val acc= 0.764885\n",
            "Epoch 379: Training loss= 0.543939 Val loss= 0.573250 Training acc= 0.765775 Val acc= 0.764950\n",
            "Epoch 380: Training loss= 0.543692 Val loss= 0.572968 Training acc= 0.765855 Val acc= 0.765070\n",
            "Epoch 381: Training loss= 0.543447 Val loss= 0.572686 Training acc= 0.765945 Val acc= 0.765110\n",
            "Epoch 382: Training loss= 0.543204 Val loss= 0.572407 Training acc= 0.765965 Val acc= 0.765150\n",
            "Epoch 383: Training loss= 0.542961 Val loss= 0.572128 Training acc= 0.766010 Val acc= 0.765245\n",
            "Epoch 384: Training loss= 0.542720 Val loss= 0.571851 Training acc= 0.766110 Val acc= 0.765260\n",
            "Epoch 385: Training loss= 0.542481 Val loss= 0.571576 Training acc= 0.766090 Val acc= 0.765260\n",
            "Epoch 386: Training loss= 0.542243 Val loss= 0.571302 Training acc= 0.766100 Val acc= 0.765310\n",
            "Epoch 387: Training loss= 0.542006 Val loss= 0.571029 Training acc= 0.766100 Val acc= 0.765390\n",
            "Epoch 388: Training loss= 0.541770 Val loss= 0.570758 Training acc= 0.766180 Val acc= 0.765440\n",
            "Epoch 389: Training loss= 0.541536 Val loss= 0.570488 Training acc= 0.766245 Val acc= 0.765450\n",
            "Epoch 390: Training loss= 0.541303 Val loss= 0.570219 Training acc= 0.766255 Val acc= 0.765460\n",
            "Epoch 391: Training loss= 0.541072 Val loss= 0.569952 Training acc= 0.766270 Val acc= 0.765520\n",
            "Epoch 392: Training loss= 0.540842 Val loss= 0.569686 Training acc= 0.766325 Val acc= 0.765625\n",
            "Epoch 393: Training loss= 0.540613 Val loss= 0.569422 Training acc= 0.766385 Val acc= 0.765710\n",
            "Epoch 394: Training loss= 0.540386 Val loss= 0.569159 Training acc= 0.766500 Val acc= 0.765785\n",
            "Epoch 395: Training loss= 0.540159 Val loss= 0.568897 Training acc= 0.766580 Val acc= 0.765830\n",
            "Epoch 396: Training loss= 0.539935 Val loss= 0.568636 Training acc= 0.766665 Val acc= 0.765850\n",
            "Epoch 397: Training loss= 0.539711 Val loss= 0.568377 Training acc= 0.766650 Val acc= 0.765905\n",
            "Epoch 398: Training loss= 0.539488 Val loss= 0.568119 Training acc= 0.766695 Val acc= 0.765980\n",
            "Epoch 399: Training loss= 0.539267 Val loss= 0.567863 Training acc= 0.766760 Val acc= 0.766015\n",
            "Epoch 400: Training loss= 0.539047 Val loss= 0.567607 Training acc= 0.766805 Val acc= 0.766045\n",
            "Epoch 401: Training loss= 0.538829 Val loss= 0.567353 Training acc= 0.766855 Val acc= 0.766150\n",
            "Epoch 402: Training loss= 0.538611 Val loss= 0.567101 Training acc= 0.766965 Val acc= 0.766195\n",
            "Epoch 403: Training loss= 0.538395 Val loss= 0.566849 Training acc= 0.767005 Val acc= 0.766285\n",
            "Epoch 404: Training loss= 0.538180 Val loss= 0.566599 Training acc= 0.767095 Val acc= 0.766300\n",
            "Epoch 405: Training loss= 0.537966 Val loss= 0.566350 Training acc= 0.767140 Val acc= 0.766330\n",
            "Epoch 406: Training loss= 0.537753 Val loss= 0.566102 Training acc= 0.767190 Val acc= 0.766415\n",
            "Epoch 407: Training loss= 0.537541 Val loss= 0.565855 Training acc= 0.767270 Val acc= 0.766460\n",
            "Epoch 408: Training loss= 0.537331 Val loss= 0.565610 Training acc= 0.767300 Val acc= 0.766530\n",
            "Epoch 409: Training loss= 0.537121 Val loss= 0.565365 Training acc= 0.767350 Val acc= 0.766595\n",
            "Epoch 410: Training loss= 0.536913 Val loss= 0.565122 Training acc= 0.767410 Val acc= 0.766655\n",
            "Epoch 411: Training loss= 0.536706 Val loss= 0.564880 Training acc= 0.767450 Val acc= 0.766760\n",
            "Epoch 412: Training loss= 0.536500 Val loss= 0.564640 Training acc= 0.767550 Val acc= 0.766790\n",
            "Epoch 413: Training loss= 0.536295 Val loss= 0.564400 Training acc= 0.767570 Val acc= 0.766895\n",
            "Epoch 414: Training loss= 0.536091 Val loss= 0.564162 Training acc= 0.767685 Val acc= 0.766960\n",
            "Epoch 415: Training loss= 0.535888 Val loss= 0.563924 Training acc= 0.767785 Val acc= 0.767060\n",
            "Epoch 416: Training loss= 0.535686 Val loss= 0.563688 Training acc= 0.767920 Val acc= 0.767130\n",
            "Epoch 417: Training loss= 0.535485 Val loss= 0.563453 Training acc= 0.767960 Val acc= 0.767135\n",
            "Epoch 418: Training loss= 0.535285 Val loss= 0.563219 Training acc= 0.767965 Val acc= 0.767165\n",
            "Epoch 419: Training loss= 0.535086 Val loss= 0.562986 Training acc= 0.767980 Val acc= 0.767205\n",
            "Epoch 420: Training loss= 0.534889 Val loss= 0.562754 Training acc= 0.768005 Val acc= 0.767230\n",
            "Epoch 421: Training loss= 0.534692 Val loss= 0.562523 Training acc= 0.768050 Val acc= 0.767295\n",
            "Epoch 422: Training loss= 0.534496 Val loss= 0.562294 Training acc= 0.768120 Val acc= 0.767310\n",
            "Epoch 423: Training loss= 0.534301 Val loss= 0.562065 Training acc= 0.768150 Val acc= 0.767410\n",
            "Epoch 424: Training loss= 0.534107 Val loss= 0.561837 Training acc= 0.768295 Val acc= 0.767475\n",
            "Epoch 425: Training loss= 0.533914 Val loss= 0.561611 Training acc= 0.768340 Val acc= 0.767540\n",
            "Epoch 426: Training loss= 0.533722 Val loss= 0.561385 Training acc= 0.768400 Val acc= 0.767585\n",
            "Epoch 427: Training loss= 0.533531 Val loss= 0.561161 Training acc= 0.768495 Val acc= 0.767610\n",
            "Epoch 428: Training loss= 0.533341 Val loss= 0.560937 Training acc= 0.768505 Val acc= 0.767630\n",
            "Epoch 429: Training loss= 0.533152 Val loss= 0.560715 Training acc= 0.768545 Val acc= 0.767660\n",
            "Epoch 430: Training loss= 0.532964 Val loss= 0.560493 Training acc= 0.768590 Val acc= 0.767645\n",
            "Epoch 431: Training loss= 0.532776 Val loss= 0.560273 Training acc= 0.768580 Val acc= 0.767720\n",
            "Epoch 432: Training loss= 0.532590 Val loss= 0.560053 Training acc= 0.768645 Val acc= 0.767760\n",
            "Epoch 433: Training loss= 0.532405 Val loss= 0.559835 Training acc= 0.768695 Val acc= 0.767780\n",
            "Epoch 434: Training loss= 0.532220 Val loss= 0.559618 Training acc= 0.768705 Val acc= 0.767835\n",
            "Epoch 435: Training loss= 0.532037 Val loss= 0.559401 Training acc= 0.768780 Val acc= 0.767905\n",
            "Epoch 436: Training loss= 0.531854 Val loss= 0.559186 Training acc= 0.768835 Val acc= 0.767905\n",
            "Epoch 437: Training loss= 0.531672 Val loss= 0.558972 Training acc= 0.768845 Val acc= 0.767975\n",
            "Epoch 438: Training loss= 0.531491 Val loss= 0.558758 Training acc= 0.768865 Val acc= 0.767995\n",
            "Epoch 439: Training loss= 0.531311 Val loss= 0.558546 Training acc= 0.768900 Val acc= 0.768065\n",
            "Epoch 440: Training loss= 0.531132 Val loss= 0.558334 Training acc= 0.769025 Val acc= 0.768055\n",
            "Epoch 441: Training loss= 0.530954 Val loss= 0.558124 Training acc= 0.769065 Val acc= 0.768090\n",
            "Epoch 442: Training loss= 0.530776 Val loss= 0.557914 Training acc= 0.769100 Val acc= 0.768100\n",
            "Epoch 443: Training loss= 0.530600 Val loss= 0.557705 Training acc= 0.769150 Val acc= 0.768150\n",
            "Epoch 444: Training loss= 0.530424 Val loss= 0.557497 Training acc= 0.769195 Val acc= 0.768070\n",
            "Epoch 445: Training loss= 0.530249 Val loss= 0.557291 Training acc= 0.769155 Val acc= 0.768125\n",
            "Epoch 446: Training loss= 0.530075 Val loss= 0.557084 Training acc= 0.769240 Val acc= 0.768225\n",
            "Epoch 447: Training loss= 0.529902 Val loss= 0.556879 Training acc= 0.769310 Val acc= 0.768245\n",
            "Epoch 448: Training loss= 0.529729 Val loss= 0.556675 Training acc= 0.769355 Val acc= 0.768245\n",
            "Epoch 449: Training loss= 0.529558 Val loss= 0.556471 Training acc= 0.769380 Val acc= 0.768335\n",
            "Epoch 450: Training loss= 0.529387 Val loss= 0.556269 Training acc= 0.769480 Val acc= 0.768415\n",
            "Epoch 451: Training loss= 0.529216 Val loss= 0.556067 Training acc= 0.769550 Val acc= 0.768480\n",
            "Epoch 452: Training loss= 0.529047 Val loss= 0.555866 Training acc= 0.769595 Val acc= 0.768520\n",
            "Epoch 453: Training loss= 0.528878 Val loss= 0.555666 Training acc= 0.769635 Val acc= 0.768515\n",
            "Epoch 454: Training loss= 0.528710 Val loss= 0.555466 Training acc= 0.769655 Val acc= 0.768520\n",
            "Epoch 455: Training loss= 0.528543 Val loss= 0.555268 Training acc= 0.769680 Val acc= 0.768480\n",
            "Epoch 456: Training loss= 0.528376 Val loss= 0.555070 Training acc= 0.769645 Val acc= 0.768505\n",
            "Epoch 457: Training loss= 0.528211 Val loss= 0.554873 Training acc= 0.769680 Val acc= 0.768560\n",
            "Epoch 458: Training loss= 0.528046 Val loss= 0.554676 Training acc= 0.769760 Val acc= 0.768570\n",
            "Epoch 459: Training loss= 0.527881 Val loss= 0.554481 Training acc= 0.769755 Val acc= 0.768680\n",
            "Epoch 460: Training loss= 0.527717 Val loss= 0.554286 Training acc= 0.769820 Val acc= 0.768765\n",
            "Epoch 461: Training loss= 0.527554 Val loss= 0.554092 Training acc= 0.769910 Val acc= 0.768840\n",
            "Epoch 462: Training loss= 0.527392 Val loss= 0.553899 Training acc= 0.769970 Val acc= 0.768925\n",
            "Epoch 463: Training loss= 0.527230 Val loss= 0.553706 Training acc= 0.770055 Val acc= 0.768945\n",
            "Epoch 464: Training loss= 0.527069 Val loss= 0.553514 Training acc= 0.770040 Val acc= 0.768925\n",
            "Epoch 465: Training loss= 0.526909 Val loss= 0.553323 Training acc= 0.770025 Val acc= 0.768990\n",
            "Epoch 466: Training loss= 0.526749 Val loss= 0.553133 Training acc= 0.770100 Val acc= 0.769095\n",
            "Epoch 467: Training loss= 0.526590 Val loss= 0.552943 Training acc= 0.770175 Val acc= 0.769090\n",
            "Epoch 468: Training loss= 0.526432 Val loss= 0.552754 Training acc= 0.770195 Val acc= 0.769130\n",
            "Epoch 469: Training loss= 0.526274 Val loss= 0.552566 Training acc= 0.770240 Val acc= 0.769180\n",
            "Epoch 470: Training loss= 0.526117 Val loss= 0.552378 Training acc= 0.770305 Val acc= 0.769185\n",
            "Epoch 471: Training loss= 0.525960 Val loss= 0.552191 Training acc= 0.770335 Val acc= 0.769260\n",
            "Epoch 472: Training loss= 0.525804 Val loss= 0.552004 Training acc= 0.770400 Val acc= 0.769285\n",
            "Epoch 473: Training loss= 0.525648 Val loss= 0.551819 Training acc= 0.770440 Val acc= 0.769350\n",
            "Epoch 474: Training loss= 0.525494 Val loss= 0.551633 Training acc= 0.770505 Val acc= 0.769430\n",
            "Epoch 475: Training loss= 0.525339 Val loss= 0.551449 Training acc= 0.770555 Val acc= 0.769455\n",
            "Epoch 476: Training loss= 0.525186 Val loss= 0.551265 Training acc= 0.770565 Val acc= 0.769515\n",
            "Epoch 477: Training loss= 0.525032 Val loss= 0.551082 Training acc= 0.770580 Val acc= 0.769555\n",
            "Epoch 478: Training loss= 0.524880 Val loss= 0.550899 Training acc= 0.770605 Val acc= 0.769640\n",
            "Epoch 479: Training loss= 0.524728 Val loss= 0.550717 Training acc= 0.770670 Val acc= 0.769695\n",
            "Epoch 480: Training loss= 0.524576 Val loss= 0.550535 Training acc= 0.770720 Val acc= 0.769725\n",
            "Epoch 481: Training loss= 0.524425 Val loss= 0.550354 Training acc= 0.770750 Val acc= 0.769770\n",
            "Epoch 482: Training loss= 0.524274 Val loss= 0.550174 Training acc= 0.770845 Val acc= 0.769800\n",
            "Epoch 483: Training loss= 0.524124 Val loss= 0.549994 Training acc= 0.770855 Val acc= 0.769850\n",
            "Epoch 484: Training loss= 0.523975 Val loss= 0.549815 Training acc= 0.770920 Val acc= 0.769940\n",
            "Epoch 485: Training loss= 0.523826 Val loss= 0.549636 Training acc= 0.770990 Val acc= 0.770015\n",
            "Epoch 486: Training loss= 0.523677 Val loss= 0.549458 Training acc= 0.771050 Val acc= 0.770060\n",
            "Epoch 487: Training loss= 0.523530 Val loss= 0.549280 Training acc= 0.771090 Val acc= 0.770085\n",
            "Epoch 488: Training loss= 0.523382 Val loss= 0.549103 Training acc= 0.771110 Val acc= 0.770130\n",
            "Epoch 489: Training loss= 0.523235 Val loss= 0.548926 Training acc= 0.771140 Val acc= 0.770175\n",
            "Epoch 490: Training loss= 0.523089 Val loss= 0.548750 Training acc= 0.771215 Val acc= 0.770180\n",
            "Epoch 491: Training loss= 0.522943 Val loss= 0.548575 Training acc= 0.771210 Val acc= 0.770215\n",
            "Epoch 492: Training loss= 0.522797 Val loss= 0.548400 Training acc= 0.771260 Val acc= 0.770275\n",
            "Epoch 493: Training loss= 0.522652 Val loss= 0.548226 Training acc= 0.771325 Val acc= 0.770315\n",
            "Epoch 494: Training loss= 0.522507 Val loss= 0.548052 Training acc= 0.771385 Val acc= 0.770335\n",
            "Epoch 495: Training loss= 0.522363 Val loss= 0.547878 Training acc= 0.771415 Val acc= 0.770380\n",
            "Epoch 496: Training loss= 0.522220 Val loss= 0.547706 Training acc= 0.771465 Val acc= 0.770415\n",
            "Epoch 497: Training loss= 0.522077 Val loss= 0.547533 Training acc= 0.771485 Val acc= 0.770465\n",
            "Epoch 498: Training loss= 0.521934 Val loss= 0.547361 Training acc= 0.771500 Val acc= 0.770450\n",
            "Epoch 499: Training loss= 0.521792 Val loss= 0.547190 Training acc= 0.771485 Val acc= 0.770540\n",
            "Epoch 500: Training loss= 0.521650 Val loss= 0.547019 Training acc= 0.771545 Val acc= 0.770545\n",
            "Epoch 501: Training loss= 0.521509 Val loss= 0.546849 Training acc= 0.771565 Val acc= 0.770560\n",
            "Epoch 502: Training loss= 0.521368 Val loss= 0.546679 Training acc= 0.771555 Val acc= 0.770585\n",
            "Epoch 503: Training loss= 0.521228 Val loss= 0.546510 Training acc= 0.771600 Val acc= 0.770610\n",
            "Epoch 504: Training loss= 0.521088 Val loss= 0.546341 Training acc= 0.771660 Val acc= 0.770630\n",
            "Epoch 505: Training loss= 0.520948 Val loss= 0.546173 Training acc= 0.771720 Val acc= 0.770660\n",
            "Epoch 506: Training loss= 0.520809 Val loss= 0.546006 Training acc= 0.771780 Val acc= 0.770700\n",
            "Epoch 507: Training loss= 0.520671 Val loss= 0.545838 Training acc= 0.771825 Val acc= 0.770765\n",
            "Epoch 508: Training loss= 0.520533 Val loss= 0.545672 Training acc= 0.771885 Val acc= 0.770780\n",
            "Epoch 509: Training loss= 0.520395 Val loss= 0.545505 Training acc= 0.771870 Val acc= 0.770805\n",
            "Epoch 510: Training loss= 0.520258 Val loss= 0.545340 Training acc= 0.771900 Val acc= 0.770825\n",
            "Epoch 511: Training loss= 0.520121 Val loss= 0.545175 Training acc= 0.771900 Val acc= 0.770830\n",
            "Epoch 512: Training loss= 0.519985 Val loss= 0.545010 Training acc= 0.771915 Val acc= 0.770860\n",
            "Epoch 513: Training loss= 0.519849 Val loss= 0.544846 Training acc= 0.771965 Val acc= 0.770915\n",
            "Epoch 514: Training loss= 0.519713 Val loss= 0.544682 Training acc= 0.772010 Val acc= 0.770935\n",
            "Epoch 515: Training loss= 0.519578 Val loss= 0.544518 Training acc= 0.772020 Val acc= 0.770985\n",
            "Epoch 516: Training loss= 0.519444 Val loss= 0.544356 Training acc= 0.772040 Val acc= 0.771030\n",
            "Epoch 517: Training loss= 0.519310 Val loss= 0.544193 Training acc= 0.772080 Val acc= 0.771110\n",
            "Epoch 518: Training loss= 0.519176 Val loss= 0.544031 Training acc= 0.772130 Val acc= 0.771170\n",
            "Epoch 519: Training loss= 0.519042 Val loss= 0.543870 Training acc= 0.772165 Val acc= 0.771155\n",
            "Epoch 520: Training loss= 0.518910 Val loss= 0.543709 Training acc= 0.772175 Val acc= 0.771190\n",
            "Epoch 521: Training loss= 0.518777 Val loss= 0.543548 Training acc= 0.772180 Val acc= 0.771215\n",
            "Epoch 522: Training loss= 0.518645 Val loss= 0.543388 Training acc= 0.772220 Val acc= 0.771235\n",
            "Epoch 523: Training loss= 0.518513 Val loss= 0.543229 Training acc= 0.772250 Val acc= 0.771250\n",
            "Epoch 524: Training loss= 0.518382 Val loss= 0.543069 Training acc= 0.772265 Val acc= 0.771270\n",
            "Epoch 525: Training loss= 0.518251 Val loss= 0.542911 Training acc= 0.772310 Val acc= 0.771325\n",
            "Epoch 526: Training loss= 0.518120 Val loss= 0.542752 Training acc= 0.772375 Val acc= 0.771395\n",
            "Epoch 527: Training loss= 0.517990 Val loss= 0.542594 Training acc= 0.772420 Val acc= 0.771435\n",
            "Epoch 528: Training loss= 0.517860 Val loss= 0.542437 Training acc= 0.772470 Val acc= 0.771475\n",
            "Epoch 529: Training loss= 0.517730 Val loss= 0.542280 Training acc= 0.772510 Val acc= 0.771505\n",
            "Epoch 530: Training loss= 0.517601 Val loss= 0.542123 Training acc= 0.772540 Val acc= 0.771565\n",
            "Epoch 531: Training loss= 0.517473 Val loss= 0.541967 Training acc= 0.772585 Val acc= 0.771615\n",
            "Epoch 532: Training loss= 0.517344 Val loss= 0.541811 Training acc= 0.772615 Val acc= 0.771635\n",
            "Epoch 533: Training loss= 0.517216 Val loss= 0.541656 Training acc= 0.772650 Val acc= 0.771660\n",
            "Epoch 534: Training loss= 0.517089 Val loss= 0.541501 Training acc= 0.772680 Val acc= 0.771700\n",
            "Epoch 535: Training loss= 0.516961 Val loss= 0.541346 Training acc= 0.772695 Val acc= 0.771690\n",
            "Epoch 536: Training loss= 0.516834 Val loss= 0.541192 Training acc= 0.772690 Val acc= 0.771685\n",
            "Epoch 537: Training loss= 0.516708 Val loss= 0.541038 Training acc= 0.772680 Val acc= 0.771720\n",
            "Epoch 538: Training loss= 0.516582 Val loss= 0.540885 Training acc= 0.772730 Val acc= 0.771740\n",
            "Epoch 539: Training loss= 0.516456 Val loss= 0.540732 Training acc= 0.772770 Val acc= 0.771740\n",
            "Epoch 540: Training loss= 0.516330 Val loss= 0.540580 Training acc= 0.772755 Val acc= 0.771735\n",
            "Epoch 541: Training loss= 0.516205 Val loss= 0.540428 Training acc= 0.772770 Val acc= 0.771690\n",
            "Epoch 542: Training loss= 0.516081 Val loss= 0.540276 Training acc= 0.772755 Val acc= 0.771725\n",
            "Epoch 543: Training loss= 0.515956 Val loss= 0.540125 Training acc= 0.772770 Val acc= 0.771735\n",
            "Epoch 544: Training loss= 0.515832 Val loss= 0.539974 Training acc= 0.772805 Val acc= 0.771755\n",
            "Epoch 545: Training loss= 0.515708 Val loss= 0.539823 Training acc= 0.772825 Val acc= 0.771775\n",
            "Epoch 546: Training loss= 0.515585 Val loss= 0.539673 Training acc= 0.772835 Val acc= 0.771835\n",
            "Epoch 547: Training loss= 0.515462 Val loss= 0.539524 Training acc= 0.772870 Val acc= 0.771880\n",
            "Epoch 548: Training loss= 0.515339 Val loss= 0.539374 Training acc= 0.772890 Val acc= 0.771925\n",
            "Epoch 549: Training loss= 0.515217 Val loss= 0.539226 Training acc= 0.772915 Val acc= 0.771975\n",
            "Epoch 550: Training loss= 0.515095 Val loss= 0.539077 Training acc= 0.772935 Val acc= 0.771930\n",
            "Epoch 551: Training loss= 0.514973 Val loss= 0.538929 Training acc= 0.772890 Val acc= 0.771945\n",
            "Epoch 552: Training loss= 0.514852 Val loss= 0.538781 Training acc= 0.772900 Val acc= 0.771955\n",
            "Epoch 553: Training loss= 0.514731 Val loss= 0.538634 Training acc= 0.772910 Val acc= 0.771970\n",
            "Epoch 554: Training loss= 0.514610 Val loss= 0.538487 Training acc= 0.772935 Val acc= 0.772040\n",
            "Epoch 555: Training loss= 0.514490 Val loss= 0.538341 Training acc= 0.773005 Val acc= 0.772085\n",
            "Epoch 556: Training loss= 0.514370 Val loss= 0.538195 Training acc= 0.773035 Val acc= 0.772075\n",
            "Epoch 557: Training loss= 0.514250 Val loss= 0.538049 Training acc= 0.773035 Val acc= 0.772075\n",
            "Epoch 558: Training loss= 0.514131 Val loss= 0.537904 Training acc= 0.773045 Val acc= 0.772105\n",
            "Epoch 559: Training loss= 0.514012 Val loss= 0.537759 Training acc= 0.773095 Val acc= 0.772115\n",
            "Epoch 560: Training loss= 0.513894 Val loss= 0.537615 Training acc= 0.773090 Val acc= 0.772180\n",
            "Epoch 561: Training loss= 0.513775 Val loss= 0.537471 Training acc= 0.773150 Val acc= 0.772155\n",
            "Epoch 562: Training loss= 0.513657 Val loss= 0.537327 Training acc= 0.773170 Val acc= 0.772185\n",
            "Epoch 563: Training loss= 0.513540 Val loss= 0.537184 Training acc= 0.773225 Val acc= 0.772240\n",
            "Epoch 564: Training loss= 0.513422 Val loss= 0.537041 Training acc= 0.773250 Val acc= 0.772230\n",
            "Epoch 565: Training loss= 0.513306 Val loss= 0.536899 Training acc= 0.773250 Val acc= 0.772290\n",
            "Epoch 566: Training loss= 0.513189 Val loss= 0.536757 Training acc= 0.773300 Val acc= 0.772305\n",
            "Epoch 567: Training loss= 0.513073 Val loss= 0.536616 Training acc= 0.773320 Val acc= 0.772370\n",
            "Epoch 568: Training loss= 0.512957 Val loss= 0.536475 Training acc= 0.773360 Val acc= 0.772410\n",
            "Epoch 569: Training loss= 0.512842 Val loss= 0.536334 Training acc= 0.773395 Val acc= 0.772415\n",
            "Epoch 570: Training loss= 0.512726 Val loss= 0.536194 Training acc= 0.773415 Val acc= 0.772485\n",
            "Epoch 571: Training loss= 0.512612 Val loss= 0.536055 Training acc= 0.773480 Val acc= 0.772510\n",
            "Epoch 572: Training loss= 0.512497 Val loss= 0.535916 Training acc= 0.773530 Val acc= 0.772515\n",
            "Epoch 573: Training loss= 0.512383 Val loss= 0.535777 Training acc= 0.773540 Val acc= 0.772565\n",
            "Epoch 574: Training loss= 0.512270 Val loss= 0.535639 Training acc= 0.773580 Val acc= 0.772595\n",
            "Epoch 575: Training loss= 0.512156 Val loss= 0.535501 Training acc= 0.773580 Val acc= 0.772625\n",
            "Epoch 576: Training loss= 0.512043 Val loss= 0.535363 Training acc= 0.773610 Val acc= 0.772665\n",
            "Epoch 577: Training loss= 0.511931 Val loss= 0.535226 Training acc= 0.773630 Val acc= 0.772650\n",
            "Epoch 578: Training loss= 0.511818 Val loss= 0.535090 Training acc= 0.773615 Val acc= 0.772700\n",
            "Epoch 579: Training loss= 0.511706 Val loss= 0.534953 Training acc= 0.773675 Val acc= 0.772710\n",
            "Epoch 580: Training loss= 0.511595 Val loss= 0.534817 Training acc= 0.773705 Val acc= 0.772665\n",
            "Epoch 581: Training loss= 0.511483 Val loss= 0.534682 Training acc= 0.773685 Val acc= 0.772700\n",
            "Epoch 582: Training loss= 0.511372 Val loss= 0.534547 Training acc= 0.773745 Val acc= 0.772730\n",
            "Epoch 583: Training loss= 0.511262 Val loss= 0.534412 Training acc= 0.773790 Val acc= 0.772760\n",
            "Epoch 584: Training loss= 0.511151 Val loss= 0.534278 Training acc= 0.773785 Val acc= 0.772785\n",
            "Epoch 585: Training loss= 0.511041 Val loss= 0.534144 Training acc= 0.773825 Val acc= 0.772805\n",
            "Epoch 586: Training loss= 0.510931 Val loss= 0.534010 Training acc= 0.773880 Val acc= 0.772830\n",
            "Epoch 587: Training loss= 0.510822 Val loss= 0.533876 Training acc= 0.773925 Val acc= 0.772845\n",
            "Epoch 588: Training loss= 0.510712 Val loss= 0.533743 Training acc= 0.773965 Val acc= 0.772875\n",
            "Epoch 589: Training loss= 0.510603 Val loss= 0.533611 Training acc= 0.774015 Val acc= 0.772925\n",
            "Epoch 590: Training loss= 0.510495 Val loss= 0.533478 Training acc= 0.774040 Val acc= 0.772935\n",
            "Epoch 591: Training loss= 0.510386 Val loss= 0.533346 Training acc= 0.774040 Val acc= 0.772965\n",
            "Epoch 592: Training loss= 0.510278 Val loss= 0.533214 Training acc= 0.774060 Val acc= 0.772960\n",
            "Epoch 593: Training loss= 0.510170 Val loss= 0.533082 Training acc= 0.774055 Val acc= 0.772995\n",
            "Epoch 594: Training loss= 0.510062 Val loss= 0.532951 Training acc= 0.774090 Val acc= 0.773035\n",
            "Epoch 595: Training loss= 0.509955 Val loss= 0.532820 Training acc= 0.774135 Val acc= 0.773060\n",
            "Epoch 596: Training loss= 0.509848 Val loss= 0.532690 Training acc= 0.774155 Val acc= 0.773090\n",
            "Epoch 597: Training loss= 0.509741 Val loss= 0.532559 Training acc= 0.774170 Val acc= 0.773100\n",
            "Epoch 598: Training loss= 0.509634 Val loss= 0.532429 Training acc= 0.774175 Val acc= 0.773125\n",
            "Epoch 599: Training loss= 0.509528 Val loss= 0.532299 Training acc= 0.774195 Val acc= 0.773130\n",
            "Epoch 600: Training loss= 0.509421 Val loss= 0.532170 Training acc= 0.774195 Val acc= 0.773190\n",
            "Epoch 601: Training loss= 0.509315 Val loss= 0.532040 Training acc= 0.774235 Val acc= 0.773225\n",
            "Epoch 602: Training loss= 0.509210 Val loss= 0.531911 Training acc= 0.774270 Val acc= 0.773240\n",
            "Epoch 603: Training loss= 0.509104 Val loss= 0.531782 Training acc= 0.774310 Val acc= 0.773280\n",
            "Epoch 604: Training loss= 0.508999 Val loss= 0.531654 Training acc= 0.774300 Val acc= 0.773295\n",
            "Epoch 605: Training loss= 0.508894 Val loss= 0.531526 Training acc= 0.774330 Val acc= 0.773300\n",
            "Epoch 606: Training loss= 0.508789 Val loss= 0.531398 Training acc= 0.774320 Val acc= 0.773345\n",
            "Epoch 607: Training loss= 0.508685 Val loss= 0.531270 Training acc= 0.774355 Val acc= 0.773365\n",
            "Epoch 608: Training loss= 0.508580 Val loss= 0.531143 Training acc= 0.774345 Val acc= 0.773410\n",
            "Epoch 609: Training loss= 0.508476 Val loss= 0.531015 Training acc= 0.774395 Val acc= 0.773445\n",
            "Epoch 610: Training loss= 0.508372 Val loss= 0.530889 Training acc= 0.774415 Val acc= 0.773450\n",
            "Epoch 611: Training loss= 0.508269 Val loss= 0.530762 Training acc= 0.774415 Val acc= 0.773445\n",
            "Epoch 612: Training loss= 0.508165 Val loss= 0.530635 Training acc= 0.774400 Val acc= 0.773490\n",
            "Epoch 613: Training loss= 0.508062 Val loss= 0.530509 Training acc= 0.774430 Val acc= 0.773525\n",
            "Epoch 614: Training loss= 0.507959 Val loss= 0.530383 Training acc= 0.774470 Val acc= 0.773565\n",
            "Epoch 615: Training loss= 0.507857 Val loss= 0.530258 Training acc= 0.774490 Val acc= 0.773610\n",
            "Epoch 616: Training loss= 0.507754 Val loss= 0.530132 Training acc= 0.774530 Val acc= 0.773645\n",
            "Epoch 617: Training loss= 0.507652 Val loss= 0.530007 Training acc= 0.774540 Val acc= 0.773705\n",
            "Epoch 618: Training loss= 0.507550 Val loss= 0.529882 Training acc= 0.774595 Val acc= 0.773740\n",
            "Epoch 619: Training loss= 0.507448 Val loss= 0.529758 Training acc= 0.774640 Val acc= 0.773730\n",
            "Epoch 620: Training loss= 0.507346 Val loss= 0.529633 Training acc= 0.774635 Val acc= 0.773750\n",
            "Epoch 621: Training loss= 0.507245 Val loss= 0.529509 Training acc= 0.774655 Val acc= 0.773795\n",
            "Epoch 622: Training loss= 0.507144 Val loss= 0.529385 Training acc= 0.774700 Val acc= 0.773880\n",
            "Epoch 623: Training loss= 0.507043 Val loss= 0.529262 Training acc= 0.774760 Val acc= 0.773935\n",
            "Epoch 624: Training loss= 0.506942 Val loss= 0.529138 Training acc= 0.774815 Val acc= 0.773975\n",
            "Epoch 625: Training loss= 0.506841 Val loss= 0.529015 Training acc= 0.774850 Val acc= 0.773970\n",
            "Epoch 626: Training loss= 0.506741 Val loss= 0.528892 Training acc= 0.774840 Val acc= 0.773980\n",
            "Epoch 627: Training loss= 0.506641 Val loss= 0.528770 Training acc= 0.774865 Val acc= 0.774000\n",
            "Epoch 628: Training loss= 0.506541 Val loss= 0.528647 Training acc= 0.774895 Val acc= 0.774025\n",
            "Epoch 629: Training loss= 0.506441 Val loss= 0.528525 Training acc= 0.774915 Val acc= 0.774065\n",
            "Epoch 630: Training loss= 0.506342 Val loss= 0.528403 Training acc= 0.774940 Val acc= 0.774045\n",
            "Epoch 631: Training loss= 0.506243 Val loss= 0.528281 Training acc= 0.774910 Val acc= 0.774095\n",
            "Epoch 632: Training loss= 0.506144 Val loss= 0.528160 Training acc= 0.774975 Val acc= 0.774115\n",
            "Epoch 633: Training loss= 0.506045 Val loss= 0.528039 Training acc= 0.774995 Val acc= 0.774130\n",
            "Epoch 634: Training loss= 0.505947 Val loss= 0.527918 Training acc= 0.775010 Val acc= 0.774115\n",
            "Epoch 635: Training loss= 0.505848 Val loss= 0.527797 Training acc= 0.774990 Val acc= 0.774145\n",
            "Epoch 636: Training loss= 0.505750 Val loss= 0.527677 Training acc= 0.775015 Val acc= 0.774175\n",
            "Epoch 637: Training loss= 0.505652 Val loss= 0.527557 Training acc= 0.775055 Val acc= 0.774205\n",
            "Epoch 638: Training loss= 0.505554 Val loss= 0.527437 Training acc= 0.775060 Val acc= 0.774270\n",
            "Epoch 639: Training loss= 0.505457 Val loss= 0.527317 Training acc= 0.775125 Val acc= 0.774280\n",
            "Epoch 640: Training loss= 0.505360 Val loss= 0.527198 Training acc= 0.775150 Val acc= 0.774320\n",
            "Epoch 641: Training loss= 0.505263 Val loss= 0.527078 Training acc= 0.775160 Val acc= 0.774370\n",
            "Epoch 642: Training loss= 0.505166 Val loss= 0.526959 Training acc= 0.775210 Val acc= 0.774385\n",
            "Epoch 643: Training loss= 0.505069 Val loss= 0.526841 Training acc= 0.775210 Val acc= 0.774405\n",
            "Epoch 644: Training loss= 0.504973 Val loss= 0.526722 Training acc= 0.775225 Val acc= 0.774455\n",
            "Epoch 645: Training loss= 0.504877 Val loss= 0.526604 Training acc= 0.775235 Val acc= 0.774500\n",
            "Epoch 646: Training loss= 0.504780 Val loss= 0.526486 Training acc= 0.775260 Val acc= 0.774480\n",
            "Epoch 647: Training loss= 0.504685 Val loss= 0.526369 Training acc= 0.775270 Val acc= 0.774485\n",
            "Epoch 648: Training loss= 0.504589 Val loss= 0.526251 Training acc= 0.775250 Val acc= 0.774515\n",
            "Epoch 649: Training loss= 0.504494 Val loss= 0.526134 Training acc= 0.775265 Val acc= 0.774540\n",
            "Epoch 650: Training loss= 0.504399 Val loss= 0.526017 Training acc= 0.775280 Val acc= 0.774515\n",
            "Epoch 651: Training loss= 0.504304 Val loss= 0.525900 Training acc= 0.775270 Val acc= 0.774570\n",
            "Epoch 652: Training loss= 0.504209 Val loss= 0.525784 Training acc= 0.775315 Val acc= 0.774560\n",
            "Epoch 653: Training loss= 0.504114 Val loss= 0.525668 Training acc= 0.775315 Val acc= 0.774575\n",
            "Epoch 654: Training loss= 0.504020 Val loss= 0.525552 Training acc= 0.775330 Val acc= 0.774590\n",
            "Epoch 655: Training loss= 0.503926 Val loss= 0.525436 Training acc= 0.775360 Val acc= 0.774610\n",
            "Epoch 656: Training loss= 0.503831 Val loss= 0.525321 Training acc= 0.775390 Val acc= 0.774620\n",
            "Epoch 657: Training loss= 0.503738 Val loss= 0.525206 Training acc= 0.775380 Val acc= 0.774660\n",
            "Epoch 658: Training loss= 0.503644 Val loss= 0.525091 Training acc= 0.775415 Val acc= 0.774655\n",
            "Epoch 659: Training loss= 0.503551 Val loss= 0.524976 Training acc= 0.775385 Val acc= 0.774680\n",
            "Epoch 660: Training loss= 0.503457 Val loss= 0.524862 Training acc= 0.775425 Val acc= 0.774710\n",
            "Epoch 661: Training loss= 0.503364 Val loss= 0.524747 Training acc= 0.775465 Val acc= 0.774755\n",
            "Epoch 662: Training loss= 0.503271 Val loss= 0.524633 Training acc= 0.775515 Val acc= 0.774795\n",
            "Epoch 663: Training loss= 0.503179 Val loss= 0.524520 Training acc= 0.775545 Val acc= 0.774815\n",
            "Epoch 664: Training loss= 0.503086 Val loss= 0.524406 Training acc= 0.775545 Val acc= 0.774870\n",
            "Epoch 665: Training loss= 0.502994 Val loss= 0.524293 Training acc= 0.775565 Val acc= 0.774880\n",
            "Epoch 666: Training loss= 0.502901 Val loss= 0.524180 Training acc= 0.775570 Val acc= 0.774925\n",
            "Epoch 667: Training loss= 0.502809 Val loss= 0.524067 Training acc= 0.775600 Val acc= 0.774930\n",
            "Epoch 668: Training loss= 0.502718 Val loss= 0.523955 Training acc= 0.775605 Val acc= 0.774960\n",
            "Epoch 669: Training loss= 0.502626 Val loss= 0.523842 Training acc= 0.775645 Val acc= 0.774960\n",
            "Epoch 670: Training loss= 0.502534 Val loss= 0.523730 Training acc= 0.775675 Val acc= 0.774970\n",
            "Epoch 671: Training loss= 0.502443 Val loss= 0.523618 Training acc= 0.775685 Val acc= 0.774985\n",
            "Epoch 672: Training loss= 0.502352 Val loss= 0.523507 Training acc= 0.775690 Val acc= 0.775005\n",
            "Epoch 673: Training loss= 0.502261 Val loss= 0.523395 Training acc= 0.775740 Val acc= 0.775005\n",
            "Epoch 674: Training loss= 0.502170 Val loss= 0.523284 Training acc= 0.775750 Val acc= 0.775020\n",
            "Epoch 675: Training loss= 0.502079 Val loss= 0.523173 Training acc= 0.775765 Val acc= 0.775040\n",
            "Epoch 676: Training loss= 0.501989 Val loss= 0.523062 Training acc= 0.775770 Val acc= 0.775015\n",
            "Epoch 677: Training loss= 0.501898 Val loss= 0.522951 Training acc= 0.775760 Val acc= 0.775015\n",
            "Epoch 678: Training loss= 0.501808 Val loss= 0.522841 Training acc= 0.775760 Val acc= 0.775035\n",
            "Epoch 679: Training loss= 0.501718 Val loss= 0.522731 Training acc= 0.775770 Val acc= 0.775075\n",
            "Epoch 680: Training loss= 0.501628 Val loss= 0.522621 Training acc= 0.775785 Val acc= 0.775085\n",
            "Epoch 681: Training loss= 0.501538 Val loss= 0.522511 Training acc= 0.775815 Val acc= 0.775070\n",
            "Epoch 682: Training loss= 0.501449 Val loss= 0.522401 Training acc= 0.775810 Val acc= 0.775055\n",
            "Epoch 683: Training loss= 0.501359 Val loss= 0.522292 Training acc= 0.775830 Val acc= 0.775125\n",
            "Epoch 684: Training loss= 0.501270 Val loss= 0.522183 Training acc= 0.775890 Val acc= 0.775135\n",
            "Epoch 685: Training loss= 0.501181 Val loss= 0.522074 Training acc= 0.775920 Val acc= 0.775175\n",
            "Epoch 686: Training loss= 0.501092 Val loss= 0.521965 Training acc= 0.775965 Val acc= 0.775230\n",
            "Epoch 687: Training loss= 0.501003 Val loss= 0.521856 Training acc= 0.776025 Val acc= 0.775255\n",
            "Epoch 688: Training loss= 0.500914 Val loss= 0.521748 Training acc= 0.776030 Val acc= 0.775255\n",
            "Epoch 689: Training loss= 0.500826 Val loss= 0.521640 Training acc= 0.776065 Val acc= 0.775300\n",
            "Epoch 690: Training loss= 0.500737 Val loss= 0.521533 Training acc= 0.776085 Val acc= 0.775315\n",
            "Epoch 691: Training loss= 0.500649 Val loss= 0.521425 Training acc= 0.776135 Val acc= 0.775300\n",
            "Epoch 692: Training loss= 0.500561 Val loss= 0.521318 Training acc= 0.776125 Val acc= 0.775335\n",
            "Epoch 693: Training loss= 0.500473 Val loss= 0.521211 Training acc= 0.776150 Val acc= 0.775350\n",
            "Epoch 694: Training loss= 0.500385 Val loss= 0.521105 Training acc= 0.776175 Val acc= 0.775365\n",
            "Epoch 695: Training loss= 0.500298 Val loss= 0.520999 Training acc= 0.776180 Val acc= 0.775380\n",
            "Epoch 696: Training loss= 0.500210 Val loss= 0.520893 Training acc= 0.776200 Val acc= 0.775415\n",
            "Epoch 697: Training loss= 0.500123 Val loss= 0.520787 Training acc= 0.776245 Val acc= 0.775420\n",
            "Epoch 698: Training loss= 0.500036 Val loss= 0.520682 Training acc= 0.776255 Val acc= 0.775465\n",
            "Epoch 699: Training loss= 0.499950 Val loss= 0.520577 Training acc= 0.776300 Val acc= 0.775490\n",
            "Epoch 700: Training loss= 0.499863 Val loss= 0.520473 Training acc= 0.776325 Val acc= 0.775495\n",
            "Epoch 701: Training loss= 0.499777 Val loss= 0.520369 Training acc= 0.776315 Val acc= 0.775520\n",
            "Epoch 702: Training loss= 0.499692 Val loss= 0.520265 Training acc= 0.776335 Val acc= 0.775520\n",
            "Epoch 703: Training loss= 0.499606 Val loss= 0.520162 Training acc= 0.776335 Val acc= 0.775535\n",
            "Epoch 704: Training loss= 0.499522 Val loss= 0.520059 Training acc= 0.776380 Val acc= 0.775560\n",
            "Epoch 705: Training loss= 0.499437 Val loss= 0.519957 Training acc= 0.776410 Val acc= 0.775560\n",
            "Epoch 706: Training loss= 0.499353 Val loss= 0.519854 Training acc= 0.776420 Val acc= 0.775590\n",
            "Epoch 707: Training loss= 0.499269 Val loss= 0.519753 Training acc= 0.776450 Val acc= 0.775625\n",
            "Epoch 708: Training loss= 0.499185 Val loss= 0.519651 Training acc= 0.776485 Val acc= 0.775640\n",
            "Epoch 709: Training loss= 0.499102 Val loss= 0.519550 Training acc= 0.776510 Val acc= 0.775655\n",
            "Epoch 710: Training loss= 0.499019 Val loss= 0.519449 Training acc= 0.776515 Val acc= 0.775665\n",
            "Epoch 711: Training loss= 0.498936 Val loss= 0.519349 Training acc= 0.776535 Val acc= 0.775725\n",
            "Epoch 712: Training loss= 0.498853 Val loss= 0.519248 Training acc= 0.776605 Val acc= 0.775755\n",
            "Epoch 713: Training loss= 0.498771 Val loss= 0.519148 Training acc= 0.776625 Val acc= 0.775785\n",
            "Epoch 714: Training loss= 0.498688 Val loss= 0.519048 Training acc= 0.776655 Val acc= 0.775815\n",
            "Epoch 715: Training loss= 0.498606 Val loss= 0.518948 Training acc= 0.776690 Val acc= 0.775870\n",
            "Epoch 716: Training loss= 0.498524 Val loss= 0.518849 Training acc= 0.776740 Val acc= 0.775890\n",
            "Epoch 717: Training loss= 0.498442 Val loss= 0.518749 Training acc= 0.776770 Val acc= 0.775910\n",
            "Epoch 718: Training loss= 0.498361 Val loss= 0.518650 Training acc= 0.776790 Val acc= 0.775910\n",
            "Epoch 719: Training loss= 0.498279 Val loss= 0.518551 Training acc= 0.776805 Val acc= 0.775920\n",
            "Epoch 720: Training loss= 0.498198 Val loss= 0.518452 Training acc= 0.776825 Val acc= 0.775920\n",
            "Epoch 721: Training loss= 0.498117 Val loss= 0.518354 Training acc= 0.776850 Val acc= 0.775945\n",
            "Epoch 722: Training loss= 0.498036 Val loss= 0.518255 Training acc= 0.776880 Val acc= 0.775980\n",
            "Epoch 723: Training loss= 0.497955 Val loss= 0.518157 Training acc= 0.776900 Val acc= 0.775995\n",
            "Epoch 724: Training loss= 0.497874 Val loss= 0.518059 Training acc= 0.776920 Val acc= 0.775995\n",
            "Epoch 725: Training loss= 0.497794 Val loss= 0.517961 Training acc= 0.776925 Val acc= 0.776025\n",
            "Epoch 726: Training loss= 0.497713 Val loss= 0.517863 Training acc= 0.776970 Val acc= 0.776040\n",
            "Epoch 727: Training loss= 0.497633 Val loss= 0.517766 Training acc= 0.776985 Val acc= 0.776065\n",
            "Epoch 728: Training loss= 0.497553 Val loss= 0.517668 Training acc= 0.776990 Val acc= 0.776080\n",
            "Epoch 729: Training loss= 0.497473 Val loss= 0.517571 Training acc= 0.777020 Val acc= 0.776095\n",
            "Epoch 730: Training loss= 0.497393 Val loss= 0.517474 Training acc= 0.777015 Val acc= 0.776120\n",
            "Epoch 731: Training loss= 0.497314 Val loss= 0.517377 Training acc= 0.777055 Val acc= 0.776085\n",
            "Epoch 732: Training loss= 0.497234 Val loss= 0.517280 Training acc= 0.776995 Val acc= 0.776100\n",
            "Epoch 733: Training loss= 0.497155 Val loss= 0.517184 Training acc= 0.777010 Val acc= 0.776115\n",
            "Epoch 734: Training loss= 0.497075 Val loss= 0.517087 Training acc= 0.777040 Val acc= 0.776130\n",
            "Epoch 735: Training loss= 0.496996 Val loss= 0.516991 Training acc= 0.777045 Val acc= 0.776125\n",
            "Epoch 736: Training loss= 0.496917 Val loss= 0.516895 Training acc= 0.777060 Val acc= 0.776130\n",
            "Epoch 737: Training loss= 0.496839 Val loss= 0.516799 Training acc= 0.777070 Val acc= 0.776165\n",
            "Epoch 738: Training loss= 0.496760 Val loss= 0.516704 Training acc= 0.777100 Val acc= 0.776210\n",
            "Epoch 739: Training loss= 0.496681 Val loss= 0.516608 Training acc= 0.777160 Val acc= 0.776230\n",
            "Epoch 740: Training loss= 0.496603 Val loss= 0.516513 Training acc= 0.777175 Val acc= 0.776265\n",
            "Epoch 741: Training loss= 0.496525 Val loss= 0.516418 Training acc= 0.777205 Val acc= 0.776280\n",
            "Epoch 742: Training loss= 0.496446 Val loss= 0.516323 Training acc= 0.777220 Val acc= 0.776275\n",
            "Epoch 743: Training loss= 0.496369 Val loss= 0.516228 Training acc= 0.777235 Val acc= 0.776300\n",
            "Epoch 744: Training loss= 0.496291 Val loss= 0.516133 Training acc= 0.777275 Val acc= 0.776335\n",
            "Epoch 745: Training loss= 0.496213 Val loss= 0.516039 Training acc= 0.777320 Val acc= 0.776365\n",
            "Epoch 746: Training loss= 0.496135 Val loss= 0.515944 Training acc= 0.777355 Val acc= 0.776375\n",
            "Epoch 747: Training loss= 0.496058 Val loss= 0.515850 Training acc= 0.777365 Val acc= 0.776375\n",
            "Epoch 748: Training loss= 0.495981 Val loss= 0.515756 Training acc= 0.777365 Val acc= 0.776385\n",
            "Epoch 749: Training loss= 0.495903 Val loss= 0.515662 Training acc= 0.777380 Val acc= 0.776395\n",
            "Epoch 750: Training loss= 0.495826 Val loss= 0.515569 Training acc= 0.777405 Val acc= 0.776395\n",
            "Epoch 751: Training loss= 0.495750 Val loss= 0.515475 Training acc= 0.777410 Val acc= 0.776420\n",
            "Epoch 752: Training loss= 0.495673 Val loss= 0.515382 Training acc= 0.777435 Val acc= 0.776425\n",
            "Epoch 753: Training loss= 0.495596 Val loss= 0.515289 Training acc= 0.777425 Val acc= 0.776440\n",
            "Epoch 754: Training loss= 0.495520 Val loss= 0.515195 Training acc= 0.777455 Val acc= 0.776425\n",
            "Epoch 755: Training loss= 0.495443 Val loss= 0.515103 Training acc= 0.777430 Val acc= 0.776420\n",
            "Epoch 756: Training loss= 0.495367 Val loss= 0.515010 Training acc= 0.777415 Val acc= 0.776450\n",
            "Epoch 757: Training loss= 0.495291 Val loss= 0.514917 Training acc= 0.777440 Val acc= 0.776485\n",
            "Epoch 758: Training loss= 0.495215 Val loss= 0.514825 Training acc= 0.777470 Val acc= 0.776495\n",
            "Epoch 759: Training loss= 0.495139 Val loss= 0.514732 Training acc= 0.777505 Val acc= 0.776505\n",
            "Epoch 760: Training loss= 0.495064 Val loss= 0.514640 Training acc= 0.777500 Val acc= 0.776520\n",
            "Epoch 761: Training loss= 0.494988 Val loss= 0.514548 Training acc= 0.777495 Val acc= 0.776520\n",
            "Epoch 762: Training loss= 0.494912 Val loss= 0.514456 Training acc= 0.777510 Val acc= 0.776540\n",
            "Epoch 763: Training loss= 0.494837 Val loss= 0.514364 Training acc= 0.777535 Val acc= 0.776575\n",
            "Epoch 764: Training loss= 0.494762 Val loss= 0.514273 Training acc= 0.777555 Val acc= 0.776605\n",
            "Epoch 765: Training loss= 0.494687 Val loss= 0.514181 Training acc= 0.777565 Val acc= 0.776595\n",
            "Epoch 766: Training loss= 0.494612 Val loss= 0.514090 Training acc= 0.777590 Val acc= 0.776595\n",
            "Epoch 767: Training loss= 0.494537 Val loss= 0.513999 Training acc= 0.777580 Val acc= 0.776605\n",
            "Epoch 768: Training loss= 0.494462 Val loss= 0.513908 Training acc= 0.777615 Val acc= 0.776615\n",
            "Epoch 769: Training loss= 0.494388 Val loss= 0.513817 Training acc= 0.777630 Val acc= 0.776645\n",
            "Epoch 770: Training loss= 0.494313 Val loss= 0.513726 Training acc= 0.777625 Val acc= 0.776670\n",
            "Epoch 771: Training loss= 0.494239 Val loss= 0.513635 Training acc= 0.777660 Val acc= 0.776690\n",
            "Epoch 772: Training loss= 0.494165 Val loss= 0.513545 Training acc= 0.777670 Val acc= 0.776710\n",
            "Epoch 773: Training loss= 0.494090 Val loss= 0.513455 Training acc= 0.777690 Val acc= 0.776710\n",
            "Epoch 774: Training loss= 0.494016 Val loss= 0.513364 Training acc= 0.777690 Val acc= 0.776740\n",
            "Epoch 775: Training loss= 0.493943 Val loss= 0.513274 Training acc= 0.777690 Val acc= 0.776750\n",
            "Epoch 776: Training loss= 0.493869 Val loss= 0.513184 Training acc= 0.777700 Val acc= 0.776820\n",
            "Epoch 777: Training loss= 0.493795 Val loss= 0.513094 Training acc= 0.777770 Val acc= 0.776860\n",
            "Epoch 778: Training loss= 0.493722 Val loss= 0.513005 Training acc= 0.777800 Val acc= 0.776875\n",
            "Epoch 779: Training loss= 0.493648 Val loss= 0.512915 Training acc= 0.777825 Val acc= 0.776895\n",
            "Epoch 780: Training loss= 0.493575 Val loss= 0.512826 Training acc= 0.777840 Val acc= 0.776900\n",
            "Epoch 781: Training loss= 0.493502 Val loss= 0.512736 Training acc= 0.777850 Val acc= 0.776920\n",
            "Epoch 782: Training loss= 0.493429 Val loss= 0.512647 Training acc= 0.777870 Val acc= 0.776910\n",
            "Epoch 783: Training loss= 0.493356 Val loss= 0.512558 Training acc= 0.777865 Val acc= 0.776920\n",
            "Epoch 784: Training loss= 0.493283 Val loss= 0.512469 Training acc= 0.777885 Val acc= 0.776950\n",
            "Epoch 785: Training loss= 0.493210 Val loss= 0.512380 Training acc= 0.777915 Val acc= 0.776960\n",
            "Epoch 786: Training loss= 0.493137 Val loss= 0.512292 Training acc= 0.777915 Val acc= 0.777000\n",
            "Epoch 787: Training loss= 0.493065 Val loss= 0.512203 Training acc= 0.777935 Val acc= 0.776980\n",
            "Epoch 788: Training loss= 0.492993 Val loss= 0.512115 Training acc= 0.777920 Val acc= 0.777055\n",
            "Epoch 789: Training loss= 0.492920 Val loss= 0.512027 Training acc= 0.777980 Val acc= 0.777080\n",
            "Epoch 790: Training loss= 0.492848 Val loss= 0.511938 Training acc= 0.777975 Val acc= 0.777120\n",
            "Epoch 791: Training loss= 0.492776 Val loss= 0.511850 Training acc= 0.778005 Val acc= 0.777155\n",
            "Epoch 792: Training loss= 0.492704 Val loss= 0.511763 Training acc= 0.778025 Val acc= 0.777195\n",
            "Epoch 793: Training loss= 0.492632 Val loss= 0.511675 Training acc= 0.778070 Val acc= 0.777205\n",
            "Epoch 794: Training loss= 0.492561 Val loss= 0.511587 Training acc= 0.778080 Val acc= 0.777170\n",
            "Epoch 795: Training loss= 0.492489 Val loss= 0.511500 Training acc= 0.778050 Val acc= 0.777185\n",
            "Epoch 796: Training loss= 0.492418 Val loss= 0.511413 Training acc= 0.778080 Val acc= 0.777185\n",
            "Epoch 797: Training loss= 0.492346 Val loss= 0.511325 Training acc= 0.778085 Val acc= 0.777180\n",
            "Epoch 798: Training loss= 0.492275 Val loss= 0.511238 Training acc= 0.778070 Val acc= 0.777165\n",
            "Epoch 799: Training loss= 0.492204 Val loss= 0.511151 Training acc= 0.778065 Val acc= 0.777210\n",
            "Epoch 800: Training loss= 0.492133 Val loss= 0.511065 Training acc= 0.778075 Val acc= 0.777220\n",
            "Epoch 801: Training loss= 0.492062 Val loss= 0.510978 Training acc= 0.778090 Val acc= 0.777240\n",
            "Epoch 802: Training loss= 0.491991 Val loss= 0.510891 Training acc= 0.778100 Val acc= 0.777275\n",
            "Epoch 803: Training loss= 0.491921 Val loss= 0.510805 Training acc= 0.778130 Val acc= 0.777300\n",
            "Epoch 804: Training loss= 0.491850 Val loss= 0.510719 Training acc= 0.778160 Val acc= 0.777345\n",
            "Epoch 805: Training loss= 0.491780 Val loss= 0.510633 Training acc= 0.778205 Val acc= 0.777355\n",
            "Epoch 806: Training loss= 0.491710 Val loss= 0.510547 Training acc= 0.778235 Val acc= 0.777325\n",
            "Epoch 807: Training loss= 0.491639 Val loss= 0.510461 Training acc= 0.778230 Val acc= 0.777350\n",
            "Epoch 808: Training loss= 0.491569 Val loss= 0.510375 Training acc= 0.778240 Val acc= 0.777375\n",
            "Epoch 809: Training loss= 0.491499 Val loss= 0.510289 Training acc= 0.778275 Val acc= 0.777365\n",
            "Epoch 810: Training loss= 0.491430 Val loss= 0.510204 Training acc= 0.778255 Val acc= 0.777350\n",
            "Epoch 811: Training loss= 0.491360 Val loss= 0.510119 Training acc= 0.778250 Val acc= 0.777360\n",
            "Epoch 812: Training loss= 0.491290 Val loss= 0.510033 Training acc= 0.778250 Val acc= 0.777405\n",
            "Epoch 813: Training loss= 0.491221 Val loss= 0.509948 Training acc= 0.778290 Val acc= 0.777405\n",
            "Epoch 814: Training loss= 0.491152 Val loss= 0.509864 Training acc= 0.778305 Val acc= 0.777410\n",
            "Epoch 815: Training loss= 0.491083 Val loss= 0.509779 Training acc= 0.778335 Val acc= 0.777405\n",
            "Epoch 816: Training loss= 0.491014 Val loss= 0.509694 Training acc= 0.778330 Val acc= 0.777440\n",
            "Epoch 817: Training loss= 0.490945 Val loss= 0.509610 Training acc= 0.778365 Val acc= 0.777435\n",
            "Epoch 818: Training loss= 0.490876 Val loss= 0.509526 Training acc= 0.778365 Val acc= 0.777430\n",
            "Epoch 819: Training loss= 0.490807 Val loss= 0.509441 Training acc= 0.778390 Val acc= 0.777425\n",
            "Epoch 820: Training loss= 0.490739 Val loss= 0.509357 Training acc= 0.778425 Val acc= 0.777430\n",
            "Epoch 821: Training loss= 0.490671 Val loss= 0.509274 Training acc= 0.778435 Val acc= 0.777445\n",
            "Epoch 822: Training loss= 0.490603 Val loss= 0.509190 Training acc= 0.778455 Val acc= 0.777470\n",
            "Epoch 823: Training loss= 0.490535 Val loss= 0.509107 Training acc= 0.778485 Val acc= 0.777485\n",
            "Epoch 824: Training loss= 0.490467 Val loss= 0.509023 Training acc= 0.778495 Val acc= 0.777485\n",
            "Epoch 825: Training loss= 0.490399 Val loss= 0.508940 Training acc= 0.778485 Val acc= 0.777505\n",
            "Epoch 826: Training loss= 0.490331 Val loss= 0.508857 Training acc= 0.778515 Val acc= 0.777520\n",
            "Epoch 827: Training loss= 0.490264 Val loss= 0.508774 Training acc= 0.778540 Val acc= 0.777540\n",
            "Epoch 828: Training loss= 0.490197 Val loss= 0.508692 Training acc= 0.778565 Val acc= 0.777550\n",
            "Epoch 829: Training loss= 0.490130 Val loss= 0.508609 Training acc= 0.778570 Val acc= 0.777555\n",
            "Epoch 830: Training loss= 0.490063 Val loss= 0.508527 Training acc= 0.778580 Val acc= 0.777560\n",
            "Epoch 831: Training loss= 0.489996 Val loss= 0.508445 Training acc= 0.778560 Val acc= 0.777590\n",
            "Epoch 832: Training loss= 0.489929 Val loss= 0.508363 Training acc= 0.778580 Val acc= 0.777605\n",
            "Epoch 833: Training loss= 0.489863 Val loss= 0.508281 Training acc= 0.778595 Val acc= 0.777630\n",
            "Epoch 834: Training loss= 0.489796 Val loss= 0.508200 Training acc= 0.778615 Val acc= 0.777635\n",
            "Epoch 835: Training loss= 0.489730 Val loss= 0.508118 Training acc= 0.778605 Val acc= 0.777640\n",
            "Epoch 836: Training loss= 0.489664 Val loss= 0.508037 Training acc= 0.778620 Val acc= 0.777670\n",
            "Epoch 837: Training loss= 0.489598 Val loss= 0.507956 Training acc= 0.778650 Val acc= 0.777675\n",
            "Epoch 838: Training loss= 0.489532 Val loss= 0.507875 Training acc= 0.778650 Val acc= 0.777695\n",
            "Epoch 839: Training loss= 0.489466 Val loss= 0.507794 Training acc= 0.778705 Val acc= 0.777715\n",
            "Epoch 840: Training loss= 0.489400 Val loss= 0.507713 Training acc= 0.778750 Val acc= 0.777725\n",
            "Epoch 841: Training loss= 0.489335 Val loss= 0.507633 Training acc= 0.778750 Val acc= 0.777755\n",
            "Epoch 842: Training loss= 0.489269 Val loss= 0.507552 Training acc= 0.778805 Val acc= 0.777780\n",
            "Epoch 843: Training loss= 0.489204 Val loss= 0.507472 Training acc= 0.778825 Val acc= 0.777770\n",
            "Epoch 844: Training loss= 0.489139 Val loss= 0.507391 Training acc= 0.778815 Val acc= 0.777770\n",
            "Epoch 845: Training loss= 0.489073 Val loss= 0.507311 Training acc= 0.778815 Val acc= 0.777760\n",
            "Epoch 846: Training loss= 0.489008 Val loss= 0.507231 Training acc= 0.778810 Val acc= 0.777800\n",
            "Epoch 847: Training loss= 0.488943 Val loss= 0.507151 Training acc= 0.778835 Val acc= 0.777825\n",
            "Epoch 848: Training loss= 0.488878 Val loss= 0.507071 Training acc= 0.778875 Val acc= 0.777850\n",
            "Epoch 849: Training loss= 0.488813 Val loss= 0.506992 Training acc= 0.778900 Val acc= 0.777905\n",
            "Epoch 850: Training loss= 0.488749 Val loss= 0.506912 Training acc= 0.778945 Val acc= 0.777940\n",
            "Epoch 851: Training loss= 0.488684 Val loss= 0.506832 Training acc= 0.778985 Val acc= 0.777975\n",
            "Epoch 852: Training loss= 0.488619 Val loss= 0.506753 Training acc= 0.779025 Val acc= 0.777990\n",
            "Epoch 853: Training loss= 0.488555 Val loss= 0.506674 Training acc= 0.779030 Val acc= 0.778010\n",
            "Epoch 854: Training loss= 0.488490 Val loss= 0.506594 Training acc= 0.779030 Val acc= 0.778020\n",
            "Epoch 855: Training loss= 0.488426 Val loss= 0.506515 Training acc= 0.779050 Val acc= 0.778035\n",
            "Epoch 856: Training loss= 0.488361 Val loss= 0.506436 Training acc= 0.779070 Val acc= 0.778020\n",
            "Epoch 857: Training loss= 0.488297 Val loss= 0.506357 Training acc= 0.779080 Val acc= 0.778035\n",
            "Epoch 858: Training loss= 0.488233 Val loss= 0.506278 Training acc= 0.779100 Val acc= 0.778065\n",
            "Epoch 859: Training loss= 0.488169 Val loss= 0.506199 Training acc= 0.779160 Val acc= 0.778085\n",
            "Epoch 860: Training loss= 0.488105 Val loss= 0.506120 Training acc= 0.779170 Val acc= 0.778075\n",
            "Epoch 861: Training loss= 0.488041 Val loss= 0.506042 Training acc= 0.779165 Val acc= 0.778090\n",
            "Epoch 862: Training loss= 0.487977 Val loss= 0.505963 Training acc= 0.779175 Val acc= 0.778095\n",
            "Epoch 863: Training loss= 0.487914 Val loss= 0.505885 Training acc= 0.779200 Val acc= 0.778125\n",
            "Epoch 864: Training loss= 0.487850 Val loss= 0.505806 Training acc= 0.779220 Val acc= 0.778140\n",
            "Epoch 865: Training loss= 0.487786 Val loss= 0.505728 Training acc= 0.779235 Val acc= 0.778180\n",
            "Epoch 866: Training loss= 0.487723 Val loss= 0.505650 Training acc= 0.779280 Val acc= 0.778195\n",
            "Epoch 867: Training loss= 0.487659 Val loss= 0.505571 Training acc= 0.779300 Val acc= 0.778185\n",
            "Epoch 868: Training loss= 0.487596 Val loss= 0.505493 Training acc= 0.779300 Val acc= 0.778195\n",
            "Epoch 869: Training loss= 0.487533 Val loss= 0.505415 Training acc= 0.779315 Val acc= 0.778235\n",
            "Epoch 870: Training loss= 0.487469 Val loss= 0.505337 Training acc= 0.779350 Val acc= 0.778280\n",
            "Epoch 871: Training loss= 0.487406 Val loss= 0.505260 Training acc= 0.779395 Val acc= 0.778335\n",
            "Epoch 872: Training loss= 0.487343 Val loss= 0.505182 Training acc= 0.779440 Val acc= 0.778365\n",
            "Epoch 873: Training loss= 0.487280 Val loss= 0.505104 Training acc= 0.779475 Val acc= 0.778385\n",
            "Epoch 874: Training loss= 0.487217 Val loss= 0.505026 Training acc= 0.779485 Val acc= 0.778395\n",
            "Epoch 875: Training loss= 0.487154 Val loss= 0.504949 Training acc= 0.779485 Val acc= 0.778390\n",
            "Epoch 876: Training loss= 0.487091 Val loss= 0.504871 Training acc= 0.779480 Val acc= 0.778410\n",
            "Epoch 877: Training loss= 0.487029 Val loss= 0.504794 Training acc= 0.779480 Val acc= 0.778425\n",
            "Epoch 878: Training loss= 0.486966 Val loss= 0.504717 Training acc= 0.779495 Val acc= 0.778415\n",
            "Epoch 879: Training loss= 0.486903 Val loss= 0.504639 Training acc= 0.779495 Val acc= 0.778420\n",
            "Epoch 880: Training loss= 0.486841 Val loss= 0.504562 Training acc= 0.779495 Val acc= 0.778430\n",
            "Epoch 881: Training loss= 0.486779 Val loss= 0.504485 Training acc= 0.779515 Val acc= 0.778430\n",
            "Epoch 882: Training loss= 0.486716 Val loss= 0.504408 Training acc= 0.779520 Val acc= 0.778430\n",
            "Epoch 883: Training loss= 0.486654 Val loss= 0.504331 Training acc= 0.779515 Val acc= 0.778440\n",
            "Epoch 884: Training loss= 0.486592 Val loss= 0.504254 Training acc= 0.779525 Val acc= 0.778485\n",
            "Epoch 885: Training loss= 0.486530 Val loss= 0.504178 Training acc= 0.779570 Val acc= 0.778505\n",
            "Epoch 886: Training loss= 0.486467 Val loss= 0.504101 Training acc= 0.779600 Val acc= 0.778510\n",
            "Epoch 887: Training loss= 0.486405 Val loss= 0.504024 Training acc= 0.779610 Val acc= 0.778540\n",
            "Epoch 888: Training loss= 0.486344 Val loss= 0.503948 Training acc= 0.779655 Val acc= 0.778565\n",
            "Epoch 889: Training loss= 0.486282 Val loss= 0.503871 Training acc= 0.779680 Val acc= 0.778600\n",
            "Epoch 890: Training loss= 0.486220 Val loss= 0.503795 Training acc= 0.779690 Val acc= 0.778620\n",
            "Epoch 891: Training loss= 0.486158 Val loss= 0.503719 Training acc= 0.779700 Val acc= 0.778645\n",
            "Epoch 892: Training loss= 0.486097 Val loss= 0.503643 Training acc= 0.779700 Val acc= 0.778680\n",
            "Epoch 893: Training loss= 0.486035 Val loss= 0.503566 Training acc= 0.779740 Val acc= 0.778700\n",
            "Epoch 894: Training loss= 0.485974 Val loss= 0.503490 Training acc= 0.779755 Val acc= 0.778720\n",
            "Epoch 895: Training loss= 0.485912 Val loss= 0.503414 Training acc= 0.779760 Val acc= 0.778720\n",
            "Epoch 896: Training loss= 0.485851 Val loss= 0.503339 Training acc= 0.779760 Val acc= 0.778700\n",
            "Epoch 897: Training loss= 0.485790 Val loss= 0.503263 Training acc= 0.779745 Val acc= 0.778735\n",
            "Epoch 898: Training loss= 0.485728 Val loss= 0.503187 Training acc= 0.779785 Val acc= 0.778735\n",
            "Epoch 899: Training loss= 0.485667 Val loss= 0.503111 Training acc= 0.779770 Val acc= 0.778750\n",
            "Epoch 900: Training loss= 0.485606 Val loss= 0.503036 Training acc= 0.779805 Val acc= 0.778760\n",
            "Epoch 901: Training loss= 0.485545 Val loss= 0.502960 Training acc= 0.779810 Val acc= 0.778765\n",
            "Epoch 902: Training loss= 0.485484 Val loss= 0.502885 Training acc= 0.779815 Val acc= 0.778790\n",
            "Epoch 903: Training loss= 0.485424 Val loss= 0.502810 Training acc= 0.779845 Val acc= 0.778760\n",
            "Epoch 904: Training loss= 0.485363 Val loss= 0.502734 Training acc= 0.779845 Val acc= 0.778770\n",
            "Epoch 905: Training loss= 0.485302 Val loss= 0.502659 Training acc= 0.779845 Val acc= 0.778800\n",
            "Epoch 906: Training loss= 0.485242 Val loss= 0.502584 Training acc= 0.779860 Val acc= 0.778835\n",
            "Epoch 907: Training loss= 0.485181 Val loss= 0.502509 Training acc= 0.779890 Val acc= 0.778820\n",
            "Epoch 908: Training loss= 0.485121 Val loss= 0.502434 Training acc= 0.779890 Val acc= 0.778815\n",
            "Epoch 909: Training loss= 0.485060 Val loss= 0.502360 Training acc= 0.779900 Val acc= 0.778815\n",
            "Epoch 910: Training loss= 0.485000 Val loss= 0.502285 Training acc= 0.779910 Val acc= 0.778850\n",
            "Epoch 911: Training loss= 0.484940 Val loss= 0.502210 Training acc= 0.779945 Val acc= 0.778865\n",
            "Epoch 912: Training loss= 0.484879 Val loss= 0.502136 Training acc= 0.779945 Val acc= 0.778885\n",
            "Epoch 913: Training loss= 0.484819 Val loss= 0.502061 Training acc= 0.779955 Val acc= 0.778890\n",
            "Epoch 914: Training loss= 0.484759 Val loss= 0.501987 Training acc= 0.779970 Val acc= 0.778915\n",
            "Epoch 915: Training loss= 0.484699 Val loss= 0.501912 Training acc= 0.780000 Val acc= 0.778930\n",
            "Epoch 916: Training loss= 0.484640 Val loss= 0.501838 Training acc= 0.780030 Val acc= 0.778910\n",
            "Epoch 917: Training loss= 0.484580 Val loss= 0.501764 Training acc= 0.780005 Val acc= 0.778875\n",
            "Epoch 918: Training loss= 0.484520 Val loss= 0.501690 Training acc= 0.779990 Val acc= 0.778880\n",
            "Epoch 919: Training loss= 0.484460 Val loss= 0.501616 Training acc= 0.780005 Val acc= 0.778895\n",
            "Epoch 920: Training loss= 0.484401 Val loss= 0.501542 Training acc= 0.780040 Val acc= 0.778930\n",
            "Epoch 921: Training loss= 0.484341 Val loss= 0.501468 Training acc= 0.780055 Val acc= 0.778940\n",
            "Epoch 922: Training loss= 0.484282 Val loss= 0.501395 Training acc= 0.780075 Val acc= 0.778960\n",
            "Epoch 923: Training loss= 0.484223 Val loss= 0.501321 Training acc= 0.780095 Val acc= 0.778965\n",
            "Epoch 924: Training loss= 0.484163 Val loss= 0.501247 Training acc= 0.780095 Val acc= 0.778960\n",
            "Epoch 925: Training loss= 0.484104 Val loss= 0.501174 Training acc= 0.780085 Val acc= 0.779010\n",
            "Epoch 926: Training loss= 0.484045 Val loss= 0.501101 Training acc= 0.780145 Val acc= 0.779000\n",
            "Epoch 927: Training loss= 0.483986 Val loss= 0.501027 Training acc= 0.780130 Val acc= 0.779035\n",
            "Epoch 928: Training loss= 0.483927 Val loss= 0.500954 Training acc= 0.780155 Val acc= 0.779050\n",
            "Epoch 929: Training loss= 0.483868 Val loss= 0.500881 Training acc= 0.780170 Val acc= 0.779055\n",
            "Epoch 930: Training loss= 0.483810 Val loss= 0.500808 Training acc= 0.780185 Val acc= 0.779085\n",
            "Epoch 931: Training loss= 0.483751 Val loss= 0.500736 Training acc= 0.780215 Val acc= 0.779140\n",
            "Epoch 932: Training loss= 0.483693 Val loss= 0.500663 Training acc= 0.780250 Val acc= 0.779160\n",
            "Epoch 933: Training loss= 0.483634 Val loss= 0.500591 Training acc= 0.780275 Val acc= 0.779155\n",
            "Epoch 934: Training loss= 0.483576 Val loss= 0.500518 Training acc= 0.780280 Val acc= 0.779155\n",
            "Epoch 935: Training loss= 0.483518 Val loss= 0.500446 Training acc= 0.780275 Val acc= 0.779160\n",
            "Epoch 936: Training loss= 0.483459 Val loss= 0.500374 Training acc= 0.780295 Val acc= 0.779180\n",
            "Epoch 937: Training loss= 0.483401 Val loss= 0.500302 Training acc= 0.780310 Val acc= 0.779195\n",
            "Epoch 938: Training loss= 0.483344 Val loss= 0.500231 Training acc= 0.780325 Val acc= 0.779190\n",
            "Epoch 939: Training loss= 0.483286 Val loss= 0.500159 Training acc= 0.780325 Val acc= 0.779205\n",
            "Epoch 940: Training loss= 0.483228 Val loss= 0.500088 Training acc= 0.780335 Val acc= 0.779240\n",
            "Epoch 941: Training loss= 0.483171 Val loss= 0.500017 Training acc= 0.780370 Val acc= 0.779260\n",
            "Epoch 942: Training loss= 0.483113 Val loss= 0.499946 Training acc= 0.780405 Val acc= 0.779275\n",
            "Epoch 943: Training loss= 0.483056 Val loss= 0.499876 Training acc= 0.780420 Val acc= 0.779295\n",
            "Epoch 944: Training loss= 0.482999 Val loss= 0.499805 Training acc= 0.780425 Val acc= 0.779305\n",
            "Epoch 945: Training loss= 0.482942 Val loss= 0.499735 Training acc= 0.780420 Val acc= 0.779315\n",
            "Epoch 946: Training loss= 0.482886 Val loss= 0.499665 Training acc= 0.780435 Val acc= 0.779325\n",
            "Epoch 947: Training loss= 0.482829 Val loss= 0.499595 Training acc= 0.780450 Val acc= 0.779320\n",
            "Epoch 948: Training loss= 0.482773 Val loss= 0.499525 Training acc= 0.780450 Val acc= 0.779315\n",
            "Epoch 949: Training loss= 0.482716 Val loss= 0.499456 Training acc= 0.780445 Val acc= 0.779370\n",
            "Epoch 950: Training loss= 0.482660 Val loss= 0.499387 Training acc= 0.780485 Val acc= 0.779375\n",
            "Epoch 951: Training loss= 0.482604 Val loss= 0.499318 Training acc= 0.780490 Val acc= 0.779395\n",
            "Epoch 952: Training loss= 0.482548 Val loss= 0.499249 Training acc= 0.780520 Val acc= 0.779400\n",
            "Epoch 953: Training loss= 0.482492 Val loss= 0.499180 Training acc= 0.780535 Val acc= 0.779405\n",
            "Epoch 954: Training loss= 0.482436 Val loss= 0.499111 Training acc= 0.780550 Val acc= 0.779415\n",
            "Epoch 955: Training loss= 0.482380 Val loss= 0.499042 Training acc= 0.780560 Val acc= 0.779415\n",
            "Epoch 956: Training loss= 0.482325 Val loss= 0.498974 Training acc= 0.780585 Val acc= 0.779450\n",
            "Epoch 957: Training loss= 0.482269 Val loss= 0.498905 Training acc= 0.780600 Val acc= 0.779460\n",
            "Epoch 958: Training loss= 0.482214 Val loss= 0.498837 Training acc= 0.780610 Val acc= 0.779460\n",
            "Epoch 959: Training loss= 0.482158 Val loss= 0.498769 Training acc= 0.780605 Val acc= 0.779455\n",
            "Epoch 960: Training loss= 0.482103 Val loss= 0.498701 Training acc= 0.780610 Val acc= 0.779485\n",
            "Epoch 961: Training loss= 0.482048 Val loss= 0.498633 Training acc= 0.780640 Val acc= 0.779495\n",
            "Epoch 962: Training loss= 0.481993 Val loss= 0.498565 Training acc= 0.780630 Val acc= 0.779515\n",
            "Epoch 963: Training loss= 0.481938 Val loss= 0.498497 Training acc= 0.780655 Val acc= 0.779505\n",
            "Epoch 964: Training loss= 0.481883 Val loss= 0.498429 Training acc= 0.780650 Val acc= 0.779540\n",
            "Epoch 965: Training loss= 0.481828 Val loss= 0.498361 Training acc= 0.780670 Val acc= 0.779550\n",
            "Epoch 966: Training loss= 0.481773 Val loss= 0.498294 Training acc= 0.780690 Val acc= 0.779575\n",
            "Epoch 967: Training loss= 0.481718 Val loss= 0.498226 Training acc= 0.780700 Val acc= 0.779580\n",
            "Epoch 968: Training loss= 0.481663 Val loss= 0.498158 Training acc= 0.780705 Val acc= 0.779615\n",
            "Epoch 969: Training loss= 0.481609 Val loss= 0.498091 Training acc= 0.780735 Val acc= 0.779555\n",
            "Epoch 970: Training loss= 0.481554 Val loss= 0.498024 Training acc= 0.780705 Val acc= 0.779605\n",
            "Epoch 971: Training loss= 0.481500 Val loss= 0.497956 Training acc= 0.780755 Val acc= 0.779615\n",
            "Epoch 972: Training loss= 0.481445 Val loss= 0.497889 Training acc= 0.780760 Val acc= 0.779630\n",
            "Epoch 973: Training loss= 0.481391 Val loss= 0.497822 Training acc= 0.780780 Val acc= 0.779655\n",
            "Epoch 974: Training loss= 0.481336 Val loss= 0.497755 Training acc= 0.780805 Val acc= 0.779685\n",
            "Epoch 975: Training loss= 0.481282 Val loss= 0.497688 Training acc= 0.780845 Val acc= 0.779700\n",
            "Epoch 976: Training loss= 0.481228 Val loss= 0.497621 Training acc= 0.780865 Val acc= 0.779715\n",
            "Epoch 977: Training loss= 0.481174 Val loss= 0.497555 Training acc= 0.780875 Val acc= 0.779725\n",
            "Epoch 978: Training loss= 0.481120 Val loss= 0.497489 Training acc= 0.780880 Val acc= 0.779730\n",
            "Epoch 979: Training loss= 0.481067 Val loss= 0.497423 Training acc= 0.780880 Val acc= 0.779770\n",
            "Epoch 980: Training loss= 0.481013 Val loss= 0.497358 Training acc= 0.780905 Val acc= 0.779780\n",
            "Epoch 981: Training loss= 0.480960 Val loss= 0.497294 Training acc= 0.780895 Val acc= 0.779765\n",
            "Epoch 982: Training loss= 0.480907 Val loss= 0.497230 Training acc= 0.780880 Val acc= 0.779785\n",
            "Epoch 983: Training loss= 0.480855 Val loss= 0.497167 Training acc= 0.780875 Val acc= 0.779775\n",
            "Epoch 984: Training loss= 0.480803 Val loss= 0.497105 Training acc= 0.780875 Val acc= 0.779765\n",
            "Epoch 985: Training loss= 0.480751 Val loss= 0.497042 Training acc= 0.780875 Val acc= 0.779780\n",
            "Epoch 986: Training loss= 0.480699 Val loss= 0.496981 Training acc= 0.780905 Val acc= 0.779785\n",
            "Epoch 987: Training loss= 0.480648 Val loss= 0.496919 Training acc= 0.780900 Val acc= 0.779795\n",
            "Epoch 988: Training loss= 0.480596 Val loss= 0.496858 Training acc= 0.780920 Val acc= 0.779795\n",
            "Epoch 989: Training loss= 0.480545 Val loss= 0.496797 Training acc= 0.780935 Val acc= 0.779805\n",
            "Epoch 990: Training loss= 0.480494 Val loss= 0.496736 Training acc= 0.780920 Val acc= 0.779850\n",
            "Epoch 991: Training loss= 0.480442 Val loss= 0.496675 Training acc= 0.780960 Val acc= 0.779840\n",
            "Epoch 992: Training loss= 0.480391 Val loss= 0.496614 Training acc= 0.780945 Val acc= 0.779875\n",
            "Epoch 993: Training loss= 0.480340 Val loss= 0.496553 Training acc= 0.780965 Val acc= 0.779875\n",
            "Epoch 994: Training loss= 0.480289 Val loss= 0.496493 Training acc= 0.780970 Val acc= 0.779895\n",
            "Epoch 995: Training loss= 0.480238 Val loss= 0.496432 Training acc= 0.781000 Val acc= 0.779925\n",
            "Epoch 996: Training loss= 0.480187 Val loss= 0.496372 Training acc= 0.781005 Val acc= 0.779955\n",
            "Epoch 997: Training loss= 0.480136 Val loss= 0.496311 Training acc= 0.781040 Val acc= 0.779980\n",
            "Epoch 998: Training loss= 0.480086 Val loss= 0.496251 Training acc= 0.781060 Val acc= 0.779945\n",
            "Epoch 999: Training loss= 0.480035 Val loss= 0.496191 Training acc= 0.781030 Val acc= 0.779960\n",
            "Best model info *** :\n",
            "Epoch 999: Training loss= 0.480035 Val loss= 0.496191 Training acc= 0.781030 Val acc= 0.779960\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-1.01558939,  0.0973676 ,  0.54742838,  0.0714579 ,  0.74239577,\n",
              "         0.34170413,  0.41889476,  0.81485606, -0.45861957,  0.69398313,\n",
              "         0.20582739,  0.28272049,  0.33057366,  0.21512716,  0.76425041,\n",
              "         0.04887915, -0.12463207, -0.04130119, -0.06429992,  0.04648961,\n",
              "         0.12428062, -0.17251569, -0.25325788, -0.41613792,  0.13064606,\n",
              "         0.16872904, -0.13628496,  0.73734904, -0.22935483,  0.12720947,\n",
              "        -0.31765264,  0.21514093,  0.27070964,  0.7452129 ,  0.1449081 ,\n",
              "         0.19811124,  0.89513085,  0.65313762,  0.02679643,  0.73863562,\n",
              "        -0.22681053, -0.13503007, -0.31819657, -0.19212465,  0.91646902,\n",
              "         0.21199492,  0.18129228,  0.65118436,  0.03622469,  0.05688161,\n",
              "         0.42649866, -0.0841772 ,  0.46535803,  0.05510449,  0.57889717,\n",
              "        -0.19188393, -0.09897433, -0.06499733,  0.25292338, -0.11424947,\n",
              "         0.47649948, -0.04856382,  0.18746415,  0.14047515,  0.11375601,\n",
              "         0.65731294,  0.69912811,  0.20841866, -0.18072522,  0.99067302,\n",
              "         0.35854096, -0.21074241, -0.23910199,  0.1216492 ,  0.82477333,\n",
              "        -0.18135777, -0.16398592, -0.06752516, -0.04108298,  0.07090087,\n",
              "         0.30002801, -0.01406621, -0.19295863, -0.17853681, -0.19886264,\n",
              "         0.13198564,  0.40617374,  0.48758825,  0.5697113 ,  0.15457652,\n",
              "         0.01776387,  0.14696012,  0.09650853, -0.01704315,  0.16149558,\n",
              "         0.10919643,  0.21575418,  0.14594311,  0.0191684 ,  0.14649744,\n",
              "        -0.28565894,  0.44350097,  0.21623871, -0.07313152,  0.2675622 ,\n",
              "        -0.19377627, -0.4006782 ,  0.11692707, -0.11096385, -0.08152479,\n",
              "         0.90011624,  0.31990987,  0.48540131,  0.06747341,  0.38242985,\n",
              "         0.22811216,  0.09316882,  0.43516651, -0.46634694, -0.24994507,\n",
              "        -0.17350921, -0.02124061, -0.12258719,  0.47318472,  0.99029627,\n",
              "        -0.27916996,  0.31161181,  0.59790581,  0.05765784,  0.52092037,\n",
              "        -0.20364126, -0.4685668 , -0.25610203, -0.21483513,  0.52404349,\n",
              "         0.34060863,  0.27159957,  0.30475287,  0.27102712,  0.07511091,\n",
              "         0.33592806,  0.33633582, -0.40034282, -0.17024906,  0.35761185,\n",
              "        -0.26915429, -0.26494715,  0.39552856, -0.3284851 , -0.48420349,\n",
              "         0.37737024,  0.08794116,  0.25436042, -0.05461648,  0.82869073,\n",
              "         0.31668073,  0.01824033, -0.33004513, -0.19311969,  0.06334708,\n",
              "        -0.10005985,  0.11121783,  0.12662103, -0.0430095 ,  0.22366539,\n",
              "        -0.16236157,  0.24548344, -0.52541266,  0.09937323, -0.09998754,\n",
              "         0.08435704, -0.38497758, -0.28619834,  0.35451128,  0.08629025,\n",
              "        -0.02392718, -0.14048519,  0.1337125 ,  0.2698516 ,  0.49951919,\n",
              "        -0.55396248, -0.58371331,  0.30917496, -0.24902303,  0.25874486,\n",
              "         0.36037174,  0.63425664,  0.27773731, -0.59946869,  0.20276388,\n",
              "        -0.1817444 ,  0.03703101, -0.01267824,  0.4176123 , -0.13516325,\n",
              "        -0.27781752,  0.13406122,  0.01890386, -0.20343264, -0.33370171,\n",
              "         0.95966083, -0.14814229,  0.11340933,  0.31514123, -0.11590326,\n",
              "        -0.11115056, -0.02904079,  0.08550376,  0.0425922 ,  0.31862959,\n",
              "         0.18306677, -0.22479222, -0.34733841, -1.07755637, -0.08298654,\n",
              "        -0.17121701,  0.05540286, -0.26706224,  0.58604976,  0.30288866,\n",
              "        -0.37335578, -0.07937113,  0.06802927, -0.2578336 , -0.42972057,\n",
              "         0.03072723,  0.01264061,  0.10647284, -0.21644279,  0.18113694,\n",
              "        -0.12828091,  0.180046  , -0.27266287, -0.16376168,  0.06949947,\n",
              "         0.21857396,  0.21433809,  0.1604794 , -0.12464056, -0.11889891,\n",
              "        -0.31456218,  0.38435312, -0.52608193, -0.22870863,  0.49274314,\n",
              "        -0.03329615,  0.20100772,  0.14732314,  1.18690046, -0.01964423,\n",
              "         0.25732221, -0.4127801 ,  0.3215993 ,  0.45077949,  0.92985407,\n",
              "         0.08171992, -0.13600492,  0.64153783,  0.02680315,  0.15984539,\n",
              "         0.07195427, -0.00808034,  0.1412709 ,  0.4171865 ,  0.35441086,\n",
              "         0.13700787,  0.03658695,  0.23480299, -0.0179072 , -0.11869909,\n",
              "        -0.11655779], dtype=float128), 0.4800351766946892)"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXjiyt2UtAh3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3036a5f-68d3-4fae-8d2c-8c621414b190"
      },
      "source": [
        "\n",
        "\n",
        "def sigmoid(z):\n",
        "  return 1/(1+np.exp(-z))\n",
        "def reg_logistic_regression(y, X, lambda_, theta, num_iters, gamma, show=False):\n",
        "  y=y.astype(dtype=np.float128)\n",
        "  X=X.astype(dtype=np.float128)\n",
        "  theta=theta.astype(dtype=np.float128)\n",
        "\n",
        "\n",
        "  m = len(y);\n",
        "  train_loss= np.zeros(num_iters)\n",
        "  val_loss = np.zeros(num_iters)\n",
        "  train_acc= np.zeros(num_iters)\n",
        "  val_acc = np.zeros(num_iters)\n",
        "  models=[]\n",
        "\n",
        "  for iter in range (num_iters):\n",
        "    h = sigmoid(np.matmul(X,theta))\n",
        "    train_loss[iter] =  1/m*np.sum(np.log(1+np.exp(np.matmul(X,theta)))-y*np.matmul(X,theta))+ lambda_/(2*m)*np.linalg.norm(theta[1:],ord=2)**2\n",
        "    # update weights\n",
        "    theta = theta - gamma * 1/m * ( np.matmul(np.transpose(X),(h-y)) + lambda_/m *np.array( [0]+ list(theta)[1:]))\n",
        "    val_h = sigmoid(np.matmul(val_X,theta))\n",
        "    val_loss[iter] =  1/m*np.sum(np.log(1+np.exp(np.matmul(val_X,theta)))-val_y*np.matmul(val_X,theta)) + lambda_/(2*len(val_y))*np.linalg.norm(theta[1:],ord=2)**2\n",
        "    train_acc[iter] = find_acc(y, h)\n",
        "    val_acc[iter] = find_acc(val_y, val_h)\n",
        "    models.append(np.copy(theta))\n",
        "    print('Epoch {:d}: Training loss= {:.6f} Val loss= {:.6f} Training acc= {:.6f} Val acc= {:.6f}'.format(iter, train_loss[iter], val_loss[iter],\n",
        "                                                                                                           train_acc[iter], val_acc[iter]))\n",
        "\n",
        "  best_model_idx=np.argmin(val_loss)\n",
        "  print(\"Best model info *** :\")\n",
        "  print('Epoch {:d}: Training loss= {:.6f} Val loss= {:.6f} Training acc= {:.6f} Val acc= {:.6f}'.format(iter, train_loss[best_model_idx],val_loss[best_model_idx],\n",
        "                                                                                                         train_acc[best_model_idx],val_acc[best_model_idx],))\n",
        "  \n",
        "  if show:\n",
        "    plt.plot(range(1,num_iters+1), train_loss)\n",
        "    plt.plot(range(1,num_iters+1), val_loss)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('acc')\n",
        "    plt.legend(['training', 'validation'], loc='upper right')\n",
        "    plt.show()\n",
        "  return models[best_model_idx], train_loss[best_model_idx]\n",
        "reg_logistic_regression(train_y,train_X,0.5, np.random.rand(train_X.shape[1]),1000,0.1,show=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Training loss= 5.369292 Val loss= 5.298313 Training acc= 0.567460 Val acc= 0.567475\n",
            "Epoch 1: Training loss= 5.262680 Val loss= 5.192937 Training acc= 0.568345 Val acc= 0.568475\n",
            "Epoch 2: Training loss= 5.157172 Val loss= 5.088699 Training acc= 0.569250 Val acc= 0.569285\n",
            "Epoch 3: Training loss= 5.052790 Val loss= 4.985621 Training acc= 0.569885 Val acc= 0.570325\n",
            "Epoch 4: Training loss= 4.949557 Val loss= 4.883723 Training acc= 0.570865 Val acc= 0.571325\n",
            "Epoch 5: Training loss= 4.847493 Val loss= 4.783026 Training acc= 0.571730 Val acc= 0.572125\n",
            "Epoch 6: Training loss= 4.746619 Val loss= 4.683546 Training acc= 0.572535 Val acc= 0.573210\n",
            "Epoch 7: Training loss= 4.646956 Val loss= 4.585301 Training acc= 0.573625 Val acc= 0.574255\n",
            "Epoch 8: Training loss= 4.548524 Val loss= 4.488308 Training acc= 0.574755 Val acc= 0.575455\n",
            "Epoch 9: Training loss= 4.451339 Val loss= 4.392582 Training acc= 0.575820 Val acc= 0.576365\n",
            "Epoch 10: Training loss= 4.355417 Val loss= 4.298134 Training acc= 0.576820 Val acc= 0.577370\n",
            "Epoch 11: Training loss= 4.260772 Val loss= 4.204978 Training acc= 0.577880 Val acc= 0.578385\n",
            "Epoch 12: Training loss= 4.167416 Val loss= 4.113124 Training acc= 0.578970 Val acc= 0.579460\n",
            "Epoch 13: Training loss= 4.075359 Val loss= 4.022585 Training acc= 0.580105 Val acc= 0.580580\n",
            "Epoch 14: Training loss= 3.984613 Val loss= 3.933370 Training acc= 0.581375 Val acc= 0.581795\n",
            "Epoch 15: Training loss= 3.895189 Val loss= 3.845493 Training acc= 0.582540 Val acc= 0.582790\n",
            "Epoch 16: Training loss= 3.807098 Val loss= 3.758967 Training acc= 0.583575 Val acc= 0.584000\n",
            "Epoch 17: Training loss= 3.720353 Val loss= 3.673807 Training acc= 0.584690 Val acc= 0.585225\n",
            "Epoch 18: Training loss= 3.634970 Val loss= 3.590032 Training acc= 0.585970 Val acc= 0.586440\n",
            "Epoch 19: Training loss= 3.550967 Val loss= 3.507658 Training acc= 0.587255 Val acc= 0.587780\n",
            "Epoch 20: Training loss= 3.468362 Val loss= 3.426704 Training acc= 0.588550 Val acc= 0.589465\n",
            "Epoch 21: Training loss= 3.387172 Val loss= 3.347184 Training acc= 0.589930 Val acc= 0.591200\n",
            "Epoch 22: Training loss= 3.307414 Val loss= 3.269114 Training acc= 0.591705 Val acc= 0.592680\n",
            "Epoch 23: Training loss= 3.229104 Val loss= 3.192509 Training acc= 0.593255 Val acc= 0.594135\n",
            "Epoch 24: Training loss= 3.152259 Val loss= 3.117384 Training acc= 0.594835 Val acc= 0.595760\n",
            "Epoch 25: Training loss= 3.076895 Val loss= 3.043756 Training acc= 0.596420 Val acc= 0.597495\n",
            "Epoch 26: Training loss= 3.003030 Val loss= 2.971639 Training acc= 0.598195 Val acc= 0.599160\n",
            "Epoch 27: Training loss= 2.930682 Val loss= 2.901052 Training acc= 0.599810 Val acc= 0.601080\n",
            "Epoch 28: Training loss= 2.859867 Val loss= 2.832009 Training acc= 0.601810 Val acc= 0.602975\n",
            "Epoch 29: Training loss= 2.790602 Val loss= 2.764525 Training acc= 0.603925 Val acc= 0.604980\n",
            "Epoch 30: Training loss= 2.722902 Val loss= 2.698611 Training acc= 0.605940 Val acc= 0.606685\n",
            "Epoch 31: Training loss= 2.656779 Val loss= 2.634276 Training acc= 0.607645 Val acc= 0.608575\n",
            "Epoch 32: Training loss= 2.592242 Val loss= 2.571530 Training acc= 0.609450 Val acc= 0.610335\n",
            "Epoch 33: Training loss= 2.529302 Val loss= 2.510383 Training acc= 0.611305 Val acc= 0.612585\n",
            "Epoch 34: Training loss= 2.467970 Val loss= 2.450851 Training acc= 0.613525 Val acc= 0.614695\n",
            "Epoch 35: Training loss= 2.408261 Val loss= 2.392950 Training acc= 0.615715 Val acc= 0.616570\n",
            "Epoch 36: Training loss= 2.350195 Val loss= 2.336702 Training acc= 0.617530 Val acc= 0.618760\n",
            "Epoch 37: Training loss= 2.293796 Val loss= 2.282134 Training acc= 0.619575 Val acc= 0.620845\n",
            "Epoch 38: Training loss= 2.239090 Val loss= 2.229268 Training acc= 0.621735 Val acc= 0.622830\n",
            "Epoch 39: Training loss= 2.186101 Val loss= 2.178129 Training acc= 0.623770 Val acc= 0.624725\n",
            "Epoch 40: Training loss= 2.134848 Val loss= 2.128737 Training acc= 0.625525 Val acc= 0.626810\n",
            "Epoch 41: Training loss= 2.085350 Val loss= 2.081109 Training acc= 0.627835 Val acc= 0.628940\n",
            "Epoch 42: Training loss= 2.037620 Val loss= 2.035251 Training acc= 0.629965 Val acc= 0.631260\n",
            "Epoch 43: Training loss= 1.991669 Val loss= 1.991166 Training acc= 0.632025 Val acc= 0.634105\n",
            "Epoch 44: Training loss= 1.947507 Val loss= 1.948858 Training acc= 0.634635 Val acc= 0.636250\n",
            "Epoch 45: Training loss= 1.905148 Val loss= 1.908313 Training acc= 0.637050 Val acc= 0.638500\n",
            "Epoch 46: Training loss= 1.864577 Val loss= 1.869487 Training acc= 0.639295 Val acc= 0.640860\n",
            "Epoch 47: Training loss= 1.825747 Val loss= 1.832333 Training acc= 0.641520 Val acc= 0.642945\n",
            "Epoch 48: Training loss= 1.788603 Val loss= 1.796805 Training acc= 0.643460 Val acc= 0.645265\n",
            "Epoch 49: Training loss= 1.753099 Val loss= 1.762849 Training acc= 0.645855 Val acc= 0.647540\n",
            "Epoch 50: Training loss= 1.719181 Val loss= 1.730397 Training acc= 0.648145 Val acc= 0.649430\n",
            "Epoch 51: Training loss= 1.686779 Val loss= 1.699379 Training acc= 0.650115 Val acc= 0.651505\n",
            "Epoch 52: Training loss= 1.655820 Val loss= 1.669728 Training acc= 0.652335 Val acc= 0.653455\n",
            "Epoch 53: Training loss= 1.626238 Val loss= 1.641383 Training acc= 0.654560 Val acc= 0.655680\n",
            "Epoch 54: Training loss= 1.597969 Val loss= 1.614282 Training acc= 0.656630 Val acc= 0.657550\n",
            "Epoch 55: Training loss= 1.570951 Val loss= 1.588363 Training acc= 0.658560 Val acc= 0.659600\n",
            "Epoch 56: Training loss= 1.545117 Val loss= 1.563564 Training acc= 0.660660 Val acc= 0.661150\n",
            "Epoch 57: Training loss= 1.520405 Val loss= 1.539827 Training acc= 0.662285 Val acc= 0.663090\n",
            "Epoch 58: Training loss= 1.496756 Val loss= 1.517094 Training acc= 0.664205 Val acc= 0.665240\n",
            "Epoch 59: Training loss= 1.474111 Val loss= 1.495309 Training acc= 0.666320 Val acc= 0.667075\n",
            "Epoch 60: Training loss= 1.452416 Val loss= 1.474422 Training acc= 0.668270 Val acc= 0.668680\n",
            "Epoch 61: Training loss= 1.431620 Val loss= 1.454387 Training acc= 0.669890 Val acc= 0.670815\n",
            "Epoch 62: Training loss= 1.411675 Val loss= 1.435161 Training acc= 0.671830 Val acc= 0.672725\n",
            "Epoch 63: Training loss= 1.392540 Val loss= 1.416700 Training acc= 0.673700 Val acc= 0.674615\n",
            "Epoch 64: Training loss= 1.374172 Val loss= 1.398966 Training acc= 0.675535 Val acc= 0.676295\n",
            "Epoch 65: Training loss= 1.356532 Val loss= 1.381920 Training acc= 0.677050 Val acc= 0.678055\n",
            "Epoch 66: Training loss= 1.339580 Val loss= 1.365525 Training acc= 0.678825 Val acc= 0.679725\n",
            "Epoch 67: Training loss= 1.323280 Val loss= 1.349745 Training acc= 0.680560 Val acc= 0.681160\n",
            "Epoch 68: Training loss= 1.307597 Val loss= 1.334546 Training acc= 0.681990 Val acc= 0.682795\n",
            "Epoch 69: Training loss= 1.292496 Val loss= 1.319897 Training acc= 0.683570 Val acc= 0.684095\n",
            "Epoch 70: Training loss= 1.277945 Val loss= 1.305767 Training acc= 0.684845 Val acc= 0.685715\n",
            "Epoch 71: Training loss= 1.263913 Val loss= 1.292127 Training acc= 0.686510 Val acc= 0.686975\n",
            "Epoch 72: Training loss= 1.250371 Val loss= 1.278949 Training acc= 0.687600 Val acc= 0.688475\n",
            "Epoch 73: Training loss= 1.237291 Val loss= 1.266208 Training acc= 0.689200 Val acc= 0.689675\n",
            "Epoch 74: Training loss= 1.224648 Val loss= 1.253881 Training acc= 0.690450 Val acc= 0.691185\n",
            "Epoch 75: Training loss= 1.212417 Val loss= 1.241944 Training acc= 0.691775 Val acc= 0.692515\n",
            "Epoch 76: Training loss= 1.200577 Val loss= 1.230376 Training acc= 0.693150 Val acc= 0.693705\n",
            "Epoch 77: Training loss= 1.189104 Val loss= 1.219156 Training acc= 0.694335 Val acc= 0.695045\n",
            "Epoch 78: Training loss= 1.177980 Val loss= 1.208267 Training acc= 0.695625 Val acc= 0.696220\n",
            "Epoch 79: Training loss= 1.167186 Val loss= 1.197690 Training acc= 0.696870 Val acc= 0.697270\n",
            "Epoch 80: Training loss= 1.156703 Val loss= 1.187408 Training acc= 0.697890 Val acc= 0.698230\n",
            "Epoch 81: Training loss= 1.146514 Val loss= 1.177406 Training acc= 0.698780 Val acc= 0.699155\n",
            "Epoch 82: Training loss= 1.136606 Val loss= 1.167670 Training acc= 0.699715 Val acc= 0.700190\n",
            "Epoch 83: Training loss= 1.126962 Val loss= 1.158186 Training acc= 0.700765 Val acc= 0.701145\n",
            "Epoch 84: Training loss= 1.117570 Val loss= 1.148940 Training acc= 0.701935 Val acc= 0.702260\n",
            "Epoch 85: Training loss= 1.108416 Val loss= 1.139923 Training acc= 0.703030 Val acc= 0.703050\n",
            "Epoch 86: Training loss= 1.099490 Val loss= 1.131122 Training acc= 0.703785 Val acc= 0.703980\n",
            "Epoch 87: Training loss= 1.090780 Val loss= 1.122528 Training acc= 0.704715 Val acc= 0.704810\n",
            "Epoch 88: Training loss= 1.082277 Val loss= 1.114132 Training acc= 0.705520 Val acc= 0.705545\n",
            "Epoch 89: Training loss= 1.073971 Val loss= 1.105924 Training acc= 0.706430 Val acc= 0.706120\n",
            "Epoch 90: Training loss= 1.065853 Val loss= 1.097896 Training acc= 0.707020 Val acc= 0.706860\n",
            "Epoch 91: Training loss= 1.057915 Val loss= 1.090040 Training acc= 0.707860 Val acc= 0.707435\n",
            "Epoch 92: Training loss= 1.050149 Val loss= 1.082350 Training acc= 0.708455 Val acc= 0.708105\n",
            "Epoch 93: Training loss= 1.042547 Val loss= 1.074818 Training acc= 0.709140 Val acc= 0.708880\n",
            "Epoch 94: Training loss= 1.035103 Val loss= 1.067439 Training acc= 0.709830 Val acc= 0.709405\n",
            "Epoch 95: Training loss= 1.027811 Val loss= 1.060205 Training acc= 0.710430 Val acc= 0.709960\n",
            "Epoch 96: Training loss= 1.020664 Val loss= 1.053112 Training acc= 0.711015 Val acc= 0.710555\n",
            "Epoch 97: Training loss= 1.013656 Val loss= 1.046155 Training acc= 0.711670 Val acc= 0.711230\n",
            "Epoch 98: Training loss= 1.006783 Val loss= 1.039327 Training acc= 0.712390 Val acc= 0.711790\n",
            "Epoch 99: Training loss= 1.000040 Val loss= 1.032626 Training acc= 0.712830 Val acc= 0.712370\n",
            "Epoch 100: Training loss= 0.993421 Val loss= 1.026046 Training acc= 0.713520 Val acc= 0.712975\n",
            "Epoch 101: Training loss= 0.986923 Val loss= 1.019583 Training acc= 0.714090 Val acc= 0.713350\n",
            "Epoch 102: Training loss= 0.980541 Val loss= 1.013235 Training acc= 0.714370 Val acc= 0.713955\n",
            "Epoch 103: Training loss= 0.974273 Val loss= 1.006996 Training acc= 0.714965 Val acc= 0.714420\n",
            "Epoch 104: Training loss= 0.968113 Val loss= 1.000864 Training acc= 0.715430 Val acc= 0.714950\n",
            "Epoch 105: Training loss= 0.962060 Val loss= 0.994836 Training acc= 0.715820 Val acc= 0.715465\n",
            "Epoch 106: Training loss= 0.956109 Val loss= 0.988909 Training acc= 0.716345 Val acc= 0.716045\n",
            "Epoch 107: Training loss= 0.950258 Val loss= 0.983079 Training acc= 0.716935 Val acc= 0.716515\n",
            "Epoch 108: Training loss= 0.944504 Val loss= 0.977345 Training acc= 0.717505 Val acc= 0.716990\n",
            "Epoch 109: Training loss= 0.938845 Val loss= 0.971704 Training acc= 0.718070 Val acc= 0.717420\n",
            "Epoch 110: Training loss= 0.933277 Val loss= 0.966153 Training acc= 0.718510 Val acc= 0.717840\n",
            "Epoch 111: Training loss= 0.927799 Val loss= 0.960690 Training acc= 0.718900 Val acc= 0.718150\n",
            "Epoch 112: Training loss= 0.922408 Val loss= 0.955314 Training acc= 0.719285 Val acc= 0.718365\n",
            "Epoch 113: Training loss= 0.917103 Val loss= 0.950022 Training acc= 0.719490 Val acc= 0.718715\n",
            "Epoch 114: Training loss= 0.911880 Val loss= 0.944812 Training acc= 0.719900 Val acc= 0.719260\n",
            "Epoch 115: Training loss= 0.906740 Val loss= 0.939682 Training acc= 0.720455 Val acc= 0.719690\n",
            "Epoch 116: Training loss= 0.901679 Val loss= 0.934632 Training acc= 0.720785 Val acc= 0.719990\n",
            "Epoch 117: Training loss= 0.896696 Val loss= 0.929658 Training acc= 0.721105 Val acc= 0.720235\n",
            "Epoch 118: Training loss= 0.891789 Val loss= 0.924761 Training acc= 0.721415 Val acc= 0.720660\n",
            "Epoch 119: Training loss= 0.886958 Val loss= 0.919937 Training acc= 0.721875 Val acc= 0.720935\n",
            "Epoch 120: Training loss= 0.882200 Val loss= 0.915187 Training acc= 0.722120 Val acc= 0.721350\n",
            "Epoch 121: Training loss= 0.877514 Val loss= 0.910508 Training acc= 0.722490 Val acc= 0.721670\n",
            "Epoch 122: Training loss= 0.872899 Val loss= 0.905899 Training acc= 0.722800 Val acc= 0.721940\n",
            "Epoch 123: Training loss= 0.868354 Val loss= 0.901359 Training acc= 0.723040 Val acc= 0.722185\n",
            "Epoch 124: Training loss= 0.863877 Val loss= 0.896888 Training acc= 0.723305 Val acc= 0.722415\n",
            "Epoch 125: Training loss= 0.859468 Val loss= 0.892483 Training acc= 0.723550 Val acc= 0.722720\n",
            "Epoch 126: Training loss= 0.855125 Val loss= 0.888144 Training acc= 0.723810 Val acc= 0.722975\n",
            "Epoch 127: Training loss= 0.850847 Val loss= 0.883869 Training acc= 0.724110 Val acc= 0.723190\n",
            "Epoch 128: Training loss= 0.846634 Val loss= 0.879658 Training acc= 0.724275 Val acc= 0.723325\n",
            "Epoch 129: Training loss= 0.842483 Val loss= 0.875509 Training acc= 0.724545 Val acc= 0.723655\n",
            "Epoch 130: Training loss= 0.838395 Val loss= 0.871423 Training acc= 0.724770 Val acc= 0.724070\n",
            "Epoch 131: Training loss= 0.834368 Val loss= 0.867396 Training acc= 0.725230 Val acc= 0.724385\n",
            "Epoch 132: Training loss= 0.830400 Val loss= 0.863430 Training acc= 0.725550 Val acc= 0.724720\n",
            "Epoch 133: Training loss= 0.826493 Val loss= 0.859522 Training acc= 0.725860 Val acc= 0.725140\n",
            "Epoch 134: Training loss= 0.822643 Val loss= 0.855671 Training acc= 0.726140 Val acc= 0.725360\n",
            "Epoch 135: Training loss= 0.818851 Val loss= 0.851878 Training acc= 0.726340 Val acc= 0.725560\n",
            "Epoch 136: Training loss= 0.815116 Val loss= 0.848140 Training acc= 0.726495 Val acc= 0.725800\n",
            "Epoch 137: Training loss= 0.811436 Val loss= 0.844458 Training acc= 0.726780 Val acc= 0.726055\n",
            "Epoch 138: Training loss= 0.807811 Val loss= 0.840829 Training acc= 0.727060 Val acc= 0.726280\n",
            "Epoch 139: Training loss= 0.804239 Val loss= 0.837254 Training acc= 0.727310 Val acc= 0.726505\n",
            "Epoch 140: Training loss= 0.800721 Val loss= 0.833730 Training acc= 0.727590 Val acc= 0.726680\n",
            "Epoch 141: Training loss= 0.797254 Val loss= 0.830259 Training acc= 0.727865 Val acc= 0.726835\n",
            "Epoch 142: Training loss= 0.793839 Val loss= 0.826837 Training acc= 0.728050 Val acc= 0.727175\n",
            "Epoch 143: Training loss= 0.790474 Val loss= 0.823465 Training acc= 0.728365 Val acc= 0.727495\n",
            "Epoch 144: Training loss= 0.787159 Val loss= 0.820142 Training acc= 0.728660 Val acc= 0.727760\n",
            "Epoch 145: Training loss= 0.783892 Val loss= 0.816867 Training acc= 0.728940 Val acc= 0.728055\n",
            "Epoch 146: Training loss= 0.780673 Val loss= 0.813640 Training acc= 0.729240 Val acc= 0.728385\n",
            "Epoch 147: Training loss= 0.777502 Val loss= 0.810459 Training acc= 0.729540 Val acc= 0.728580\n",
            "Epoch 148: Training loss= 0.774377 Val loss= 0.807323 Training acc= 0.729780 Val acc= 0.728730\n",
            "Epoch 149: Training loss= 0.771298 Val loss= 0.804233 Training acc= 0.729960 Val acc= 0.728955\n",
            "Epoch 150: Training loss= 0.768263 Val loss= 0.801187 Training acc= 0.730210 Val acc= 0.729185\n",
            "Epoch 151: Training loss= 0.765273 Val loss= 0.798185 Training acc= 0.730445 Val acc= 0.729270\n",
            "Epoch 152: Training loss= 0.762327 Val loss= 0.795225 Training acc= 0.730515 Val acc= 0.729645\n",
            "Epoch 153: Training loss= 0.759424 Val loss= 0.792308 Training acc= 0.730795 Val acc= 0.729825\n",
            "Epoch 154: Training loss= 0.756563 Val loss= 0.789433 Training acc= 0.730985 Val acc= 0.729980\n",
            "Epoch 155: Training loss= 0.753743 Val loss= 0.786599 Training acc= 0.731180 Val acc= 0.730290\n",
            "Epoch 156: Training loss= 0.750965 Val loss= 0.783805 Training acc= 0.731535 Val acc= 0.730510\n",
            "Epoch 157: Training loss= 0.748227 Val loss= 0.781051 Training acc= 0.731650 Val acc= 0.730740\n",
            "Epoch 158: Training loss= 0.745528 Val loss= 0.778336 Training acc= 0.731915 Val acc= 0.730985\n",
            "Epoch 159: Training loss= 0.742869 Val loss= 0.775660 Training acc= 0.732100 Val acc= 0.731315\n",
            "Epoch 160: Training loss= 0.740249 Val loss= 0.773021 Training acc= 0.732405 Val acc= 0.731580\n",
            "Epoch 161: Training loss= 0.737666 Val loss= 0.770420 Training acc= 0.732670 Val acc= 0.731765\n",
            "Epoch 162: Training loss= 0.735121 Val loss= 0.767856 Training acc= 0.732795 Val acc= 0.731980\n",
            "Epoch 163: Training loss= 0.732613 Val loss= 0.765327 Training acc= 0.733150 Val acc= 0.732090\n",
            "Epoch 164: Training loss= 0.730141 Val loss= 0.762835 Training acc= 0.733280 Val acc= 0.732135\n",
            "Epoch 165: Training loss= 0.727704 Val loss= 0.760377 Training acc= 0.733325 Val acc= 0.732290\n",
            "Epoch 166: Training loss= 0.725302 Val loss= 0.757953 Training acc= 0.733540 Val acc= 0.732560\n",
            "Epoch 167: Training loss= 0.722935 Val loss= 0.755563 Training acc= 0.733810 Val acc= 0.732785\n",
            "Epoch 168: Training loss= 0.720601 Val loss= 0.753207 Training acc= 0.734035 Val acc= 0.733055\n",
            "Epoch 169: Training loss= 0.718301 Val loss= 0.750882 Training acc= 0.734300 Val acc= 0.733110\n",
            "Epoch 170: Training loss= 0.716033 Val loss= 0.748590 Training acc= 0.734440 Val acc= 0.733270\n",
            "Epoch 171: Training loss= 0.713797 Val loss= 0.746330 Training acc= 0.734605 Val acc= 0.733475\n",
            "Epoch 172: Training loss= 0.711593 Val loss= 0.744100 Training acc= 0.734800 Val acc= 0.733750\n",
            "Epoch 173: Training loss= 0.709420 Val loss= 0.741902 Training acc= 0.735095 Val acc= 0.734085\n",
            "Epoch 174: Training loss= 0.707277 Val loss= 0.739734 Training acc= 0.735330 Val acc= 0.734240\n",
            "Epoch 175: Training loss= 0.705165 Val loss= 0.737596 Training acc= 0.735390 Val acc= 0.734440\n",
            "Epoch 176: Training loss= 0.703083 Val loss= 0.735487 Training acc= 0.735635 Val acc= 0.734680\n",
            "Epoch 177: Training loss= 0.701030 Val loss= 0.733408 Training acc= 0.735850 Val acc= 0.734965\n",
            "Epoch 178: Training loss= 0.699007 Val loss= 0.731357 Training acc= 0.736065 Val acc= 0.735230\n",
            "Epoch 179: Training loss= 0.697012 Val loss= 0.729335 Training acc= 0.736350 Val acc= 0.735500\n",
            "Epoch 180: Training loss= 0.695045 Val loss= 0.727341 Training acc= 0.736645 Val acc= 0.735705\n",
            "Epoch 181: Training loss= 0.693106 Val loss= 0.725374 Training acc= 0.736925 Val acc= 0.735900\n",
            "Epoch 182: Training loss= 0.691195 Val loss= 0.723434 Training acc= 0.737035 Val acc= 0.736155\n",
            "Epoch 183: Training loss= 0.689310 Val loss= 0.721520 Training acc= 0.737320 Val acc= 0.736350\n",
            "Epoch 184: Training loss= 0.687452 Val loss= 0.719633 Training acc= 0.737540 Val acc= 0.736710\n",
            "Epoch 185: Training loss= 0.685620 Val loss= 0.717770 Training acc= 0.737850 Val acc= 0.736895\n",
            "Epoch 186: Training loss= 0.683813 Val loss= 0.715933 Training acc= 0.738120 Val acc= 0.737110\n",
            "Epoch 187: Training loss= 0.682031 Val loss= 0.714121 Training acc= 0.738275 Val acc= 0.737300\n",
            "Epoch 188: Training loss= 0.680274 Val loss= 0.712333 Training acc= 0.738475 Val acc= 0.737465\n",
            "Epoch 189: Training loss= 0.678541 Val loss= 0.710568 Training acc= 0.738665 Val acc= 0.737645\n",
            "Epoch 190: Training loss= 0.676831 Val loss= 0.708827 Training acc= 0.738890 Val acc= 0.737790\n",
            "Epoch 191: Training loss= 0.675145 Val loss= 0.707109 Training acc= 0.739105 Val acc= 0.738000\n",
            "Epoch 192: Training loss= 0.673482 Val loss= 0.705413 Training acc= 0.739380 Val acc= 0.738205\n",
            "Epoch 193: Training loss= 0.671842 Val loss= 0.703739 Training acc= 0.739605 Val acc= 0.738450\n",
            "Epoch 194: Training loss= 0.670224 Val loss= 0.702088 Training acc= 0.739750 Val acc= 0.738585\n",
            "Epoch 195: Training loss= 0.668627 Val loss= 0.700457 Training acc= 0.739935 Val acc= 0.738735\n",
            "Epoch 196: Training loss= 0.667052 Val loss= 0.698848 Training acc= 0.740150 Val acc= 0.739005\n",
            "Epoch 197: Training loss= 0.665497 Val loss= 0.697259 Training acc= 0.740455 Val acc= 0.739270\n",
            "Epoch 198: Training loss= 0.663963 Val loss= 0.695690 Training acc= 0.740645 Val acc= 0.739425\n",
            "Epoch 199: Training loss= 0.662450 Val loss= 0.694141 Training acc= 0.740825 Val acc= 0.739555\n",
            "Epoch 200: Training loss= 0.660956 Val loss= 0.692611 Training acc= 0.740965 Val acc= 0.739730\n",
            "Epoch 201: Training loss= 0.659481 Val loss= 0.691101 Training acc= 0.741155 Val acc= 0.739985\n",
            "Epoch 202: Training loss= 0.658025 Val loss= 0.689609 Training acc= 0.741370 Val acc= 0.740195\n",
            "Epoch 203: Training loss= 0.656589 Val loss= 0.688136 Training acc= 0.741600 Val acc= 0.740355\n",
            "Epoch 204: Training loss= 0.655170 Val loss= 0.686681 Training acc= 0.741780 Val acc= 0.740625\n",
            "Epoch 205: Training loss= 0.653769 Val loss= 0.685244 Training acc= 0.742005 Val acc= 0.740975\n",
            "Epoch 206: Training loss= 0.652386 Val loss= 0.683824 Training acc= 0.742260 Val acc= 0.741220\n",
            "Epoch 207: Training loss= 0.651020 Val loss= 0.682421 Training acc= 0.742545 Val acc= 0.741450\n",
            "Epoch 208: Training loss= 0.649671 Val loss= 0.681035 Training acc= 0.742780 Val acc= 0.741635\n",
            "Epoch 209: Training loss= 0.648339 Val loss= 0.679665 Training acc= 0.742965 Val acc= 0.741845\n",
            "Epoch 210: Training loss= 0.647023 Val loss= 0.678311 Training acc= 0.743240 Val acc= 0.742065\n",
            "Epoch 211: Training loss= 0.645723 Val loss= 0.676974 Training acc= 0.743420 Val acc= 0.742100\n",
            "Epoch 212: Training loss= 0.644438 Val loss= 0.675651 Training acc= 0.743485 Val acc= 0.742180\n",
            "Epoch 213: Training loss= 0.643169 Val loss= 0.674344 Training acc= 0.743625 Val acc= 0.742445\n",
            "Epoch 214: Training loss= 0.641915 Val loss= 0.673052 Training acc= 0.743910 Val acc= 0.742610\n",
            "Epoch 215: Training loss= 0.640676 Val loss= 0.671774 Training acc= 0.744130 Val acc= 0.742815\n",
            "Epoch 216: Training loss= 0.639451 Val loss= 0.670511 Training acc= 0.744365 Val acc= 0.742960\n",
            "Epoch 217: Training loss= 0.638241 Val loss= 0.669261 Training acc= 0.744515 Val acc= 0.743230\n",
            "Epoch 218: Training loss= 0.637045 Val loss= 0.668026 Training acc= 0.744795 Val acc= 0.743445\n",
            "Epoch 219: Training loss= 0.635862 Val loss= 0.666804 Training acc= 0.744970 Val acc= 0.743680\n",
            "Epoch 220: Training loss= 0.634693 Val loss= 0.665596 Training acc= 0.745170 Val acc= 0.743860\n",
            "Epoch 221: Training loss= 0.633538 Val loss= 0.664400 Training acc= 0.745375 Val acc= 0.744040\n",
            "Epoch 222: Training loss= 0.632395 Val loss= 0.663218 Training acc= 0.745620 Val acc= 0.744265\n",
            "Epoch 223: Training loss= 0.631265 Val loss= 0.662048 Training acc= 0.745835 Val acc= 0.744605\n",
            "Epoch 224: Training loss= 0.630148 Val loss= 0.660891 Training acc= 0.746125 Val acc= 0.744790\n",
            "Epoch 225: Training loss= 0.629043 Val loss= 0.659746 Training acc= 0.746315 Val acc= 0.745010\n",
            "Epoch 226: Training loss= 0.627951 Val loss= 0.658613 Training acc= 0.746565 Val acc= 0.745185\n",
            "Epoch 227: Training loss= 0.626870 Val loss= 0.657492 Training acc= 0.746725 Val acc= 0.745355\n",
            "Epoch 228: Training loss= 0.625802 Val loss= 0.656382 Training acc= 0.746875 Val acc= 0.745570\n",
            "Epoch 229: Training loss= 0.624745 Val loss= 0.655284 Training acc= 0.747085 Val acc= 0.745730\n",
            "Epoch 230: Training loss= 0.623699 Val loss= 0.654198 Training acc= 0.747245 Val acc= 0.745940\n",
            "Epoch 231: Training loss= 0.622665 Val loss= 0.653122 Training acc= 0.747455 Val acc= 0.746150\n",
            "Epoch 232: Training loss= 0.621641 Val loss= 0.652058 Training acc= 0.747645 Val acc= 0.746285\n",
            "Epoch 233: Training loss= 0.620629 Val loss= 0.651004 Training acc= 0.747795 Val acc= 0.746410\n",
            "Epoch 234: Training loss= 0.619628 Val loss= 0.649961 Training acc= 0.747900 Val acc= 0.746545\n",
            "Epoch 235: Training loss= 0.618637 Val loss= 0.648929 Training acc= 0.748030 Val acc= 0.746750\n",
            "Epoch 236: Training loss= 0.617657 Val loss= 0.647907 Training acc= 0.748245 Val acc= 0.746835\n",
            "Epoch 237: Training loss= 0.616687 Val loss= 0.646896 Training acc= 0.748320 Val acc= 0.747105\n",
            "Epoch 238: Training loss= 0.615728 Val loss= 0.645895 Training acc= 0.748515 Val acc= 0.747385\n",
            "Epoch 239: Training loss= 0.614779 Val loss= 0.644904 Training acc= 0.748735 Val acc= 0.747545\n",
            "Epoch 240: Training loss= 0.613840 Val loss= 0.643923 Training acc= 0.748890 Val acc= 0.747770\n",
            "Epoch 241: Training loss= 0.612911 Val loss= 0.642952 Training acc= 0.749095 Val acc= 0.747910\n",
            "Epoch 242: Training loss= 0.611992 Val loss= 0.641991 Training acc= 0.749225 Val acc= 0.748105\n",
            "Epoch 243: Training loss= 0.611082 Val loss= 0.641040 Training acc= 0.749460 Val acc= 0.748355\n",
            "Epoch 244: Training loss= 0.610182 Val loss= 0.640098 Training acc= 0.749695 Val acc= 0.748520\n",
            "Epoch 245: Training loss= 0.609292 Val loss= 0.639165 Training acc= 0.749815 Val acc= 0.748740\n",
            "Epoch 246: Training loss= 0.608411 Val loss= 0.638242 Training acc= 0.750045 Val acc= 0.748885\n",
            "Epoch 247: Training loss= 0.607540 Val loss= 0.637328 Training acc= 0.750190 Val acc= 0.748980\n",
            "Epoch 248: Training loss= 0.606677 Val loss= 0.636423 Training acc= 0.750320 Val acc= 0.749065\n",
            "Epoch 249: Training loss= 0.605824 Val loss= 0.635527 Training acc= 0.750405 Val acc= 0.749195\n",
            "Epoch 250: Training loss= 0.604979 Val loss= 0.634640 Training acc= 0.750500 Val acc= 0.749400\n",
            "Epoch 251: Training loss= 0.604144 Val loss= 0.633762 Training acc= 0.750685 Val acc= 0.749540\n",
            "Epoch 252: Training loss= 0.603317 Val loss= 0.632892 Training acc= 0.750835 Val acc= 0.749710\n",
            "Epoch 253: Training loss= 0.602499 Val loss= 0.632031 Training acc= 0.750975 Val acc= 0.749825\n",
            "Epoch 254: Training loss= 0.601690 Val loss= 0.631178 Training acc= 0.751110 Val acc= 0.749945\n",
            "Epoch 255: Training loss= 0.600888 Val loss= 0.630333 Training acc= 0.751230 Val acc= 0.750065\n",
            "Epoch 256: Training loss= 0.600095 Val loss= 0.629496 Training acc= 0.751320 Val acc= 0.750180\n",
            "Epoch 257: Training loss= 0.599311 Val loss= 0.628667 Training acc= 0.751425 Val acc= 0.750345\n",
            "Epoch 258: Training loss= 0.598534 Val loss= 0.627846 Training acc= 0.751590 Val acc= 0.750505\n",
            "Epoch 259: Training loss= 0.597765 Val loss= 0.627033 Training acc= 0.751810 Val acc= 0.750610\n",
            "Epoch 260: Training loss= 0.597004 Val loss= 0.626227 Training acc= 0.751905 Val acc= 0.750780\n",
            "Epoch 261: Training loss= 0.596250 Val loss= 0.625429 Training acc= 0.752080 Val acc= 0.750805\n",
            "Epoch 262: Training loss= 0.595503 Val loss= 0.624638 Training acc= 0.752115 Val acc= 0.750930\n",
            "Epoch 263: Training loss= 0.594764 Val loss= 0.623854 Training acc= 0.752245 Val acc= 0.751170\n",
            "Epoch 264: Training loss= 0.594032 Val loss= 0.623077 Training acc= 0.752480 Val acc= 0.751335\n",
            "Epoch 265: Training loss= 0.593306 Val loss= 0.622307 Training acc= 0.752640 Val acc= 0.751565\n",
            "Epoch 266: Training loss= 0.592588 Val loss= 0.621544 Training acc= 0.752780 Val acc= 0.751680\n",
            "Epoch 267: Training loss= 0.591876 Val loss= 0.620787 Training acc= 0.752865 Val acc= 0.751815\n",
            "Epoch 268: Training loss= 0.591171 Val loss= 0.620038 Training acc= 0.753050 Val acc= 0.751985\n",
            "Epoch 269: Training loss= 0.590472 Val loss= 0.619295 Training acc= 0.753190 Val acc= 0.752125\n",
            "Epoch 270: Training loss= 0.589780 Val loss= 0.618558 Training acc= 0.753325 Val acc= 0.752275\n",
            "Epoch 271: Training loss= 0.589095 Val loss= 0.617828 Training acc= 0.753475 Val acc= 0.752430\n",
            "Epoch 272: Training loss= 0.588415 Val loss= 0.617105 Training acc= 0.753620 Val acc= 0.752595\n",
            "Epoch 273: Training loss= 0.587743 Val loss= 0.616388 Training acc= 0.753790 Val acc= 0.752745\n",
            "Epoch 274: Training loss= 0.587076 Val loss= 0.615677 Training acc= 0.753955 Val acc= 0.752890\n",
            "Epoch 275: Training loss= 0.586415 Val loss= 0.614973 Training acc= 0.754145 Val acc= 0.753040\n",
            "Epoch 276: Training loss= 0.585761 Val loss= 0.614275 Training acc= 0.754300 Val acc= 0.753105\n",
            "Epoch 277: Training loss= 0.585113 Val loss= 0.613583 Training acc= 0.754445 Val acc= 0.753255\n",
            "Epoch 278: Training loss= 0.584471 Val loss= 0.612897 Training acc= 0.754635 Val acc= 0.753345\n",
            "Epoch 279: Training loss= 0.583835 Val loss= 0.612217 Training acc= 0.754695 Val acc= 0.753475\n",
            "Epoch 280: Training loss= 0.583205 Val loss= 0.611543 Training acc= 0.754830 Val acc= 0.753590\n",
            "Epoch 281: Training loss= 0.582581 Val loss= 0.610875 Training acc= 0.754960 Val acc= 0.753750\n",
            "Epoch 282: Training loss= 0.581962 Val loss= 0.610213 Training acc= 0.755105 Val acc= 0.753890\n",
            "Epoch 283: Training loss= 0.581349 Val loss= 0.609557 Training acc= 0.755280 Val acc= 0.754035\n",
            "Epoch 284: Training loss= 0.580742 Val loss= 0.608906 Training acc= 0.755505 Val acc= 0.754185\n",
            "Epoch 285: Training loss= 0.580140 Val loss= 0.608260 Training acc= 0.755640 Val acc= 0.754320\n",
            "Epoch 286: Training loss= 0.579544 Val loss= 0.607620 Training acc= 0.755730 Val acc= 0.754430\n",
            "Epoch 287: Training loss= 0.578952 Val loss= 0.606985 Training acc= 0.755860 Val acc= 0.754680\n",
            "Epoch 288: Training loss= 0.578366 Val loss= 0.606356 Training acc= 0.756110 Val acc= 0.754800\n",
            "Epoch 289: Training loss= 0.577785 Val loss= 0.605732 Training acc= 0.756135 Val acc= 0.754810\n",
            "Epoch 290: Training loss= 0.577209 Val loss= 0.605113 Training acc= 0.756130 Val acc= 0.754870\n",
            "Epoch 291: Training loss= 0.576638 Val loss= 0.604499 Training acc= 0.756170 Val acc= 0.754925\n",
            "Epoch 292: Training loss= 0.576072 Val loss= 0.603889 Training acc= 0.756255 Val acc= 0.755100\n",
            "Epoch 293: Training loss= 0.575511 Val loss= 0.603285 Training acc= 0.756480 Val acc= 0.755235\n",
            "Epoch 294: Training loss= 0.574955 Val loss= 0.602686 Training acc= 0.756605 Val acc= 0.755440\n",
            "Epoch 295: Training loss= 0.574403 Val loss= 0.602092 Training acc= 0.756840 Val acc= 0.755505\n",
            "Epoch 296: Training loss= 0.573856 Val loss= 0.601502 Training acc= 0.756890 Val acc= 0.755565\n",
            "Epoch 297: Training loss= 0.573314 Val loss= 0.600918 Training acc= 0.756950 Val acc= 0.755710\n",
            "Epoch 298: Training loss= 0.572777 Val loss= 0.600338 Training acc= 0.757015 Val acc= 0.755785\n",
            "Epoch 299: Training loss= 0.572244 Val loss= 0.599762 Training acc= 0.757080 Val acc= 0.755945\n",
            "Epoch 300: Training loss= 0.571716 Val loss= 0.599192 Training acc= 0.757210 Val acc= 0.756030\n",
            "Epoch 301: Training loss= 0.571192 Val loss= 0.598626 Training acc= 0.757275 Val acc= 0.756145\n",
            "Epoch 302: Training loss= 0.570673 Val loss= 0.598065 Training acc= 0.757410 Val acc= 0.756260\n",
            "Epoch 303: Training loss= 0.570158 Val loss= 0.597509 Training acc= 0.757565 Val acc= 0.756310\n",
            "Epoch 304: Training loss= 0.569648 Val loss= 0.596957 Training acc= 0.757615 Val acc= 0.756455\n",
            "Epoch 305: Training loss= 0.569142 Val loss= 0.596410 Training acc= 0.757715 Val acc= 0.756520\n",
            "Epoch 306: Training loss= 0.568641 Val loss= 0.595867 Training acc= 0.757750 Val acc= 0.756640\n",
            "Epoch 307: Training loss= 0.568144 Val loss= 0.595330 Training acc= 0.757875 Val acc= 0.756735\n",
            "Epoch 308: Training loss= 0.567651 Val loss= 0.594796 Training acc= 0.757945 Val acc= 0.756850\n",
            "Epoch 309: Training loss= 0.567163 Val loss= 0.594267 Training acc= 0.758045 Val acc= 0.756925\n",
            "Epoch 310: Training loss= 0.566679 Val loss= 0.593743 Training acc= 0.758095 Val acc= 0.757040\n",
            "Epoch 311: Training loss= 0.566199 Val loss= 0.593223 Training acc= 0.758130 Val acc= 0.757100\n",
            "Epoch 312: Training loss= 0.565724 Val loss= 0.592708 Training acc= 0.758130 Val acc= 0.757195\n",
            "Epoch 313: Training loss= 0.565252 Val loss= 0.592197 Training acc= 0.758280 Val acc= 0.757355\n",
            "Epoch 314: Training loss= 0.564785 Val loss= 0.591690 Training acc= 0.758440 Val acc= 0.757445\n",
            "Epoch 315: Training loss= 0.564322 Val loss= 0.591188 Training acc= 0.758550 Val acc= 0.757405\n",
            "Epoch 316: Training loss= 0.563863 Val loss= 0.590689 Training acc= 0.758580 Val acc= 0.757545\n",
            "Epoch 317: Training loss= 0.563407 Val loss= 0.590195 Training acc= 0.758680 Val acc= 0.757680\n",
            "Epoch 318: Training loss= 0.562956 Val loss= 0.589704 Training acc= 0.758735 Val acc= 0.757800\n",
            "Epoch 319: Training loss= 0.562508 Val loss= 0.589218 Training acc= 0.758840 Val acc= 0.757930\n",
            "Epoch 320: Training loss= 0.562064 Val loss= 0.588735 Training acc= 0.758985 Val acc= 0.757945\n",
            "Epoch 321: Training loss= 0.561624 Val loss= 0.588256 Training acc= 0.759045 Val acc= 0.758035\n",
            "Epoch 322: Training loss= 0.561188 Val loss= 0.587781 Training acc= 0.759165 Val acc= 0.758140\n",
            "Epoch 323: Training loss= 0.560755 Val loss= 0.587310 Training acc= 0.759270 Val acc= 0.758200\n",
            "Epoch 324: Training loss= 0.560326 Val loss= 0.586842 Training acc= 0.759360 Val acc= 0.758335\n",
            "Epoch 325: Training loss= 0.559900 Val loss= 0.586377 Training acc= 0.759490 Val acc= 0.758515\n",
            "Epoch 326: Training loss= 0.559477 Val loss= 0.585917 Training acc= 0.759595 Val acc= 0.758560\n",
            "Epoch 327: Training loss= 0.559058 Val loss= 0.585459 Training acc= 0.759690 Val acc= 0.758655\n",
            "Epoch 328: Training loss= 0.558643 Val loss= 0.585005 Training acc= 0.759755 Val acc= 0.758750\n",
            "Epoch 329: Training loss= 0.558231 Val loss= 0.584555 Training acc= 0.759805 Val acc= 0.758880\n",
            "Epoch 330: Training loss= 0.557822 Val loss= 0.584108 Training acc= 0.759955 Val acc= 0.758985\n",
            "Epoch 331: Training loss= 0.557416 Val loss= 0.583664 Training acc= 0.760055 Val acc= 0.759055\n",
            "Epoch 332: Training loss= 0.557013 Val loss= 0.583223 Training acc= 0.760130 Val acc= 0.759195\n",
            "Epoch 333: Training loss= 0.556614 Val loss= 0.582786 Training acc= 0.760320 Val acc= 0.759245\n",
            "Epoch 334: Training loss= 0.556218 Val loss= 0.582352 Training acc= 0.760415 Val acc= 0.759340\n",
            "Epoch 335: Training loss= 0.555825 Val loss= 0.581921 Training acc= 0.760510 Val acc= 0.759460\n",
            "Epoch 336: Training loss= 0.555435 Val loss= 0.581493 Training acc= 0.760610 Val acc= 0.759585\n",
            "Epoch 337: Training loss= 0.555049 Val loss= 0.581068 Training acc= 0.760725 Val acc= 0.759600\n",
            "Epoch 338: Training loss= 0.554666 Val loss= 0.580647 Training acc= 0.760755 Val acc= 0.759610\n",
            "Epoch 339: Training loss= 0.554286 Val loss= 0.580229 Training acc= 0.760770 Val acc= 0.759700\n",
            "Epoch 340: Training loss= 0.553909 Val loss= 0.579813 Training acc= 0.760870 Val acc= 0.759830\n",
            "Epoch 341: Training loss= 0.553535 Val loss= 0.579401 Training acc= 0.760990 Val acc= 0.759885\n",
            "Epoch 342: Training loss= 0.553164 Val loss= 0.578992 Training acc= 0.761045 Val acc= 0.759965\n",
            "Epoch 343: Training loss= 0.552796 Val loss= 0.578586 Training acc= 0.761115 Val acc= 0.760100\n",
            "Epoch 344: Training loss= 0.552432 Val loss= 0.578183 Training acc= 0.761250 Val acc= 0.760170\n",
            "Epoch 345: Training loss= 0.552070 Val loss= 0.577782 Training acc= 0.761380 Val acc= 0.760220\n",
            "Epoch 346: Training loss= 0.551711 Val loss= 0.577385 Training acc= 0.761390 Val acc= 0.760275\n",
            "Epoch 347: Training loss= 0.551355 Val loss= 0.576990 Training acc= 0.761425 Val acc= 0.760395\n",
            "Epoch 348: Training loss= 0.551002 Val loss= 0.576599 Training acc= 0.761565 Val acc= 0.760570\n",
            "Epoch 349: Training loss= 0.550652 Val loss= 0.576210 Training acc= 0.761730 Val acc= 0.760630\n",
            "Epoch 350: Training loss= 0.550305 Val loss= 0.575824 Training acc= 0.761830 Val acc= 0.760720\n",
            "Epoch 351: Training loss= 0.549960 Val loss= 0.575441 Training acc= 0.761865 Val acc= 0.760795\n",
            "Epoch 352: Training loss= 0.549619 Val loss= 0.575061 Training acc= 0.761865 Val acc= 0.760895\n",
            "Epoch 353: Training loss= 0.549280 Val loss= 0.574683 Training acc= 0.761915 Val acc= 0.761010\n",
            "Epoch 354: Training loss= 0.548944 Val loss= 0.574308 Training acc= 0.762060 Val acc= 0.761140\n",
            "Epoch 355: Training loss= 0.548610 Val loss= 0.573936 Training acc= 0.762190 Val acc= 0.761310\n",
            "Epoch 356: Training loss= 0.548280 Val loss= 0.573567 Training acc= 0.762350 Val acc= 0.761355\n",
            "Epoch 357: Training loss= 0.547951 Val loss= 0.573200 Training acc= 0.762385 Val acc= 0.761470\n",
            "Epoch 358: Training loss= 0.547626 Val loss= 0.572836 Training acc= 0.762480 Val acc= 0.761615\n",
            "Epoch 359: Training loss= 0.547302 Val loss= 0.572474 Training acc= 0.762595 Val acc= 0.761625\n",
            "Epoch 360: Training loss= 0.546982 Val loss= 0.572115 Training acc= 0.762620 Val acc= 0.761630\n",
            "Epoch 361: Training loss= 0.546663 Val loss= 0.571758 Training acc= 0.762620 Val acc= 0.761720\n",
            "Epoch 362: Training loss= 0.546348 Val loss= 0.571404 Training acc= 0.762690 Val acc= 0.761730\n",
            "Epoch 363: Training loss= 0.546034 Val loss= 0.571053 Training acc= 0.762700 Val acc= 0.761850\n",
            "Epoch 364: Training loss= 0.545723 Val loss= 0.570703 Training acc= 0.762805 Val acc= 0.761935\n",
            "Epoch 365: Training loss= 0.545414 Val loss= 0.570357 Training acc= 0.762895 Val acc= 0.761975\n",
            "Epoch 366: Training loss= 0.545108 Val loss= 0.570012 Training acc= 0.762970 Val acc= 0.762090\n",
            "Epoch 367: Training loss= 0.544804 Val loss= 0.569671 Training acc= 0.763100 Val acc= 0.762200\n",
            "Epoch 368: Training loss= 0.544502 Val loss= 0.569331 Training acc= 0.763225 Val acc= 0.762310\n",
            "Epoch 369: Training loss= 0.544202 Val loss= 0.568994 Training acc= 0.763300 Val acc= 0.762320\n",
            "Epoch 370: Training loss= 0.543905 Val loss= 0.568660 Training acc= 0.763295 Val acc= 0.762400\n",
            "Epoch 371: Training loss= 0.543610 Val loss= 0.568327 Training acc= 0.763390 Val acc= 0.762500\n",
            "Epoch 372: Training loss= 0.543318 Val loss= 0.567998 Training acc= 0.763485 Val acc= 0.762610\n",
            "Epoch 373: Training loss= 0.543028 Val loss= 0.567671 Training acc= 0.763600 Val acc= 0.762735\n",
            "Epoch 374: Training loss= 0.542740 Val loss= 0.567346 Training acc= 0.763725 Val acc= 0.762815\n",
            "Epoch 375: Training loss= 0.542454 Val loss= 0.567024 Training acc= 0.763775 Val acc= 0.762885\n",
            "Epoch 376: Training loss= 0.542171 Val loss= 0.566704 Training acc= 0.763865 Val acc= 0.762925\n",
            "Epoch 377: Training loss= 0.541890 Val loss= 0.566386 Training acc= 0.763945 Val acc= 0.762995\n",
            "Epoch 378: Training loss= 0.541611 Val loss= 0.566071 Training acc= 0.764005 Val acc= 0.763100\n",
            "Epoch 379: Training loss= 0.541334 Val loss= 0.565757 Training acc= 0.764120 Val acc= 0.763180\n",
            "Epoch 380: Training loss= 0.541059 Val loss= 0.565446 Training acc= 0.764195 Val acc= 0.763230\n",
            "Epoch 381: Training loss= 0.540786 Val loss= 0.565137 Training acc= 0.764225 Val acc= 0.763315\n",
            "Epoch 382: Training loss= 0.540515 Val loss= 0.564830 Training acc= 0.764300 Val acc= 0.763355\n",
            "Epoch 383: Training loss= 0.540245 Val loss= 0.564524 Training acc= 0.764355 Val acc= 0.763425\n",
            "Epoch 384: Training loss= 0.539978 Val loss= 0.564221 Training acc= 0.764430 Val acc= 0.763485\n",
            "Epoch 385: Training loss= 0.539712 Val loss= 0.563920 Training acc= 0.764510 Val acc= 0.763565\n",
            "Epoch 386: Training loss= 0.539449 Val loss= 0.563621 Training acc= 0.764630 Val acc= 0.763630\n",
            "Epoch 387: Training loss= 0.539187 Val loss= 0.563323 Training acc= 0.764700 Val acc= 0.763675\n",
            "Epoch 388: Training loss= 0.538927 Val loss= 0.563028 Training acc= 0.764705 Val acc= 0.763755\n",
            "Epoch 389: Training loss= 0.538668 Val loss= 0.562735 Training acc= 0.764820 Val acc= 0.763800\n",
            "Epoch 390: Training loss= 0.538412 Val loss= 0.562444 Training acc= 0.764875 Val acc= 0.763880\n",
            "Epoch 391: Training loss= 0.538158 Val loss= 0.562155 Training acc= 0.764950 Val acc= 0.763955\n",
            "Epoch 392: Training loss= 0.537905 Val loss= 0.561867 Training acc= 0.765025 Val acc= 0.764020\n",
            "Epoch 393: Training loss= 0.537655 Val loss= 0.561582 Training acc= 0.765110 Val acc= 0.764025\n",
            "Epoch 394: Training loss= 0.537406 Val loss= 0.561299 Training acc= 0.765110 Val acc= 0.764140\n",
            "Epoch 395: Training loss= 0.537159 Val loss= 0.561018 Training acc= 0.765220 Val acc= 0.764260\n",
            "Epoch 396: Training loss= 0.536914 Val loss= 0.560739 Training acc= 0.765325 Val acc= 0.764340\n",
            "Epoch 397: Training loss= 0.536671 Val loss= 0.560462 Training acc= 0.765380 Val acc= 0.764450\n",
            "Epoch 398: Training loss= 0.536430 Val loss= 0.560186 Training acc= 0.765540 Val acc= 0.764500\n",
            "Epoch 399: Training loss= 0.536190 Val loss= 0.559913 Training acc= 0.765570 Val acc= 0.764550\n",
            "Epoch 400: Training loss= 0.535952 Val loss= 0.559641 Training acc= 0.765605 Val acc= 0.764540\n",
            "Epoch 401: Training loss= 0.535716 Val loss= 0.559372 Training acc= 0.765545 Val acc= 0.764605\n",
            "Epoch 402: Training loss= 0.535482 Val loss= 0.559104 Training acc= 0.765605 Val acc= 0.764665\n",
            "Epoch 403: Training loss= 0.535250 Val loss= 0.558837 Training acc= 0.765685 Val acc= 0.764690\n",
            "Epoch 404: Training loss= 0.535019 Val loss= 0.558573 Training acc= 0.765730 Val acc= 0.764745\n",
            "Epoch 405: Training loss= 0.534790 Val loss= 0.558311 Training acc= 0.765790 Val acc= 0.764850\n",
            "Epoch 406: Training loss= 0.534563 Val loss= 0.558050 Training acc= 0.765910 Val acc= 0.764905\n",
            "Epoch 407: Training loss= 0.534338 Val loss= 0.557791 Training acc= 0.766000 Val acc= 0.764935\n",
            "Epoch 408: Training loss= 0.534114 Val loss= 0.557534 Training acc= 0.766025 Val acc= 0.764930\n",
            "Epoch 409: Training loss= 0.533892 Val loss= 0.557279 Training acc= 0.766075 Val acc= 0.764980\n",
            "Epoch 410: Training loss= 0.533672 Val loss= 0.557025 Training acc= 0.766120 Val acc= 0.764990\n",
            "Epoch 411: Training loss= 0.533454 Val loss= 0.556774 Training acc= 0.766110 Val acc= 0.765125\n",
            "Epoch 412: Training loss= 0.533237 Val loss= 0.556524 Training acc= 0.766215 Val acc= 0.765220\n",
            "Epoch 413: Training loss= 0.533023 Val loss= 0.556276 Training acc= 0.766295 Val acc= 0.765285\n",
            "Epoch 414: Training loss= 0.532809 Val loss= 0.556029 Training acc= 0.766390 Val acc= 0.765325\n",
            "Epoch 415: Training loss= 0.532598 Val loss= 0.555784 Training acc= 0.766440 Val acc= 0.765390\n",
            "Epoch 416: Training loss= 0.532388 Val loss= 0.555541 Training acc= 0.766490 Val acc= 0.765425\n",
            "Epoch 417: Training loss= 0.532180 Val loss= 0.555300 Training acc= 0.766555 Val acc= 0.765445\n",
            "Epoch 418: Training loss= 0.531973 Val loss= 0.555059 Training acc= 0.766565 Val acc= 0.765480\n",
            "Epoch 419: Training loss= 0.531768 Val loss= 0.554821 Training acc= 0.766600 Val acc= 0.765530\n",
            "Epoch 420: Training loss= 0.531564 Val loss= 0.554584 Training acc= 0.766635 Val acc= 0.765585\n",
            "Epoch 421: Training loss= 0.531362 Val loss= 0.554348 Training acc= 0.766665 Val acc= 0.765585\n",
            "Epoch 422: Training loss= 0.531161 Val loss= 0.554113 Training acc= 0.766695 Val acc= 0.765660\n",
            "Epoch 423: Training loss= 0.530961 Val loss= 0.553881 Training acc= 0.766725 Val acc= 0.765690\n",
            "Epoch 424: Training loss= 0.530762 Val loss= 0.553649 Training acc= 0.766765 Val acc= 0.765805\n",
            "Epoch 425: Training loss= 0.530565 Val loss= 0.553419 Training acc= 0.766875 Val acc= 0.765885\n",
            "Epoch 426: Training loss= 0.530370 Val loss= 0.553190 Training acc= 0.766950 Val acc= 0.765915\n",
            "Epoch 427: Training loss= 0.530175 Val loss= 0.552962 Training acc= 0.767000 Val acc= 0.765890\n",
            "Epoch 428: Training loss= 0.529981 Val loss= 0.552735 Training acc= 0.767050 Val acc= 0.765965\n",
            "Epoch 429: Training loss= 0.529789 Val loss= 0.552510 Training acc= 0.767145 Val acc= 0.766025\n",
            "Epoch 430: Training loss= 0.529598 Val loss= 0.552286 Training acc= 0.767205 Val acc= 0.766080\n",
            "Epoch 431: Training loss= 0.529408 Val loss= 0.552063 Training acc= 0.767220 Val acc= 0.766160\n",
            "Epoch 432: Training loss= 0.529219 Val loss= 0.551841 Training acc= 0.767270 Val acc= 0.766165\n",
            "Epoch 433: Training loss= 0.529031 Val loss= 0.551621 Training acc= 0.767295 Val acc= 0.766185\n",
            "Epoch 434: Training loss= 0.528845 Val loss= 0.551401 Training acc= 0.767290 Val acc= 0.766215\n",
            "Epoch 435: Training loss= 0.528659 Val loss= 0.551182 Training acc= 0.767285 Val acc= 0.766250\n",
            "Epoch 436: Training loss= 0.528474 Val loss= 0.550965 Training acc= 0.767305 Val acc= 0.766300\n",
            "Epoch 437: Training loss= 0.528290 Val loss= 0.550749 Training acc= 0.767350 Val acc= 0.766315\n",
            "Epoch 438: Training loss= 0.528107 Val loss= 0.550533 Training acc= 0.767355 Val acc= 0.766345\n",
            "Epoch 439: Training loss= 0.527925 Val loss= 0.550319 Training acc= 0.767355 Val acc= 0.766390\n",
            "Epoch 440: Training loss= 0.527745 Val loss= 0.550105 Training acc= 0.767395 Val acc= 0.766380\n",
            "Epoch 441: Training loss= 0.527564 Val loss= 0.549893 Training acc= 0.767360 Val acc= 0.766420\n",
            "Epoch 442: Training loss= 0.527385 Val loss= 0.549681 Training acc= 0.767375 Val acc= 0.766485\n",
            "Epoch 443: Training loss= 0.527207 Val loss= 0.549471 Training acc= 0.767420 Val acc= 0.766510\n",
            "Epoch 444: Training loss= 0.527030 Val loss= 0.549261 Training acc= 0.767455 Val acc= 0.766570\n",
            "Epoch 445: Training loss= 0.526853 Val loss= 0.549052 Training acc= 0.767515 Val acc= 0.766615\n",
            "Epoch 446: Training loss= 0.526677 Val loss= 0.548845 Training acc= 0.767545 Val acc= 0.766660\n",
            "Epoch 447: Training loss= 0.526503 Val loss= 0.548638 Training acc= 0.767600 Val acc= 0.766675\n",
            "Epoch 448: Training loss= 0.526329 Val loss= 0.548432 Training acc= 0.767605 Val acc= 0.766720\n",
            "Epoch 449: Training loss= 0.526155 Val loss= 0.548226 Training acc= 0.767660 Val acc= 0.766770\n",
            "Epoch 450: Training loss= 0.525983 Val loss= 0.548022 Training acc= 0.767685 Val acc= 0.766795\n",
            "Epoch 451: Training loss= 0.525811 Val loss= 0.547818 Training acc= 0.767690 Val acc= 0.766835\n",
            "Epoch 452: Training loss= 0.525640 Val loss= 0.547616 Training acc= 0.767740 Val acc= 0.766890\n",
            "Epoch 453: Training loss= 0.525470 Val loss= 0.547414 Training acc= 0.767795 Val acc= 0.766955\n",
            "Epoch 454: Training loss= 0.525301 Val loss= 0.547213 Training acc= 0.767880 Val acc= 0.766975\n",
            "Epoch 455: Training loss= 0.525132 Val loss= 0.547013 Training acc= 0.767915 Val acc= 0.767000\n",
            "Epoch 456: Training loss= 0.524965 Val loss= 0.546813 Training acc= 0.767940 Val acc= 0.767085\n",
            "Epoch 457: Training loss= 0.524797 Val loss= 0.546615 Training acc= 0.768020 Val acc= 0.767135\n",
            "Epoch 458: Training loss= 0.524631 Val loss= 0.546417 Training acc= 0.768070 Val acc= 0.767155\n",
            "Epoch 459: Training loss= 0.524465 Val loss= 0.546220 Training acc= 0.768095 Val acc= 0.767205\n",
            "Epoch 460: Training loss= 0.524300 Val loss= 0.546023 Training acc= 0.768165 Val acc= 0.767280\n",
            "Epoch 461: Training loss= 0.524136 Val loss= 0.545828 Training acc= 0.768205 Val acc= 0.767350\n",
            "Epoch 462: Training loss= 0.523972 Val loss= 0.545633 Training acc= 0.768295 Val acc= 0.767375\n",
            "Epoch 463: Training loss= 0.523809 Val loss= 0.545439 Training acc= 0.768325 Val acc= 0.767420\n",
            "Epoch 464: Training loss= 0.523647 Val loss= 0.545245 Training acc= 0.768360 Val acc= 0.767485\n",
            "Epoch 465: Training loss= 0.523486 Val loss= 0.545053 Training acc= 0.768400 Val acc= 0.767525\n",
            "Epoch 466: Training loss= 0.523325 Val loss= 0.544861 Training acc= 0.768415 Val acc= 0.767545\n",
            "Epoch 467: Training loss= 0.523164 Val loss= 0.544669 Training acc= 0.768440 Val acc= 0.767545\n",
            "Epoch 468: Training loss= 0.523004 Val loss= 0.544479 Training acc= 0.768455 Val acc= 0.767605\n",
            "Epoch 469: Training loss= 0.522845 Val loss= 0.544289 Training acc= 0.768495 Val acc= 0.767580\n",
            "Epoch 470: Training loss= 0.522687 Val loss= 0.544100 Training acc= 0.768465 Val acc= 0.767620\n",
            "Epoch 471: Training loss= 0.522529 Val loss= 0.543911 Training acc= 0.768480 Val acc= 0.767645\n",
            "Epoch 472: Training loss= 0.522372 Val loss= 0.543723 Training acc= 0.768525 Val acc= 0.767720\n",
            "Epoch 473: Training loss= 0.522215 Val loss= 0.543536 Training acc= 0.768585 Val acc= 0.767725\n",
            "Epoch 474: Training loss= 0.522059 Val loss= 0.543350 Training acc= 0.768605 Val acc= 0.767710\n",
            "Epoch 475: Training loss= 0.521903 Val loss= 0.543164 Training acc= 0.768615 Val acc= 0.767755\n",
            "Epoch 476: Training loss= 0.521748 Val loss= 0.542978 Training acc= 0.768640 Val acc= 0.767775\n",
            "Epoch 477: Training loss= 0.521594 Val loss= 0.542794 Training acc= 0.768665 Val acc= 0.767800\n",
            "Epoch 478: Training loss= 0.521440 Val loss= 0.542610 Training acc= 0.768705 Val acc= 0.767825\n",
            "Epoch 479: Training loss= 0.521287 Val loss= 0.542426 Training acc= 0.768755 Val acc= 0.767785\n",
            "Epoch 480: Training loss= 0.521134 Val loss= 0.542243 Training acc= 0.768720 Val acc= 0.767860\n",
            "Epoch 481: Training loss= 0.520982 Val loss= 0.542061 Training acc= 0.768795 Val acc= 0.767900\n",
            "Epoch 482: Training loss= 0.520830 Val loss= 0.541879 Training acc= 0.768835 Val acc= 0.767920\n",
            "Epoch 483: Training loss= 0.520679 Val loss= 0.541698 Training acc= 0.768845 Val acc= 0.767955\n",
            "Epoch 484: Training loss= 0.520528 Val loss= 0.541518 Training acc= 0.768915 Val acc= 0.768025\n",
            "Epoch 485: Training loss= 0.520378 Val loss= 0.541338 Training acc= 0.768965 Val acc= 0.768015\n",
            "Epoch 486: Training loss= 0.520229 Val loss= 0.541159 Training acc= 0.768950 Val acc= 0.768075\n",
            "Epoch 487: Training loss= 0.520080 Val loss= 0.540980 Training acc= 0.769005 Val acc= 0.768085\n",
            "Epoch 488: Training loss= 0.519931 Val loss= 0.540802 Training acc= 0.769010 Val acc= 0.768120\n",
            "Epoch 489: Training loss= 0.519783 Val loss= 0.540624 Training acc= 0.769025 Val acc= 0.768210\n",
            "Epoch 490: Training loss= 0.519635 Val loss= 0.540447 Training acc= 0.769120 Val acc= 0.768240\n",
            "Epoch 491: Training loss= 0.519488 Val loss= 0.540270 Training acc= 0.769150 Val acc= 0.768265\n",
            "Epoch 492: Training loss= 0.519342 Val loss= 0.540094 Training acc= 0.769195 Val acc= 0.768300\n",
            "Epoch 493: Training loss= 0.519195 Val loss= 0.539919 Training acc= 0.769250 Val acc= 0.768320\n",
            "Epoch 494: Training loss= 0.519050 Val loss= 0.539744 Training acc= 0.769270 Val acc= 0.768355\n",
            "Epoch 495: Training loss= 0.518905 Val loss= 0.539570 Training acc= 0.769295 Val acc= 0.768385\n",
            "Epoch 496: Training loss= 0.518760 Val loss= 0.539396 Training acc= 0.769350 Val acc= 0.768480\n",
            "Epoch 497: Training loss= 0.518616 Val loss= 0.539222 Training acc= 0.769455 Val acc= 0.768480\n",
            "Epoch 498: Training loss= 0.518472 Val loss= 0.539050 Training acc= 0.769470 Val acc= 0.768535\n",
            "Epoch 499: Training loss= 0.518329 Val loss= 0.538877 Training acc= 0.769505 Val acc= 0.768545\n",
            "Epoch 500: Training loss= 0.518186 Val loss= 0.538706 Training acc= 0.769525 Val acc= 0.768630\n",
            "Epoch 501: Training loss= 0.518043 Val loss= 0.538534 Training acc= 0.769615 Val acc= 0.768705\n",
            "Epoch 502: Training loss= 0.517901 Val loss= 0.538364 Training acc= 0.769670 Val acc= 0.768750\n",
            "Epoch 503: Training loss= 0.517760 Val loss= 0.538194 Training acc= 0.769705 Val acc= 0.768740\n",
            "Epoch 504: Training loss= 0.517619 Val loss= 0.538024 Training acc= 0.769680 Val acc= 0.768775\n",
            "Epoch 505: Training loss= 0.517478 Val loss= 0.537855 Training acc= 0.769695 Val acc= 0.768790\n",
            "Epoch 506: Training loss= 0.517338 Val loss= 0.537686 Training acc= 0.769695 Val acc= 0.768795\n",
            "Epoch 507: Training loss= 0.517199 Val loss= 0.537518 Training acc= 0.769725 Val acc= 0.768825\n",
            "Epoch 508: Training loss= 0.517060 Val loss= 0.537351 Training acc= 0.769710 Val acc= 0.768880\n",
            "Epoch 509: Training loss= 0.516921 Val loss= 0.537184 Training acc= 0.769810 Val acc= 0.768945\n",
            "Epoch 510: Training loss= 0.516783 Val loss= 0.537018 Training acc= 0.769875 Val acc= 0.768995\n",
            "Epoch 511: Training loss= 0.516645 Val loss= 0.536852 Training acc= 0.769905 Val acc= 0.769035\n",
            "Epoch 512: Training loss= 0.516508 Val loss= 0.536687 Training acc= 0.769960 Val acc= 0.769090\n",
            "Epoch 513: Training loss= 0.516372 Val loss= 0.536522 Training acc= 0.770010 Val acc= 0.769175\n",
            "Epoch 514: Training loss= 0.516236 Val loss= 0.536358 Training acc= 0.770120 Val acc= 0.769265\n",
            "Epoch 515: Training loss= 0.516100 Val loss= 0.536195 Training acc= 0.770180 Val acc= 0.769300\n",
            "Epoch 516: Training loss= 0.515965 Val loss= 0.536032 Training acc= 0.770205 Val acc= 0.769340\n",
            "Epoch 517: Training loss= 0.515830 Val loss= 0.535869 Training acc= 0.770265 Val acc= 0.769345\n",
            "Epoch 518: Training loss= 0.515696 Val loss= 0.535708 Training acc= 0.770305 Val acc= 0.769345\n",
            "Epoch 519: Training loss= 0.515563 Val loss= 0.535547 Training acc= 0.770315 Val acc= 0.769385\n",
            "Epoch 520: Training loss= 0.515430 Val loss= 0.535386 Training acc= 0.770355 Val acc= 0.769480\n",
            "Epoch 521: Training loss= 0.515298 Val loss= 0.535226 Training acc= 0.770405 Val acc= 0.769515\n",
            "Epoch 522: Training loss= 0.515166 Val loss= 0.535067 Training acc= 0.770435 Val acc= 0.769590\n",
            "Epoch 523: Training loss= 0.515034 Val loss= 0.534908 Training acc= 0.770480 Val acc= 0.769630\n",
            "Epoch 524: Training loss= 0.514904 Val loss= 0.534750 Training acc= 0.770530 Val acc= 0.769695\n",
            "Epoch 525: Training loss= 0.514773 Val loss= 0.534593 Training acc= 0.770575 Val acc= 0.769775\n",
            "Epoch 526: Training loss= 0.514644 Val loss= 0.534436 Training acc= 0.770660 Val acc= 0.769850\n",
            "Epoch 527: Training loss= 0.514514 Val loss= 0.534280 Training acc= 0.770710 Val acc= 0.769935\n",
            "Epoch 528: Training loss= 0.514386 Val loss= 0.534124 Training acc= 0.770790 Val acc= 0.769920\n",
            "Epoch 529: Training loss= 0.514257 Val loss= 0.533969 Training acc= 0.770765 Val acc= 0.769880\n",
            "Epoch 530: Training loss= 0.514130 Val loss= 0.533814 Training acc= 0.770735 Val acc= 0.769910\n",
            "Epoch 531: Training loss= 0.514002 Val loss= 0.533660 Training acc= 0.770755 Val acc= 0.769985\n",
            "Epoch 532: Training loss= 0.513876 Val loss= 0.533507 Training acc= 0.770790 Val acc= 0.770000\n",
            "Epoch 533: Training loss= 0.513750 Val loss= 0.533354 Training acc= 0.770810 Val acc= 0.770060\n",
            "Epoch 534: Training loss= 0.513624 Val loss= 0.533202 Training acc= 0.770860 Val acc= 0.770105\n",
            "Epoch 535: Training loss= 0.513499 Val loss= 0.533051 Training acc= 0.770890 Val acc= 0.770100\n",
            "Epoch 536: Training loss= 0.513374 Val loss= 0.532900 Training acc= 0.770925 Val acc= 0.770110\n",
            "Epoch 537: Training loss= 0.513249 Val loss= 0.532749 Training acc= 0.770945 Val acc= 0.770115\n",
            "Epoch 538: Training loss= 0.513126 Val loss= 0.532599 Training acc= 0.770950 Val acc= 0.770160\n",
            "Epoch 539: Training loss= 0.513002 Val loss= 0.532450 Training acc= 0.771000 Val acc= 0.770180\n",
            "Epoch 540: Training loss= 0.512879 Val loss= 0.532301 Training acc= 0.771035 Val acc= 0.770210\n",
            "Epoch 541: Training loss= 0.512757 Val loss= 0.532152 Training acc= 0.771070 Val acc= 0.770265\n",
            "Epoch 542: Training loss= 0.512634 Val loss= 0.532004 Training acc= 0.771135 Val acc= 0.770305\n",
            "Epoch 543: Training loss= 0.512513 Val loss= 0.531857 Training acc= 0.771160 Val acc= 0.770330\n",
            "Epoch 544: Training loss= 0.512391 Val loss= 0.531710 Training acc= 0.771180 Val acc= 0.770360\n",
            "Epoch 545: Training loss= 0.512270 Val loss= 0.531564 Training acc= 0.771205 Val acc= 0.770415\n",
            "Epoch 546: Training loss= 0.512150 Val loss= 0.531418 Training acc= 0.771245 Val acc= 0.770500\n",
            "Epoch 547: Training loss= 0.512030 Val loss= 0.531272 Training acc= 0.771290 Val acc= 0.770500\n",
            "Epoch 548: Training loss= 0.511910 Val loss= 0.531127 Training acc= 0.771310 Val acc= 0.770525\n",
            "Epoch 549: Training loss= 0.511791 Val loss= 0.530982 Training acc= 0.771320 Val acc= 0.770545\n",
            "Epoch 550: Training loss= 0.511672 Val loss= 0.530838 Training acc= 0.771325 Val acc= 0.770575\n",
            "Epoch 551: Training loss= 0.511553 Val loss= 0.530694 Training acc= 0.771350 Val acc= 0.770610\n",
            "Epoch 552: Training loss= 0.511435 Val loss= 0.530551 Training acc= 0.771410 Val acc= 0.770665\n",
            "Epoch 553: Training loss= 0.511317 Val loss= 0.530408 Training acc= 0.771445 Val acc= 0.770710\n",
            "Epoch 554: Training loss= 0.511199 Val loss= 0.530266 Training acc= 0.771460 Val acc= 0.770730\n",
            "Epoch 555: Training loss= 0.511082 Val loss= 0.530124 Training acc= 0.771485 Val acc= 0.770785\n",
            "Epoch 556: Training loss= 0.510965 Val loss= 0.529982 Training acc= 0.771525 Val acc= 0.770825\n",
            "Epoch 557: Training loss= 0.510848 Val loss= 0.529841 Training acc= 0.771570 Val acc= 0.770880\n",
            "Epoch 558: Training loss= 0.510732 Val loss= 0.529700 Training acc= 0.771605 Val acc= 0.770915\n",
            "Epoch 559: Training loss= 0.510616 Val loss= 0.529560 Training acc= 0.771650 Val acc= 0.770920\n",
            "Epoch 560: Training loss= 0.510501 Val loss= 0.529420 Training acc= 0.771650 Val acc= 0.770965\n",
            "Epoch 561: Training loss= 0.510386 Val loss= 0.529280 Training acc= 0.771680 Val acc= 0.770990\n",
            "Epoch 562: Training loss= 0.510271 Val loss= 0.529141 Training acc= 0.771705 Val acc= 0.771030\n",
            "Epoch 563: Training loss= 0.510156 Val loss= 0.529002 Training acc= 0.771755 Val acc= 0.771040\n",
            "Epoch 564: Training loss= 0.510042 Val loss= 0.528863 Training acc= 0.771745 Val acc= 0.771055\n",
            "Epoch 565: Training loss= 0.509928 Val loss= 0.528725 Training acc= 0.771770 Val acc= 0.771070\n",
            "Epoch 566: Training loss= 0.509814 Val loss= 0.528587 Training acc= 0.771770 Val acc= 0.771120\n",
            "Epoch 567: Training loss= 0.509701 Val loss= 0.528450 Training acc= 0.771865 Val acc= 0.771110\n",
            "Epoch 568: Training loss= 0.509588 Val loss= 0.528313 Training acc= 0.771855 Val acc= 0.771135\n",
            "Epoch 569: Training loss= 0.509475 Val loss= 0.528176 Training acc= 0.771865 Val acc= 0.771150\n",
            "Epoch 570: Training loss= 0.509363 Val loss= 0.528040 Training acc= 0.771885 Val acc= 0.771195\n",
            "Epoch 571: Training loss= 0.509251 Val loss= 0.527904 Training acc= 0.771900 Val acc= 0.771230\n",
            "Epoch 572: Training loss= 0.509139 Val loss= 0.527768 Training acc= 0.771955 Val acc= 0.771255\n",
            "Epoch 573: Training loss= 0.509027 Val loss= 0.527633 Training acc= 0.771975 Val acc= 0.771270\n",
            "Epoch 574: Training loss= 0.508916 Val loss= 0.527498 Training acc= 0.771985 Val acc= 0.771280\n",
            "Epoch 575: Training loss= 0.508805 Val loss= 0.527363 Training acc= 0.771985 Val acc= 0.771305\n",
            "Epoch 576: Training loss= 0.508695 Val loss= 0.527229 Training acc= 0.771990 Val acc= 0.771290\n",
            "Epoch 577: Training loss= 0.508584 Val loss= 0.527095 Training acc= 0.772000 Val acc= 0.771295\n",
            "Epoch 578: Training loss= 0.508474 Val loss= 0.526961 Training acc= 0.772020 Val acc= 0.771285\n",
            "Epoch 579: Training loss= 0.508364 Val loss= 0.526828 Training acc= 0.772000 Val acc= 0.771295\n",
            "Epoch 580: Training loss= 0.508255 Val loss= 0.526695 Training acc= 0.772030 Val acc= 0.771335\n",
            "Epoch 581: Training loss= 0.508145 Val loss= 0.526562 Training acc= 0.772060 Val acc= 0.771370\n",
            "Epoch 582: Training loss= 0.508036 Val loss= 0.526430 Training acc= 0.772105 Val acc= 0.771400\n",
            "Epoch 583: Training loss= 0.507928 Val loss= 0.526298 Training acc= 0.772150 Val acc= 0.771420\n",
            "Epoch 584: Training loss= 0.507819 Val loss= 0.526166 Training acc= 0.772195 Val acc= 0.771450\n",
            "Epoch 585: Training loss= 0.507711 Val loss= 0.526035 Training acc= 0.772215 Val acc= 0.771470\n",
            "Epoch 586: Training loss= 0.507603 Val loss= 0.525904 Training acc= 0.772235 Val acc= 0.771475\n",
            "Epoch 587: Training loss= 0.507496 Val loss= 0.525773 Training acc= 0.772245 Val acc= 0.771515\n",
            "Epoch 588: Training loss= 0.507388 Val loss= 0.525642 Training acc= 0.772275 Val acc= 0.771575\n",
            "Epoch 589: Training loss= 0.507281 Val loss= 0.525512 Training acc= 0.772355 Val acc= 0.771570\n",
            "Epoch 590: Training loss= 0.507175 Val loss= 0.525383 Training acc= 0.772365 Val acc= 0.771590\n",
            "Epoch 591: Training loss= 0.507068 Val loss= 0.525253 Training acc= 0.772390 Val acc= 0.771580\n",
            "Epoch 592: Training loss= 0.506962 Val loss= 0.525124 Training acc= 0.772390 Val acc= 0.771625\n",
            "Epoch 593: Training loss= 0.506856 Val loss= 0.524996 Training acc= 0.772435 Val acc= 0.771660\n",
            "Epoch 594: Training loss= 0.506750 Val loss= 0.524867 Training acc= 0.772465 Val acc= 0.771690\n",
            "Epoch 595: Training loss= 0.506645 Val loss= 0.524739 Training acc= 0.772510 Val acc= 0.771690\n",
            "Epoch 596: Training loss= 0.506539 Val loss= 0.524611 Training acc= 0.772515 Val acc= 0.771740\n",
            "Epoch 597: Training loss= 0.506434 Val loss= 0.524484 Training acc= 0.772570 Val acc= 0.771800\n",
            "Epoch 598: Training loss= 0.506330 Val loss= 0.524357 Training acc= 0.772640 Val acc= 0.771795\n",
            "Epoch 599: Training loss= 0.506225 Val loss= 0.524230 Training acc= 0.772660 Val acc= 0.771800\n",
            "Epoch 600: Training loss= 0.506121 Val loss= 0.524103 Training acc= 0.772665 Val acc= 0.771810\n",
            "Epoch 601: Training loss= 0.506017 Val loss= 0.523977 Training acc= 0.772655 Val acc= 0.771875\n",
            "Epoch 602: Training loss= 0.505914 Val loss= 0.523851 Training acc= 0.772715 Val acc= 0.771915\n",
            "Epoch 603: Training loss= 0.505810 Val loss= 0.523726 Training acc= 0.772755 Val acc= 0.771940\n",
            "Epoch 604: Training loss= 0.505707 Val loss= 0.523600 Training acc= 0.772775 Val acc= 0.771965\n",
            "Epoch 605: Training loss= 0.505604 Val loss= 0.523475 Training acc= 0.772780 Val acc= 0.771975\n",
            "Epoch 606: Training loss= 0.505501 Val loss= 0.523350 Training acc= 0.772800 Val acc= 0.772000\n",
            "Epoch 607: Training loss= 0.505399 Val loss= 0.523226 Training acc= 0.772830 Val acc= 0.772055\n",
            "Epoch 608: Training loss= 0.505296 Val loss= 0.523102 Training acc= 0.772875 Val acc= 0.772110\n",
            "Epoch 609: Training loss= 0.505194 Val loss= 0.522978 Training acc= 0.772895 Val acc= 0.772145\n",
            "Epoch 610: Training loss= 0.505092 Val loss= 0.522854 Training acc= 0.772905 Val acc= 0.772205\n",
            "Epoch 611: Training loss= 0.504991 Val loss= 0.522731 Training acc= 0.772945 Val acc= 0.772195\n",
            "Epoch 612: Training loss= 0.504889 Val loss= 0.522607 Training acc= 0.772940 Val acc= 0.772270\n",
            "Epoch 613: Training loss= 0.504788 Val loss= 0.522484 Training acc= 0.772985 Val acc= 0.772280\n",
            "Epoch 614: Training loss= 0.504687 Val loss= 0.522362 Training acc= 0.773010 Val acc= 0.772335\n",
            "Epoch 615: Training loss= 0.504586 Val loss= 0.522239 Training acc= 0.773065 Val acc= 0.772365\n",
            "Epoch 616: Training loss= 0.504486 Val loss= 0.522117 Training acc= 0.773090 Val acc= 0.772365\n",
            "Epoch 617: Training loss= 0.504385 Val loss= 0.521995 Training acc= 0.773115 Val acc= 0.772380\n",
            "Epoch 618: Training loss= 0.504285 Val loss= 0.521874 Training acc= 0.773125 Val acc= 0.772475\n",
            "Epoch 619: Training loss= 0.504185 Val loss= 0.521752 Training acc= 0.773195 Val acc= 0.772475\n",
            "Epoch 620: Training loss= 0.504086 Val loss= 0.521631 Training acc= 0.773235 Val acc= 0.772500\n",
            "Epoch 621: Training loss= 0.503986 Val loss= 0.521510 Training acc= 0.773250 Val acc= 0.772535\n",
            "Epoch 622: Training loss= 0.503887 Val loss= 0.521390 Training acc= 0.773275 Val acc= 0.772535\n",
            "Epoch 623: Training loss= 0.503788 Val loss= 0.521269 Training acc= 0.773275 Val acc= 0.772565\n",
            "Epoch 624: Training loss= 0.503689 Val loss= 0.521149 Training acc= 0.773300 Val acc= 0.772615\n",
            "Epoch 625: Training loss= 0.503590 Val loss= 0.521029 Training acc= 0.773315 Val acc= 0.772660\n",
            "Epoch 626: Training loss= 0.503491 Val loss= 0.520909 Training acc= 0.773350 Val acc= 0.772680\n",
            "Epoch 627: Training loss= 0.503393 Val loss= 0.520790 Training acc= 0.773365 Val acc= 0.772660\n",
            "Epoch 628: Training loss= 0.503295 Val loss= 0.520670 Training acc= 0.773380 Val acc= 0.772680\n",
            "Epoch 629: Training loss= 0.503197 Val loss= 0.520551 Training acc= 0.773385 Val acc= 0.772700\n",
            "Epoch 630: Training loss= 0.503099 Val loss= 0.520432 Training acc= 0.773425 Val acc= 0.772725\n",
            "Epoch 631: Training loss= 0.503001 Val loss= 0.520314 Training acc= 0.773415 Val acc= 0.772750\n",
            "Epoch 632: Training loss= 0.502904 Val loss= 0.520195 Training acc= 0.773460 Val acc= 0.772805\n",
            "Epoch 633: Training loss= 0.502807 Val loss= 0.520077 Training acc= 0.773500 Val acc= 0.772840\n",
            "Epoch 634: Training loss= 0.502710 Val loss= 0.519959 Training acc= 0.773555 Val acc= 0.772910\n",
            "Epoch 635: Training loss= 0.502613 Val loss= 0.519841 Training acc= 0.773580 Val acc= 0.772890\n",
            "Epoch 636: Training loss= 0.502516 Val loss= 0.519724 Training acc= 0.773590 Val acc= 0.772930\n",
            "Epoch 637: Training loss= 0.502420 Val loss= 0.519606 Training acc= 0.773645 Val acc= 0.772945\n",
            "Epoch 638: Training loss= 0.502324 Val loss= 0.519489 Training acc= 0.773650 Val acc= 0.772980\n",
            "Epoch 639: Training loss= 0.502228 Val loss= 0.519372 Training acc= 0.773700 Val acc= 0.773020\n",
            "Epoch 640: Training loss= 0.502132 Val loss= 0.519255 Training acc= 0.773765 Val acc= 0.773070\n",
            "Epoch 641: Training loss= 0.502036 Val loss= 0.519139 Training acc= 0.773820 Val acc= 0.773080\n",
            "Epoch 642: Training loss= 0.501940 Val loss= 0.519022 Training acc= 0.773865 Val acc= 0.773135\n",
            "Epoch 643: Training loss= 0.501845 Val loss= 0.518906 Training acc= 0.773915 Val acc= 0.773145\n",
            "Epoch 644: Training loss= 0.501750 Val loss= 0.518790 Training acc= 0.773925 Val acc= 0.773170\n",
            "Epoch 645: Training loss= 0.501655 Val loss= 0.518675 Training acc= 0.773940 Val acc= 0.773195\n",
            "Epoch 646: Training loss= 0.501560 Val loss= 0.518559 Training acc= 0.773985 Val acc= 0.773220\n",
            "Epoch 647: Training loss= 0.501465 Val loss= 0.518444 Training acc= 0.774015 Val acc= 0.773280\n",
            "Epoch 648: Training loss= 0.501371 Val loss= 0.518329 Training acc= 0.774075 Val acc= 0.773315\n",
            "Epoch 649: Training loss= 0.501277 Val loss= 0.518214 Training acc= 0.774100 Val acc= 0.773360\n",
            "Epoch 650: Training loss= 0.501182 Val loss= 0.518099 Training acc= 0.774150 Val acc= 0.773395\n",
            "Epoch 651: Training loss= 0.501088 Val loss= 0.517985 Training acc= 0.774190 Val acc= 0.773395\n",
            "Epoch 652: Training loss= 0.500995 Val loss= 0.517871 Training acc= 0.774190 Val acc= 0.773400\n",
            "Epoch 653: Training loss= 0.500901 Val loss= 0.517757 Training acc= 0.774195 Val acc= 0.773455\n",
            "Epoch 654: Training loss= 0.500808 Val loss= 0.517643 Training acc= 0.774265 Val acc= 0.773470\n",
            "Epoch 655: Training loss= 0.500714 Val loss= 0.517529 Training acc= 0.774295 Val acc= 0.773490\n",
            "Epoch 656: Training loss= 0.500621 Val loss= 0.517416 Training acc= 0.774330 Val acc= 0.773495\n",
            "Epoch 657: Training loss= 0.500528 Val loss= 0.517303 Training acc= 0.774310 Val acc= 0.773510\n",
            "Epoch 658: Training loss= 0.500436 Val loss= 0.517190 Training acc= 0.774315 Val acc= 0.773530\n",
            "Epoch 659: Training loss= 0.500343 Val loss= 0.517077 Training acc= 0.774350 Val acc= 0.773500\n",
            "Epoch 660: Training loss= 0.500251 Val loss= 0.516964 Training acc= 0.774345 Val acc= 0.773500\n",
            "Epoch 661: Training loss= 0.500159 Val loss= 0.516852 Training acc= 0.774360 Val acc= 0.773525\n",
            "Epoch 662: Training loss= 0.500067 Val loss= 0.516740 Training acc= 0.774390 Val acc= 0.773580\n",
            "Epoch 663: Training loss= 0.499975 Val loss= 0.516628 Training acc= 0.774450 Val acc= 0.773610\n",
            "Epoch 664: Training loss= 0.499883 Val loss= 0.516516 Training acc= 0.774490 Val acc= 0.773640\n",
            "Epoch 665: Training loss= 0.499791 Val loss= 0.516404 Training acc= 0.774515 Val acc= 0.773635\n",
            "Epoch 666: Training loss= 0.499700 Val loss= 0.516293 Training acc= 0.774515 Val acc= 0.773690\n",
            "Epoch 667: Training loss= 0.499609 Val loss= 0.516181 Training acc= 0.774585 Val acc= 0.773690\n",
            "Epoch 668: Training loss= 0.499518 Val loss= 0.516070 Training acc= 0.774575 Val acc= 0.773700\n",
            "Epoch 669: Training loss= 0.499427 Val loss= 0.515960 Training acc= 0.774570 Val acc= 0.773700\n",
            "Epoch 670: Training loss= 0.499336 Val loss= 0.515849 Training acc= 0.774555 Val acc= 0.773705\n",
            "Epoch 671: Training loss= 0.499246 Val loss= 0.515738 Training acc= 0.774570 Val acc= 0.773735\n",
            "Epoch 672: Training loss= 0.499155 Val loss= 0.515628 Training acc= 0.774610 Val acc= 0.773780\n",
            "Epoch 673: Training loss= 0.499065 Val loss= 0.515518 Training acc= 0.774665 Val acc= 0.773820\n",
            "Epoch 674: Training loss= 0.498975 Val loss= 0.515408 Training acc= 0.774710 Val acc= 0.773865\n",
            "Epoch 675: Training loss= 0.498885 Val loss= 0.515299 Training acc= 0.774735 Val acc= 0.773925\n",
            "Epoch 676: Training loss= 0.498796 Val loss= 0.515189 Training acc= 0.774770 Val acc= 0.773960\n",
            "Epoch 677: Training loss= 0.498706 Val loss= 0.515080 Training acc= 0.774835 Val acc= 0.773985\n",
            "Epoch 678: Training loss= 0.498617 Val loss= 0.514971 Training acc= 0.774865 Val acc= 0.774005\n",
            "Epoch 679: Training loss= 0.498528 Val loss= 0.514862 Training acc= 0.774855 Val acc= 0.773985\n",
            "Epoch 680: Training loss= 0.498439 Val loss= 0.514753 Training acc= 0.774845 Val acc= 0.773985\n",
            "Epoch 681: Training loss= 0.498350 Val loss= 0.514645 Training acc= 0.774850 Val acc= 0.773980\n",
            "Epoch 682: Training loss= 0.498261 Val loss= 0.514536 Training acc= 0.774855 Val acc= 0.773995\n",
            "Epoch 683: Training loss= 0.498172 Val loss= 0.514428 Training acc= 0.774870 Val acc= 0.774010\n",
            "Epoch 684: Training loss= 0.498084 Val loss= 0.514320 Training acc= 0.774875 Val acc= 0.774010\n",
            "Epoch 685: Training loss= 0.497996 Val loss= 0.514212 Training acc= 0.774890 Val acc= 0.774030\n",
            "Epoch 686: Training loss= 0.497908 Val loss= 0.514105 Training acc= 0.774915 Val acc= 0.774055\n",
            "Epoch 687: Training loss= 0.497820 Val loss= 0.513997 Training acc= 0.774950 Val acc= 0.774065\n",
            "Epoch 688: Training loss= 0.497732 Val loss= 0.513890 Training acc= 0.774955 Val acc= 0.774075\n",
            "Epoch 689: Training loss= 0.497644 Val loss= 0.513783 Training acc= 0.774970 Val acc= 0.774080\n",
            "Epoch 690: Training loss= 0.497557 Val loss= 0.513676 Training acc= 0.774980 Val acc= 0.774105\n",
            "Epoch 691: Training loss= 0.497469 Val loss= 0.513569 Training acc= 0.774980 Val acc= 0.774095\n",
            "Epoch 692: Training loss= 0.497382 Val loss= 0.513463 Training acc= 0.774975 Val acc= 0.774110\n",
            "Epoch 693: Training loss= 0.497295 Val loss= 0.513356 Training acc= 0.774980 Val acc= 0.774185\n",
            "Epoch 694: Training loss= 0.497208 Val loss= 0.513250 Training acc= 0.775045 Val acc= 0.774205\n",
            "Epoch 695: Training loss= 0.497122 Val loss= 0.513144 Training acc= 0.775075 Val acc= 0.774215\n",
            "Epoch 696: Training loss= 0.497035 Val loss= 0.513039 Training acc= 0.775080 Val acc= 0.774235\n",
            "Epoch 697: Training loss= 0.496949 Val loss= 0.512933 Training acc= 0.775100 Val acc= 0.774290\n",
            "Epoch 698: Training loss= 0.496862 Val loss= 0.512827 Training acc= 0.775135 Val acc= 0.774325\n",
            "Epoch 699: Training loss= 0.496776 Val loss= 0.512722 Training acc= 0.775150 Val acc= 0.774335\n",
            "Epoch 700: Training loss= 0.496690 Val loss= 0.512617 Training acc= 0.775145 Val acc= 0.774345\n",
            "Epoch 701: Training loss= 0.496604 Val loss= 0.512512 Training acc= 0.775170 Val acc= 0.774350\n",
            "Epoch 702: Training loss= 0.496519 Val loss= 0.512407 Training acc= 0.775190 Val acc= 0.774370\n",
            "Epoch 703: Training loss= 0.496433 Val loss= 0.512303 Training acc= 0.775245 Val acc= 0.774345\n",
            "Epoch 704: Training loss= 0.496348 Val loss= 0.512198 Training acc= 0.775225 Val acc= 0.774365\n",
            "Epoch 705: Training loss= 0.496263 Val loss= 0.512094 Training acc= 0.775250 Val acc= 0.774395\n",
            "Epoch 706: Training loss= 0.496178 Val loss= 0.511990 Training acc= 0.775280 Val acc= 0.774430\n",
            "Epoch 707: Training loss= 0.496093 Val loss= 0.511886 Training acc= 0.775305 Val acc= 0.774465\n",
            "Epoch 708: Training loss= 0.496008 Val loss= 0.511783 Training acc= 0.775350 Val acc= 0.774470\n",
            "Epoch 709: Training loss= 0.495923 Val loss= 0.511679 Training acc= 0.775360 Val acc= 0.774435\n",
            "Epoch 710: Training loss= 0.495839 Val loss= 0.511576 Training acc= 0.775340 Val acc= 0.774415\n",
            "Epoch 711: Training loss= 0.495754 Val loss= 0.511472 Training acc= 0.775325 Val acc= 0.774435\n",
            "Epoch 712: Training loss= 0.495670 Val loss= 0.511369 Training acc= 0.775340 Val acc= 0.774420\n",
            "Epoch 713: Training loss= 0.495586 Val loss= 0.511267 Training acc= 0.775305 Val acc= 0.774425\n",
            "Epoch 714: Training loss= 0.495502 Val loss= 0.511164 Training acc= 0.775310 Val acc= 0.774460\n",
            "Epoch 715: Training loss= 0.495419 Val loss= 0.511061 Training acc= 0.775345 Val acc= 0.774500\n",
            "Epoch 716: Training loss= 0.495335 Val loss= 0.510959 Training acc= 0.775385 Val acc= 0.774520\n",
            "Epoch 717: Training loss= 0.495251 Val loss= 0.510857 Training acc= 0.775410 Val acc= 0.774520\n",
            "Epoch 718: Training loss= 0.495168 Val loss= 0.510755 Training acc= 0.775455 Val acc= 0.774545\n",
            "Epoch 719: Training loss= 0.495085 Val loss= 0.510653 Training acc= 0.775460 Val acc= 0.774590\n",
            "Epoch 720: Training loss= 0.495002 Val loss= 0.510551 Training acc= 0.775495 Val acc= 0.774585\n",
            "Epoch 721: Training loss= 0.494919 Val loss= 0.510450 Training acc= 0.775505 Val acc= 0.774580\n",
            "Epoch 722: Training loss= 0.494836 Val loss= 0.510348 Training acc= 0.775520 Val acc= 0.774600\n",
            "Epoch 723: Training loss= 0.494754 Val loss= 0.510247 Training acc= 0.775545 Val acc= 0.774630\n",
            "Epoch 724: Training loss= 0.494671 Val loss= 0.510146 Training acc= 0.775530 Val acc= 0.774700\n",
            "Epoch 725: Training loss= 0.494589 Val loss= 0.510045 Training acc= 0.775560 Val acc= 0.774745\n",
            "Epoch 726: Training loss= 0.494507 Val loss= 0.509945 Training acc= 0.775610 Val acc= 0.774825\n",
            "Epoch 727: Training loss= 0.494425 Val loss= 0.509844 Training acc= 0.775665 Val acc= 0.774830\n",
            "Epoch 728: Training loss= 0.494343 Val loss= 0.509744 Training acc= 0.775680 Val acc= 0.774875\n",
            "Epoch 729: Training loss= 0.494261 Val loss= 0.509644 Training acc= 0.775715 Val acc= 0.774865\n",
            "Epoch 730: Training loss= 0.494179 Val loss= 0.509544 Training acc= 0.775710 Val acc= 0.774885\n",
            "Epoch 731: Training loss= 0.494098 Val loss= 0.509444 Training acc= 0.775720 Val acc= 0.774920\n",
            "Epoch 732: Training loss= 0.494016 Val loss= 0.509344 Training acc= 0.775740 Val acc= 0.774940\n",
            "Epoch 733: Training loss= 0.493935 Val loss= 0.509245 Training acc= 0.775760 Val acc= 0.774980\n",
            "Epoch 734: Training loss= 0.493854 Val loss= 0.509146 Training acc= 0.775790 Val acc= 0.774985\n",
            "Epoch 735: Training loss= 0.493773 Val loss= 0.509046 Training acc= 0.775795 Val acc= 0.775010\n",
            "Epoch 736: Training loss= 0.493693 Val loss= 0.508947 Training acc= 0.775820 Val acc= 0.775055\n",
            "Epoch 737: Training loss= 0.493612 Val loss= 0.508849 Training acc= 0.775865 Val acc= 0.775075\n",
            "Epoch 738: Training loss= 0.493531 Val loss= 0.508750 Training acc= 0.775905 Val acc= 0.775095\n",
            "Epoch 739: Training loss= 0.493451 Val loss= 0.508652 Training acc= 0.775915 Val acc= 0.775125\n",
            "Epoch 740: Training loss= 0.493371 Val loss= 0.508553 Training acc= 0.775930 Val acc= 0.775175\n",
            "Epoch 741: Training loss= 0.493291 Val loss= 0.508455 Training acc= 0.775960 Val acc= 0.775175\n",
            "Epoch 742: Training loss= 0.493211 Val loss= 0.508358 Training acc= 0.775955 Val acc= 0.775200\n",
            "Epoch 743: Training loss= 0.493131 Val loss= 0.508260 Training acc= 0.775980 Val acc= 0.775235\n",
            "Epoch 744: Training loss= 0.493052 Val loss= 0.508162 Training acc= 0.776035 Val acc= 0.775250\n",
            "Epoch 745: Training loss= 0.492973 Val loss= 0.508065 Training acc= 0.776060 Val acc= 0.775250\n",
            "Epoch 746: Training loss= 0.492893 Val loss= 0.507968 Training acc= 0.776065 Val acc= 0.775275\n",
            "Epoch 747: Training loss= 0.492814 Val loss= 0.507871 Training acc= 0.776110 Val acc= 0.775315\n",
            "Epoch 748: Training loss= 0.492735 Val loss= 0.507775 Training acc= 0.776145 Val acc= 0.775325\n",
            "Epoch 749: Training loss= 0.492657 Val loss= 0.507678 Training acc= 0.776180 Val acc= 0.775370\n",
            "Epoch 750: Training loss= 0.492578 Val loss= 0.507582 Training acc= 0.776190 Val acc= 0.775410\n",
            "Epoch 751: Training loss= 0.492500 Val loss= 0.507486 Training acc= 0.776225 Val acc= 0.775415\n",
            "Epoch 752: Training loss= 0.492422 Val loss= 0.507391 Training acc= 0.776210 Val acc= 0.775465\n",
            "Epoch 753: Training loss= 0.492344 Val loss= 0.507295 Training acc= 0.776255 Val acc= 0.775505\n",
            "Epoch 754: Training loss= 0.492266 Val loss= 0.507200 Training acc= 0.776300 Val acc= 0.775540\n",
            "Epoch 755: Training loss= 0.492188 Val loss= 0.507105 Training acc= 0.776315 Val acc= 0.775535\n",
            "Epoch 756: Training loss= 0.492111 Val loss= 0.507011 Training acc= 0.776330 Val acc= 0.775575\n",
            "Epoch 757: Training loss= 0.492034 Val loss= 0.506917 Training acc= 0.776370 Val acc= 0.775625\n",
            "Epoch 758: Training loss= 0.491957 Val loss= 0.506823 Training acc= 0.776420 Val acc= 0.775655\n",
            "Epoch 759: Training loss= 0.491880 Val loss= 0.506730 Training acc= 0.776440 Val acc= 0.775690\n",
            "Epoch 760: Training loss= 0.491804 Val loss= 0.506637 Training acc= 0.776475 Val acc= 0.775700\n",
            "Epoch 761: Training loss= 0.491728 Val loss= 0.506544 Training acc= 0.776485 Val acc= 0.775715\n",
            "Epoch 762: Training loss= 0.491652 Val loss= 0.506451 Training acc= 0.776500 Val acc= 0.775720\n",
            "Epoch 763: Training loss= 0.491576 Val loss= 0.506359 Training acc= 0.776485 Val acc= 0.775730\n",
            "Epoch 764: Training loss= 0.491501 Val loss= 0.506267 Training acc= 0.776510 Val acc= 0.775740\n",
            "Epoch 765: Training loss= 0.491425 Val loss= 0.506176 Training acc= 0.776525 Val acc= 0.775825\n",
            "Epoch 766: Training loss= 0.491350 Val loss= 0.506085 Training acc= 0.776595 Val acc= 0.775840\n",
            "Epoch 767: Training loss= 0.491276 Val loss= 0.505994 Training acc= 0.776605 Val acc= 0.775820\n",
            "Epoch 768: Training loss= 0.491201 Val loss= 0.505903 Training acc= 0.776585 Val acc= 0.775830\n",
            "Epoch 769: Training loss= 0.491127 Val loss= 0.505813 Training acc= 0.776595 Val acc= 0.775835\n",
            "Epoch 770: Training loss= 0.491052 Val loss= 0.505722 Training acc= 0.776600 Val acc= 0.775855\n",
            "Epoch 771: Training loss= 0.490978 Val loss= 0.505633 Training acc= 0.776655 Val acc= 0.775840\n",
            "Epoch 772: Training loss= 0.490905 Val loss= 0.505543 Training acc= 0.776635 Val acc= 0.775860\n",
            "Epoch 773: Training loss= 0.490831 Val loss= 0.505453 Training acc= 0.776660 Val acc= 0.775895\n",
            "Epoch 774: Training loss= 0.490758 Val loss= 0.505364 Training acc= 0.776680 Val acc= 0.775925\n",
            "Epoch 775: Training loss= 0.490684 Val loss= 0.505275 Training acc= 0.776710 Val acc= 0.775940\n",
            "Epoch 776: Training loss= 0.490611 Val loss= 0.505186 Training acc= 0.776745 Val acc= 0.775955\n",
            "Epoch 777: Training loss= 0.490538 Val loss= 0.505098 Training acc= 0.776765 Val acc= 0.775960\n",
            "Epoch 778: Training loss= 0.490466 Val loss= 0.505009 Training acc= 0.776760 Val acc= 0.775945\n",
            "Epoch 779: Training loss= 0.490393 Val loss= 0.504921 Training acc= 0.776745 Val acc= 0.775985\n",
            "Epoch 780: Training loss= 0.490321 Val loss= 0.504833 Training acc= 0.776785 Val acc= 0.776005\n",
            "Epoch 781: Training loss= 0.490249 Val loss= 0.504745 Training acc= 0.776810 Val acc= 0.776000\n",
            "Epoch 782: Training loss= 0.490177 Val loss= 0.504658 Training acc= 0.776815 Val acc= 0.776035\n",
            "Epoch 783: Training loss= 0.490105 Val loss= 0.504571 Training acc= 0.776845 Val acc= 0.776055\n",
            "Epoch 784: Training loss= 0.490034 Val loss= 0.504484 Training acc= 0.776855 Val acc= 0.776075\n",
            "Epoch 785: Training loss= 0.489963 Val loss= 0.504397 Training acc= 0.776875 Val acc= 0.776095\n",
            "Epoch 786: Training loss= 0.489892 Val loss= 0.504311 Training acc= 0.776880 Val acc= 0.776110\n",
            "Epoch 787: Training loss= 0.489821 Val loss= 0.504224 Training acc= 0.776895 Val acc= 0.776135\n",
            "Epoch 788: Training loss= 0.489750 Val loss= 0.504138 Training acc= 0.776920 Val acc= 0.776145\n",
            "Epoch 789: Training loss= 0.489680 Val loss= 0.504052 Training acc= 0.776915 Val acc= 0.776140\n",
            "Epoch 790: Training loss= 0.489610 Val loss= 0.503967 Training acc= 0.776930 Val acc= 0.776135\n",
            "Epoch 791: Training loss= 0.489540 Val loss= 0.503882 Training acc= 0.776915 Val acc= 0.776170\n",
            "Epoch 792: Training loss= 0.489470 Val loss= 0.503797 Training acc= 0.776950 Val acc= 0.776185\n",
            "Epoch 793: Training loss= 0.489400 Val loss= 0.503712 Training acc= 0.776945 Val acc= 0.776200\n",
            "Epoch 794: Training loss= 0.489331 Val loss= 0.503627 Training acc= 0.776965 Val acc= 0.776225\n",
            "Epoch 795: Training loss= 0.489261 Val loss= 0.503543 Training acc= 0.776970 Val acc= 0.776250\n",
            "Epoch 796: Training loss= 0.489192 Val loss= 0.503459 Training acc= 0.777010 Val acc= 0.776220\n",
            "Epoch 797: Training loss= 0.489123 Val loss= 0.503375 Training acc= 0.777005 Val acc= 0.776255\n",
            "Epoch 798: Training loss= 0.489055 Val loss= 0.503291 Training acc= 0.777030 Val acc= 0.776270\n",
            "Epoch 799: Training loss= 0.488986 Val loss= 0.503207 Training acc= 0.777040 Val acc= 0.776305\n",
            "Epoch 800: Training loss= 0.488917 Val loss= 0.503124 Training acc= 0.777075 Val acc= 0.776325\n",
            "Epoch 801: Training loss= 0.488849 Val loss= 0.503040 Training acc= 0.777090 Val acc= 0.776345\n",
            "Epoch 802: Training loss= 0.488781 Val loss= 0.502957 Training acc= 0.777115 Val acc= 0.776370\n",
            "Epoch 803: Training loss= 0.488713 Val loss= 0.502874 Training acc= 0.777135 Val acc= 0.776385\n",
            "Epoch 804: Training loss= 0.488645 Val loss= 0.502792 Training acc= 0.777160 Val acc= 0.776410\n",
            "Epoch 805: Training loss= 0.488577 Val loss= 0.502709 Training acc= 0.777170 Val acc= 0.776420\n",
            "Epoch 806: Training loss= 0.488510 Val loss= 0.502627 Training acc= 0.777205 Val acc= 0.776445\n",
            "Epoch 807: Training loss= 0.488442 Val loss= 0.502544 Training acc= 0.777210 Val acc= 0.776475\n",
            "Epoch 808: Training loss= 0.488375 Val loss= 0.502462 Training acc= 0.777260 Val acc= 0.776485\n",
            "Epoch 809: Training loss= 0.488308 Val loss= 0.502380 Training acc= 0.777280 Val acc= 0.776490\n",
            "Epoch 810: Training loss= 0.488241 Val loss= 0.502298 Training acc= 0.777290 Val acc= 0.776490\n",
            "Epoch 811: Training loss= 0.488174 Val loss= 0.502217 Training acc= 0.777295 Val acc= 0.776490\n",
            "Epoch 812: Training loss= 0.488107 Val loss= 0.502135 Training acc= 0.777285 Val acc= 0.776515\n",
            "Epoch 813: Training loss= 0.488040 Val loss= 0.502054 Training acc= 0.777300 Val acc= 0.776510\n",
            "Epoch 814: Training loss= 0.487974 Val loss= 0.501972 Training acc= 0.777305 Val acc= 0.776550\n",
            "Epoch 815: Training loss= 0.487907 Val loss= 0.501891 Training acc= 0.777325 Val acc= 0.776570\n",
            "Epoch 816: Training loss= 0.487841 Val loss= 0.501810 Training acc= 0.777335 Val acc= 0.776595\n",
            "Epoch 817: Training loss= 0.487775 Val loss= 0.501729 Training acc= 0.777370 Val acc= 0.776620\n",
            "Epoch 818: Training loss= 0.487709 Val loss= 0.501649 Training acc= 0.777395 Val acc= 0.776635\n",
            "Epoch 819: Training loss= 0.487643 Val loss= 0.501568 Training acc= 0.777430 Val acc= 0.776665\n",
            "Epoch 820: Training loss= 0.487577 Val loss= 0.501487 Training acc= 0.777460 Val acc= 0.776685\n",
            "Epoch 821: Training loss= 0.487511 Val loss= 0.501407 Training acc= 0.777475 Val acc= 0.776680\n",
            "Epoch 822: Training loss= 0.487445 Val loss= 0.501327 Training acc= 0.777500 Val acc= 0.776680\n",
            "Epoch 823: Training loss= 0.487380 Val loss= 0.501247 Training acc= 0.777525 Val acc= 0.776690\n",
            "Epoch 824: Training loss= 0.487315 Val loss= 0.501167 Training acc= 0.777540 Val acc= 0.776710\n",
            "Epoch 825: Training loss= 0.487249 Val loss= 0.501087 Training acc= 0.777565 Val acc= 0.776740\n",
            "Epoch 826: Training loss= 0.487184 Val loss= 0.501007 Training acc= 0.777595 Val acc= 0.776755\n",
            "Epoch 827: Training loss= 0.487119 Val loss= 0.500928 Training acc= 0.777615 Val acc= 0.776735\n",
            "Epoch 828: Training loss= 0.487054 Val loss= 0.500848 Training acc= 0.777595 Val acc= 0.776760\n",
            "Epoch 829: Training loss= 0.486989 Val loss= 0.500769 Training acc= 0.777610 Val acc= 0.776790\n",
            "Epoch 830: Training loss= 0.486924 Val loss= 0.500690 Training acc= 0.777635 Val acc= 0.776825\n",
            "Epoch 831: Training loss= 0.486860 Val loss= 0.500611 Training acc= 0.777685 Val acc= 0.776830\n",
            "Epoch 832: Training loss= 0.486795 Val loss= 0.500532 Training acc= 0.777690 Val acc= 0.776835\n",
            "Epoch 833: Training loss= 0.486731 Val loss= 0.500453 Training acc= 0.777710 Val acc= 0.776830\n",
            "Epoch 834: Training loss= 0.486666 Val loss= 0.500375 Training acc= 0.777695 Val acc= 0.776840\n",
            "Epoch 835: Training loss= 0.486602 Val loss= 0.500296 Training acc= 0.777720 Val acc= 0.776855\n",
            "Epoch 836: Training loss= 0.486538 Val loss= 0.500218 Training acc= 0.777740 Val acc= 0.776870\n",
            "Epoch 837: Training loss= 0.486474 Val loss= 0.500139 Training acc= 0.777730 Val acc= 0.776850\n",
            "Epoch 838: Training loss= 0.486410 Val loss= 0.500061 Training acc= 0.777730 Val acc= 0.776855\n",
            "Epoch 839: Training loss= 0.486346 Val loss= 0.499983 Training acc= 0.777765 Val acc= 0.776850\n",
            "Epoch 840: Training loss= 0.486283 Val loss= 0.499906 Training acc= 0.777775 Val acc= 0.776880\n",
            "Epoch 841: Training loss= 0.486219 Val loss= 0.499828 Training acc= 0.777790 Val acc= 0.776905\n",
            "Epoch 842: Training loss= 0.486156 Val loss= 0.499750 Training acc= 0.777820 Val acc= 0.776935\n",
            "Epoch 843: Training loss= 0.486092 Val loss= 0.499673 Training acc= 0.777835 Val acc= 0.776965\n",
            "Epoch 844: Training loss= 0.486029 Val loss= 0.499596 Training acc= 0.777850 Val acc= 0.777000\n",
            "Epoch 845: Training loss= 0.485966 Val loss= 0.499519 Training acc= 0.777890 Val acc= 0.777005\n",
            "Epoch 846: Training loss= 0.485903 Val loss= 0.499442 Training acc= 0.777900 Val acc= 0.777035\n",
            "Epoch 847: Training loss= 0.485840 Val loss= 0.499365 Training acc= 0.777940 Val acc= 0.777035\n",
            "Epoch 848: Training loss= 0.485777 Val loss= 0.499288 Training acc= 0.777935 Val acc= 0.777085\n",
            "Epoch 849: Training loss= 0.485714 Val loss= 0.499212 Training acc= 0.777980 Val acc= 0.777090\n",
            "Epoch 850: Training loss= 0.485651 Val loss= 0.499135 Training acc= 0.777970 Val acc= 0.777115\n",
            "Epoch 851: Training loss= 0.485589 Val loss= 0.499059 Training acc= 0.777990 Val acc= 0.777120\n",
            "Epoch 852: Training loss= 0.485526 Val loss= 0.498983 Training acc= 0.778010 Val acc= 0.777150\n",
            "Epoch 853: Training loss= 0.485464 Val loss= 0.498906 Training acc= 0.778020 Val acc= 0.777115\n",
            "Epoch 854: Training loss= 0.485401 Val loss= 0.498831 Training acc= 0.778015 Val acc= 0.777120\n",
            "Epoch 855: Training loss= 0.485339 Val loss= 0.498755 Training acc= 0.778015 Val acc= 0.777125\n",
            "Epoch 856: Training loss= 0.485277 Val loss= 0.498679 Training acc= 0.778020 Val acc= 0.777150\n",
            "Epoch 857: Training loss= 0.485215 Val loss= 0.498603 Training acc= 0.778020 Val acc= 0.777155\n",
            "Epoch 858: Training loss= 0.485153 Val loss= 0.498528 Training acc= 0.778025 Val acc= 0.777165\n",
            "Epoch 859: Training loss= 0.485091 Val loss= 0.498452 Training acc= 0.778040 Val acc= 0.777180\n",
            "Epoch 860: Training loss= 0.485029 Val loss= 0.498377 Training acc= 0.778055 Val acc= 0.777225\n",
            "Epoch 861: Training loss= 0.484968 Val loss= 0.498302 Training acc= 0.778100 Val acc= 0.777235\n",
            "Epoch 862: Training loss= 0.484906 Val loss= 0.498227 Training acc= 0.778120 Val acc= 0.777265\n",
            "Epoch 863: Training loss= 0.484845 Val loss= 0.498152 Training acc= 0.778145 Val acc= 0.777295\n",
            "Epoch 864: Training loss= 0.484783 Val loss= 0.498077 Training acc= 0.778140 Val acc= 0.777315\n",
            "Epoch 865: Training loss= 0.484722 Val loss= 0.498003 Training acc= 0.778170 Val acc= 0.777325\n",
            "Epoch 866: Training loss= 0.484661 Val loss= 0.497928 Training acc= 0.778175 Val acc= 0.777340\n",
            "Epoch 867: Training loss= 0.484600 Val loss= 0.497853 Training acc= 0.778180 Val acc= 0.777355\n",
            "Epoch 868: Training loss= 0.484539 Val loss= 0.497779 Training acc= 0.778205 Val acc= 0.777365\n",
            "Epoch 869: Training loss= 0.484478 Val loss= 0.497705 Training acc= 0.778225 Val acc= 0.777360\n",
            "Epoch 870: Training loss= 0.484417 Val loss= 0.497631 Training acc= 0.778220 Val acc= 0.777355\n",
            "Epoch 871: Training loss= 0.484356 Val loss= 0.497556 Training acc= 0.778225 Val acc= 0.777385\n",
            "Epoch 872: Training loss= 0.484295 Val loss= 0.497482 Training acc= 0.778245 Val acc= 0.777415\n",
            "Epoch 873: Training loss= 0.484235 Val loss= 0.497409 Training acc= 0.778245 Val acc= 0.777445\n",
            "Epoch 874: Training loss= 0.484174 Val loss= 0.497335 Training acc= 0.778280 Val acc= 0.777480\n",
            "Epoch 875: Training loss= 0.484114 Val loss= 0.497261 Training acc= 0.778305 Val acc= 0.777475\n",
            "Epoch 876: Training loss= 0.484053 Val loss= 0.497188 Training acc= 0.778295 Val acc= 0.777475\n",
            "Epoch 877: Training loss= 0.483993 Val loss= 0.497114 Training acc= 0.778320 Val acc= 0.777530\n",
            "Epoch 878: Training loss= 0.483933 Val loss= 0.497041 Training acc= 0.778350 Val acc= 0.777540\n",
            "Epoch 879: Training loss= 0.483873 Val loss= 0.496967 Training acc= 0.778375 Val acc= 0.777540\n",
            "Epoch 880: Training loss= 0.483813 Val loss= 0.496894 Training acc= 0.778360 Val acc= 0.777550\n",
            "Epoch 881: Training loss= 0.483753 Val loss= 0.496821 Training acc= 0.778365 Val acc= 0.777525\n",
            "Epoch 882: Training loss= 0.483693 Val loss= 0.496748 Training acc= 0.778355 Val acc= 0.777540\n",
            "Epoch 883: Training loss= 0.483633 Val loss= 0.496675 Training acc= 0.778365 Val acc= 0.777590\n",
            "Epoch 884: Training loss= 0.483574 Val loss= 0.496603 Training acc= 0.778400 Val acc= 0.777590\n",
            "Epoch 885: Training loss= 0.483514 Val loss= 0.496530 Training acc= 0.778415 Val acc= 0.777610\n",
            "Epoch 886: Training loss= 0.483455 Val loss= 0.496457 Training acc= 0.778430 Val acc= 0.777615\n",
            "Epoch 887: Training loss= 0.483395 Val loss= 0.496385 Training acc= 0.778430 Val acc= 0.777620\n",
            "Epoch 888: Training loss= 0.483336 Val loss= 0.496312 Training acc= 0.778435 Val acc= 0.777585\n",
            "Epoch 889: Training loss= 0.483277 Val loss= 0.496240 Training acc= 0.778405 Val acc= 0.777625\n",
            "Epoch 890: Training loss= 0.483217 Val loss= 0.496168 Training acc= 0.778445 Val acc= 0.777655\n",
            "Epoch 891: Training loss= 0.483158 Val loss= 0.496096 Training acc= 0.778485 Val acc= 0.777660\n",
            "Epoch 892: Training loss= 0.483099 Val loss= 0.496024 Training acc= 0.778500 Val acc= 0.777680\n",
            "Epoch 893: Training loss= 0.483040 Val loss= 0.495952 Training acc= 0.778510 Val acc= 0.777700\n",
            "Epoch 894: Training loss= 0.482981 Val loss= 0.495880 Training acc= 0.778530 Val acc= 0.777735\n",
            "Epoch 895: Training loss= 0.482923 Val loss= 0.495808 Training acc= 0.778565 Val acc= 0.777760\n",
            "Epoch 896: Training loss= 0.482864 Val loss= 0.495737 Training acc= 0.778590 Val acc= 0.777775\n",
            "Epoch 897: Training loss= 0.482805 Val loss= 0.495665 Training acc= 0.778595 Val acc= 0.777745\n",
            "Epoch 898: Training loss= 0.482747 Val loss= 0.495594 Training acc= 0.778570 Val acc= 0.777765\n",
            "Epoch 899: Training loss= 0.482688 Val loss= 0.495522 Training acc= 0.778570 Val acc= 0.777805\n",
            "Epoch 900: Training loss= 0.482630 Val loss= 0.495451 Training acc= 0.778575 Val acc= 0.777810\n",
            "Epoch 901: Training loss= 0.482572 Val loss= 0.495380 Training acc= 0.778585 Val acc= 0.777810\n",
            "Epoch 902: Training loss= 0.482513 Val loss= 0.495309 Training acc= 0.778570 Val acc= 0.777820\n",
            "Epoch 903: Training loss= 0.482455 Val loss= 0.495238 Training acc= 0.778590 Val acc= 0.777805\n",
            "Epoch 904: Training loss= 0.482397 Val loss= 0.495167 Training acc= 0.778595 Val acc= 0.777800\n",
            "Epoch 905: Training loss= 0.482339 Val loss= 0.495096 Training acc= 0.778595 Val acc= 0.777795\n",
            "Epoch 906: Training loss= 0.482281 Val loss= 0.495026 Training acc= 0.778600 Val acc= 0.777800\n",
            "Epoch 907: Training loss= 0.482224 Val loss= 0.494955 Training acc= 0.778600 Val acc= 0.777845\n",
            "Epoch 908: Training loss= 0.482166 Val loss= 0.494885 Training acc= 0.778635 Val acc= 0.777835\n",
            "Epoch 909: Training loss= 0.482108 Val loss= 0.494814 Training acc= 0.778660 Val acc= 0.777855\n",
            "Epoch 910: Training loss= 0.482051 Val loss= 0.494744 Training acc= 0.778685 Val acc= 0.777870\n",
            "Epoch 911: Training loss= 0.481993 Val loss= 0.494674 Training acc= 0.778690 Val acc= 0.777920\n",
            "Epoch 912: Training loss= 0.481936 Val loss= 0.494604 Training acc= 0.778730 Val acc= 0.777940\n",
            "Epoch 913: Training loss= 0.481879 Val loss= 0.494534 Training acc= 0.778745 Val acc= 0.777940\n",
            "Epoch 914: Training loss= 0.481822 Val loss= 0.494464 Training acc= 0.778725 Val acc= 0.777965\n",
            "Epoch 915: Training loss= 0.481765 Val loss= 0.494395 Training acc= 0.778745 Val acc= 0.777995\n",
            "Epoch 916: Training loss= 0.481708 Val loss= 0.494326 Training acc= 0.778765 Val acc= 0.777990\n",
            "Epoch 917: Training loss= 0.481651 Val loss= 0.494256 Training acc= 0.778745 Val acc= 0.778020\n",
            "Epoch 918: Training loss= 0.481595 Val loss= 0.494187 Training acc= 0.778770 Val acc= 0.778045\n",
            "Epoch 919: Training loss= 0.481538 Val loss= 0.494119 Training acc= 0.778780 Val acc= 0.778050\n",
            "Epoch 920: Training loss= 0.481482 Val loss= 0.494050 Training acc= 0.778795 Val acc= 0.778050\n",
            "Epoch 921: Training loss= 0.481426 Val loss= 0.493982 Training acc= 0.778790 Val acc= 0.778065\n",
            "Epoch 922: Training loss= 0.481370 Val loss= 0.493914 Training acc= 0.778820 Val acc= 0.778075\n",
            "Epoch 923: Training loss= 0.481314 Val loss= 0.493846 Training acc= 0.778835 Val acc= 0.778075\n",
            "Epoch 924: Training loss= 0.481259 Val loss= 0.493778 Training acc= 0.778830 Val acc= 0.778085\n",
            "Epoch 925: Training loss= 0.481204 Val loss= 0.493711 Training acc= 0.778855 Val acc= 0.778070\n",
            "Epoch 926: Training loss= 0.481149 Val loss= 0.493644 Training acc= 0.778855 Val acc= 0.778060\n",
            "Epoch 927: Training loss= 0.481094 Val loss= 0.493577 Training acc= 0.778835 Val acc= 0.778085\n",
            "Epoch 928: Training loss= 0.481039 Val loss= 0.493510 Training acc= 0.778850 Val acc= 0.778090\n",
            "Epoch 929: Training loss= 0.480984 Val loss= 0.493444 Training acc= 0.778885 Val acc= 0.778110\n",
            "Epoch 930: Training loss= 0.480930 Val loss= 0.493378 Training acc= 0.778895 Val acc= 0.778145\n",
            "Epoch 931: Training loss= 0.480876 Val loss= 0.493312 Training acc= 0.778945 Val acc= 0.778130\n",
            "Epoch 932: Training loss= 0.480821 Val loss= 0.493246 Training acc= 0.778920 Val acc= 0.778130\n",
            "Epoch 933: Training loss= 0.480767 Val loss= 0.493180 Training acc= 0.778905 Val acc= 0.778130\n",
            "Epoch 934: Training loss= 0.480714 Val loss= 0.493114 Training acc= 0.778930 Val acc= 0.778150\n",
            "Epoch 935: Training loss= 0.480660 Val loss= 0.493049 Training acc= 0.778930 Val acc= 0.778180\n",
            "Epoch 936: Training loss= 0.480606 Val loss= 0.492984 Training acc= 0.778960 Val acc= 0.778195\n",
            "Epoch 937: Training loss= 0.480553 Val loss= 0.492918 Training acc= 0.778970 Val acc= 0.778230\n",
            "Epoch 938: Training loss= 0.480499 Val loss= 0.492853 Training acc= 0.779000 Val acc= 0.778240\n",
            "Epoch 939: Training loss= 0.480446 Val loss= 0.492789 Training acc= 0.778995 Val acc= 0.778265\n",
            "Epoch 940: Training loss= 0.480393 Val loss= 0.492724 Training acc= 0.778990 Val acc= 0.778340\n",
            "Epoch 941: Training loss= 0.480340 Val loss= 0.492659 Training acc= 0.779055 Val acc= 0.778320\n",
            "Epoch 942: Training loss= 0.480287 Val loss= 0.492595 Training acc= 0.779040 Val acc= 0.778305\n",
            "Epoch 943: Training loss= 0.480235 Val loss= 0.492531 Training acc= 0.779030 Val acc= 0.778330\n",
            "Epoch 944: Training loss= 0.480182 Val loss= 0.492467 Training acc= 0.779055 Val acc= 0.778335\n",
            "Epoch 945: Training loss= 0.480130 Val loss= 0.492403 Training acc= 0.779040 Val acc= 0.778325\n",
            "Epoch 946: Training loss= 0.480077 Val loss= 0.492339 Training acc= 0.779055 Val acc= 0.778345\n",
            "Epoch 947: Training loss= 0.480025 Val loss= 0.492276 Training acc= 0.779080 Val acc= 0.778350\n",
            "Epoch 948: Training loss= 0.479973 Val loss= 0.492212 Training acc= 0.779070 Val acc= 0.778365\n",
            "Epoch 949: Training loss= 0.479921 Val loss= 0.492149 Training acc= 0.779085 Val acc= 0.778380\n",
            "Epoch 950: Training loss= 0.479869 Val loss= 0.492086 Training acc= 0.779080 Val acc= 0.778415\n",
            "Epoch 951: Training loss= 0.479818 Val loss= 0.492023 Training acc= 0.779125 Val acc= 0.778395\n",
            "Epoch 952: Training loss= 0.479766 Val loss= 0.491961 Training acc= 0.779130 Val acc= 0.778395\n",
            "Epoch 953: Training loss= 0.479715 Val loss= 0.491898 Training acc= 0.779135 Val acc= 0.778385\n",
            "Epoch 954: Training loss= 0.479664 Val loss= 0.491836 Training acc= 0.779125 Val acc= 0.778395\n",
            "Epoch 955: Training loss= 0.479613 Val loss= 0.491774 Training acc= 0.779135 Val acc= 0.778420\n",
            "Epoch 956: Training loss= 0.479562 Val loss= 0.491712 Training acc= 0.779160 Val acc= 0.778455\n",
            "Epoch 957: Training loss= 0.479511 Val loss= 0.491650 Training acc= 0.779205 Val acc= 0.778455\n",
            "Epoch 958: Training loss= 0.479460 Val loss= 0.491588 Training acc= 0.779220 Val acc= 0.778490\n",
            "Epoch 959: Training loss= 0.479410 Val loss= 0.491526 Training acc= 0.779260 Val acc= 0.778535\n",
            "Epoch 960: Training loss= 0.479359 Val loss= 0.491465 Training acc= 0.779295 Val acc= 0.778565\n",
            "Epoch 961: Training loss= 0.479309 Val loss= 0.491403 Training acc= 0.779305 Val acc= 0.778620\n",
            "Epoch 962: Training loss= 0.479258 Val loss= 0.491342 Training acc= 0.779350 Val acc= 0.778585\n",
            "Epoch 963: Training loss= 0.479208 Val loss= 0.491281 Training acc= 0.779330 Val acc= 0.778600\n",
            "Epoch 964: Training loss= 0.479158 Val loss= 0.491220 Training acc= 0.779345 Val acc= 0.778600\n",
            "Epoch 965: Training loss= 0.479108 Val loss= 0.491159 Training acc= 0.779330 Val acc= 0.778610\n",
            "Epoch 966: Training loss= 0.479058 Val loss= 0.491098 Training acc= 0.779340 Val acc= 0.778605\n",
            "Epoch 967: Training loss= 0.479008 Val loss= 0.491037 Training acc= 0.779340 Val acc= 0.778630\n",
            "Epoch 968: Training loss= 0.478958 Val loss= 0.490976 Training acc= 0.779355 Val acc= 0.778615\n",
            "Epoch 969: Training loss= 0.478908 Val loss= 0.490915 Training acc= 0.779335 Val acc= 0.778620\n",
            "Epoch 970: Training loss= 0.478859 Val loss= 0.490855 Training acc= 0.779345 Val acc= 0.778610\n",
            "Epoch 971: Training loss= 0.478809 Val loss= 0.490795 Training acc= 0.779335 Val acc= 0.778605\n",
            "Epoch 972: Training loss= 0.478760 Val loss= 0.490734 Training acc= 0.779325 Val acc= 0.778620\n",
            "Epoch 973: Training loss= 0.478710 Val loss= 0.490674 Training acc= 0.779335 Val acc= 0.778650\n",
            "Epoch 974: Training loss= 0.478661 Val loss= 0.490614 Training acc= 0.779375 Val acc= 0.778685\n",
            "Epoch 975: Training loss= 0.478612 Val loss= 0.490554 Training acc= 0.779395 Val acc= 0.778710\n",
            "Epoch 976: Training loss= 0.478563 Val loss= 0.490494 Training acc= 0.779440 Val acc= 0.778735\n",
            "Epoch 977: Training loss= 0.478514 Val loss= 0.490434 Training acc= 0.779470 Val acc= 0.778730\n",
            "Epoch 978: Training loss= 0.478465 Val loss= 0.490374 Training acc= 0.779465 Val acc= 0.778735\n",
            "Epoch 979: Training loss= 0.478416 Val loss= 0.490314 Training acc= 0.779460 Val acc= 0.778775\n",
            "Epoch 980: Training loss= 0.478367 Val loss= 0.490254 Training acc= 0.779485 Val acc= 0.778805\n",
            "Epoch 981: Training loss= 0.478318 Val loss= 0.490195 Training acc= 0.779515 Val acc= 0.778815\n",
            "Epoch 982: Training loss= 0.478270 Val loss= 0.490135 Training acc= 0.779540 Val acc= 0.778845\n",
            "Epoch 983: Training loss= 0.478221 Val loss= 0.490076 Training acc= 0.779560 Val acc= 0.778890\n",
            "Epoch 984: Training loss= 0.478172 Val loss= 0.490016 Training acc= 0.779565 Val acc= 0.778900\n",
            "Epoch 985: Training loss= 0.478124 Val loss= 0.489957 Training acc= 0.779595 Val acc= 0.778895\n",
            "Epoch 986: Training loss= 0.478076 Val loss= 0.489898 Training acc= 0.779600 Val acc= 0.778900\n",
            "Epoch 987: Training loss= 0.478027 Val loss= 0.489839 Training acc= 0.779620 Val acc= 0.778880\n",
            "Epoch 988: Training loss= 0.477979 Val loss= 0.489780 Training acc= 0.779605 Val acc= 0.778910\n",
            "Epoch 989: Training loss= 0.477931 Val loss= 0.489721 Training acc= 0.779630 Val acc= 0.778905\n",
            "Epoch 990: Training loss= 0.477883 Val loss= 0.489662 Training acc= 0.779640 Val acc= 0.778925\n",
            "Epoch 991: Training loss= 0.477835 Val loss= 0.489603 Training acc= 0.779655 Val acc= 0.778955\n",
            "Epoch 992: Training loss= 0.477787 Val loss= 0.489544 Training acc= 0.779675 Val acc= 0.778965\n",
            "Epoch 993: Training loss= 0.477739 Val loss= 0.489485 Training acc= 0.779700 Val acc= 0.778970\n",
            "Epoch 994: Training loss= 0.477691 Val loss= 0.489427 Training acc= 0.779695 Val acc= 0.778990\n",
            "Epoch 995: Training loss= 0.477643 Val loss= 0.489368 Training acc= 0.779720 Val acc= 0.779035\n",
            "Epoch 996: Training loss= 0.477596 Val loss= 0.489310 Training acc= 0.779760 Val acc= 0.779075\n",
            "Epoch 997: Training loss= 0.477548 Val loss= 0.489251 Training acc= 0.779780 Val acc= 0.779090\n",
            "Epoch 998: Training loss= 0.477501 Val loss= 0.489193 Training acc= 0.779795 Val acc= 0.779100\n",
            "Epoch 999: Training loss= 0.477453 Val loss= 0.489134 Training acc= 0.779800 Val acc= 0.779105\n",
            "Best model info *** :\n",
            "Epoch 999: Training loss= 0.477453 Val loss= 0.489134 Training acc= 0.779800 Val acc= 0.779105\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-1.03792565, -0.05472914,  0.66465482, -0.19791621,  0.3923722 ,\n",
              "         0.7053156 ,  0.35322517,  0.02941614, -0.59815567,  0.33135963,\n",
              "        -0.07821835, -0.01583748,  0.11156517, -0.18513925,  0.3970438 ,\n",
              "        -0.24436808, -0.14798586,  0.67561491, -0.15047611, -0.12242078,\n",
              "         0.81311209, -0.00981819, -0.07846336, -0.01107987,  0.31064563,\n",
              "         0.20887154,  0.34209353,  0.61501812, -0.02046568, -0.21476263,\n",
              "        -0.04173014,  0.49237963,  0.12382912, -0.0598286 ,  0.39596944,\n",
              "         0.49369166,  0.1980445 ,  0.12017558, -0.27215413,  0.29685253,\n",
              "         0.31531868, -0.04944508, -0.19139139,  0.01560707,  0.45117695,\n",
              "        -0.33953084,  0.26763053,  0.5114505 , -0.09394895, -0.00361067,\n",
              "         0.72407263, -0.14752789,  0.49490723, -0.38382483,  0.66536356,\n",
              "        -0.33385185, -0.23910693,  0.474155  ,  0.09797703,  0.12435404,\n",
              "         0.0307833 ,  0.30006155,  0.42443833,  0.39090228,  0.83815317,\n",
              "        -0.25036862, -0.03877373,  0.66798801, -0.65322647,  0.21766737,\n",
              "         0.04850734,  0.41972663, -0.51982566, -0.22221493,  0.0771123 ,\n",
              "         0.18897896, -0.01555873, -0.30022223,  0.24325222,  0.28314298,\n",
              "         0.5410081 ,  0.17055331,  0.48642684, -0.24296619,  0.59036426,\n",
              "        -0.46645602, -0.08556207,  0.40890606, -0.13599286,  0.18769469,\n",
              "        -0.35162821,  0.04831307, -0.38794131,  0.64452144,  0.80892888,\n",
              "        -0.09131019,  0.45948338,  0.04428017, -0.02987172,  0.07995079,\n",
              "        -0.30235195,  0.08823752,  0.38904737, -0.306114  ,  0.40299317,\n",
              "         0.40430223, -0.1583997 ,  0.0538918 ,  0.39511956, -0.15188045,\n",
              "         0.20424809,  0.15534931, -0.2435589 ,  0.23660479,  0.02947541,\n",
              "         0.27423264,  0.43590673,  0.54849249,  0.21209992,  0.0088846 ,\n",
              "        -0.06625994,  0.18950135, -0.09259182,  0.23126378,  0.85909122,\n",
              "         0.10409144,  0.11667795,  0.28278061,  0.04345589,  0.92696266,\n",
              "         0.26840893,  0.38259882,  0.5377154 ,  0.28880568,  0.31877119,\n",
              "         0.35185242,  0.27119693, -0.09724229, -0.14215007, -0.41442649,\n",
              "         0.51501363, -0.38629729,  0.09697998, -0.15361054, -0.28994808,\n",
              "         0.37083772, -0.38589913,  0.72578259,  0.47517778, -0.23849002,\n",
              "        -0.35904258, -0.33180774, -0.14226834, -0.26000247,  0.01913462,\n",
              "        -0.0085438 ,  0.74051129,  0.07551364, -0.08859514,  0.27993032,\n",
              "        -0.13350422, -0.24161788, -0.43096136,  0.55259337, -0.24096408,\n",
              "        -0.04615312, -0.31458886, -0.35942793, -0.45766267,  0.14214695,\n",
              "         0.00963476, -0.00104753,  0.36722447,  0.53551164, -0.36336947,\n",
              "         0.14461309, -0.33035596, -0.29174628, -0.48288624, -0.36458594,\n",
              "         0.12123685, -0.65273412,  0.15990776, -0.33783932,  0.27301281,\n",
              "        -0.26781558,  0.37893185,  0.30495152,  0.04047517,  0.71097309,\n",
              "         0.00840224, -0.22413356, -0.012828  , -0.03134087, -0.24132428,\n",
              "        -0.39205876, -0.13964767,  0.04375182,  0.07031014,  0.28731918,\n",
              "         0.33665659,  0.2468099 , -0.48148273, -0.12972263,  0.02176266,\n",
              "        -0.09540272, -0.01279381, -0.13904474, -0.40633636,  0.32138871,\n",
              "         0.12124241, -0.61180574,  0.30842866, -0.59117857,  0.30101037,\n",
              "         0.47079765,  0.24497211, -0.11693692,  0.5536322 ,  0.55729582,\n",
              "        -0.5743534 , -0.10757242,  0.35936086,  0.27730495, -0.03128475,\n",
              "        -0.16351336,  0.25201667,  0.41455463, -0.02777731,  0.05271464,\n",
              "         0.34570632,  0.00429155, -0.55629433,  0.07510042,  0.03050838,\n",
              "         0.13824243,  0.18365989, -0.25480224,  0.18071342,  0.27388404,\n",
              "        -0.30287764,  0.68627505, -0.8176924 , -0.17456982,  0.34170232,\n",
              "        -0.00455923, -0.13967165, -0.03145398,  0.65661103, -0.06464458,\n",
              "         0.43168016, -0.15062362,  0.00927661, -0.0393406 ,  0.64624757,\n",
              "         0.09883575,  0.03979822,  0.0643427 , -0.03442465, -0.01412613,\n",
              "        -0.20657144, -0.00631976,  0.43678413,  0.03605102,  0.25306874,\n",
              "        -0.0105365 ,  0.20085304,  0.3694245 ,  0.11809351, -0.05377538,\n",
              "         0.29205632], dtype=float128), 0.47745307872517556)"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "_JizidFkRLMn",
        "outputId": "03ba0033-bec2-4d03-ed83-62e3e8f5c46f"
      },
      "source": [
        "####### This bunch of code is used to plot ########\n",
        "plt.plot(range(1,1000+1), train_loss1)\n",
        "plt.plot(range(1,1000+1), val_loss1)\n",
        "# plt.plot(range(1,2000+1), train_loss2)\n",
        "# plt.plot(range(1,2000+1), val_loss2)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['train lambda= 0.1','validation lambda= 0.1',], loc='upper right')\n",
        "# plt.show()\n",
        "plt.savefig(\"acc_reg_logisticGD_train_val\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl3UPEThwDSn"
      },
      "source": [
        "##### find the predictions #######\n",
        "\n",
        "(test_y, test_X, test_ids) =load_csv_data(\"test.csv\")\n",
        "test_X = prepare_test_data(test_X, mu, sigma,degree=9)\n",
        "y_pred = predict_labels(weight,test_X)\n",
        "create_csv_submission(test_ids,y_pred, \"fatima1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}